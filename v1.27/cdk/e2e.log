  I0429 12:00:59.856786      18 e2e.go:117] Starting e2e run "8fb8af36-3b1e-465f-a851-9fb2f1b1d225" on Ginkgo node 1
  Apr 29 12:00:59.896: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1682769659 - will randomize all specs

Will run 378 of 7207 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:148
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Apr 29 12:01:00.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:01:00.083: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Apr 29 12:01:00.129: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Apr 29 12:01:00.133: INFO: e2e test version: v1.27.1
  Apr 29 12:01:00.134: INFO: kube-apiserver version: v1.27.1
  Apr 29 12:01:00.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:01:00.138: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.057 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 04/29/23 12:01:00.415
  Apr 29 12:01:00.415: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename job @ 04/29/23 12:01:00.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:01:00.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:01:00.454
  STEP: Creating a suspended job @ 04/29/23 12:01:00.461
  STEP: Patching the Job @ 04/29/23 12:01:00.47
  STEP: Watching for Job to be patched @ 04/29/23 12:01:00.499
  Apr 29 12:01:00.503: INFO: Event ADDED observed for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking:]
  Apr 29 12:01:00.503: INFO: Event MODIFIED found for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking:]
  STEP: Updating the job @ 04/29/23 12:01:00.503
  STEP: Watching for Job to be updated @ 04/29/23 12:01:00.525
  Apr 29 12:01:00.529: INFO: Event MODIFIED found for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 29 12:01:00.529: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 04/29/23 12:01:00.529
  Apr 29 12:01:00.534: INFO: Job: e2e-ckt4k as labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k]
  STEP: Waiting for job to complete @ 04/29/23 12:01:00.534
  STEP: Delete a job collection with a labelselector @ 04/29/23 12:01:12.539
  STEP: Watching for Job to be deleted @ 04/29/23 12:01:12.549
  Apr 29 12:01:12.552: INFO: Event MODIFIED observed for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 29 12:01:12.552: INFO: Event MODIFIED observed for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 29 12:01:12.552: INFO: Event MODIFIED observed for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 29 12:01:12.552: INFO: Event MODIFIED observed for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 29 12:01:12.552: INFO: Event MODIFIED observed for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 29 12:01:12.553: INFO: Event MODIFIED observed for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 29 12:01:12.553: INFO: Event MODIFIED observed for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 29 12:01:12.553: INFO: Event DELETED found for Job e2e-ckt4k in namespace job-7713 with labels: map[e2e-ckt4k:patched e2e-job-label:e2e-ckt4k] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  STEP: Relist jobs to confirm deletion @ 04/29/23 12:01:12.553
  Apr 29 12:01:12.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7713" for this suite. @ 04/29/23 12:01:12.571
• [12.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 04/29/23 12:01:12.583
  Apr 29 12:01:12.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename podtemplate @ 04/29/23 12:01:12.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:01:12.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:01:12.603
  STEP: Create set of pod templates @ 04/29/23 12:01:12.606
  Apr 29 12:01:12.612: INFO: created test-podtemplate-1
  Apr 29 12:01:12.617: INFO: created test-podtemplate-2
  Apr 29 12:01:12.622: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 04/29/23 12:01:12.622
  STEP: delete collection of pod templates @ 04/29/23 12:01:12.626
  Apr 29 12:01:12.626: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 04/29/23 12:01:12.642
  Apr 29 12:01:12.642: INFO: requesting list of pod templates to confirm quantity
  Apr 29 12:01:12.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8074" for this suite. @ 04/29/23 12:01:12.65
• [0.074 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:80
  STEP: Creating a kubernetes client @ 04/29/23 12:01:12.657
  Apr 29 12:01:12.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename subpath @ 04/29/23 12:01:12.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:01:12.677
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:01:12.682
  STEP: Setting up data @ 04/29/23 12:01:12.685
  STEP: Creating pod pod-subpath-test-configmap-rkln @ 04/29/23 12:01:12.696
  STEP: Creating a pod to test atomic-volume-subpath @ 04/29/23 12:01:12.696
  STEP: Saw pod success @ 04/29/23 12:01:38.775
  Apr 29 12:01:38.778: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-subpath-test-configmap-rkln container test-container-subpath-configmap-rkln: <nil>
  STEP: delete the pod @ 04/29/23 12:01:38.797
  STEP: Deleting pod pod-subpath-test-configmap-rkln @ 04/29/23 12:01:38.813
  Apr 29 12:01:38.813: INFO: Deleting pod "pod-subpath-test-configmap-rkln" in namespace "subpath-6519"
  Apr 29 12:01:38.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6519" for this suite. @ 04/29/23 12:01:38.821
• [26.170 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 04/29/23 12:01:38.828
  Apr 29 12:01:38.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/29/23 12:01:38.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:01:38.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:01:38.848
  Apr 29 12:01:38.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:01:45.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2491" for this suite. @ 04/29/23 12:01:45.075
• [6.255 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:92
  STEP: Creating a kubernetes client @ 04/29/23 12:01:45.083
  Apr 29 12:01:45.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename aggregator @ 04/29/23 12:01:45.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:01:45.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:01:45.108
  Apr 29 12:01:45.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Registering the sample API server. @ 04/29/23 12:01:45.112
  Apr 29 12:01:45.472: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Apr 29 12:01:45.499: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
  Apr 29 12:01:47.552: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:01:49.556: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:01:51.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:01:53.558: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:01:55.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:01:57.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:01:59.558: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:02:01.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:02:03.558: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:02:05.556: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:02:07.556: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 1, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:02:09.675: INFO: Waited 112.532386ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 04/29/23 12:02:09.708
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 04/29/23 12:02:09.712
  STEP: List APIServices @ 04/29/23 12:02:09.72
  Apr 29 12:02:09.725: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 04/29/23 12:02:09.725
  Apr 29 12:02:09.740: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 04/29/23 12:02:09.74
  Apr 29 12:02:09.749: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2023, time.April, 29, 12, 2, 9, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 04/29/23 12:02:09.749
  Apr 29 12:02:09.753: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2023-04-29 12:02:09 +0000 UTC Passed all checks passed}
  Apr 29 12:02:09.753: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 29 12:02:09.753: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 04/29/23 12:02:09.753
  Apr 29 12:02:09.766: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-1441574049" @ 04/29/23 12:02:09.766
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 04/29/23 12:02:09.785
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 04/29/23 12:02:09.791
  STEP: Patch APIService Status @ 04/29/23 12:02:09.795
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 04/29/23 12:02:09.804
  Apr 29 12:02:09.807: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2023-04-29 12:02:09 +0000 UTC Passed all checks passed}
  Apr 29 12:02:09.807: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 29 12:02:09.807: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Apr 29 12:02:09.807: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 04/29/23 12:02:09.807
  STEP: Confirm that the generated APIService has been deleted @ 04/29/23 12:02:09.813
  Apr 29 12:02:09.813: INFO: Requesting list of APIServices to confirm quantity
  Apr 29 12:02:09.818: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Apr 29 12:02:09.818: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Apr 29 12:02:09.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-9342" for this suite. @ 04/29/23 12:02:09.941
• [24.865 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 04/29/23 12:02:09.948
  Apr 29 12:02:09.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:02:09.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:02:09.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:02:09.975
  STEP: Creating projection with secret that has name projected-secret-test-map-8b9f980d-ab8d-4fe2-815e-a964ac19f24a @ 04/29/23 12:02:09.978
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:02:09.983
  STEP: Saw pod success @ 04/29/23 12:02:14.008
  Apr 29 12:02:14.012: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-secrets-bbd37f9c-cada-4210-8cbe-e30b61218e43 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:02:14.019
  Apr 29 12:02:14.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1198" for this suite. @ 04/29/23 12:02:14.039
• [4.098 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 04/29/23 12:02:14.046
  Apr 29 12:02:14.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:02:14.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:02:14.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:02:14.066
  STEP: Creating configMap with name configmap-test-upd-bf9e9e93-a717-4405-8c56-d865ff68b719 @ 04/29/23 12:02:14.073
  STEP: Creating the pod @ 04/29/23 12:02:14.078
  STEP: Updating configmap configmap-test-upd-bf9e9e93-a717-4405-8c56-d865ff68b719 @ 04/29/23 12:02:16.107
  STEP: waiting to observe update in volume @ 04/29/23 12:02:16.113
  Apr 29 12:03:34.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3950" for this suite. @ 04/29/23 12:03:34.458
• [80.419 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 04/29/23 12:03:34.466
  Apr 29 12:03:34.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:03:34.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:03:34.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:03:34.486
  STEP: Creating configMap with name configmap-test-volume-map-bfb089f3-4130-40a9-b8e2-3de1f423214a @ 04/29/23 12:03:34.489
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:03:34.493
  STEP: Saw pod success @ 04/29/23 12:03:38.514
  Apr 29 12:03:38.517: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-bd749bf4-1ff7-4110-a91a-5112ce0b6892 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 12:03:38.524
  Apr 29 12:03:38.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8608" for this suite. @ 04/29/23 12:03:38.547
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 04/29/23 12:03:38.556
  Apr 29 12:03:38.556: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 12:03:38.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:03:38.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:03:38.574
  Apr 29 12:04:38.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9498" for this suite. @ 04/29/23 12:04:38.595
• [60.047 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 04/29/23 12:04:38.603
  Apr 29 12:04:38.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:04:38.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:04:38.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:04:38.627
  STEP: creating a ConfigMap @ 04/29/23 12:04:38.63
  STEP: fetching the ConfigMap @ 04/29/23 12:04:38.635
  STEP: patching the ConfigMap @ 04/29/23 12:04:38.638
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 04/29/23 12:04:38.645
  STEP: deleting the ConfigMap by collection with a label selector @ 04/29/23 12:04:38.648
  STEP: listing all ConfigMaps in test namespace @ 04/29/23 12:04:38.656
  Apr 29 12:04:38.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4784" for this suite. @ 04/29/23 12:04:38.664
• [0.068 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 04/29/23 12:04:38.672
  Apr 29 12:04:38.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:04:38.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:04:38.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:04:38.69
  STEP: Creating configMap with name configmap-test-volume-0f7380c5-d859-41a0-bb97-5f09f4e322c2 @ 04/29/23 12:04:38.694
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:04:38.698
  STEP: Saw pod success @ 04/29/23 12:04:42.718
  Apr 29 12:04:42.722: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-982706a8-14a8-4139-b25b-f8ca8c254927 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 12:04:42.728
  Apr 29 12:04:42.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3530" for this suite. @ 04/29/23 12:04:42.746
• [4.079 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 04/29/23 12:04:42.753
  Apr 29 12:04:42.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubelet-test @ 04/29/23 12:04:42.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:04:42.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:04:42.769
  Apr 29 12:04:46.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6909" for this suite. @ 04/29/23 12:04:46.797
• [4.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 04/29/23 12:04:46.806
  Apr 29 12:04:46.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/29/23 12:04:46.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:04:46.824
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:04:46.828
  STEP: create the container to handle the HTTPGet hook request. @ 04/29/23 12:04:46.834
  STEP: create the pod with lifecycle hook @ 04/29/23 12:04:48.854
  STEP: check poststart hook @ 04/29/23 12:04:52.881
  STEP: delete the pod with lifecycle hook @ 04/29/23 12:04:52.888
  Apr 29 12:04:56.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6843" for this suite. @ 04/29/23 12:04:56.912
• [10.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 04/29/23 12:04:56.919
  Apr 29 12:04:56.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename svcaccounts @ 04/29/23 12:04:56.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:04:56.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:04:56.938
  STEP: Creating ServiceAccount "e2e-sa-5mjr2"  @ 04/29/23 12:04:56.942
  Apr 29 12:04:56.947: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-5mjr2"  @ 04/29/23 12:04:56.947
  Apr 29 12:04:56.955: INFO: AutomountServiceAccountToken: true
  Apr 29 12:04:56.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5463" for this suite. @ 04/29/23 12:04:56.961
• [0.051 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 04/29/23 12:04:56.971
  Apr 29 12:04:56.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubelet-test @ 04/29/23 12:04:56.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:04:56.993
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:04:56.997
  Apr 29 12:04:59.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2031" for this suite. @ 04/29/23 12:04:59.058
• [2.094 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 04/29/23 12:04:59.065
  Apr 29 12:04:59.065: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 12:04:59.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:04:59.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:04:59.086
  STEP: Creating a ResourceQuota @ 04/29/23 12:04:59.089
  STEP: Getting a ResourceQuota @ 04/29/23 12:04:59.095
  STEP: Listing all ResourceQuotas with LabelSelector @ 04/29/23 12:04:59.099
  STEP: Patching the ResourceQuota @ 04/29/23 12:04:59.103
  STEP: Deleting a Collection of ResourceQuotas @ 04/29/23 12:04:59.111
  STEP: Verifying the deleted ResourceQuota @ 04/29/23 12:04:59.121
  Apr 29 12:04:59.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7340" for this suite. @ 04/29/23 12:04:59.128
• [0.070 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:194
  STEP: Creating a kubernetes client @ 04/29/23 12:04:59.136
  Apr 29 12:04:59.136: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename daemonsets @ 04/29/23 12:04:59.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:04:59.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:04:59.155
  Apr 29 12:04:59.177: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 04/29/23 12:04:59.185
  Apr 29 12:04:59.189: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:04:59.189: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 04/29/23 12:04:59.189
  Apr 29 12:04:59.210: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:04:59.210: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 12:05:00.215: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:00.215: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 12:05:01.215: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:01.215: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 12:05:02.219: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:02.219: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 12:05:03.214: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:03.214: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 12:05:04.216: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 29 12:05:04.216: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 04/29/23 12:05:04.221
  Apr 29 12:05:04.266: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 29 12:05:04.266: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  Apr 29 12:05:05.273: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:05.273: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 04/29/23 12:05:05.273
  Apr 29 12:05:05.292: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:05.292: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 12:05:06.299: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:06.299: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 12:05:07.297: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:07.297: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 12:05:08.297: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 29 12:05:08.297: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/29/23 12:05:08.305
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4859, will wait for the garbage collector to delete the pods @ 04/29/23 12:05:08.305
  Apr 29 12:05:08.367: INFO: Deleting DaemonSet.extensions daemon-set took: 8.282802ms
  Apr 29 12:05:08.468: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.600429ms
  Apr 29 12:05:09.972: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:05:09.973: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 29 12:05:09.978: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3704"},"items":null}

  Apr 29 12:05:09.982: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3704"},"items":null}

  Apr 29 12:05:10.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4859" for this suite. @ 04/29/23 12:05:10.013
• [10.885 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:591
  STEP: Creating a kubernetes client @ 04/29/23 12:05:10.023
  Apr 29 12:05:10.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename statefulset @ 04/29/23 12:05:10.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:05:10.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:05:10.056
  STEP: Creating service test in namespace statefulset-3091 @ 04/29/23 12:05:10.059
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 04/29/23 12:05:10.065
  STEP: Creating stateful set ss in namespace statefulset-3091 @ 04/29/23 12:05:10.069
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3091 @ 04/29/23 12:05:10.08
  Apr 29 12:05:10.085: INFO: Found 0 stateful pods, waiting for 1
  Apr 29 12:05:20.090: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 04/29/23 12:05:20.09
  Apr 29 12:05:20.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-3091 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:05:20.236: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:05:20.236: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:05:20.236: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:05:20.239: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Apr 29 12:05:30.245: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 29 12:05:30.245: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:05:30.262: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999823s
  Apr 29 12:05:31.266: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995530633s
  Apr 29 12:05:32.271: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991491618s
  Apr 29 12:05:33.275: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987035961s
  Apr 29 12:05:34.279: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982720803s
  Apr 29 12:05:35.283: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978246318s
  Apr 29 12:05:36.288: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.974543034s
  Apr 29 12:05:37.291: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97015635s
  Apr 29 12:05:38.296: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.96581347s
  Apr 29 12:05:39.301: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.984648ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3091 @ 04/29/23 12:05:40.302
  Apr 29 12:05:40.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-3091 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:05:40.427: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 29 12:05:40.427: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:05:40.427: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 29 12:05:40.431: INFO: Found 1 stateful pods, waiting for 3
  Apr 29 12:05:50.436: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 12:05:50.436: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 12:05:50.436: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 04/29/23 12:05:50.436
  STEP: Scale down will halt with unhealthy stateful pod @ 04/29/23 12:05:50.436
  Apr 29 12:05:50.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-3091 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:05:50.570: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:05:50.570: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:05:50.570: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:05:50.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-3091 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:05:50.693: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:05:50.693: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:05:50.693: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:05:50.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-3091 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:05:50.841: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:05:50.841: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:05:50.841: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:05:50.841: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:05:50.844: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
  Apr 29 12:06:00.853: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 29 12:06:00.853: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 29 12:06:00.853: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 29 12:06:00.866: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999977s
  Apr 29 12:06:01.871: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995396157s
  Apr 29 12:06:02.875: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990404783s
  Apr 29 12:06:03.880: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986438515s
  Apr 29 12:06:04.884: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981938581s
  Apr 29 12:06:05.890: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977731114s
  Apr 29 12:06:06.894: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971402941s
  Apr 29 12:06:07.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967404801s
  Apr 29 12:06:08.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962907728s
  Apr 29 12:06:09.908: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.839509ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3091 @ 04/29/23 12:06:10.908
  Apr 29 12:06:10.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-3091 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:06:11.041: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 29 12:06:11.041: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:06:11.041: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 29 12:06:11.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-3091 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:06:11.164: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 29 12:06:11.164: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:06:11.164: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 29 12:06:11.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-3091 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:06:11.285: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 29 12:06:11.285: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:06:11.285: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 29 12:06:11.285: INFO: Scaling statefulset ss to 0
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 04/29/23 12:06:21.302
  Apr 29 12:06:21.302: INFO: Deleting all statefulset in ns statefulset-3091
  Apr 29 12:06:21.306: INFO: Scaling statefulset ss to 0
  Apr 29 12:06:21.317: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:06:21.320: INFO: Deleting statefulset ss
  Apr 29 12:06:21.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3091" for this suite. @ 04/29/23 12:06:21.339
• [71.323 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 04/29/23 12:06:21.35
  Apr 29 12:06:21.351: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:06:21.351
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:06:21.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:06:21.371
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:06:21.375
  STEP: Saw pod success @ 04/29/23 12:06:25.399
  Apr 29 12:06:25.402: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-0cb4a801-e254-47f9-9f86-c570dcc5d089 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:06:25.416
  Apr 29 12:06:25.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3829" for this suite. @ 04/29/23 12:06:25.436
• [4.093 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 04/29/23 12:06:25.444
  Apr 29 12:06:25.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:06:25.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:06:25.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:06:25.461
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 04/29/23 12:06:25.465
  STEP: Saw pod success @ 04/29/23 12:06:29.486
  Apr 29 12:06:29.490: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-b3bbf63e-7b77-4c85-bda4-584144c3135a container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:06:29.496
  Apr 29 12:06:29.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5408" for this suite. @ 04/29/23 12:06:29.515
• [4.078 seconds]
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 04/29/23 12:06:29.522
  Apr 29 12:06:29.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pod-network-test @ 04/29/23 12:06:29.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:06:29.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:06:29.539
  STEP: Performing setup for networking test in namespace pod-network-test-6787 @ 04/29/23 12:06:29.543
  STEP: creating a selector @ 04/29/23 12:06:29.543
  STEP: Creating the service pods in kubernetes @ 04/29/23 12:06:29.543
  Apr 29 12:06:29.543: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/29/23 12:06:51.649
  Apr 29 12:06:53.684: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 29 12:06:53.685: INFO: Going to poll 192.168.189.136 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 29 12:06:53.688: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.189.136:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6787 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:06:53.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:06:53.688: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:06:53.688: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6787/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.189.136%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 29 12:06:53.757: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 29 12:06:53.757: INFO: Going to poll 192.168.226.21 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 29 12:06:53.761: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.226.21:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6787 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:06:53.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:06:53.761: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:06:53.761: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6787/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.226.21%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 29 12:06:53.823: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 29 12:06:53.823: INFO: Going to poll 192.168.69.198 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 29 12:06:53.827: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.69.198:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6787 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:06:53.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:06:53.828: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:06:53.828: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6787/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.69.198%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 29 12:06:53.892: INFO: Found all 1 expected endpoints: [netserver-2]
  Apr 29 12:06:53.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6787" for this suite. @ 04/29/23 12:06:53.897
• [24.381 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 04/29/23 12:06:53.904
  Apr 29 12:06:53.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename subjectreview @ 04/29/23 12:06:53.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:06:53.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:06:53.924
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-2853" @ 04/29/23 12:06:53.927
  Apr 29 12:06:53.931: INFO: saUsername: "system:serviceaccount:subjectreview-2853:e2e"
  Apr 29 12:06:53.931: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-2853"}
  Apr 29 12:06:53.931: INFO: saUID: "9bc408bb-923e-44e9-81e4-9b682684fca8"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-2853:e2e" @ 04/29/23 12:06:53.931
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-2853:e2e" @ 04/29/23 12:06:53.932
  Apr 29 12:06:53.933: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-2853:e2e" api 'list' configmaps in "subjectreview-2853" namespace @ 04/29/23 12:06:53.933
  Apr 29 12:06:53.935: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-2853:e2e" @ 04/29/23 12:06:53.935
  Apr 29 12:06:53.937: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Apr 29 12:06:53.937: INFO: LocalSubjectAccessReview has been verified
  Apr 29 12:06:53.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-2853" for this suite. @ 04/29/23 12:06:53.941
• [0.043 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 04/29/23 12:06:53.948
  Apr 29 12:06:53.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 12:06:53.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:06:53.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:06:53.965
  STEP: Creating secret with name secret-test-c4aa9455-de02-4e9c-bc5a-f7e85fd942ad @ 04/29/23 12:06:53.969
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:06:53.973
  STEP: Saw pod success @ 04/29/23 12:06:57.995
  Apr 29 12:06:57.999: INFO: Trying to get logs from node ip-172-31-82-46 pod pod-secrets-3bfdb460-6f6b-47e7-8710-e7c8af211a45 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:06:58.014
  Apr 29 12:06:58.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1643" for this suite. @ 04/29/23 12:06:58.035
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1701
  STEP: Creating a kubernetes client @ 04/29/23 12:06:58.042
  Apr 29 12:06:58.042: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 12:06:58.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:06:58.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:06:58.061
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/29/23 12:06:58.064
  Apr 29 12:06:58.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1131 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Apr 29 12:06:58.131: INFO: stderr: ""
  Apr 29 12:06:58.131: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/29/23 12:06:58.131
  Apr 29 12:06:58.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1131 delete pods e2e-test-httpd-pod'
  Apr 29 12:07:00.028: INFO: stderr: ""
  Apr 29 12:07:00.028: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 29 12:07:00.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1131" for this suite. @ 04/29/23 12:07:00.032
• [1.997 seconds]
------------------------------
S
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 04/29/23 12:07:00.039
  Apr 29 12:07:00.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename csistoragecapacity @ 04/29/23 12:07:00.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:00.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:00.061
  STEP: getting /apis @ 04/29/23 12:07:00.064
  STEP: getting /apis/storage.k8s.io @ 04/29/23 12:07:00.067
  STEP: getting /apis/storage.k8s.io/v1 @ 04/29/23 12:07:00.069
  STEP: creating @ 04/29/23 12:07:00.07
  STEP: watching @ 04/29/23 12:07:00.086
  Apr 29 12:07:00.086: INFO: starting watch
  STEP: getting @ 04/29/23 12:07:00.093
  STEP: listing in namespace @ 04/29/23 12:07:00.096
  STEP: listing across namespaces @ 04/29/23 12:07:00.099
  STEP: patching @ 04/29/23 12:07:00.103
  STEP: updating @ 04/29/23 12:07:00.108
  Apr 29 12:07:00.112: INFO: waiting for watch events with expected annotations in namespace
  Apr 29 12:07:00.112: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 04/29/23 12:07:00.113
  STEP: deleting a collection @ 04/29/23 12:07:00.126
  Apr 29 12:07:00.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-8295" for this suite. @ 04/29/23 12:07:00.146
• [0.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 04/29/23 12:07:00.153
  Apr 29 12:07:00.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename containers @ 04/29/23 12:07:00.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:00.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:00.169
  Apr 29 12:07:02.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-1680" for this suite. @ 04/29/23 12:07:02.205
• [2.059 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 04/29/23 12:07:02.212
  Apr 29 12:07:02.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:07:02.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:02.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:02.231
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:07:02.235
  STEP: Saw pod success @ 04/29/23 12:07:06.261
  Apr 29 12:07:06.264: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-9273a5ae-1541-4f77-97a1-515c8cd79fce container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:07:06.271
  Apr 29 12:07:06.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5311" for this suite. @ 04/29/23 12:07:06.292
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 04/29/23 12:07:06.3
  Apr 29 12:07:06.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sysctl @ 04/29/23 12:07:06.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:06.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:06.319
  STEP: Creating a pod with one valid and two invalid sysctls @ 04/29/23 12:07:06.322
  Apr 29 12:07:06.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-2209" for this suite. @ 04/29/23 12:07:06.33
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 04/29/23 12:07:06.339
  Apr 29 12:07:06.339: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 12:07:06.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:06.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:06.358
  STEP: Creating secret with name secret-test-map-b7cd5a6e-1c3b-40bc-8c4f-8d594daea771 @ 04/29/23 12:07:06.362
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:07:06.367
  STEP: Saw pod success @ 04/29/23 12:07:10.393
  Apr 29 12:07:10.396: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-secrets-61604741-c942-4377-82c8-04ba9cff0ce4 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:07:10.406
  Apr 29 12:07:10.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2504" for this suite. @ 04/29/23 12:07:10.426
• [4.094 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:864
  STEP: Creating a kubernetes client @ 04/29/23 12:07:10.433
  Apr 29 12:07:10.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename daemonsets @ 04/29/23 12:07:10.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:10.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:10.449
  STEP: Creating simple DaemonSet "daemon-set" @ 04/29/23 12:07:10.475
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/29/23 12:07:10.48
  Apr 29 12:07:10.484: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:07:10.484: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:07:10.488: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:07:10.488: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 12:07:11.492: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:07:11.492: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:07:11.497: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:07:11.497: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 12:07:12.493: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:07:12.493: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:07:12.497: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 12:07:12.497: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 04/29/23 12:07:12.501
  Apr 29 12:07:12.506: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 04/29/23 12:07:12.506
  Apr 29 12:07:12.516: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 04/29/23 12:07:12.517
  Apr 29 12:07:12.518: INFO: Observed &DaemonSet event: ADDED
  Apr 29 12:07:12.519: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.519: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.519: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.519: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.519: INFO: Found daemon set daemon-set in namespace daemonsets-2319 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 29 12:07:12.519: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 04/29/23 12:07:12.519
  STEP: watching for the daemon set status to be patched @ 04/29/23 12:07:12.527
  Apr 29 12:07:12.530: INFO: Observed &DaemonSet event: ADDED
  Apr 29 12:07:12.530: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.530: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.530: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.530: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.530: INFO: Observed daemon set daemon-set in namespace daemonsets-2319 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 29 12:07:12.531: INFO: Observed &DaemonSet event: MODIFIED
  Apr 29 12:07:12.531: INFO: Found daemon set daemon-set in namespace daemonsets-2319 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Apr 29 12:07:12.531: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 04/29/23 12:07:12.535
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2319, will wait for the garbage collector to delete the pods @ 04/29/23 12:07:12.535
  Apr 29 12:07:12.597: INFO: Deleting DaemonSet.extensions daemon-set took: 7.146802ms
  Apr 29 12:07:12.698: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.454714ms
  Apr 29 12:07:15.303: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:07:15.303: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 29 12:07:15.306: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4716"},"items":null}

  Apr 29 12:07:15.309: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4716"},"items":null}

  Apr 29 12:07:15.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2319" for this suite. @ 04/29/23 12:07:15.327
• [4.901 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 04/29/23 12:07:15.334
  Apr 29 12:07:15.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 12:07:15.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:15.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:15.353
  STEP: Counting existing ResourceQuota @ 04/29/23 12:07:15.357
  STEP: Creating a ResourceQuota @ 04/29/23 12:07:20.361
  STEP: Ensuring resource quota status is calculated @ 04/29/23 12:07:20.368
  STEP: Creating a ReplicationController @ 04/29/23 12:07:22.373
  STEP: Ensuring resource quota status captures replication controller creation @ 04/29/23 12:07:22.384
  STEP: Deleting a ReplicationController @ 04/29/23 12:07:24.391
  STEP: Ensuring resource quota status released usage @ 04/29/23 12:07:24.398
  Apr 29 12:07:26.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2077" for this suite. @ 04/29/23 12:07:26.406
• [11.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 04/29/23 12:07:26.415
  Apr 29 12:07:26.415: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:07:26.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:26.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:26.436
  STEP: Creating projection with secret that has name projected-secret-test-972684b5-e24b-4f7c-a0be-e0030eca2744 @ 04/29/23 12:07:26.439
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:07:26.445
  STEP: Saw pod success @ 04/29/23 12:07:30.468
  Apr 29 12:07:30.472: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-secrets-47b4bf7c-0592-4acf-94d5-78a1f723df15 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:07:30.48
  Apr 29 12:07:30.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5350" for this suite. @ 04/29/23 12:07:30.501
• [4.096 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 04/29/23 12:07:30.511
  Apr 29 12:07:30.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:07:30.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:30.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:30.529
  STEP: Creating configMap with name configmap-test-upd-82301384-6835-4a0e-bfd7-8e93e9f5a4f7 @ 04/29/23 12:07:30.536
  STEP: Creating the pod @ 04/29/23 12:07:30.54
  STEP: Waiting for pod with text data @ 04/29/23 12:07:32.558
  STEP: Waiting for pod with binary data @ 04/29/23 12:07:32.566
  Apr 29 12:07:32.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2526" for this suite. @ 04/29/23 12:07:32.576
• [2.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 04/29/23 12:07:32.584
  Apr 29 12:07:32.584: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename job @ 04/29/23 12:07:32.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:32.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:32.604
  STEP: Creating a job @ 04/29/23 12:07:32.607
  STEP: Ensure pods equal to parallelism count is attached to the job @ 04/29/23 12:07:32.615
  STEP: patching /status @ 04/29/23 12:07:34.62
  STEP: updating /status @ 04/29/23 12:07:34.626
  STEP: get /status @ 04/29/23 12:07:34.654
  Apr 29 12:07:34.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2544" for this suite. @ 04/29/23 12:07:34.661
• [2.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1673
  STEP: Creating a kubernetes client @ 04/29/23 12:07:34.669
  Apr 29 12:07:34.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 12:07:34.67
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:34.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:34.689
  Apr 29 12:07:34.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-4333 version'
  Apr 29 12:07:34.745: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
  Apr 29 12:07:34.745: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.1\", GitCommit:\"4c9411232e10168d7b050c49a1b59f6df9d7ea4b\", GitTreeState:\"clean\", BuildDate:\"2023-04-14T13:21:19Z\", GoVersion:\"go1.20.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v5.0.1\nServer Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.1\", GitCommit:\"4c9411232e10168d7b050c49a1b59f6df9d7ea4b\", GitTreeState:\"clean\", BuildDate:\"2023-04-15T02:05:42Z\", GoVersion:\"go1.20.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
  Apr 29 12:07:34.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4333" for this suite. @ 04/29/23 12:07:34.749
• [0.087 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:852
  STEP: Creating a kubernetes client @ 04/29/23 12:07:34.757
  Apr 29 12:07:34.757: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename statefulset @ 04/29/23 12:07:34.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:34.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:34.779
  STEP: Creating service test in namespace statefulset-5681 @ 04/29/23 12:07:34.782
  STEP: Creating statefulset ss in namespace statefulset-5681 @ 04/29/23 12:07:34.789
  Apr 29 12:07:34.799: INFO: Found 0 stateful pods, waiting for 1
  Apr 29 12:07:44.804: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 04/29/23 12:07:44.812
  STEP: updating a scale subresource @ 04/29/23 12:07:44.816
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/29/23 12:07:44.822
  STEP: Patch a scale subresource @ 04/29/23 12:07:44.831
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/29/23 12:07:44.84
  Apr 29 12:07:44.861: INFO: Deleting all statefulset in ns statefulset-5681
  Apr 29 12:07:44.866: INFO: Scaling statefulset ss to 0
  Apr 29 12:07:54.898: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:07:54.904: INFO: Deleting statefulset ss
  Apr 29 12:07:54.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5681" for this suite. @ 04/29/23 12:07:54.924
• [20.174 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 04/29/23 12:07:54.931
  Apr 29 12:07:54.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:07:54.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:54.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:54.951
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/29/23 12:07:54.955
  STEP: Saw pod success @ 04/29/23 12:07:58.975
  Apr 29 12:07:58.979: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-484d32a0-63bc-426e-8a0c-e3ed09543367 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:07:58.986
  Apr 29 12:07:59.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1876" for this suite. @ 04/29/23 12:07:59.006
• [4.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 04/29/23 12:07:59.014
  Apr 29 12:07:59.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 12:07:59.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:07:59.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:07:59.032
  STEP: Discovering how many secrets are in namespace by default @ 04/29/23 12:07:59.035
  STEP: Counting existing ResourceQuota @ 04/29/23 12:08:04.039
  STEP: Creating a ResourceQuota @ 04/29/23 12:08:09.043
  STEP: Ensuring resource quota status is calculated @ 04/29/23 12:08:09.049
  STEP: Creating a Secret @ 04/29/23 12:08:11.054
  STEP: Ensuring resource quota status captures secret creation @ 04/29/23 12:08:11.067
  STEP: Deleting a secret @ 04/29/23 12:08:13.071
  STEP: Ensuring resource quota status released usage @ 04/29/23 12:08:13.078
  Apr 29 12:08:15.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9772" for this suite. @ 04/29/23 12:08:15.087
• [16.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 04/29/23 12:08:15.095
  Apr 29 12:08:15.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename namespaces @ 04/29/23 12:08:15.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:08:15.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:08:15.118
  STEP: Updating Namespace "namespaces-7862" @ 04/29/23 12:08:15.121
  Apr 29 12:08:15.129: INFO: Namespace "namespaces-7862" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"8fb8af36-3b1e-465f-a851-9fb2f1b1d225", "kubernetes.io/metadata.name":"namespaces-7862", "namespaces-7862":"updated", "pod-security.kubernetes.io/enforce":"baseline"}
  Apr 29 12:08:15.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7862" for this suite. @ 04/29/23 12:08:15.133
• [0.049 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 04/29/23 12:08:15.144
  Apr 29 12:08:15.144: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:08:15.145
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:08:15.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:08:15.213
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/29/23 12:08:15.216
  STEP: Saw pod success @ 04/29/23 12:08:19.242
  Apr 29 12:08:19.246: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-380d385d-cd04-4c92-bb75-283327d02e03 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:08:19.258
  Apr 29 12:08:19.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8835" for this suite. @ 04/29/23 12:08:19.278
• [4.141 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 04/29/23 12:08:19.288
  Apr 29 12:08:19.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:08:19.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:08:19.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:08:19.305
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/29/23 12:08:19.308
  STEP: Saw pod success @ 04/29/23 12:08:23.333
  Apr 29 12:08:23.337: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-c4c7683c-eb35-45ee-b721-696dbd2a7145 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:08:23.343
  Apr 29 12:08:23.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9731" for this suite. @ 04/29/23 12:08:23.363
• [4.082 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 04/29/23 12:08:23.37
  Apr 29 12:08:23.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pod-network-test @ 04/29/23 12:08:23.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:08:23.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:08:23.389
  STEP: Performing setup for networking test in namespace pod-network-test-1851 @ 04/29/23 12:08:23.392
  STEP: creating a selector @ 04/29/23 12:08:23.392
  STEP: Creating the service pods in kubernetes @ 04/29/23 12:08:23.392
  Apr 29 12:08:23.393: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/29/23 12:08:45.501
  Apr 29 12:08:47.519: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 29 12:08:47.519: INFO: Breadth first check of 192.168.189.138 on host 172.31.25.13...
  Apr 29 12:08:47.522: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.226.35:9080/dial?request=hostname&protocol=http&host=192.168.189.138&port=8083&tries=1'] Namespace:pod-network-test-1851 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:08:47.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:08:47.523: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:08:47.523: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1851/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.226.35%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.189.138%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 29 12:08:47.586: INFO: Waiting for responses: map[]
  Apr 29 12:08:47.586: INFO: reached 192.168.189.138 after 0/1 tries
  Apr 29 12:08:47.586: INFO: Breadth first check of 192.168.226.34 on host 172.31.41.80...
  Apr 29 12:08:47.589: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.226.35:9080/dial?request=hostname&protocol=http&host=192.168.226.34&port=8083&tries=1'] Namespace:pod-network-test-1851 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:08:47.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:08:47.590: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:08:47.590: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1851/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.226.35%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.226.34%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 29 12:08:47.651: INFO: Waiting for responses: map[]
  Apr 29 12:08:47.651: INFO: reached 192.168.226.34 after 0/1 tries
  Apr 29 12:08:47.651: INFO: Breadth first check of 192.168.69.204 on host 172.31.82.46...
  Apr 29 12:08:47.655: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.226.35:9080/dial?request=hostname&protocol=http&host=192.168.69.204&port=8083&tries=1'] Namespace:pod-network-test-1851 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:08:47.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:08:47.656: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:08:47.656: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1851/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.226.35%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.69.204%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 29 12:08:47.717: INFO: Waiting for responses: map[]
  Apr 29 12:08:47.717: INFO: reached 192.168.69.204 after 0/1 tries
  Apr 29 12:08:47.717: INFO: Going to retry 0 out of 3 pods....
  Apr 29 12:08:47.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1851" for this suite. @ 04/29/23 12:08:47.722
• [24.359 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 04/29/23 12:08:47.729
  Apr 29 12:08:47.729: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 12:08:47.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:08:47.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:08:47.748
  STEP: creating secret secrets-1802/secret-test-becd2ada-bb3b-47be-8e43-69ca199271c7 @ 04/29/23 12:08:47.752
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:08:47.757
  STEP: Saw pod success @ 04/29/23 12:08:51.78
  Apr 29 12:08:51.784: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-60e36f0c-7774-4189-a464-28e2fc982c98 container env-test: <nil>
  STEP: delete the pod @ 04/29/23 12:08:51.792
  Apr 29 12:08:51.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1802" for this suite. @ 04/29/23 12:08:51.813
• [4.090 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 04/29/23 12:08:51.82
  Apr 29 12:08:51.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename dns @ 04/29/23 12:08:51.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:08:51.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:08:51.838
  STEP: Creating a test externalName service @ 04/29/23 12:08:51.842
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7694.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7694.svc.cluster.local; sleep 1; done
   @ 04/29/23 12:08:51.848
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7694.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7694.svc.cluster.local; sleep 1; done
   @ 04/29/23 12:08:51.848
  STEP: creating a pod to probe DNS @ 04/29/23 12:08:51.848
  STEP: submitting the pod to kubernetes @ 04/29/23 12:08:51.848
  STEP: retrieving the pod @ 04/29/23 12:08:59.878
  STEP: looking for the results for each expected name from probers @ 04/29/23 12:08:59.882
  Apr 29 12:08:59.890: INFO: DNS probes using dns-test-1fcbf615-a65f-449c-9d6a-591dab686230 succeeded

  STEP: changing the externalName to bar.example.com @ 04/29/23 12:08:59.89
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7694.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7694.svc.cluster.local; sleep 1; done
   @ 04/29/23 12:08:59.899
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7694.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7694.svc.cluster.local; sleep 1; done
   @ 04/29/23 12:08:59.899
  STEP: creating a second pod to probe DNS @ 04/29/23 12:08:59.899
  STEP: submitting the pod to kubernetes @ 04/29/23 12:08:59.899
  STEP: retrieving the pod @ 04/29/23 12:09:07.927
  STEP: looking for the results for each expected name from probers @ 04/29/23 12:09:07.931
  Apr 29 12:09:07.942: INFO: DNS probes using dns-test-6017dc31-23ea-4490-acf7-b002d8dae653 succeeded

  STEP: changing the service to type=ClusterIP @ 04/29/23 12:09:07.942
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7694.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7694.svc.cluster.local; sleep 1; done
   @ 04/29/23 12:09:07.957
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7694.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7694.svc.cluster.local; sleep 1; done
   @ 04/29/23 12:09:07.957
  STEP: creating a third pod to probe DNS @ 04/29/23 12:09:07.957
  STEP: submitting the pod to kubernetes @ 04/29/23 12:09:07.961
  STEP: retrieving the pod @ 04/29/23 12:09:09.977
  STEP: looking for the results for each expected name from probers @ 04/29/23 12:09:09.982
  Apr 29 12:09:09.992: INFO: DNS probes using dns-test-28e45ef5-fbef-4d29-b38b-aa5b44eae534 succeeded

  Apr 29 12:09:09.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 12:09:09.997
  STEP: deleting the pod @ 04/29/23 12:09:10.013
  STEP: deleting the pod @ 04/29/23 12:09:10.031
  STEP: deleting the test externalName service @ 04/29/23 12:09:10.048
  STEP: Destroying namespace "dns-7694" for this suite. @ 04/29/23 12:09:10.073
• [18.260 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 04/29/23 12:09:10.082
  Apr 29 12:09:10.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:09:10.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:10.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:10.107
  Apr 29 12:09:10.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8009" for this suite. @ 04/29/23 12:09:10.165
• [0.091 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 04/29/23 12:09:10.174
  Apr 29 12:09:10.174: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 12:09:10.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:10.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:10.196
  STEP: creating the pod @ 04/29/23 12:09:10.2
  STEP: submitting the pod to kubernetes @ 04/29/23 12:09:10.2
  STEP: verifying the pod is in kubernetes @ 04/29/23 12:09:14.228
  STEP: updating the pod @ 04/29/23 12:09:14.231
  Apr 29 12:09:14.743: INFO: Successfully updated pod "pod-update-616f8b99-d7ca-4eb5-b5a0-11d1633abbff"
  STEP: verifying the updated pod is in kubernetes @ 04/29/23 12:09:14.747
  Apr 29 12:09:14.752: INFO: Pod update OK
  Apr 29 12:09:14.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9981" for this suite. @ 04/29/23 12:09:14.756
• [4.590 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 04/29/23 12:09:14.764
  Apr 29 12:09:14.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 12:09:14.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:14.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:14.787
  STEP: Counting existing ResourceQuota @ 04/29/23 12:09:14.79
  STEP: Creating a ResourceQuota @ 04/29/23 12:09:19.794
  STEP: Ensuring resource quota status is calculated @ 04/29/23 12:09:19.801
  STEP: Creating a Pod that fits quota @ 04/29/23 12:09:21.805
  STEP: Ensuring ResourceQuota status captures the pod usage @ 04/29/23 12:09:21.821
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 04/29/23 12:09:23.826
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 04/29/23 12:09:23.828
  STEP: Ensuring a pod cannot update its resource requirements @ 04/29/23 12:09:23.83
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 04/29/23 12:09:23.835
  STEP: Deleting the pod @ 04/29/23 12:09:25.84
  STEP: Ensuring resource quota status released the pod usage @ 04/29/23 12:09:25.85
  Apr 29 12:09:27.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-364" for this suite. @ 04/29/23 12:09:27.861
• [13.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 04/29/23 12:09:27.869
  Apr 29 12:09:27.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename field-validation @ 04/29/23 12:09:27.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:27.885
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:27.89
  STEP: apply creating a deployment @ 04/29/23 12:09:27.893
  Apr 29 12:09:27.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9252" for this suite. @ 04/29/23 12:09:27.912
• [0.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 04/29/23 12:09:27.921
  Apr 29 12:09:27.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:09:27.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:27.937
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:27.94
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/29/23 12:09:27.943
  STEP: Saw pod success @ 04/29/23 12:09:31.966
  Apr 29 12:09:31.969: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-98a400a5-d515-4c17-959b-222ca69b9cf9 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:09:31.976
  Apr 29 12:09:31.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7868" for this suite. @ 04/29/23 12:09:31.997
• [4.086 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 04/29/23 12:09:32.007
  Apr 29 12:09:32.007: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename svcaccounts @ 04/29/23 12:09:32.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:32.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:32.025
  STEP: creating a ServiceAccount @ 04/29/23 12:09:32.028
  STEP: watching for the ServiceAccount to be added @ 04/29/23 12:09:32.038
  STEP: patching the ServiceAccount @ 04/29/23 12:09:32.041
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 04/29/23 12:09:32.048
  STEP: deleting the ServiceAccount @ 04/29/23 12:09:32.052
  Apr 29 12:09:32.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2517" for this suite. @ 04/29/23 12:09:32.074
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 04/29/23 12:09:32.083
  Apr 29 12:09:32.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 12:09:32.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:32.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:32.102
  STEP: creating a replication controller @ 04/29/23 12:09:32.106
  Apr 29 12:09:32.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 create -f -'
  Apr 29 12:09:32.759: INFO: stderr: ""
  Apr 29 12:09:32.759: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/29/23 12:09:32.759
  Apr 29 12:09:32.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 29 12:09:32.827: INFO: stderr: ""
  Apr 29 12:09:32.827: INFO: stdout: "update-demo-nautilus-cts2h update-demo-nautilus-hnl9b "
  Apr 29 12:09:32.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get pods update-demo-nautilus-cts2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:09:32.884: INFO: stderr: ""
  Apr 29 12:09:32.884: INFO: stdout: ""
  Apr 29 12:09:32.884: INFO: update-demo-nautilus-cts2h is created but not running
  Apr 29 12:09:37.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 29 12:09:37.949: INFO: stderr: ""
  Apr 29 12:09:37.949: INFO: stdout: "update-demo-nautilus-cts2h update-demo-nautilus-hnl9b "
  Apr 29 12:09:37.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get pods update-demo-nautilus-cts2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:09:38.009: INFO: stderr: ""
  Apr 29 12:09:38.009: INFO: stdout: "true"
  Apr 29 12:09:38.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get pods update-demo-nautilus-cts2h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 29 12:09:38.066: INFO: stderr: ""
  Apr 29 12:09:38.066: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 29 12:09:38.066: INFO: validating pod update-demo-nautilus-cts2h
  Apr 29 12:09:38.071: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 29 12:09:38.071: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 29 12:09:38.071: INFO: update-demo-nautilus-cts2h is verified up and running
  Apr 29 12:09:38.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get pods update-demo-nautilus-hnl9b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:09:38.133: INFO: stderr: ""
  Apr 29 12:09:38.133: INFO: stdout: "true"
  Apr 29 12:09:38.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get pods update-demo-nautilus-hnl9b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 29 12:09:38.190: INFO: stderr: ""
  Apr 29 12:09:38.190: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 29 12:09:38.190: INFO: validating pod update-demo-nautilus-hnl9b
  Apr 29 12:09:38.196: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 29 12:09:38.196: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 29 12:09:38.196: INFO: update-demo-nautilus-hnl9b is verified up and running
  STEP: using delete to clean up resources @ 04/29/23 12:09:38.196
  Apr 29 12:09:38.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 delete --grace-period=0 --force -f -'
  Apr 29 12:09:38.257: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 12:09:38.257: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 29 12:09:38.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get rc,svc -l name=update-demo --no-headers'
  Apr 29 12:09:38.324: INFO: stderr: "No resources found in kubectl-1951 namespace.\n"
  Apr 29 12:09:38.324: INFO: stdout: ""
  Apr 29 12:09:38.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1951 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 29 12:09:38.386: INFO: stderr: ""
  Apr 29 12:09:38.386: INFO: stdout: ""
  Apr 29 12:09:38.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1951" for this suite. @ 04/29/23 12:09:38.391
• [6.315 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 04/29/23 12:09:38.399
  Apr 29 12:09:38.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename deployment @ 04/29/23 12:09:38.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:38.416
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:38.419
  Apr 29 12:09:38.423: INFO: Creating deployment "webserver-deployment"
  Apr 29 12:09:38.428: INFO: Waiting for observed generation 1
  Apr 29 12:09:40.435: INFO: Waiting for all required pods to come up
  Apr 29 12:09:40.440: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 04/29/23 12:09:40.44
  Apr 29 12:09:42.452: INFO: Waiting for deployment "webserver-deployment" to complete
  Apr 29 12:09:42.459: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Apr 29 12:09:42.469: INFO: Updating deployment webserver-deployment
  Apr 29 12:09:42.469: INFO: Waiting for observed generation 2
  Apr 29 12:09:44.482: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Apr 29 12:09:44.486: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Apr 29 12:09:44.489: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 29 12:09:44.499: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Apr 29 12:09:44.499: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Apr 29 12:09:44.503: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 29 12:09:44.509: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Apr 29 12:09:44.509: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Apr 29 12:09:44.518: INFO: Updating deployment webserver-deployment
  Apr 29 12:09:44.518: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Apr 29 12:09:44.527: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Apr 29 12:09:44.531: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Apr 29 12:09:44.561: INFO: Deployment "webserver-deployment":
  &Deployment{ObjectMeta:{webserver-deployment  deployment-6406  ea6956d6-93d1-4277-9b71-c6cb9024b237 6208 3 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00216d2d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-7b75d79cf5" is progressing.,LastUpdateTime:2023-04-29 12:09:42 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-29 12:09:44 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

  Apr 29 12:09:44.585: INFO: New ReplicaSet "webserver-deployment-7b75d79cf5" of Deployment "webserver-deployment":
  &ReplicaSet{ObjectMeta:{webserver-deployment-7b75d79cf5  deployment-6406  c666f283-e99e-411b-8812-12f7fd9bfdab 6204 3 2023-04-29 12:09:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ea6956d6-93d1-4277-9b71-c6cb9024b237 0xc0037b1c67 0xc0037b1c68}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea6956d6-93d1-4277-9b71-c6cb9024b237\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7b75d79cf5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037b1d08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:09:44.585: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Apr 29 12:09:44.585: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-67bd4bf6dc  deployment-6406  e0fde98a-f0f3-4e6f-953f-557af8faf04d 6202 3 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ea6956d6-93d1-4277-9b71-c6cb9024b237 0xc0037b1b77 0xc0037b1b78}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea6956d6-93d1-4277-9b71-c6cb9024b237\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 67bd4bf6dc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037b1c08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:09:44.608: INFO: Pod "webserver-deployment-67bd4bf6dc-2v644" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-2v644 webserver-deployment-67bd4bf6dc- deployment-6406  a63bcc2b-e67f-4fe7-99f0-716c269c04b6 6226 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc0038502d0 0xc0038502d1}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g44jn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g44jn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.609: INFO: Pod "webserver-deployment-67bd4bf6dc-4tz6b" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-4tz6b webserver-deployment-67bd4bf6dc- deployment-6406  07fe77e9-9b8d-4178-82c4-cc268f954c42 6079 0 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003850407 0xc003850408}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.45\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p4h5c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p4h5c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:192.168.226.45,StartTime:2023-04-29 12:09:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:09:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://48c7315f92cac0baa48a05a48aa11d42f84070f52983eb1dbac5e1032cd91cd3,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.226.45,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.609: INFO: Pod "webserver-deployment-67bd4bf6dc-76df2" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-76df2 webserver-deployment-67bd4bf6dc- deployment-6406  65858dae-4d31-43c4-83c4-3e8cbdd14df3 6075 0 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc0038508f7 0xc0038508f8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7v52t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7v52t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:192.168.226.42,StartTime:2023-04-29 12:09:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:09:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://85036f5bb2ab511b40dba8046bad022ae9340bfd83702253c9d6ba6f07e061ec,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.226.42,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.609: INFO: Pod "webserver-deployment-67bd4bf6dc-8772c" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-8772c webserver-deployment-67bd4bf6dc- deployment-6406  2e7ffc64-06fa-42c7-b9fa-8c347d4a30c2 6232 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003850ae7 0xc003850ae8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vhmxp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vhmxp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.610: INFO: Pod "webserver-deployment-67bd4bf6dc-9hxjc" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-9hxjc webserver-deployment-67bd4bf6dc- deployment-6406  bab9095c-5a99-4a28-b9b4-b50100722e40 6239 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003850c50 0xc003850c51}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lcs64,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lcs64,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.610: INFO: Pod "webserver-deployment-67bd4bf6dc-drdrt" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-drdrt webserver-deployment-67bd4bf6dc- deployment-6406  1d8a45ef-31dc-4fd4-a544-b810969a6dec 6238 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003850da7 0xc003850da8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s5prn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s5prn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.610: INFO: Pod "webserver-deployment-67bd4bf6dc-f97jk" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-f97jk webserver-deployment-67bd4bf6dc- deployment-6406  a0343fa3-4071-466b-9997-e9c3d9f23e0d 6065 0 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003850ee7 0xc003850ee8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.189.141\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-54r9l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-54r9l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.13,PodIP:192.168.189.141,StartTime:2023-04-29 12:09:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:09:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://f60b9c9bc1632d6defb63c13ee2572c1722066bdbafb95ea407cee8854eb340c,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.189.141,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.610: INFO: Pod "webserver-deployment-67bd4bf6dc-h8dj5" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-h8dj5 webserver-deployment-67bd4bf6dc- deployment-6406  358cb360-06bb-4216-9e3d-79fbbb30f7a5 6236 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc0038510e7 0xc0038510e8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8bzhk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8bzhk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.610: INFO: Pod "webserver-deployment-67bd4bf6dc-l7nzz" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-l7nzz webserver-deployment-67bd4bf6dc- deployment-6406  9e4a0196-6b8e-444d-b6af-012d09f782ab 6008 0 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851227 0xc003851228}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.69.208\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z4f55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z4f55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.82.46,PodIP:192.168.69.208,StartTime:2023-04-29 12:09:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:09:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://99ef9bb8ca678d0aeacdaea0b7517cf7550ea0ec0afffe8b63fc6efe8332bfd8,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.69.208,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.611: INFO: Pod "webserver-deployment-67bd4bf6dc-lqgmb" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-lqgmb webserver-deployment-67bd4bf6dc- deployment-6406  58cf075a-5085-4bd9-b1a0-15f8b0ded733 6240 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851417 0xc003851418}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jl8x9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jl8x9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.611: INFO: Pod "webserver-deployment-67bd4bf6dc-n6ncw" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-n6ncw webserver-deployment-67bd4bf6dc- deployment-6406  ed3b0787-2f2d-4774-9b53-da30b4b42b59 6223 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851557 0xc003851558}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tm4x7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tm4x7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.611: INFO: Pod "webserver-deployment-67bd4bf6dc-qsfgn" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-qsfgn webserver-deployment-67bd4bf6dc- deployment-6406  757e233d-7757-463b-b154-4a0f8f682193 6015 0 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851697 0xc003851698}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.69.207\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xrxtm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xrxtm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.82.46,PodIP:192.168.69.207,StartTime:2023-04-29 12:09:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:09:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://672d4da5b3ff0a3427089cbec8638e5bd30dced73da23e6354406563518a5485,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.69.207,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.613: INFO: Pod "webserver-deployment-67bd4bf6dc-r2r24" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-r2r24 webserver-deployment-67bd4bf6dc- deployment-6406  d0ccd8e3-7543-41ca-8dd3-4238640e79b9 6061 0 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851887 0xc003851888}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.189.139\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-86lcd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-86lcd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.13,PodIP:192.168.189.139,StartTime:2023-04-29 12:09:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:09:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://a1c5ada33944429dd12162eae0b0032a5d0efdbaa49e9f576f095bd6fabee277,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.189.139,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.614: INFO: Pod "webserver-deployment-67bd4bf6dc-rh6qk" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-rh6qk webserver-deployment-67bd4bf6dc- deployment-6406  36b1bb2a-2c52-43af-9842-1cda8dbe29e0 6058 0 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851a77 0xc003851a78}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.189.140\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r6v5f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r6v5f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.13,PodIP:192.168.189.140,StartTime:2023-04-29 12:09:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:09:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://1461f8c7a58351c7f9c711b6e2d707b1e41862ccec7026b64cb77befacebf441,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.189.140,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.615: INFO: Pod "webserver-deployment-67bd4bf6dc-scr2d" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-scr2d webserver-deployment-67bd4bf6dc- deployment-6406  29143045-f3c7-4fba-ab0d-e19f331455ac 6225 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851c67 0xc003851c68}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dchnq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dchnq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.615: INFO: Pod "webserver-deployment-67bd4bf6dc-sn8tp" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-sn8tp webserver-deployment-67bd4bf6dc- deployment-6406  df610a5f-06df-4fcc-b28c-34d10335ea7a 6237 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851db7 0xc003851db8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wnjsp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wnjsp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.615: INFO: Pod "webserver-deployment-67bd4bf6dc-t2pn9" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-t2pn9 webserver-deployment-67bd4bf6dc- deployment-6406  b27008c1-fb6b-4e49-8276-8b1dd5c11f20 6214 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003851ef7 0xc003851ef8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2mvlh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2mvlh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.616: INFO: Pod "webserver-deployment-67bd4bf6dc-t8t6r" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-t8t6r webserver-deployment-67bd4bf6dc- deployment-6406  9675ad40-c5c3-4192-817e-138ddafa3c51 6222 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003ad8090 0xc003ad8091}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6cpdz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6cpdz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.616: INFO: Pod "webserver-deployment-67bd4bf6dc-xl5fw" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-xl5fw webserver-deployment-67bd4bf6dc- deployment-6406  e83a3ebd-3011-447a-b49b-dcccc918df43 6235 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003ad81f0 0xc003ad81f1}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sw7k6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sw7k6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:,StartTime:2023-04-29 12:09:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.617: INFO: Pod "webserver-deployment-67bd4bf6dc-zsd8v" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-zsd8v webserver-deployment-67bd4bf6dc- deployment-6406  223ef4ed-27d1-45ef-98ca-b34b353ed72d 6054 0 2023-04-29 12:09:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc e0fde98a-f0f3-4e6f-953f-557af8faf04d 0xc003ad83b7 0xc003ad83b8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e0fde98a-f0f3-4e6f-953f-557af8faf04d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.69.209\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2kg6g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2kg6g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.82.46,PodIP:192.168.69.209,StartTime:2023-04-29 12:09:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:09:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://031b96e43d51b4fb26815e33b6a1e583b46917c4cfa7f9153f64b4380d7100d3,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.69.209,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.617: INFO: Pod "webserver-deployment-7b75d79cf5-5nw6p" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-5nw6p webserver-deployment-7b75d79cf5- deployment-6406  59c266fe-3450-421a-b6d6-ba339c6c27c1 6135 0 2023-04-29 12:09:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad85b7 0xc003ad85b8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-svwb8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-svwb8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:,StartTime:2023-04-29 12:09:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.617: INFO: Pod "webserver-deployment-7b75d79cf5-7jtvr" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-7jtvr webserver-deployment-7b75d79cf5- deployment-6406  b7e054de-071e-41ca-b069-e376ea7c9c9c 6180 0 2023-04-29 12:09:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad87a7 0xc003ad87a8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.189.142\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v4wlb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v4wlb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.13,PodIP:192.168.189.142,StartTime:2023-04-29 12:09:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.189.142,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.618: INFO: Pod "webserver-deployment-7b75d79cf5-dsj8q" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-dsj8q webserver-deployment-7b75d79cf5- deployment-6406  7b6d0959-6f5c-4a53-87b1-3a860e5003e9 6227 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad89d7 0xc003ad89d8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9l799,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9l799,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.618: INFO: Pod "webserver-deployment-7b75d79cf5-j2d99" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-j2d99 webserver-deployment-7b75d79cf5- deployment-6406  2e50516e-fa6b-4450-9559-4aa0ee5b67a8 6230 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad8b50 0xc003ad8b51}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hqtc2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hqtc2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.618: INFO: Pod "webserver-deployment-7b75d79cf5-jxbzd" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-jxbzd webserver-deployment-7b75d79cf5- deployment-6406  c5d310e8-1511-41e9-8158-9926e696456c 6234 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad8c97 0xc003ad8c98}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7q6qs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7q6qs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.618: INFO: Pod "webserver-deployment-7b75d79cf5-lrt24" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-lrt24 webserver-deployment-7b75d79cf5- deployment-6406  cd794708-1ccf-4ebf-820e-89bf0fce0d70 6233 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad8de7 0xc003ad8de8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cj4lf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cj4lf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.618: INFO: Pod "webserver-deployment-7b75d79cf5-m4jhq" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-m4jhq webserver-deployment-7b75d79cf5- deployment-6406  7d398d17-1dcc-43e2-a5d7-8ef093e4bf28 6173 0 2023-04-29 12:09:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad8f37 0xc003ad8f38}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.69.210\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7f6kh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7f6kh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.82.46,PodIP:192.168.69.210,StartTime:2023-04-29 12:09:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.69.210,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.618: INFO: Pod "webserver-deployment-7b75d79cf5-nx9lk" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-nx9lk webserver-deployment-7b75d79cf5- deployment-6406  cf6e7056-8104-4c44-89da-274774fc63fb 6231 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad9157 0xc003ad9158}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dr2sm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dr2sm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.619: INFO: Pod "webserver-deployment-7b75d79cf5-pj7fq" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-pj7fq webserver-deployment-7b75d79cf5- deployment-6406  6996913d-3ed0-4e9e-a614-df53bacf5622 6170 0 2023-04-29 12:09:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad92a7 0xc003ad92a8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.69.211\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cb2ws,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cb2ws,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.82.46,PodIP:192.168.69.211,StartTime:2023-04-29 12:09:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.69.211,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.619: INFO: Pod "webserver-deployment-7b75d79cf5-qlvzp" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-qlvzp webserver-deployment-7b75d79cf5- deployment-6406  0de31283-c55e-4a11-a3cc-d2f465747017 6101 0 2023-04-29 12:09:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad94c7 0xc003ad94c8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4lbq4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4lbq4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:,StartTime:2023-04-29 12:09:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.620: INFO: Pod "webserver-deployment-7b75d79cf5-rcd8j" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-rcd8j webserver-deployment-7b75d79cf5- deployment-6406  a0eee2c1-fc1c-48ce-a9df-fa3db4b27403 6218 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad96b7 0xc003ad96b8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7j8gf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7j8gf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-25-13,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.25.13,PodIP:,StartTime:2023-04-29 12:09:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.620: INFO: Pod "webserver-deployment-7b75d79cf5-tnrd9" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-tnrd9 webserver-deployment-7b75d79cf5- deployment-6406  c4156484-53e5-4acc-a92c-8eac363ad7f1 6228 0 2023-04-29 12:09:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 c666f283-e99e-411b-8812-12f7fd9bfdab 0xc003ad98a7 0xc003ad98a8}] [] [{kube-controller-manager Update v1 2023-04-29 12:09:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c666f283-e99e-411b-8812-12f7fd9bfdab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xckdc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xckdc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:09:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:09:44.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6406" for this suite. @ 04/29/23 12:09:44.655
• [6.275 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 04/29/23 12:09:44.674
  Apr 29 12:09:44.674: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 12:09:44.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:09:44.704
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:09:44.71
  STEP: Creating a ResourceQuota with terminating scope @ 04/29/23 12:09:44.713
  STEP: Ensuring ResourceQuota status is calculated @ 04/29/23 12:09:44.719
  STEP: Creating a ResourceQuota with not terminating scope @ 04/29/23 12:09:46.724
  STEP: Ensuring ResourceQuota status is calculated @ 04/29/23 12:09:46.73
  STEP: Creating a long running pod @ 04/29/23 12:09:48.735
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 04/29/23 12:09:48.748
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 04/29/23 12:09:50.752
  STEP: Deleting the pod @ 04/29/23 12:09:52.756
  STEP: Ensuring resource quota status released the pod usage @ 04/29/23 12:09:52.773
  STEP: Creating a terminating pod @ 04/29/23 12:09:54.778
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 04/29/23 12:09:54.79
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 04/29/23 12:09:56.798
  STEP: Deleting the pod @ 04/29/23 12:09:58.803
  STEP: Ensuring resource quota status released the pod usage @ 04/29/23 12:09:58.819
  Apr 29 12:10:00.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9714" for this suite. @ 04/29/23 12:10:00.828
• [16.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 04/29/23 12:10:00.84
  Apr 29 12:10:00.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-pred @ 04/29/23 12:10:00.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:10:00.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:10:00.86
  Apr 29 12:10:00.864: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 29 12:10:00.871: INFO: Waiting for terminating namespaces to be deleted...
  Apr 29 12:10:00.875: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-25-13 before test
  Apr 29 12:10:00.880: INFO: nginx-ingress-controller-kubernetes-worker-nktfk from ingress-nginx-kubernetes-worker started at 2023-04-29 11:51:02 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.880: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 12:10:00.880: INFO: coredns-5c7f76ccb8-2lgzt from kube-system started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.880: INFO: 	Container coredns ready: true, restart count 0
  Apr 29 12:10:00.880: INFO: kube-state-metrics-5b95b4459c-9469j from kube-system started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.880: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Apr 29 12:10:00.880: INFO: metrics-server-v0.5.2-6cf8c8b69c-tsmc5 from kube-system started at 2023-04-29 11:50:57 +0000 UTC (2 container statuses recorded)
  Apr 29 12:10:00.880: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 29 12:10:00.881: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Apr 29 12:10:00.881: INFO: dashboard-metrics-scraper-6b8586b5c9-k9jlf from kubernetes-dashboard started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.881: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Apr 29 12:10:00.881: INFO: kubernetes-dashboard-6869f4cd5f-w7m8c from kubernetes-dashboard started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.881: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Apr 29 12:10:00.881: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-rvknb from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 12:10:00.881: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 12:10:00.881: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 29 12:10:00.881: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-41-80 before test
  Apr 29 12:10:00.887: INFO: default-http-backend-kubernetes-worker-65fc475d49-r9hgq from ingress-nginx-kubernetes-worker started at 2023-04-29 11:51:04 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.887: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Apr 29 12:10:00.887: INFO: nginx-ingress-controller-kubernetes-worker-vht7v from ingress-nginx-kubernetes-worker started at 2023-04-29 11:51:04 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.887: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 12:10:00.887: INFO: calico-kube-controllers-577d5b7f57-b754k from kube-system started at 2023-04-29 11:54:20 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.887: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  Apr 29 12:10:00.887: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-6rcvs from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 12:10:00.887: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 12:10:00.887: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 29 12:10:00.887: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-82-46 before test
  Apr 29 12:10:00.892: INFO: nginx-ingress-controller-kubernetes-worker-m8hc4 from ingress-nginx-kubernetes-worker started at 2023-04-29 11:54:52 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.892: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 12:10:00.892: INFO: sonobuoy from sonobuoy started at 2023-04-29 12:00:46 +0000 UTC (1 container statuses recorded)
  Apr 29 12:10:00.892: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 29 12:10:00.892: INFO: sonobuoy-e2e-job-819b1466a92240b6 from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 12:10:00.893: INFO: 	Container e2e ready: true, restart count 0
  Apr 29 12:10:00.893: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 12:10:00.893: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-hpjk5 from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 12:10:00.893: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 12:10:00.893: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/29/23 12:10:00.893
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/29/23 12:10:02.914
  STEP: Trying to apply a random label on the found node. @ 04/29/23 12:10:02.924
  STEP: verifying the node has the label kubernetes.io/e2e-0bb1a0a9-ef7e-4566-944b-3f8c77d5c09a 42 @ 04/29/23 12:10:02.932
  STEP: Trying to relaunch the pod, now with labels. @ 04/29/23 12:10:02.935
  STEP: removing the label kubernetes.io/e2e-0bb1a0a9-ef7e-4566-944b-3f8c77d5c09a off the node ip-172-31-41-80 @ 04/29/23 12:10:04.956
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-0bb1a0a9-ef7e-4566-944b-3f8c77d5c09a @ 04/29/23 12:10:04.967
  Apr 29 12:10:04.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3066" for this suite. @ 04/29/23 12:10:04.977
• [4.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:344
  STEP: Creating a kubernetes client @ 04/29/23 12:10:04.986
  Apr 29 12:10:04.986: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename field-validation @ 04/29/23 12:10:04.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:10:05.001
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:10:05.004
  Apr 29 12:10:05.007: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  W0429 12:10:05.008512      18 field_validation.go:417] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc00119ddb0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W0429 12:10:07.561147      18 warnings.go:70] unknown field "alpha"
  W0429 12:10:07.561324      18 warnings.go:70] unknown field "beta"
  W0429 12:10:07.561411      18 warnings.go:70] unknown field "delta"
  W0429 12:10:07.561496      18 warnings.go:70] unknown field "epsilon"
  W0429 12:10:07.561582      18 warnings.go:70] unknown field "gamma"
  Apr 29 12:10:07.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6566" for this suite. @ 04/29/23 12:10:07.595
• [2.616 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 04/29/23 12:10:07.604
  Apr 29 12:10:07.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pod-network-test @ 04/29/23 12:10:07.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:10:07.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:10:07.626
  STEP: Performing setup for networking test in namespace pod-network-test-3719 @ 04/29/23 12:10:07.669
  STEP: creating a selector @ 04/29/23 12:10:07.669
  STEP: Creating the service pods in kubernetes @ 04/29/23 12:10:07.669
  Apr 29 12:10:07.669: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/29/23 12:10:19.752
  Apr 29 12:10:21.787: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 29 12:10:21.787: INFO: Going to poll 192.168.189.143 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 29 12:10:21.790: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.189.143 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3719 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:10:21.790: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:10:21.791: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:10:21.791: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3719/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.189.143+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 29 12:10:22.875: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 29 12:10:22.875: INFO: Going to poll 192.168.226.50 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 29 12:10:22.879: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.226.50 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3719 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:10:22.879: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:10:22.880: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:10:22.880: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3719/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.226.50+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 29 12:10:23.941: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 29 12:10:23.941: INFO: Going to poll 192.168.69.212 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 29 12:10:23.945: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.69.212 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3719 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:10:23.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:10:23.945: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:10:23.945: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3719/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.69.212+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 29 12:10:25.006: INFO: Found all 1 expected endpoints: [netserver-2]
  Apr 29 12:10:25.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3719" for this suite. @ 04/29/23 12:10:25.01
• [17.413 seconds]
------------------------------
S
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 04/29/23 12:10:25.017
  Apr 29 12:10:25.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename svc-latency @ 04/29/23 12:10:25.018
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:10:25.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:10:25.036
  Apr 29 12:10:25.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-9500 @ 04/29/23 12:10:25.04
  I0429 12:10:25.047924      18 runners.go:194] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9500, replica count: 1
  I0429 12:10:26.099030      18 runners.go:194] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0429 12:10:27.099871      18 runners.go:194] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 12:10:27.214: INFO: Created: latency-svc-tqmsk
  Apr 29 12:10:27.222: INFO: Got endpoints: latency-svc-tqmsk [22.128841ms]
  Apr 29 12:10:27.235: INFO: Created: latency-svc-fpxc5
  Apr 29 12:10:27.238: INFO: Got endpoints: latency-svc-fpxc5 [16.504143ms]
  Apr 29 12:10:27.306: INFO: Created: latency-svc-4kjf4
  Apr 29 12:10:27.308: INFO: Created: latency-svc-84q2p
  Apr 29 12:10:27.312: INFO: Created: latency-svc-d2lsd
  Apr 29 12:10:27.320: INFO: Created: latency-svc-jxc7l
  Apr 29 12:10:27.320: INFO: Created: latency-svc-8l2vf
  Apr 29 12:10:27.323: INFO: Got endpoints: latency-svc-4kjf4 [100.731028ms]
  Apr 29 12:10:27.324: INFO: Created: latency-svc-dkt2f
  Apr 29 12:10:27.324: INFO: Created: latency-svc-tf49q
  Apr 29 12:10:27.324: INFO: Created: latency-svc-wvnp5
  Apr 29 12:10:27.325: INFO: Created: latency-svc-s8x8j
  Apr 29 12:10:27.328: INFO: Created: latency-svc-4trqm
  Apr 29 12:10:27.328: INFO: Created: latency-svc-bw7bb
  Apr 29 12:10:27.329: INFO: Created: latency-svc-vr9cv
  Apr 29 12:10:27.330: INFO: Created: latency-svc-ghd78
  Apr 29 12:10:27.330: INFO: Created: latency-svc-7pb5m
  Apr 29 12:10:27.331: INFO: Created: latency-svc-4wmt7
  Apr 29 12:10:27.336: INFO: Got endpoints: latency-svc-84q2p [113.54512ms]
  Apr 29 12:10:27.339: INFO: Got endpoints: latency-svc-d2lsd [117.003775ms]
  Apr 29 12:10:27.344: INFO: Got endpoints: latency-svc-s8x8j [122.132314ms]
  Apr 29 12:10:27.347: INFO: Got endpoints: latency-svc-jxc7l [124.466087ms]
  Apr 29 12:10:27.352: INFO: Got endpoints: latency-svc-4trqm [129.668161ms]
  Apr 29 12:10:27.356: INFO: Got endpoints: latency-svc-dkt2f [133.223138ms]
  Apr 29 12:10:27.356: INFO: Got endpoints: latency-svc-bw7bb [117.56176ms]
  Apr 29 12:10:27.358: INFO: Created: latency-svc-jnc5t
  Apr 29 12:10:27.361: INFO: Got endpoints: latency-svc-7pb5m [138.427282ms]
  Apr 29 12:10:27.361: INFO: Got endpoints: latency-svc-vr9cv [138.561144ms]
  Apr 29 12:10:27.368: INFO: Got endpoints: latency-svc-8l2vf [145.594471ms]
  Apr 29 12:10:27.373: INFO: Got endpoints: latency-svc-tf49q [150.543763ms]
  Apr 29 12:10:27.376: INFO: Got endpoints: latency-svc-wvnp5 [153.406532ms]
  Apr 29 12:10:27.376: INFO: Got endpoints: latency-svc-4wmt7 [153.708533ms]
  Apr 29 12:10:27.381: INFO: Got endpoints: latency-svc-jnc5t [57.115644ms]
  Apr 29 12:10:27.382: INFO: Created: latency-svc-vbdfs
  Apr 29 12:10:27.384: INFO: Got endpoints: latency-svc-ghd78 [161.719454ms]
  Apr 29 12:10:27.392: INFO: Got endpoints: latency-svc-vbdfs [55.476976ms]
  Apr 29 12:10:27.393: INFO: Created: latency-svc-6knj4
  Apr 29 12:10:27.401: INFO: Got endpoints: latency-svc-6knj4 [61.536131ms]
  Apr 29 12:10:27.405: INFO: Created: latency-svc-lz2kx
  Apr 29 12:10:27.411: INFO: Got endpoints: latency-svc-lz2kx [66.657313ms]
  Apr 29 12:10:27.412: INFO: Created: latency-svc-wqzfw
  Apr 29 12:10:27.417: INFO: Created: latency-svc-qvcq2
  Apr 29 12:10:27.418: INFO: Got endpoints: latency-svc-wqzfw [70.813636ms]
  Apr 29 12:10:27.424: INFO: Got endpoints: latency-svc-qvcq2 [72.052162ms]
  Apr 29 12:10:27.431: INFO: Created: latency-svc-hts5c
  Apr 29 12:10:27.435: INFO: Got endpoints: latency-svc-hts5c [78.493282ms]
  Apr 29 12:10:27.441: INFO: Created: latency-svc-9sbxv
  Apr 29 12:10:27.443: INFO: Got endpoints: latency-svc-9sbxv [87.073678ms]
  Apr 29 12:10:27.447: INFO: Created: latency-svc-82rd5
  Apr 29 12:10:27.453: INFO: Got endpoints: latency-svc-82rd5 [92.081784ms]
  Apr 29 12:10:27.458: INFO: Created: latency-svc-4p65q
  Apr 29 12:10:27.463: INFO: Got endpoints: latency-svc-4p65q [101.484758ms]
  Apr 29 12:10:27.464: INFO: Created: latency-svc-x74p9
  Apr 29 12:10:27.470: INFO: Created: latency-svc-4vk4f
  Apr 29 12:10:27.471: INFO: Got endpoints: latency-svc-x74p9 [103.441676ms]
  Apr 29 12:10:27.478: INFO: Got endpoints: latency-svc-4vk4f [104.838312ms]
  Apr 29 12:10:27.482: INFO: Created: latency-svc-pbq66
  Apr 29 12:10:27.487: INFO: Got endpoints: latency-svc-pbq66 [110.685628ms]
  Apr 29 12:10:27.495: INFO: Created: latency-svc-sx557
  Apr 29 12:10:27.499: INFO: Created: latency-svc-tb658
  Apr 29 12:10:27.500: INFO: Got endpoints: latency-svc-sx557 [123.67169ms]
  Apr 29 12:10:27.505: INFO: Got endpoints: latency-svc-tb658 [124.212286ms]
  Apr 29 12:10:27.510: INFO: Created: latency-svc-6qn2t
  Apr 29 12:10:27.515: INFO: Got endpoints: latency-svc-6qn2t [130.747394ms]
  Apr 29 12:10:27.519: INFO: Created: latency-svc-skmbf
  Apr 29 12:10:27.524: INFO: Got endpoints: latency-svc-skmbf [132.134515ms]
  Apr 29 12:10:27.528: INFO: Created: latency-svc-79cpx
  Apr 29 12:10:27.534: INFO: Got endpoints: latency-svc-79cpx [133.792185ms]
  Apr 29 12:10:27.538: INFO: Created: latency-svc-lzzh8
  Apr 29 12:10:27.543: INFO: Got endpoints: latency-svc-lzzh8 [131.122124ms]
  Apr 29 12:10:27.547: INFO: Created: latency-svc-mqgl9
  Apr 29 12:10:27.551: INFO: Created: latency-svc-fgrfr
  Apr 29 12:10:27.558: INFO: Created: latency-svc-m5gld
  Apr 29 12:10:27.564: INFO: Created: latency-svc-4p4b7
  Apr 29 12:10:27.565: INFO: Got endpoints: latency-svc-mqgl9 [146.791301ms]
  Apr 29 12:10:27.572: INFO: Created: latency-svc-tjkwl
  Apr 29 12:10:27.616: INFO: Got endpoints: latency-svc-fgrfr [191.444839ms]
  Apr 29 12:10:27.628: INFO: Created: latency-svc-c6mtm
  Apr 29 12:10:27.637: INFO: Created: latency-svc-4shxm
  Apr 29 12:10:27.638: INFO: Created: latency-svc-2d8v7
  Apr 29 12:10:27.642: INFO: Created: latency-svc-stql2
  Apr 29 12:10:27.643: INFO: Created: latency-svc-6vxgv
  Apr 29 12:10:27.644: INFO: Created: latency-svc-52mjm
  Apr 29 12:10:27.644: INFO: Created: latency-svc-rnjhh
  Apr 29 12:10:27.644: INFO: Created: latency-svc-ktth4
  Apr 29 12:10:27.644: INFO: Created: latency-svc-bltvf
  Apr 29 12:10:27.645: INFO: Created: latency-svc-frkhg
  Apr 29 12:10:27.645: INFO: Created: latency-svc-vtw7n
  Apr 29 12:10:27.645: INFO: Created: latency-svc-v26r8
  Apr 29 12:10:27.666: INFO: Got endpoints: latency-svc-m5gld [231.310913ms]
  Apr 29 12:10:27.676: INFO: Created: latency-svc-gvxd2
  Apr 29 12:10:27.715: INFO: Got endpoints: latency-svc-4p4b7 [271.961338ms]
  Apr 29 12:10:27.731: INFO: Created: latency-svc-nghhf
  Apr 29 12:10:27.765: INFO: Got endpoints: latency-svc-tjkwl [311.775304ms]
  Apr 29 12:10:27.775: INFO: Created: latency-svc-ck4qh
  Apr 29 12:10:27.816: INFO: Got endpoints: latency-svc-c6mtm [273.693399ms]
  Apr 29 12:10:27.827: INFO: Created: latency-svc-75czj
  Apr 29 12:10:27.866: INFO: Got endpoints: latency-svc-stql2 [379.306749ms]
  Apr 29 12:10:27.879: INFO: Created: latency-svc-kwdpz
  Apr 29 12:10:27.916: INFO: Got endpoints: latency-svc-v26r8 [300.028075ms]
  Apr 29 12:10:27.926: INFO: Created: latency-svc-b8n6t
  Apr 29 12:10:27.966: INFO: Got endpoints: latency-svc-2d8v7 [503.37443ms]
  Apr 29 12:10:27.977: INFO: Created: latency-svc-rr757
  Apr 29 12:10:28.018: INFO: Got endpoints: latency-svc-4shxm [546.429672ms]
  Apr 29 12:10:28.037: INFO: Created: latency-svc-z2v7t
  Apr 29 12:10:28.064: INFO: Got endpoints: latency-svc-bltvf [499.719132ms]
  Apr 29 12:10:28.076: INFO: Created: latency-svc-jmsb9
  Apr 29 12:10:28.117: INFO: Got endpoints: latency-svc-6vxgv [617.252458ms]
  Apr 29 12:10:28.128: INFO: Created: latency-svc-zpzrh
  Apr 29 12:10:28.166: INFO: Got endpoints: latency-svc-ktth4 [651.252807ms]
  Apr 29 12:10:28.177: INFO: Created: latency-svc-8ql8s
  Apr 29 12:10:28.214: INFO: Got endpoints: latency-svc-52mjm [679.553005ms]
  Apr 29 12:10:28.226: INFO: Created: latency-svc-cpxdp
  Apr 29 12:10:28.267: INFO: Got endpoints: latency-svc-frkhg [788.831267ms]
  Apr 29 12:10:28.277: INFO: Created: latency-svc-69k8k
  Apr 29 12:10:28.315: INFO: Got endpoints: latency-svc-vtw7n [809.737792ms]
  Apr 29 12:10:28.326: INFO: Created: latency-svc-q7b6m
  Apr 29 12:10:28.366: INFO: Got endpoints: latency-svc-rnjhh [841.738059ms]
  Apr 29 12:10:28.377: INFO: Created: latency-svc-mdpgp
  Apr 29 12:10:28.416: INFO: Got endpoints: latency-svc-gvxd2 [749.881472ms]
  Apr 29 12:10:28.426: INFO: Created: latency-svc-q2txp
  Apr 29 12:10:28.465: INFO: Got endpoints: latency-svc-nghhf [750.149134ms]
  Apr 29 12:10:28.476: INFO: Created: latency-svc-sk2c7
  Apr 29 12:10:28.517: INFO: Got endpoints: latency-svc-ck4qh [751.872737ms]
  Apr 29 12:10:28.529: INFO: Created: latency-svc-flmrw
  Apr 29 12:10:28.567: INFO: Got endpoints: latency-svc-75czj [751.051392ms]
  Apr 29 12:10:28.578: INFO: Created: latency-svc-428l7
  Apr 29 12:10:28.616: INFO: Got endpoints: latency-svc-kwdpz [749.810607ms]
  Apr 29 12:10:28.628: INFO: Created: latency-svc-pmnzj
  Apr 29 12:10:28.665: INFO: Got endpoints: latency-svc-b8n6t [748.900328ms]
  Apr 29 12:10:28.675: INFO: Created: latency-svc-hjnhp
  Apr 29 12:10:28.718: INFO: Got endpoints: latency-svc-rr757 [751.406829ms]
  Apr 29 12:10:28.729: INFO: Created: latency-svc-zxrsx
  Apr 29 12:10:28.765: INFO: Got endpoints: latency-svc-z2v7t [746.930039ms]
  Apr 29 12:10:28.778: INFO: Created: latency-svc-vl2kj
  Apr 29 12:10:28.815: INFO: Got endpoints: latency-svc-jmsb9 [750.483308ms]
  Apr 29 12:10:28.825: INFO: Created: latency-svc-nkq6x
  Apr 29 12:10:28.867: INFO: Got endpoints: latency-svc-zpzrh [749.527027ms]
  Apr 29 12:10:28.877: INFO: Created: latency-svc-dzd4m
  Apr 29 12:10:28.916: INFO: Got endpoints: latency-svc-8ql8s [750.297968ms]
  Apr 29 12:10:28.928: INFO: Created: latency-svc-9ls5m
  Apr 29 12:10:28.965: INFO: Got endpoints: latency-svc-cpxdp [750.764207ms]
  Apr 29 12:10:28.976: INFO: Created: latency-svc-74jjj
  Apr 29 12:10:29.017: INFO: Got endpoints: latency-svc-69k8k [750.069112ms]
  Apr 29 12:10:29.027: INFO: Created: latency-svc-n8l4j
  Apr 29 12:10:29.065: INFO: Got endpoints: latency-svc-q7b6m [750.212952ms]
  Apr 29 12:10:29.079: INFO: Created: latency-svc-dmfll
  Apr 29 12:10:29.116: INFO: Got endpoints: latency-svc-mdpgp [750.024173ms]
  Apr 29 12:10:29.127: INFO: Created: latency-svc-46x9j
  Apr 29 12:10:29.168: INFO: Got endpoints: latency-svc-q2txp [751.69044ms]
  Apr 29 12:10:29.178: INFO: Created: latency-svc-q5pw5
  Apr 29 12:10:29.215: INFO: Got endpoints: latency-svc-sk2c7 [749.066375ms]
  Apr 29 12:10:29.229: INFO: Created: latency-svc-td6xg
  Apr 29 12:10:29.264: INFO: Got endpoints: latency-svc-flmrw [747.437326ms]
  Apr 29 12:10:29.274: INFO: Created: latency-svc-57xvf
  Apr 29 12:10:29.317: INFO: Got endpoints: latency-svc-428l7 [749.648421ms]
  Apr 29 12:10:29.327: INFO: Created: latency-svc-xsggc
  Apr 29 12:10:29.366: INFO: Got endpoints: latency-svc-pmnzj [750.117298ms]
  Apr 29 12:10:29.378: INFO: Created: latency-svc-9hwrh
  Apr 29 12:10:29.416: INFO: Got endpoints: latency-svc-hjnhp [751.049175ms]
  Apr 29 12:10:29.427: INFO: Created: latency-svc-nngc2
  Apr 29 12:10:29.466: INFO: Got endpoints: latency-svc-zxrsx [748.160319ms]
  Apr 29 12:10:29.478: INFO: Created: latency-svc-xkg5b
  Apr 29 12:10:29.515: INFO: Got endpoints: latency-svc-vl2kj [750.530963ms]
  Apr 29 12:10:29.527: INFO: Created: latency-svc-h9nz7
  Apr 29 12:10:29.565: INFO: Got endpoints: latency-svc-nkq6x [750.03329ms]
  Apr 29 12:10:29.575: INFO: Created: latency-svc-skdzz
  Apr 29 12:10:29.616: INFO: Got endpoints: latency-svc-dzd4m [749.726726ms]
  Apr 29 12:10:29.628: INFO: Created: latency-svc-fbqlm
  Apr 29 12:10:29.666: INFO: Got endpoints: latency-svc-9ls5m [749.483812ms]
  Apr 29 12:10:29.679: INFO: Created: latency-svc-hqpgj
  Apr 29 12:10:29.715: INFO: Got endpoints: latency-svc-74jjj [750.400095ms]
  Apr 29 12:10:29.727: INFO: Created: latency-svc-t4cxp
  Apr 29 12:10:29.766: INFO: Got endpoints: latency-svc-n8l4j [749.101225ms]
  Apr 29 12:10:29.778: INFO: Created: latency-svc-lkzvs
  Apr 29 12:10:29.816: INFO: Got endpoints: latency-svc-dmfll [750.665431ms]
  Apr 29 12:10:29.827: INFO: Created: latency-svc-k8ghs
  Apr 29 12:10:29.865: INFO: Got endpoints: latency-svc-46x9j [749.679706ms]
  Apr 29 12:10:29.877: INFO: Created: latency-svc-745sb
  Apr 29 12:10:29.916: INFO: Got endpoints: latency-svc-q5pw5 [748.390034ms]
  Apr 29 12:10:29.928: INFO: Created: latency-svc-zmv4w
  Apr 29 12:10:29.966: INFO: Got endpoints: latency-svc-td6xg [750.914796ms]
  Apr 29 12:10:29.978: INFO: Created: latency-svc-5ttqs
  Apr 29 12:10:30.015: INFO: Got endpoints: latency-svc-57xvf [750.599958ms]
  Apr 29 12:10:30.028: INFO: Created: latency-svc-wd2mb
  Apr 29 12:10:30.066: INFO: Got endpoints: latency-svc-xsggc [748.474845ms]
  Apr 29 12:10:30.078: INFO: Created: latency-svc-9m27q
  Apr 29 12:10:30.117: INFO: Got endpoints: latency-svc-9hwrh [750.588656ms]
  Apr 29 12:10:30.128: INFO: Created: latency-svc-2gzkg
  Apr 29 12:10:30.165: INFO: Got endpoints: latency-svc-nngc2 [749.188557ms]
  Apr 29 12:10:30.177: INFO: Created: latency-svc-8d29z
  Apr 29 12:10:30.215: INFO: Got endpoints: latency-svc-xkg5b [748.789072ms]
  Apr 29 12:10:30.234: INFO: Created: latency-svc-qmj5v
  Apr 29 12:10:30.268: INFO: Got endpoints: latency-svc-h9nz7 [753.14707ms]
  Apr 29 12:10:30.280: INFO: Created: latency-svc-ctt4v
  Apr 29 12:10:30.315: INFO: Got endpoints: latency-svc-skdzz [750.094002ms]
  Apr 29 12:10:30.331: INFO: Created: latency-svc-6tlvc
  Apr 29 12:10:30.365: INFO: Got endpoints: latency-svc-fbqlm [748.249385ms]
  Apr 29 12:10:30.377: INFO: Created: latency-svc-jk7mt
  Apr 29 12:10:30.416: INFO: Got endpoints: latency-svc-hqpgj [749.725943ms]
  Apr 29 12:10:30.428: INFO: Created: latency-svc-4wpq5
  Apr 29 12:10:30.465: INFO: Got endpoints: latency-svc-t4cxp [749.371806ms]
  Apr 29 12:10:30.476: INFO: Created: latency-svc-4mx4w
  Apr 29 12:10:30.515: INFO: Got endpoints: latency-svc-lkzvs [748.980948ms]
  Apr 29 12:10:30.526: INFO: Created: latency-svc-qwzx7
  Apr 29 12:10:30.565: INFO: Got endpoints: latency-svc-k8ghs [749.546963ms]
  Apr 29 12:10:30.584: INFO: Created: latency-svc-2bbvd
  Apr 29 12:10:30.615: INFO: Got endpoints: latency-svc-745sb [749.269001ms]
  Apr 29 12:10:30.630: INFO: Created: latency-svc-wwh2w
  Apr 29 12:10:30.665: INFO: Got endpoints: latency-svc-zmv4w [748.599377ms]
  Apr 29 12:10:30.686: INFO: Created: latency-svc-jm99v
  Apr 29 12:10:30.715: INFO: Got endpoints: latency-svc-5ttqs [748.97066ms]
  Apr 29 12:10:30.730: INFO: Created: latency-svc-n274h
  Apr 29 12:10:30.764: INFO: Got endpoints: latency-svc-wd2mb [749.053027ms]
  Apr 29 12:10:30.775: INFO: Created: latency-svc-zpqvk
  Apr 29 12:10:30.815: INFO: Got endpoints: latency-svc-9m27q [748.53961ms]
  Apr 29 12:10:30.826: INFO: Created: latency-svc-lshcg
  Apr 29 12:10:30.867: INFO: Got endpoints: latency-svc-2gzkg [749.384643ms]
  Apr 29 12:10:30.878: INFO: Created: latency-svc-gpdcb
  Apr 29 12:10:30.916: INFO: Got endpoints: latency-svc-8d29z [750.512621ms]
  Apr 29 12:10:30.928: INFO: Created: latency-svc-fnls7
  Apr 29 12:10:30.965: INFO: Got endpoints: latency-svc-qmj5v [750.054411ms]
  Apr 29 12:10:30.976: INFO: Created: latency-svc-vs2bg
  Apr 29 12:10:31.016: INFO: Got endpoints: latency-svc-ctt4v [747.480235ms]
  Apr 29 12:10:31.027: INFO: Created: latency-svc-fqhwq
  Apr 29 12:10:31.065: INFO: Got endpoints: latency-svc-6tlvc [749.504477ms]
  Apr 29 12:10:31.077: INFO: Created: latency-svc-sggdd
  Apr 29 12:10:31.115: INFO: Got endpoints: latency-svc-jk7mt [750.211741ms]
  Apr 29 12:10:31.127: INFO: Created: latency-svc-rvvlz
  Apr 29 12:10:31.167: INFO: Got endpoints: latency-svc-4wpq5 [751.021065ms]
  Apr 29 12:10:31.177: INFO: Created: latency-svc-jglhz
  Apr 29 12:10:31.216: INFO: Got endpoints: latency-svc-4mx4w [751.160878ms]
  Apr 29 12:10:31.232: INFO: Created: latency-svc-n69s7
  Apr 29 12:10:31.266: INFO: Got endpoints: latency-svc-qwzx7 [751.113908ms]
  Apr 29 12:10:31.277: INFO: Created: latency-svc-b9n79
  Apr 29 12:10:31.317: INFO: Got endpoints: latency-svc-2bbvd [751.106711ms]
  Apr 29 12:10:31.327: INFO: Created: latency-svc-9nwhh
  Apr 29 12:10:31.366: INFO: Got endpoints: latency-svc-wwh2w [751.130315ms]
  Apr 29 12:10:31.379: INFO: Created: latency-svc-ts4l2
  Apr 29 12:10:31.415: INFO: Got endpoints: latency-svc-jm99v [750.717541ms]
  Apr 29 12:10:31.426: INFO: Created: latency-svc-pmjk9
  Apr 29 12:10:31.466: INFO: Got endpoints: latency-svc-n274h [751.340436ms]
  Apr 29 12:10:31.477: INFO: Created: latency-svc-5pk9x
  Apr 29 12:10:31.515: INFO: Got endpoints: latency-svc-zpqvk [750.54578ms]
  Apr 29 12:10:31.528: INFO: Created: latency-svc-t78g6
  Apr 29 12:10:31.565: INFO: Got endpoints: latency-svc-lshcg [750.055591ms]
  Apr 29 12:10:31.575: INFO: Created: latency-svc-qh5kk
  Apr 29 12:10:31.615: INFO: Got endpoints: latency-svc-gpdcb [748.791696ms]
  Apr 29 12:10:31.628: INFO: Created: latency-svc-s2lpn
  Apr 29 12:10:31.667: INFO: Got endpoints: latency-svc-fnls7 [750.814615ms]
  Apr 29 12:10:31.678: INFO: Created: latency-svc-gdqt2
  Apr 29 12:10:31.714: INFO: Got endpoints: latency-svc-vs2bg [748.987809ms]
  Apr 29 12:10:31.725: INFO: Created: latency-svc-dgjxc
  Apr 29 12:10:31.764: INFO: Got endpoints: latency-svc-fqhwq [748.578875ms]
  Apr 29 12:10:31.776: INFO: Created: latency-svc-c44sh
  Apr 29 12:10:31.816: INFO: Got endpoints: latency-svc-sggdd [750.601595ms]
  Apr 29 12:10:31.831: INFO: Created: latency-svc-nzpst
  Apr 29 12:10:31.865: INFO: Got endpoints: latency-svc-rvvlz [749.998176ms]
  Apr 29 12:10:31.876: INFO: Created: latency-svc-5s7dq
  Apr 29 12:10:31.918: INFO: Got endpoints: latency-svc-jglhz [751.300205ms]
  Apr 29 12:10:31.928: INFO: Created: latency-svc-fp5c9
  Apr 29 12:10:31.966: INFO: Got endpoints: latency-svc-n69s7 [750.355941ms]
  Apr 29 12:10:31.978: INFO: Created: latency-svc-ktht7
  Apr 29 12:10:32.017: INFO: Got endpoints: latency-svc-b9n79 [750.842336ms]
  Apr 29 12:10:32.027: INFO: Created: latency-svc-vgm7q
  Apr 29 12:10:32.065: INFO: Got endpoints: latency-svc-9nwhh [748.376317ms]
  Apr 29 12:10:32.077: INFO: Created: latency-svc-rqnfs
  Apr 29 12:10:32.114: INFO: Got endpoints: latency-svc-ts4l2 [748.062521ms]
  Apr 29 12:10:32.127: INFO: Created: latency-svc-qckjq
  Apr 29 12:10:32.164: INFO: Got endpoints: latency-svc-pmjk9 [749.026682ms]
  Apr 29 12:10:32.175: INFO: Created: latency-svc-mzpcq
  Apr 29 12:10:32.215: INFO: Got endpoints: latency-svc-5pk9x [749.45357ms]
  Apr 29 12:10:32.230: INFO: Created: latency-svc-z4jfr
  Apr 29 12:10:32.264: INFO: Got endpoints: latency-svc-t78g6 [749.647792ms]
  Apr 29 12:10:32.274: INFO: Created: latency-svc-8kz5p
  Apr 29 12:10:32.318: INFO: Got endpoints: latency-svc-qh5kk [752.859992ms]
  Apr 29 12:10:32.329: INFO: Created: latency-svc-hwmzs
  Apr 29 12:10:32.367: INFO: Got endpoints: latency-svc-s2lpn [751.869619ms]
  Apr 29 12:10:32.379: INFO: Created: latency-svc-8qfc5
  Apr 29 12:10:32.416: INFO: Got endpoints: latency-svc-gdqt2 [748.861054ms]
  Apr 29 12:10:32.430: INFO: Created: latency-svc-lh8hq
  Apr 29 12:10:32.467: INFO: Got endpoints: latency-svc-dgjxc [752.890276ms]
  Apr 29 12:10:32.479: INFO: Created: latency-svc-dnhrl
  Apr 29 12:10:32.518: INFO: Got endpoints: latency-svc-c44sh [753.891167ms]
  Apr 29 12:10:32.530: INFO: Created: latency-svc-b96cr
  Apr 29 12:10:32.566: INFO: Got endpoints: latency-svc-nzpst [750.189842ms]
  Apr 29 12:10:32.582: INFO: Created: latency-svc-htbxk
  Apr 29 12:10:32.617: INFO: Got endpoints: latency-svc-5s7dq [751.594616ms]
  Apr 29 12:10:32.627: INFO: Created: latency-svc-gknxz
  Apr 29 12:10:32.665: INFO: Got endpoints: latency-svc-fp5c9 [746.55901ms]
  Apr 29 12:10:32.675: INFO: Created: latency-svc-vrqxc
  Apr 29 12:10:32.714: INFO: Got endpoints: latency-svc-ktht7 [747.302993ms]
  Apr 29 12:10:32.724: INFO: Created: latency-svc-mwtx7
  Apr 29 12:10:32.766: INFO: Got endpoints: latency-svc-vgm7q [748.986282ms]
  Apr 29 12:10:32.778: INFO: Created: latency-svc-mkpkg
  Apr 29 12:10:32.814: INFO: Got endpoints: latency-svc-rqnfs [749.270197ms]
  Apr 29 12:10:32.826: INFO: Created: latency-svc-ndvtm
  Apr 29 12:10:32.865: INFO: Got endpoints: latency-svc-qckjq [751.084003ms]
  Apr 29 12:10:32.876: INFO: Created: latency-svc-jsjgk
  Apr 29 12:10:32.917: INFO: Got endpoints: latency-svc-mzpcq [752.676004ms]
  Apr 29 12:10:32.930: INFO: Created: latency-svc-9kn5p
  Apr 29 12:10:32.966: INFO: Got endpoints: latency-svc-z4jfr [750.282783ms]
  Apr 29 12:10:32.977: INFO: Created: latency-svc-qbntd
  Apr 29 12:10:33.015: INFO: Got endpoints: latency-svc-8kz5p [750.505145ms]
  Apr 29 12:10:33.026: INFO: Created: latency-svc-v9dtw
  Apr 29 12:10:33.066: INFO: Got endpoints: latency-svc-hwmzs [747.778788ms]
  Apr 29 12:10:33.077: INFO: Created: latency-svc-bltx7
  Apr 29 12:10:33.115: INFO: Got endpoints: latency-svc-8qfc5 [748.055673ms]
  Apr 29 12:10:33.127: INFO: Created: latency-svc-dvqnb
  Apr 29 12:10:33.166: INFO: Got endpoints: latency-svc-lh8hq [749.910198ms]
  Apr 29 12:10:33.176: INFO: Created: latency-svc-b64fx
  Apr 29 12:10:33.215: INFO: Got endpoints: latency-svc-dnhrl [748.118957ms]
  Apr 29 12:10:33.230: INFO: Created: latency-svc-2qjnh
  Apr 29 12:10:33.268: INFO: Got endpoints: latency-svc-b96cr [749.554525ms]
  Apr 29 12:10:33.279: INFO: Created: latency-svc-npfhf
  Apr 29 12:10:33.315: INFO: Got endpoints: latency-svc-htbxk [749.263608ms]
  Apr 29 12:10:33.326: INFO: Created: latency-svc-mnfxn
  Apr 29 12:10:33.368: INFO: Got endpoints: latency-svc-gknxz [750.706261ms]
  Apr 29 12:10:33.378: INFO: Created: latency-svc-b7bqc
  Apr 29 12:10:33.414: INFO: Got endpoints: latency-svc-vrqxc [749.428423ms]
  Apr 29 12:10:33.425: INFO: Created: latency-svc-5jh4v
  Apr 29 12:10:33.466: INFO: Got endpoints: latency-svc-mwtx7 [752.540593ms]
  Apr 29 12:10:33.480: INFO: Created: latency-svc-f695v
  Apr 29 12:10:33.515: INFO: Got endpoints: latency-svc-mkpkg [748.996844ms]
  Apr 29 12:10:33.527: INFO: Created: latency-svc-gxzpm
  Apr 29 12:10:33.565: INFO: Got endpoints: latency-svc-ndvtm [750.652029ms]
  Apr 29 12:10:33.580: INFO: Created: latency-svc-mcck8
  Apr 29 12:10:33.615: INFO: Got endpoints: latency-svc-jsjgk [750.099806ms]
  Apr 29 12:10:33.627: INFO: Created: latency-svc-skvkv
  Apr 29 12:10:33.667: INFO: Got endpoints: latency-svc-9kn5p [750.202099ms]
  Apr 29 12:10:33.679: INFO: Created: latency-svc-wkldk
  Apr 29 12:10:33.715: INFO: Got endpoints: latency-svc-qbntd [749.06632ms]
  Apr 29 12:10:33.727: INFO: Created: latency-svc-6pgnc
  Apr 29 12:10:33.766: INFO: Got endpoints: latency-svc-v9dtw [751.129135ms]
  Apr 29 12:10:33.777: INFO: Created: latency-svc-z9vd2
  Apr 29 12:10:33.817: INFO: Got endpoints: latency-svc-bltx7 [751.236444ms]
  Apr 29 12:10:33.828: INFO: Created: latency-svc-l2f7h
  Apr 29 12:10:33.869: INFO: Got endpoints: latency-svc-dvqnb [753.55367ms]
  Apr 29 12:10:33.879: INFO: Created: latency-svc-gqvj4
  Apr 29 12:10:33.916: INFO: Got endpoints: latency-svc-b64fx [750.182317ms]
  Apr 29 12:10:33.927: INFO: Created: latency-svc-vv56p
  Apr 29 12:10:33.967: INFO: Got endpoints: latency-svc-2qjnh [751.235908ms]
  Apr 29 12:10:33.978: INFO: Created: latency-svc-8wmbp
  Apr 29 12:10:34.015: INFO: Got endpoints: latency-svc-npfhf [746.537626ms]
  Apr 29 12:10:34.026: INFO: Created: latency-svc-sd6lj
  Apr 29 12:10:34.065: INFO: Got endpoints: latency-svc-mnfxn [749.936999ms]
  Apr 29 12:10:34.077: INFO: Created: latency-svc-2gqcd
  Apr 29 12:10:34.117: INFO: Got endpoints: latency-svc-b7bqc [749.713016ms]
  Apr 29 12:10:34.130: INFO: Created: latency-svc-m7fgw
  Apr 29 12:10:34.167: INFO: Got endpoints: latency-svc-5jh4v [752.249048ms]
  Apr 29 12:10:34.177: INFO: Created: latency-svc-hshng
  Apr 29 12:10:34.215: INFO: Got endpoints: latency-svc-f695v [748.042338ms]
  Apr 29 12:10:34.230: INFO: Created: latency-svc-bmpzx
  Apr 29 12:10:34.266: INFO: Got endpoints: latency-svc-gxzpm [750.979755ms]
  Apr 29 12:10:34.278: INFO: Created: latency-svc-cmsjf
  Apr 29 12:10:34.316: INFO: Got endpoints: latency-svc-mcck8 [750.539683ms]
  Apr 29 12:10:34.328: INFO: Created: latency-svc-q57cv
  Apr 29 12:10:34.366: INFO: Got endpoints: latency-svc-skvkv [750.233421ms]
  Apr 29 12:10:34.377: INFO: Created: latency-svc-xzxk4
  Apr 29 12:10:34.418: INFO: Got endpoints: latency-svc-wkldk [750.62736ms]
  Apr 29 12:10:34.429: INFO: Created: latency-svc-6zr7f
  Apr 29 12:10:34.465: INFO: Got endpoints: latency-svc-6pgnc [750.02201ms]
  Apr 29 12:10:34.477: INFO: Created: latency-svc-x7mvv
  Apr 29 12:10:34.515: INFO: Got endpoints: latency-svc-z9vd2 [749.274234ms]
  Apr 29 12:10:34.527: INFO: Created: latency-svc-94dvz
  Apr 29 12:10:34.571: INFO: Got endpoints: latency-svc-l2f7h [753.983923ms]
  Apr 29 12:10:34.582: INFO: Created: latency-svc-sc4kx
  Apr 29 12:10:34.615: INFO: Got endpoints: latency-svc-gqvj4 [746.084093ms]
  Apr 29 12:10:34.626: INFO: Created: latency-svc-4gzmb
  Apr 29 12:10:34.665: INFO: Got endpoints: latency-svc-vv56p [749.182751ms]
  Apr 29 12:10:34.677: INFO: Created: latency-svc-f6dr5
  Apr 29 12:10:34.715: INFO: Got endpoints: latency-svc-8wmbp [747.734509ms]
  Apr 29 12:10:34.726: INFO: Created: latency-svc-vmk5v
  Apr 29 12:10:34.768: INFO: Got endpoints: latency-svc-sd6lj [753.688697ms]
  Apr 29 12:10:34.779: INFO: Created: latency-svc-4xdnb
  Apr 29 12:10:34.816: INFO: Got endpoints: latency-svc-2gqcd [751.154585ms]
  Apr 29 12:10:34.828: INFO: Created: latency-svc-k4ph4
  Apr 29 12:10:34.868: INFO: Got endpoints: latency-svc-m7fgw [750.984746ms]
  Apr 29 12:10:34.880: INFO: Created: latency-svc-hkkhx
  Apr 29 12:10:34.915: INFO: Got endpoints: latency-svc-hshng [748.316331ms]
  Apr 29 12:10:34.928: INFO: Created: latency-svc-wsgv9
  Apr 29 12:10:34.966: INFO: Got endpoints: latency-svc-bmpzx [751.200734ms]
  Apr 29 12:10:34.979: INFO: Created: latency-svc-4h6rm
  Apr 29 12:10:35.018: INFO: Got endpoints: latency-svc-cmsjf [752.126159ms]
  Apr 29 12:10:35.036: INFO: Created: latency-svc-lpv7p
  Apr 29 12:10:35.072: INFO: Got endpoints: latency-svc-q57cv [756.255643ms]
  Apr 29 12:10:35.117: INFO: Got endpoints: latency-svc-xzxk4 [751.156052ms]
  Apr 29 12:10:35.168: INFO: Got endpoints: latency-svc-6zr7f [749.647515ms]
  Apr 29 12:10:35.216: INFO: Got endpoints: latency-svc-x7mvv [751.2361ms]
  Apr 29 12:10:35.267: INFO: Got endpoints: latency-svc-94dvz [750.730073ms]
  Apr 29 12:10:35.317: INFO: Got endpoints: latency-svc-sc4kx [746.148204ms]
  Apr 29 12:10:35.366: INFO: Got endpoints: latency-svc-4gzmb [751.366544ms]
  Apr 29 12:10:35.417: INFO: Got endpoints: latency-svc-f6dr5 [751.045662ms]
  Apr 29 12:10:35.468: INFO: Got endpoints: latency-svc-vmk5v [753.323741ms]
  Apr 29 12:10:35.515: INFO: Got endpoints: latency-svc-4xdnb [746.578432ms]
  Apr 29 12:10:35.565: INFO: Got endpoints: latency-svc-k4ph4 [748.579243ms]
  Apr 29 12:10:35.615: INFO: Got endpoints: latency-svc-hkkhx [746.74673ms]
  Apr 29 12:10:35.667: INFO: Got endpoints: latency-svc-wsgv9 [751.277007ms]
  Apr 29 12:10:35.715: INFO: Got endpoints: latency-svc-4h6rm [749.238225ms]
  Apr 29 12:10:35.767: INFO: Got endpoints: latency-svc-lpv7p [748.768329ms]
  Apr 29 12:10:35.767: INFO: Latencies: [16.504143ms 55.476976ms 57.115644ms 61.536131ms 66.657313ms 70.813636ms 72.052162ms 78.493282ms 87.073678ms 92.081784ms 100.731028ms 101.484758ms 103.441676ms 104.838312ms 110.685628ms 113.54512ms 117.003775ms 117.56176ms 122.132314ms 123.67169ms 124.212286ms 124.466087ms 129.668161ms 130.747394ms 131.122124ms 132.134515ms 133.223138ms 133.792185ms 138.427282ms 138.561144ms 145.594471ms 146.791301ms 150.543763ms 153.406532ms 153.708533ms 161.719454ms 191.444839ms 231.310913ms 271.961338ms 273.693399ms 300.028075ms 311.775304ms 379.306749ms 499.719132ms 503.37443ms 546.429672ms 617.252458ms 651.252807ms 679.553005ms 746.084093ms 746.148204ms 746.537626ms 746.55901ms 746.578432ms 746.74673ms 746.930039ms 747.302993ms 747.437326ms 747.480235ms 747.734509ms 747.778788ms 748.042338ms 748.055673ms 748.062521ms 748.118957ms 748.160319ms 748.249385ms 748.316331ms 748.376317ms 748.390034ms 748.474845ms 748.53961ms 748.578875ms 748.579243ms 748.599377ms 748.768329ms 748.789072ms 748.791696ms 748.861054ms 748.900328ms 748.97066ms 748.980948ms 748.986282ms 748.987809ms 748.996844ms 749.026682ms 749.053027ms 749.06632ms 749.066375ms 749.101225ms 749.182751ms 749.188557ms 749.238225ms 749.263608ms 749.269001ms 749.270197ms 749.274234ms 749.371806ms 749.384643ms 749.428423ms 749.45357ms 749.483812ms 749.504477ms 749.527027ms 749.546963ms 749.554525ms 749.647515ms 749.647792ms 749.648421ms 749.679706ms 749.713016ms 749.725943ms 749.726726ms 749.810607ms 749.881472ms 749.910198ms 749.936999ms 749.998176ms 750.02201ms 750.024173ms 750.03329ms 750.054411ms 750.055591ms 750.069112ms 750.094002ms 750.099806ms 750.117298ms 750.149134ms 750.182317ms 750.189842ms 750.202099ms 750.211741ms 750.212952ms 750.233421ms 750.282783ms 750.297968ms 750.355941ms 750.400095ms 750.483308ms 750.505145ms 750.512621ms 750.530963ms 750.539683ms 750.54578ms 750.588656ms 750.599958ms 750.601595ms 750.62736ms 750.652029ms 750.665431ms 750.706261ms 750.717541ms 750.730073ms 750.764207ms 750.814615ms 750.842336ms 750.914796ms 750.979755ms 750.984746ms 751.021065ms 751.045662ms 751.049175ms 751.051392ms 751.084003ms 751.106711ms 751.113908ms 751.129135ms 751.130315ms 751.154585ms 751.156052ms 751.160878ms 751.200734ms 751.235908ms 751.2361ms 751.236444ms 751.277007ms 751.300205ms 751.340436ms 751.366544ms 751.406829ms 751.594616ms 751.69044ms 751.869619ms 751.872737ms 752.126159ms 752.249048ms 752.540593ms 752.676004ms 752.859992ms 752.890276ms 753.14707ms 753.323741ms 753.55367ms 753.688697ms 753.891167ms 753.983923ms 756.255643ms 788.831267ms 809.737792ms 841.738059ms]
  Apr 29 12:10:35.767: INFO: 50 %ile: 749.45357ms
  Apr 29 12:10:35.767: INFO: 90 %ile: 751.594616ms
  Apr 29 12:10:35.767: INFO: 99 %ile: 809.737792ms
  Apr 29 12:10:35.768: INFO: Total sample count: 200
  Apr 29 12:10:35.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-9500" for this suite. @ 04/29/23 12:10:35.773
• [10.764 seconds]
------------------------------
S
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:131
  STEP: Creating a kubernetes client @ 04/29/23 12:10:35.782
  Apr 29 12:10:35.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/29/23 12:10:35.782
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:10:35.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:10:35.801
  STEP: creating @ 04/29/23 12:10:35.805
  STEP: getting @ 04/29/23 12:10:35.823
  STEP: listing in namespace @ 04/29/23 12:10:35.827
  STEP: patching @ 04/29/23 12:10:35.831
  STEP: deleting @ 04/29/23 12:10:35.843
  Apr 29 12:10:35.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-6896" for this suite. @ 04/29/23 12:10:35.858
• [0.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 04/29/23 12:10:35.868
  Apr 29 12:10:35.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 12:10:35.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:10:35.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:10:35.893
  STEP: Create a pod @ 04/29/23 12:10:35.897
  STEP: patching /status @ 04/29/23 12:10:37.913
  Apr 29 12:10:37.921: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Apr 29 12:10:37.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8502" for this suite. @ 04/29/23 12:10:37.926
• [2.064 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 04/29/23 12:10:37.932
  Apr 29 12:10:37.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename taint-multiple-pods @ 04/29/23 12:10:37.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:10:37.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:10:37.951
  Apr 29 12:10:37.954: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 29 12:11:37.971: INFO: Waiting for terminating namespaces to be deleted...
  Apr 29 12:11:37.974: INFO: Starting informer...
  STEP: Starting pods... @ 04/29/23 12:11:37.974
  Apr 29 12:11:38.193: INFO: Pod1 is running on ip-172-31-41-80. Tainting Node
  Apr 29 12:11:40.415: INFO: Pod2 is running on ip-172-31-41-80. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/29/23 12:11:40.415
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/29/23 12:11:40.425
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 04/29/23 12:11:40.429
  Apr 29 12:11:45.971: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  Apr 29 12:12:06.007: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Apr 29 12:12:06.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/29/23 12:12:06.022
  STEP: Destroying namespace "taint-multiple-pods-4224" for this suite. @ 04/29/23 12:12:06.026
• [88.101 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 04/29/23 12:12:06.035
  Apr 29 12:12:06.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:12:06.036
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:12:06.054
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:12:06.058
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:12:06.064
  STEP: Saw pod success @ 04/29/23 12:12:10.09
  Apr 29 12:12:10.093: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-0c95323f-451f-436b-a3a6-c9625f79c184 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:12:10.111
  Apr 29 12:12:10.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5370" for this suite. @ 04/29/23 12:12:10.131
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 04/29/23 12:12:10.138
  Apr 29 12:12:10.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename endpointslice @ 04/29/23 12:12:10.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:12:10.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:12:10.158
  STEP: referencing a single matching pod @ 04/29/23 12:12:15.239
  STEP: referencing matching pods with named port @ 04/29/23 12:12:20.249
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 04/29/23 12:12:25.258
  STEP: recreating EndpointSlices after they've been deleted @ 04/29/23 12:12:30.268
  Apr 29 12:12:30.291: INFO: EndpointSlice for Service endpointslice-5323/example-named-port not found
  Apr 29 12:12:40.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5323" for this suite. @ 04/29/23 12:12:40.305
• [30.174 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:523
  STEP: Creating a kubernetes client @ 04/29/23 12:12:40.313
  Apr 29 12:12:40.313: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 12:12:40.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:12:40.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:12:40.333
  STEP: Creating pod test-grpc-46e49c59-3528-4b07-a9c0-ea70389eb4ac in namespace container-probe-7069 @ 04/29/23 12:12:40.336
  Apr 29 12:12:42.354: INFO: Started pod test-grpc-46e49c59-3528-4b07-a9c0-ea70389eb4ac in namespace container-probe-7069
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/29/23 12:12:42.354
  Apr 29 12:12:42.358: INFO: Initial restart count of pod test-grpc-46e49c59-3528-4b07-a9c0-ea70389eb4ac is 0
  Apr 29 12:16:42.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 12:16:42.939
  STEP: Destroying namespace "container-probe-7069" for this suite. @ 04/29/23 12:16:42.953
• [242.647 seconds]
------------------------------
SS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 04/29/23 12:16:42.96
  Apr 29 12:16:42.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename taint-single-pod @ 04/29/23 12:16:42.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:16:42.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:16:42.98
  Apr 29 12:16:42.983: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 29 12:17:43.004: INFO: Waiting for terminating namespaces to be deleted...
  Apr 29 12:17:43.007: INFO: Starting informer...
  STEP: Starting pod... @ 04/29/23 12:17:43.007
  Apr 29 12:17:43.222: INFO: Pod is running on ip-172-31-41-80. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/29/23 12:17:43.222
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/29/23 12:17:43.233
  STEP: Waiting short time to make sure Pod is queued for deletion @ 04/29/23 12:17:43.24
  Apr 29 12:17:43.240: INFO: Pod wasn't evicted. Proceeding
  Apr 29 12:17:43.240: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/29/23 12:17:43.255
  STEP: Waiting some time to make sure that toleration time passed. @ 04/29/23 12:17:43.262
  Apr 29 12:18:58.265: INFO: Pod wasn't evicted. Test successful
  Apr 29 12:18:58.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-8381" for this suite. @ 04/29/23 12:18:58.27
• [135.317 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 04/29/23 12:18:58.279
  Apr 29 12:18:58.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:18:58.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:18:58.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:18:58.298
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/29/23 12:18:58.302
  STEP: Saw pod success @ 04/29/23 12:19:02.326
  Apr 29 12:19:02.330: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-72de4f68-2a9c-479e-aece-fae410d5a261 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:19:02.346
  Apr 29 12:19:02.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7629" for this suite. @ 04/29/23 12:19:02.364
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 04/29/23 12:19:02.374
  Apr 29 12:19:02.374: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename svcaccounts @ 04/29/23 12:19:02.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:02.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:02.392
  STEP: Creating a pod to test service account token:  @ 04/29/23 12:19:02.396
  STEP: Saw pod success @ 04/29/23 12:19:06.423
  Apr 29 12:19:06.426: INFO: Trying to get logs from node ip-172-31-41-80 pod test-pod-344c7985-0cac-4993-a94a-dc82a00262ea container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 12:19:06.434
  Apr 29 12:19:06.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7587" for this suite. @ 04/29/23 12:19:06.454
• [4.087 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 04/29/23 12:19:06.462
  Apr 29 12:19:06.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename dns @ 04/29/23 12:19:06.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:06.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:06.481
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7743.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7743.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 04/29/23 12:19:06.485
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7743.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7743.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 04/29/23 12:19:06.485
  STEP: creating a pod to probe /etc/hosts @ 04/29/23 12:19:06.485
  STEP: submitting the pod to kubernetes @ 04/29/23 12:19:06.485
  STEP: retrieving the pod @ 04/29/23 12:19:08.504
  STEP: looking for the results for each expected name from probers @ 04/29/23 12:19:08.508
  Apr 29 12:19:08.525: INFO: DNS probes using dns-7743/dns-test-4822d49b-5e49-4bf3-8aa5-8f1468187750 succeeded

  Apr 29 12:19:08.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 12:19:08.529
  STEP: Destroying namespace "dns-7743" for this suite. @ 04/29/23 12:19:08.543
• [2.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:122
  STEP: Creating a kubernetes client @ 04/29/23 12:19:08.556
  Apr 29 12:19:08.556: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename discovery @ 04/29/23 12:19:08.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:08.573
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:08.576
  STEP: Setting up server cert @ 04/29/23 12:19:08.581
  Apr 29 12:19:08.918: INFO: Checking APIGroup: apiregistration.k8s.io
  Apr 29 12:19:08.919: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Apr 29 12:19:08.919: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Apr 29 12:19:08.919: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Apr 29 12:19:08.919: INFO: Checking APIGroup: apps
  Apr 29 12:19:08.921: INFO: PreferredVersion.GroupVersion: apps/v1
  Apr 29 12:19:08.921: INFO: Versions found [{apps/v1 v1}]
  Apr 29 12:19:08.921: INFO: apps/v1 matches apps/v1
  Apr 29 12:19:08.921: INFO: Checking APIGroup: events.k8s.io
  Apr 29 12:19:08.922: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Apr 29 12:19:08.922: INFO: Versions found [{events.k8s.io/v1 v1}]
  Apr 29 12:19:08.922: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Apr 29 12:19:08.922: INFO: Checking APIGroup: authentication.k8s.io
  Apr 29 12:19:08.924: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Apr 29 12:19:08.924: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Apr 29 12:19:08.924: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Apr 29 12:19:08.924: INFO: Checking APIGroup: authorization.k8s.io
  Apr 29 12:19:08.925: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Apr 29 12:19:08.925: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Apr 29 12:19:08.925: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Apr 29 12:19:08.925: INFO: Checking APIGroup: autoscaling
  Apr 29 12:19:08.926: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Apr 29 12:19:08.926: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Apr 29 12:19:08.926: INFO: autoscaling/v2 matches autoscaling/v2
  Apr 29 12:19:08.926: INFO: Checking APIGroup: batch
  Apr 29 12:19:08.928: INFO: PreferredVersion.GroupVersion: batch/v1
  Apr 29 12:19:08.928: INFO: Versions found [{batch/v1 v1}]
  Apr 29 12:19:08.928: INFO: batch/v1 matches batch/v1
  Apr 29 12:19:08.928: INFO: Checking APIGroup: certificates.k8s.io
  Apr 29 12:19:08.929: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Apr 29 12:19:08.929: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Apr 29 12:19:08.929: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Apr 29 12:19:08.929: INFO: Checking APIGroup: networking.k8s.io
  Apr 29 12:19:08.930: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Apr 29 12:19:08.930: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Apr 29 12:19:08.930: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Apr 29 12:19:08.930: INFO: Checking APIGroup: policy
  Apr 29 12:19:08.932: INFO: PreferredVersion.GroupVersion: policy/v1
  Apr 29 12:19:08.932: INFO: Versions found [{policy/v1 v1}]
  Apr 29 12:19:08.932: INFO: policy/v1 matches policy/v1
  Apr 29 12:19:08.932: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Apr 29 12:19:08.933: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Apr 29 12:19:08.933: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Apr 29 12:19:08.933: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Apr 29 12:19:08.933: INFO: Checking APIGroup: storage.k8s.io
  Apr 29 12:19:08.934: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Apr 29 12:19:08.934: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Apr 29 12:19:08.934: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Apr 29 12:19:08.934: INFO: Checking APIGroup: admissionregistration.k8s.io
  Apr 29 12:19:08.935: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Apr 29 12:19:08.936: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Apr 29 12:19:08.936: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Apr 29 12:19:08.936: INFO: Checking APIGroup: apiextensions.k8s.io
  Apr 29 12:19:08.937: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Apr 29 12:19:08.937: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Apr 29 12:19:08.937: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Apr 29 12:19:08.937: INFO: Checking APIGroup: scheduling.k8s.io
  Apr 29 12:19:08.938: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Apr 29 12:19:08.938: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Apr 29 12:19:08.938: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Apr 29 12:19:08.938: INFO: Checking APIGroup: coordination.k8s.io
  Apr 29 12:19:08.940: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Apr 29 12:19:08.940: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Apr 29 12:19:08.940: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Apr 29 12:19:08.940: INFO: Checking APIGroup: node.k8s.io
  Apr 29 12:19:08.941: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Apr 29 12:19:08.941: INFO: Versions found [{node.k8s.io/v1 v1}]
  Apr 29 12:19:08.941: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Apr 29 12:19:08.941: INFO: Checking APIGroup: discovery.k8s.io
  Apr 29 12:19:08.942: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Apr 29 12:19:08.942: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Apr 29 12:19:08.942: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Apr 29 12:19:08.942: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Apr 29 12:19:08.944: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Apr 29 12:19:08.944: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Apr 29 12:19:08.944: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Apr 29 12:19:08.944: INFO: Checking APIGroup: metrics.k8s.io
  Apr 29 12:19:08.945: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  Apr 29 12:19:08.945: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  Apr 29 12:19:08.945: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  Apr 29 12:19:08.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1482" for this suite. @ 04/29/23 12:19:08.95
• [0.401 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 04/29/23 12:19:08.957
  Apr 29 12:19:08.957: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:19:08.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:08.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:08.976
  STEP: Creating the pod @ 04/29/23 12:19:08.979
  Apr 29 12:19:11.520: INFO: Successfully updated pod "annotationupdate67215f1f-433c-4f48-bee6-7193d915e91a"
  Apr 29 12:19:13.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4537" for this suite. @ 04/29/23 12:19:13.54
• [4.590 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:485
  STEP: Creating a kubernetes client @ 04/29/23 12:19:13.548
  Apr 29 12:19:13.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename deployment @ 04/29/23 12:19:13.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:13.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:13.569
  STEP: creating a Deployment @ 04/29/23 12:19:13.576
  Apr 29 12:19:13.576: INFO: Creating simple deployment test-deployment-mrx8d
  Apr 29 12:19:13.589: INFO: deployment "test-deployment-mrx8d" doesn't have the required revision set
  STEP: Getting /status @ 04/29/23 12:19:15.605
  Apr 29 12:19:15.608: INFO: Deployment test-deployment-mrx8d has Conditions: [{Available True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mrx8d-5994cf9475" has successfully progressed.}]
  STEP: updating Deployment Status @ 04/29/23 12:19:15.608
  Apr 29 12:19:15.618: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 19, 14, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 19, 14, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 19, 14, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 19, 13, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-mrx8d-5994cf9475\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 04/29/23 12:19:15.618
  Apr 29 12:19:15.620: INFO: Observed &Deployment event: ADDED
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mrx8d-5994cf9475"}
  Apr 29 12:19:15.620: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mrx8d-5994cf9475"}
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 29 12:19:15.620: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-mrx8d-5994cf9475" is progressing.}
  Apr 29 12:19:15.620: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mrx8d-5994cf9475" has successfully progressed.}
  Apr 29 12:19:15.620: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 29 12:19:15.620: INFO: Observed Deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mrx8d-5994cf9475" has successfully progressed.}
  Apr 29 12:19:15.620: INFO: Found Deployment test-deployment-mrx8d in namespace deployment-8232 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 29 12:19:15.620: INFO: Deployment test-deployment-mrx8d has an updated status
  STEP: patching the Statefulset Status @ 04/29/23 12:19:15.62
  Apr 29 12:19:15.620: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 29 12:19:15.627: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 04/29/23 12:19:15.627
  Apr 29 12:19:15.630: INFO: Observed &Deployment event: ADDED
  Apr 29 12:19:15.630: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mrx8d-5994cf9475"}
  Apr 29 12:19:15.630: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.630: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mrx8d-5994cf9475"}
  Apr 29 12:19:15.630: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 29 12:19:15.631: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.631: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 29 12:19:15.631: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:13 +0000 UTC 2023-04-29 12:19:13 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-mrx8d-5994cf9475" is progressing.}
  Apr 29 12:19:15.631: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.631: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 29 12:19:15.631: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mrx8d-5994cf9475" has successfully progressed.}
  Apr 29 12:19:15.631: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.631: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 29 12:19:15.631: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-29 12:19:14 +0000 UTC 2023-04-29 12:19:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mrx8d-5994cf9475" has successfully progressed.}
  Apr 29 12:19:15.631: INFO: Observed deployment test-deployment-mrx8d in namespace deployment-8232 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 29 12:19:15.632: INFO: Observed &Deployment event: MODIFIED
  Apr 29 12:19:15.632: INFO: Found deployment test-deployment-mrx8d in namespace deployment-8232 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Apr 29 12:19:15.632: INFO: Deployment test-deployment-mrx8d has a patched status
  Apr 29 12:19:15.635: INFO: Deployment "test-deployment-mrx8d":
  &Deployment{ObjectMeta:{test-deployment-mrx8d  deployment-8232  9122460c-e2bb-4bf5-bda0-07985fd307ee 10195 1 2023-04-29 12:19:13 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-29 12:19:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-29 12:19:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-29 12:19:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003968348 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-mrx8d-5994cf9475",LastUpdateTime:2023-04-29 12:19:15 +0000 UTC,LastTransitionTime:2023-04-29 12:19:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 29 12:19:15.639: INFO: New ReplicaSet "test-deployment-mrx8d-5994cf9475" of Deployment "test-deployment-mrx8d":
  &ReplicaSet{ObjectMeta:{test-deployment-mrx8d-5994cf9475  deployment-8232  b36d07a0-0653-46dd-8e89-10757abe370a 10190 1 2023-04-29 12:19:13 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-mrx8d 9122460c-e2bb-4bf5-bda0-07985fd307ee 0xc0035a84a0 0xc0035a84a1}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:19:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9122460c-e2bb-4bf5-bda0-07985fd307ee\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:19:14 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 5994cf9475,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035a8548 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:19:15.645: INFO: Pod "test-deployment-mrx8d-5994cf9475-6zg9z" is available:
  &Pod{ObjectMeta:{test-deployment-mrx8d-5994cf9475-6zg9z test-deployment-mrx8d-5994cf9475- deployment-8232  68f5ec6a-7a0b-4a45-bd6b-af29030db3eb 10189 0 2023-04-29 12:19:13 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[] [{apps/v1 ReplicaSet test-deployment-mrx8d-5994cf9475 b36d07a0-0653-46dd-8e89-10757abe370a 0xc0035a88e0 0xc0035a88e1}] [] [{kube-controller-manager Update v1 2023-04-29 12:19:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b36d07a0-0653-46dd-8e89-10757abe370a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:19:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.0\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5cp2w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5cp2w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:19:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:19:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:19:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:19:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:192.168.226.0,StartTime:2023-04-29 12:19:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:19:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://07c24228d8153ac3a7578a36fffbe4589eed57b504c2ac0b28793492354bf1b8,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.226.0,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:19:15.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8232" for this suite. @ 04/29/23 12:19:15.649
• [2.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 04/29/23 12:19:15.657
  Apr 29 12:19:15.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:19:15.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:15.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:15.676
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:19:15.682
  STEP: Saw pod success @ 04/29/23 12:19:19.705
  Apr 29 12:19:19.709: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-38b921c0-7264-4d44-a845-8f7e32276c85 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:19:19.715
  Apr 29 12:19:19.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3011" for this suite. @ 04/29/23 12:19:19.736
• [4.085 seconds]
------------------------------
S
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 04/29/23 12:19:19.743
  Apr 29 12:19:19.743: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename endpointslice @ 04/29/23 12:19:19.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:19.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:19.765
  Apr 29 12:19:19.782: INFO: Endpoints addresses: [172.31.11.190 172.31.34.185] , ports: [6443]
  Apr 29 12:19:19.782: INFO: EndpointSlices addresses: [172.31.11.190 172.31.34.185] , ports: [6443]
  Apr 29 12:19:19.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8921" for this suite. @ 04/29/23 12:19:19.786
• [0.051 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:402
  STEP: Creating a kubernetes client @ 04/29/23 12:19:19.794
  Apr 29 12:19:19.794: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:19:19.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:19.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:19.813
  STEP: Setting up server cert @ 04/29/23 12:19:19.845
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:19:20.264
  STEP: Deploying the webhook pod @ 04/29/23 12:19:20.273
  STEP: Wait for the deployment to be ready @ 04/29/23 12:19:20.294
  Apr 29 12:19:20.302: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:19:22.315
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:19:22.326
  Apr 29 12:19:23.326: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 04/29/23 12:19:23.33
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/29/23 12:19:23.346
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 04/29/23 12:19:23.353
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/29/23 12:19:23.363
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 04/29/23 12:19:23.374
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/29/23 12:19:23.383
  Apr 29 12:19:23.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5366" for this suite. @ 04/29/23 12:19:23.44
  STEP: Destroying namespace "webhook-markers-7920" for this suite. @ 04/29/23 12:19:23.447
• [3.658 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 04/29/23 12:19:23.454
  Apr 29 12:19:23.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename gc @ 04/29/23 12:19:23.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:23.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:23.472
  Apr 29 12:19:23.521: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"8941c98d-ab7f-4361-9fcf-4c1bf79e8311", Controller:(*bool)(0xc00378b47e), BlockOwnerDeletion:(*bool)(0xc00378b47f)}}
  Apr 29 12:19:23.530: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a9b3a048-a37c-4499-b6f6-0866f4997a7b", Controller:(*bool)(0xc00342cd26), BlockOwnerDeletion:(*bool)(0xc00342cd27)}}
  Apr 29 12:19:23.540: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"6053e88d-c618-4365-a280-b8a08af83db9", Controller:(*bool)(0xc00378b6a6), BlockOwnerDeletion:(*bool)(0xc00378b6a7)}}
  Apr 29 12:19:28.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-845" for this suite. @ 04/29/23 12:19:28.565
• [5.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 04/29/23 12:19:28.58
  Apr 29 12:19:28.580: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename watch @ 04/29/23 12:19:28.58
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:28.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:28.601
  STEP: getting a starting resourceVersion @ 04/29/23 12:19:28.605
  STEP: starting a background goroutine to produce watch events @ 04/29/23 12:19:28.609
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 04/29/23 12:19:28.609
  Apr 29 12:19:31.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5969" for this suite. @ 04/29/23 12:19:31.435
• [2.909 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 04/29/23 12:19:31.491
  Apr 29 12:19:31.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename disruption @ 04/29/23 12:19:31.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:31.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:31.513
  STEP: Waiting for the pdb to be processed @ 04/29/23 12:19:31.521
  STEP: Waiting for all pods to be running @ 04/29/23 12:19:33.553
  Apr 29 12:19:33.563: INFO: running pods: 0 < 3
  Apr 29 12:19:35.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6080" for this suite. @ 04/29/23 12:19:35.575
• [4.092 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 04/29/23 12:19:35.583
  Apr 29 12:19:35.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-preemption @ 04/29/23 12:19:35.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:19:35.597
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:19:35.601
  Apr 29 12:19:35.618: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 29 12:20:35.641: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/29/23 12:20:35.645
  Apr 29 12:20:35.645: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/29/23 12:20:35.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:20:35.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:20:35.673
  Apr 29 12:20:35.693: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Apr 29 12:20:35.697: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Apr 29 12:20:35.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 12:20:35.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-9656" for this suite. @ 04/29/23 12:20:35.784
  STEP: Destroying namespace "sched-preemption-2768" for this suite. @ 04/29/23 12:20:35.793
• [60.216 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 04/29/23 12:20:35.8
  Apr 29 12:20:35.800: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 12:20:35.801
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:20:35.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:20:35.825
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-7359 @ 04/29/23 12:20:35.83
  STEP: changing the ExternalName service to type=ClusterIP @ 04/29/23 12:20:35.837
  STEP: creating replication controller externalname-service in namespace services-7359 @ 04/29/23 12:20:35.855
  I0429 12:20:35.873209      18 runners.go:194] Created replication controller with name: externalname-service, namespace: services-7359, replica count: 2
  I0429 12:20:38.925951      18 runners.go:194] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 12:20:38.925: INFO: Creating new exec pod
  Apr 29 12:20:41.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-7359 exec execpodfgdlq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 29 12:20:42.079: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 29 12:20:42.079: INFO: stdout: ""
  Apr 29 12:20:43.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-7359 exec execpodfgdlq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 29 12:20:43.204: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 29 12:20:43.204: INFO: stdout: "externalname-service-2xqlp"
  Apr 29 12:20:43.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-7359 exec execpodfgdlq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.205 80'
  Apr 29 12:20:43.330: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.205 80\nConnection to 10.152.183.205 80 port [tcp/http] succeeded!\n"
  Apr 29 12:20:43.330: INFO: stdout: "externalname-service-2xqlp"
  Apr 29 12:20:43.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 12:20:43.335: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-7359" for this suite. @ 04/29/23 12:20:43.366
• [7.574 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 04/29/23 12:20:43.374
  Apr 29 12:20:43.374: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename namespaces @ 04/29/23 12:20:43.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:20:43.395
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:20:43.399
  STEP: creating a Namespace @ 04/29/23 12:20:43.402
  STEP: patching the Namespace @ 04/29/23 12:20:43.42
  STEP: get the Namespace and ensuring it has the label @ 04/29/23 12:20:43.427
  Apr 29 12:20:43.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-918" for this suite. @ 04/29/23 12:20:43.437
  STEP: Destroying namespace "nspatchtest-3e0dde5b-b7fe-483a-a684-a200a616aa6e-6117" for this suite. @ 04/29/23 12:20:43.445
• [0.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 04/29/23 12:20:43.457
  Apr 29 12:20:43.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename deployment @ 04/29/23 12:20:43.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:20:43.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:20:43.48
  Apr 29 12:20:43.483: INFO: Creating simple deployment test-new-deployment
  Apr 29 12:20:43.501: INFO: deployment "test-new-deployment" doesn't have the required revision set
  STEP: getting scale subresource @ 04/29/23 12:20:45.516
  STEP: updating a scale subresource @ 04/29/23 12:20:45.519
  STEP: verifying the deployment Spec.Replicas was modified @ 04/29/23 12:20:45.526
  STEP: Patch a scale subresource @ 04/29/23 12:20:45.53
  Apr 29 12:20:45.556: INFO: Deployment "test-new-deployment":
  &Deployment{ObjectMeta:{test-new-deployment  deployment-282  cece2b8d-2570-47e0-a85f-6e1aa4860317 10938 3 2023-04-29 12:20:43 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-29 12:20:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005046808 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-29 12:20:44 +0000 UTC,LastTransitionTime:2023-04-29 12:20:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-67bd4bf6dc" has successfully progressed.,LastUpdateTime:2023-04-29 12:20:44 +0000 UTC,LastTransitionTime:2023-04-29 12:20:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 29 12:20:45.572: INFO: New ReplicaSet "test-new-deployment-67bd4bf6dc" of Deployment "test-new-deployment":
  &ReplicaSet{ObjectMeta:{test-new-deployment-67bd4bf6dc  deployment-282  9586efa8-7677-4e56-b382-7b93d15252bd 10944 2 2023-04-29 12:20:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment cece2b8d-2570-47e0-a85f-6e1aa4860317 0xc0051aee67 0xc0051aee68}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:20:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cece2b8d-2570-47e0-a85f-6e1aa4860317\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:20:45 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 67bd4bf6dc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0051aeef8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:20:45.579: INFO: Pod "test-new-deployment-67bd4bf6dc-nppzf" is not available:
  &Pod{ObjectMeta:{test-new-deployment-67bd4bf6dc-nppzf test-new-deployment-67bd4bf6dc- deployment-282  e9ff665a-5231-416e-9666-fcdd8a98cb4a 10946 0 2023-04-29 12:20:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet test-new-deployment-67bd4bf6dc 9586efa8-7677-4e56-b382-7b93d15252bd 0xc005046bc7 0xc005046bc8}] [] [{kube-controller-manager Update v1 2023-04-29 12:20:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9586efa8-7677-4e56-b382-7b93d15252bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:20:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hwv7p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hwv7p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:20:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:20:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:20:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:20:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.82.46,PodIP:,StartTime:2023-04-29 12:20:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:20:45.579: INFO: Pod "test-new-deployment-67bd4bf6dc-p42w5" is available:
  &Pod{ObjectMeta:{test-new-deployment-67bd4bf6dc-p42w5 test-new-deployment-67bd4bf6dc- deployment-282  5f1f7018-28c2-40f8-8020-fdb593a3a340 10933 0 2023-04-29 12:20:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet test-new-deployment-67bd4bf6dc 9586efa8-7677-4e56-b382-7b93d15252bd 0xc005046d97 0xc005046d98}] [] [{kube-controller-manager Update v1 2023-04-29 12:20:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9586efa8-7677-4e56-b382-7b93d15252bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:20:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p2bgr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p2bgr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:20:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:20:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:20:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:20:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:192.168.226.11,StartTime:2023-04-29 12:20:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:20:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://902fa695afaec2fba853c28118ab870714d45ff5d5f68086b83cb1b60a89916b,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.226.11,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:20:45.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-282" for this suite. @ 04/29/23 12:20:45.584
• [2.144 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 04/29/23 12:20:45.601
  Apr 29 12:20:45.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:20:45.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:20:45.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:20:45.63
  STEP: Creating configMap with name configmap-test-volume-660a7b39-e001-4f9d-bbdc-1b8d6bde4ef2 @ 04/29/23 12:20:45.634
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:20:45.639
  STEP: Saw pod success @ 04/29/23 12:20:49.662
  Apr 29 12:20:49.667: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-927033dc-5c59-43bf-b8a0-cd150017c5ec container configmap-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:20:49.674
  Apr 29 12:20:49.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4816" for this suite. @ 04/29/23 12:20:49.697
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:825
  STEP: Creating a kubernetes client @ 04/29/23 12:20:49.707
  Apr 29 12:20:49.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename daemonsets @ 04/29/23 12:20:49.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:20:49.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:20:49.737
  STEP: Creating simple DaemonSet "daemon-set" @ 04/29/23 12:20:49.782
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/29/23 12:20:49.787
  Apr 29 12:20:49.794: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:20:49.794: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:20:49.798: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 12:20:49.798: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 12:20:50.802: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:20:50.802: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:20:50.807: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 29 12:20:50.807: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 12:20:51.803: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:20:51.803: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 12:20:51.808: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 12:20:51.808: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 04/29/23 12:20:51.811
  STEP: DeleteCollection of the DaemonSets @ 04/29/23 12:20:51.815
  STEP: Verify that ReplicaSets have been deleted @ 04/29/23 12:20:51.83
  Apr 29 12:20:51.854: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11145"},"items":null}

  Apr 29 12:20:51.862: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11145"},"items":[{"metadata":{"name":"daemon-set-msw75","generateName":"daemon-set-","namespace":"daemonsets-7964","uid":"10b9b066-8198-48c2-bc42-93282fddae03","resourceVersion":"11141","creationTimestamp":"2023-04-29T12:20:49Z","deletionTimestamp":"2023-04-29T12:21:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a496de3d-db5c-41d5-901a-f310ba654d0d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-29T12:20:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a496de3d-db5c-41d5-901a-f310ba654d0d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-29T12:20:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.189.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-nqqn6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-nqqn6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-25-13","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-25-13"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:49Z"}],"hostIP":"172.31.25.13","podIP":"192.168.189.144","podIPs":[{"ip":"192.168.189.144"}],"startTime":"2023-04-29T12:20:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-29T12:20:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://e6b4a54661bafdb5947053270dd852e4fc6d0b846e9b84420b1c8768fe719b13","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-r6hh6","generateName":"daemon-set-","namespace":"daemonsets-7964","uid":"5de10509-2d65-4883-b66f-221f01a6c401","resourceVersion":"11142","creationTimestamp":"2023-04-29T12:20:49Z","deletionTimestamp":"2023-04-29T12:21:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a496de3d-db5c-41d5-901a-f310ba654d0d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-29T12:20:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a496de3d-db5c-41d5-901a-f310ba654d0d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-29T12:20:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.13\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-mnlqj","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-mnlqj","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-41-80","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-41-80"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:49Z"}],"hostIP":"172.31.41.80","podIP":"192.168.226.13","podIPs":[{"ip":"192.168.226.13"}],"startTime":"2023-04-29T12:20:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-29T12:20:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://8affcf653d745f9e74a03edd1fdc38eabc10697578b91e269983d7ad184e546c","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-rh2c7","generateName":"daemon-set-","namespace":"daemonsets-7964","uid":"52065202-b8cf-4952-8001-8957737be263","resourceVersion":"11144","creationTimestamp":"2023-04-29T12:20:49Z","deletionTimestamp":"2023-04-29T12:21:21Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a496de3d-db5c-41d5-901a-f310ba654d0d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-29T12:20:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a496de3d-db5c-41d5-901a-f310ba654d0d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-29T12:20:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.69.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-kdxjd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-kdxjd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-82-46","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-82-46"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-29T12:20:49Z"}],"hostIP":"172.31.82.46","podIP":"192.168.69.216","podIPs":[{"ip":"192.168.69.216"}],"startTime":"2023-04-29T12:20:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-29T12:20:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://3061867c86cdf83c6ab5a14f2d2a14b5fa1a8a1b5baba640de222e9c94e7ac00","started":true}],"qosClass":"BestEffort"}}]}

  Apr 29 12:20:51.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7964" for this suite. @ 04/29/23 12:20:51.883
• [2.184 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 04/29/23 12:20:51.895
  Apr 29 12:20:51.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 12:20:51.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:20:51.934
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:20:51.947
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/29/23 12:20:51.959
  Apr 29 12:20:51.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-2602 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 29 12:20:52.063: INFO: stderr: ""
  Apr 29 12:20:52.063: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 04/29/23 12:20:52.063
  Apr 29 12:20:52.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-2602 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
  Apr 29 12:20:52.191: INFO: stderr: ""
  Apr 29 12:20:52.191: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/29/23 12:20:52.191
  Apr 29 12:20:52.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-2602 delete pods e2e-test-httpd-pod'
  Apr 29 12:20:53.991: INFO: stderr: ""
  Apr 29 12:20:53.991: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 29 12:20:53.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2602" for this suite. @ 04/29/23 12:20:53.995
• [2.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 04/29/23 12:20:54.004
  Apr 29 12:20:54.004: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:20:54.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:20:54.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:20:54.022
  STEP: Creating configMap with name cm-test-opt-del-d611948f-2923-4a40-9e01-ffa32bb9c7e2 @ 04/29/23 12:20:54.03
  STEP: Creating configMap with name cm-test-opt-upd-3b78a8f2-19fc-4875-9493-b4194a05bd63 @ 04/29/23 12:20:54.034
  STEP: Creating the pod @ 04/29/23 12:20:54.04
  STEP: Deleting configmap cm-test-opt-del-d611948f-2923-4a40-9e01-ffa32bb9c7e2 @ 04/29/23 12:20:56.084
  STEP: Updating configmap cm-test-opt-upd-3b78a8f2-19fc-4875-9493-b4194a05bd63 @ 04/29/23 12:20:56.091
  STEP: Creating configMap with name cm-test-opt-create-70ca0213-71b5-455b-9c93-2e717db3dfce @ 04/29/23 12:20:56.096
  STEP: waiting to observe update in volume @ 04/29/23 12:20:56.102
  Apr 29 12:22:06.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5145" for this suite. @ 04/29/23 12:22:06.422
• [72.425 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 04/29/23 12:22:06.429
  Apr 29 12:22:06.429: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename job @ 04/29/23 12:22:06.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:06.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:06.449
  STEP: Creating a job @ 04/29/23 12:22:06.453
  STEP: Ensuring job reaches completions @ 04/29/23 12:22:06.459
  Apr 29 12:22:16.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7012" for this suite. @ 04/29/23 12:22:16.469
• [10.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:645
  STEP: Creating a kubernetes client @ 04/29/23 12:22:16.478
  Apr 29 12:22:16.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:22:16.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:16.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:16.498
  STEP: Setting up server cert @ 04/29/23 12:22:16.521
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:22:16.886
  STEP: Deploying the webhook pod @ 04/29/23 12:22:16.894
  STEP: Wait for the deployment to be ready @ 04/29/23 12:22:16.906
  Apr 29 12:22:16.924: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:22:18.936
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:22:18.95
  Apr 29 12:22:19.950: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/29/23 12:22:20.016
  STEP: Creating a configMap that should be mutated @ 04/29/23 12:22:20.027
  STEP: Deleting the collection of validation webhooks @ 04/29/23 12:22:20.053
  STEP: Creating a configMap that should not be mutated @ 04/29/23 12:22:20.104
  Apr 29 12:22:20.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3900" for this suite. @ 04/29/23 12:22:20.165
  STEP: Destroying namespace "webhook-markers-9615" for this suite. @ 04/29/23 12:22:20.173
• [3.704 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 04/29/23 12:22:20.183
  Apr 29 12:22:20.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 12:22:20.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:20.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:20.202
  Apr 29 12:22:20.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 04/29/23 12:22:21.524
  Apr 29 12:22:21.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 create -f -'
  Apr 29 12:22:22.254: INFO: stderr: ""
  Apr 29 12:22:22.254: INFO: stdout: "e2e-test-crd-publish-openapi-3567-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 29 12:22:22.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 delete e2e-test-crd-publish-openapi-3567-crds test-foo'
  Apr 29 12:22:22.322: INFO: stderr: ""
  Apr 29 12:22:22.322: INFO: stdout: "e2e-test-crd-publish-openapi-3567-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Apr 29 12:22:22.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 apply -f -'
  Apr 29 12:22:22.895: INFO: stderr: ""
  Apr 29 12:22:22.895: INFO: stdout: "e2e-test-crd-publish-openapi-3567-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 29 12:22:22.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 delete e2e-test-crd-publish-openapi-3567-crds test-foo'
  Apr 29 12:22:22.961: INFO: stderr: ""
  Apr 29 12:22:22.961: INFO: stdout: "e2e-test-crd-publish-openapi-3567-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 04/29/23 12:22:22.961
  Apr 29 12:22:22.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 create -f -'
  Apr 29 12:22:23.183: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 04/29/23 12:22:23.183
  Apr 29 12:22:23.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 create -f -'
  Apr 29 12:22:23.425: INFO: rc: 1
  Apr 29 12:22:23.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 apply -f -'
  Apr 29 12:22:23.616: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 04/29/23 12:22:23.616
  Apr 29 12:22:23.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 create -f -'
  Apr 29 12:22:23.804: INFO: rc: 1
  Apr 29 12:22:23.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 --namespace=crd-publish-openapi-2640 apply -f -'
  Apr 29 12:22:24.001: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 04/29/23 12:22:24.001
  Apr 29 12:22:24.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 explain e2e-test-crd-publish-openapi-3567-crds'
  Apr 29 12:22:24.187: INFO: stderr: ""
  Apr 29 12:22:24.187: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3567-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 04/29/23 12:22:24.187
  Apr 29 12:22:24.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 explain e2e-test-crd-publish-openapi-3567-crds.metadata'
  Apr 29 12:22:24.375: INFO: stderr: ""
  Apr 29 12:22:24.375: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3567-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Apr 29 12:22:24.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 explain e2e-test-crd-publish-openapi-3567-crds.spec'
  Apr 29 12:22:24.561: INFO: stderr: ""
  Apr 29 12:22:24.561: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3567-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Apr 29 12:22:24.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 explain e2e-test-crd-publish-openapi-3567-crds.spec.bars'
  Apr 29 12:22:24.742: INFO: stderr: ""
  Apr 29 12:22:24.742: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-3567-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 04/29/23 12:22:24.742
  Apr 29 12:22:24.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-2640 explain e2e-test-crd-publish-openapi-3567-crds.spec.bars2'
  Apr 29 12:22:24.926: INFO: rc: 1
  Apr 29 12:22:26.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2640" for this suite. @ 04/29/23 12:22:26.281
• [6.105 seconds]
------------------------------
S
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 04/29/23 12:22:26.287
  Apr 29 12:22:26.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename job @ 04/29/23 12:22:26.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:26.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:26.31
  STEP: Creating Indexed job @ 04/29/23 12:22:26.314
  STEP: Ensuring job reaches completions @ 04/29/23 12:22:26.319
  STEP: Ensuring pods with index for job exist @ 04/29/23 12:22:36.324
  Apr 29 12:22:36.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5978" for this suite. @ 04/29/23 12:22:36.333
• [10.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 04/29/23 12:22:36.34
  Apr 29 12:22:36.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:22:36.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:36.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:36.358
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:22:36.362
  STEP: Saw pod success @ 04/29/23 12:22:40.384
  Apr 29 12:22:40.388: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-2cf42e00-252e-4708-8d33-58e00bd8f92c container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:22:40.395
  Apr 29 12:22:40.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3368" for this suite. @ 04/29/23 12:22:40.424
• [4.091 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 04/29/23 12:22:40.432
  Apr 29 12:22:40.432: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename proxy @ 04/29/23 12:22:40.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:40.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:40.45
  Apr 29 12:22:40.455: INFO: Creating pod...
  Apr 29 12:22:42.472: INFO: Creating service...
  Apr 29 12:22:42.484: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/pods/agnhost/proxy/some/path/with/DELETE
  Apr 29 12:22:42.491: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 29 12:22:42.491: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/pods/agnhost/proxy/some/path/with/GET
  Apr 29 12:22:42.496: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 29 12:22:42.496: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/pods/agnhost/proxy/some/path/with/HEAD
  Apr 29 12:22:42.500: INFO: http.Client request:HEAD | StatusCode:200
  Apr 29 12:22:42.500: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/pods/agnhost/proxy/some/path/with/OPTIONS
  Apr 29 12:22:42.504: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 29 12:22:42.504: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/pods/agnhost/proxy/some/path/with/PATCH
  Apr 29 12:22:42.508: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 29 12:22:42.508: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/pods/agnhost/proxy/some/path/with/POST
  Apr 29 12:22:42.512: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 29 12:22:42.512: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/pods/agnhost/proxy/some/path/with/PUT
  Apr 29 12:22:42.516: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 29 12:22:42.516: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/services/test-service/proxy/some/path/with/DELETE
  Apr 29 12:22:42.521: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 29 12:22:42.521: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/services/test-service/proxy/some/path/with/GET
  Apr 29 12:22:42.527: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 29 12:22:42.527: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/services/test-service/proxy/some/path/with/HEAD
  Apr 29 12:22:42.533: INFO: http.Client request:HEAD | StatusCode:200
  Apr 29 12:22:42.533: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/services/test-service/proxy/some/path/with/OPTIONS
  Apr 29 12:22:42.538: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 29 12:22:42.538: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/services/test-service/proxy/some/path/with/PATCH
  Apr 29 12:22:42.543: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 29 12:22:42.543: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/services/test-service/proxy/some/path/with/POST
  Apr 29 12:22:42.549: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 29 12:22:42.549: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-182/services/test-service/proxy/some/path/with/PUT
  Apr 29 12:22:42.553: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 29 12:22:42.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-182" for this suite. @ 04/29/23 12:22:42.558
• [2.132 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 04/29/23 12:22:42.567
  Apr 29 12:22:42.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:22:42.568
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:42.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:42.587
  STEP: Creating configMap configmap-2444/configmap-test-21820129-0be5-482f-a544-2034aa1ec632 @ 04/29/23 12:22:42.591
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:22:42.596
  STEP: Saw pod success @ 04/29/23 12:22:46.619
  Apr 29 12:22:46.623: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-d9ab554e-dbe4-4afd-be23-e836a125250b container env-test: <nil>
  STEP: delete the pod @ 04/29/23 12:22:46.63
  Apr 29 12:22:46.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2444" for this suite. @ 04/29/23 12:22:46.652
• [4.091 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 04/29/23 12:22:46.659
  Apr 29 12:22:46.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 12:22:46.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:46.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:46.678
  STEP: creating the pod @ 04/29/23 12:22:46.681
  STEP: submitting the pod to kubernetes @ 04/29/23 12:22:46.681
  W0429 12:22:46.690107      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: verifying the pod is in kubernetes @ 04/29/23 12:22:48.705
  STEP: updating the pod @ 04/29/23 12:22:48.709
  Apr 29 12:22:49.222: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c76cd3c5-bd15-4c41-b8ff-1f73d6d9aca6"
  Apr 29 12:22:53.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7781" for this suite. @ 04/29/23 12:22:53.239
• [6.587 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 04/29/23 12:22:53.246
  Apr 29 12:22:53.246: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:22:53.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:53.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:53.265
  STEP: Creating projection with secret that has name projected-secret-test-map-88f170e3-8a66-431f-97e7-12d92e20b393 @ 04/29/23 12:22:53.268
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:22:53.274
  STEP: Saw pod success @ 04/29/23 12:22:57.301
  Apr 29 12:22:57.306: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-secrets-aa367956-94d7-47cd-a1ca-6d626beeebc3 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:22:57.314
  Apr 29 12:22:57.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9840" for this suite. @ 04/29/23 12:22:57.34
• [4.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1640
  STEP: Creating a kubernetes client @ 04/29/23 12:22:57.349
  Apr 29 12:22:57.349: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 12:22:57.349
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:57.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:57.381
  STEP: creating Agnhost RC @ 04/29/23 12:22:57.386
  Apr 29 12:22:57.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-7309 create -f -'
  Apr 29 12:22:58.530: INFO: stderr: ""
  Apr 29 12:22:58.530: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/29/23 12:22:58.53
  Apr 29 12:22:59.537: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 29 12:22:59.537: INFO: Found 1 / 1
  Apr 29 12:22:59.537: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 04/29/23 12:22:59.537
  Apr 29 12:22:59.541: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 29 12:22:59.541: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 29 12:22:59.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-7309 patch pod agnhost-primary-4cqmf -p {"metadata":{"annotations":{"x":"y"}}}'
  Apr 29 12:22:59.608: INFO: stderr: ""
  Apr 29 12:22:59.608: INFO: stdout: "pod/agnhost-primary-4cqmf patched\n"
  STEP: checking annotations @ 04/29/23 12:22:59.608
  Apr 29 12:22:59.612: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 29 12:22:59.612: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 29 12:22:59.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7309" for this suite. @ 04/29/23 12:22:59.616
• [2.274 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 04/29/23 12:22:59.624
  Apr 29 12:22:59.624: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replicaset @ 04/29/23 12:22:59.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:22:59.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:22:59.645
  STEP: Create a ReplicaSet @ 04/29/23 12:22:59.648
  STEP: Verify that the required pods have come up @ 04/29/23 12:22:59.653
  Apr 29 12:22:59.656: INFO: Pod name sample-pod: Found 0 pods out of 3
  Apr 29 12:23:04.667: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 04/29/23 12:23:04.667
  Apr 29 12:23:04.671: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 04/29/23 12:23:04.671
  STEP: DeleteCollection of the ReplicaSets @ 04/29/23 12:23:04.675
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 04/29/23 12:23:04.684
  Apr 29 12:23:04.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7717" for this suite. @ 04/29/23 12:23:04.694
• [5.083 seconds]
------------------------------
SSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 04/29/23 12:23:04.708
  Apr 29 12:23:04.708: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename events @ 04/29/23 12:23:04.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:04.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:04.726
  STEP: Create set of events @ 04/29/23 12:23:04.73
  Apr 29 12:23:04.735: INFO: created test-event-1
  Apr 29 12:23:04.740: INFO: created test-event-2
  Apr 29 12:23:04.745: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 04/29/23 12:23:04.746
  STEP: delete collection of events @ 04/29/23 12:23:04.75
  Apr 29 12:23:04.750: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/29/23 12:23:04.775
  Apr 29 12:23:04.775: INFO: requesting list of events to confirm quantity
  Apr 29 12:23:04.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7033" for this suite. @ 04/29/23 12:23:04.783
• [0.081 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 04/29/23 12:23:04.79
  Apr 29 12:23:04.790: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:23:04.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:04.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:04.816
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/29/23 12:23:04.819
  STEP: Saw pod success @ 04/29/23 12:23:08.842
  Apr 29 12:23:08.846: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-6527945f-0bb3-43fb-a3b9-364b9087ed19 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:23:08.853
  Apr 29 12:23:08.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-970" for this suite. @ 04/29/23 12:23:08.875
• [4.092 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 04/29/23 12:23:08.883
  Apr 29 12:23:08.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:23:08.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:08.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:08.902
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:23:08.905
  STEP: Saw pod success @ 04/29/23 12:23:12.931
  Apr 29 12:23:12.935: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-5b022c5a-095e-49d1-9be5-2b4fe7d19a84 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:23:12.941
  Apr 29 12:23:12.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5088" for this suite. @ 04/29/23 12:23:12.971
• [4.095 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 04/29/23 12:23:12.978
  Apr 29 12:23:12.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename lease-test @ 04/29/23 12:23:12.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:12.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:12.998
  Apr 29 12:23:13.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-4761" for this suite. @ 04/29/23 12:23:13.081
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 04/29/23 12:23:13.095
  Apr 29 12:23:13.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename cronjob @ 04/29/23 12:23:13.096
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:13.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:13.122
  STEP: Creating a cronjob @ 04/29/23 12:23:13.126
  STEP: creating @ 04/29/23 12:23:13.126
  STEP: getting @ 04/29/23 12:23:13.133
  STEP: listing @ 04/29/23 12:23:13.142
  STEP: watching @ 04/29/23 12:23:13.146
  Apr 29 12:23:13.146: INFO: starting watch
  STEP: cluster-wide listing @ 04/29/23 12:23:13.147
  STEP: cluster-wide watching @ 04/29/23 12:23:13.151
  Apr 29 12:23:13.151: INFO: starting watch
  STEP: patching @ 04/29/23 12:23:13.152
  STEP: updating @ 04/29/23 12:23:13.159
  Apr 29 12:23:13.168: INFO: waiting for watch events with expected annotations
  Apr 29 12:23:13.168: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/29/23 12:23:13.168
  STEP: updating /status @ 04/29/23 12:23:13.174
  STEP: get /status @ 04/29/23 12:23:13.181
  STEP: deleting @ 04/29/23 12:23:13.185
  STEP: deleting a collection @ 04/29/23 12:23:13.2
  Apr 29 12:23:13.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-440" for this suite. @ 04/29/23 12:23:13.215
• [0.127 seconds]
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 04/29/23 12:23:13.222
  Apr 29 12:23:13.222: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubelet-test @ 04/29/23 12:23:13.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:13.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:13.24
  Apr 29 12:23:15.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3536" for this suite. @ 04/29/23 12:23:15.275
• [2.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 04/29/23 12:23:15.284
  Apr 29 12:23:15.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 12:23:15.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:15.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:15.303
  STEP: set up a multi version CRD @ 04/29/23 12:23:15.306
  Apr 29 12:23:15.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: rename a version @ 04/29/23 12:23:18.711
  STEP: check the new version name is served @ 04/29/23 12:23:18.73
  STEP: check the old version name is removed @ 04/29/23 12:23:20.016
  STEP: check the other version is not changed @ 04/29/23 12:23:20.713
  Apr 29 12:23:23.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-655" for this suite. @ 04/29/23 12:23:23.448
• [8.171 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 04/29/23 12:23:23.455
  Apr 29 12:23:23.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:23:23.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:23.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:23.476
  STEP: Creating a pod to test downward api env vars @ 04/29/23 12:23:23.478
  STEP: Saw pod success @ 04/29/23 12:23:27.498
  Apr 29 12:23:27.502: INFO: Trying to get logs from node ip-172-31-41-80 pod downward-api-6c6fabe6-1114-43ab-9db0-c9af7720a383 container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 12:23:27.517
  Apr 29 12:23:27.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7066" for this suite. @ 04/29/23 12:23:27.536
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 04/29/23 12:23:27.542
  Apr 29 12:23:27.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:23:27.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:27.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:27.561
  STEP: Creating configMap with name projected-configmap-test-volume-8ea07528-2b5b-460d-bfa1-31f6024ddc1b @ 04/29/23 12:23:27.564
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:23:27.569
  STEP: Saw pod success @ 04/29/23 12:23:31.589
  Apr 29 12:23:31.591: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-configmaps-1e5a4a29-0f04-4076-a661-9e31a0b9e034 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:23:31.599
  Apr 29 12:23:31.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8520" for this suite. @ 04/29/23 12:23:31.619
• [4.083 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 04/29/23 12:23:31.626
  Apr 29 12:23:31.626: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename gc @ 04/29/23 12:23:31.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:31.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:31.647
  STEP: create the deployment @ 04/29/23 12:23:31.649
  W0429 12:23:31.655074      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/29/23 12:23:31.655
  STEP: delete the deployment @ 04/29/23 12:23:32.161
  STEP: wait for all rs to be garbage collected @ 04/29/23 12:23:32.17
  STEP: expected 0 rs, got 1 rs @ 04/29/23 12:23:32.177
  STEP: expected 0 pods, got 2 pods @ 04/29/23 12:23:32.18
  STEP: Gathering metrics @ 04/29/23 12:23:32.689
  W0429 12:23:32.693135      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 29 12:23:32.693: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 29 12:23:32.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1327" for this suite. @ 04/29/23 12:23:32.698
• [1.079 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 04/29/23 12:23:32.706
  Apr 29 12:23:32.706: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename tables @ 04/29/23 12:23:32.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:32.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:32.728
  Apr 29 12:23:32.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-3511" for this suite. @ 04/29/23 12:23:32.738
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:209
  STEP: Creating a kubernetes client @ 04/29/23 12:23:32.749
  Apr 29 12:23:32.749: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:23:32.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:32.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:32.778
  STEP: Setting up server cert @ 04/29/23 12:23:32.807
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:23:33.053
  STEP: Deploying the webhook pod @ 04/29/23 12:23:33.061
  STEP: Wait for the deployment to be ready @ 04/29/23 12:23:33.071
  Apr 29 12:23:33.078: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:23:35.089
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:23:35.099
  Apr 29 12:23:36.100: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/29/23 12:23:36.104
  STEP: create a pod @ 04/29/23 12:23:36.119
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 04/29/23 12:23:38.133
  Apr 29 12:23:38.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=webhook-9341 attach --namespace=webhook-9341 to-be-attached-pod -i -c=container1'
  Apr 29 12:23:38.202: INFO: rc: 1
  Apr 29 12:23:38.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9341" for this suite. @ 04/29/23 12:23:38.248
  STEP: Destroying namespace "webhook-markers-7198" for this suite. @ 04/29/23 12:23:38.261
• [5.518 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 04/29/23 12:23:38.267
  Apr 29 12:23:38.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename deployment @ 04/29/23 12:23:38.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:38.284
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:38.287
  Apr 29 12:23:38.290: INFO: Creating deployment "test-recreate-deployment"
  Apr 29 12:23:38.296: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Apr 29 12:23:38.303: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
  Apr 29 12:23:40.309: INFO: Waiting deployment "test-recreate-deployment" to complete
  Apr 29 12:23:40.312: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Apr 29 12:23:40.322: INFO: Updating deployment test-recreate-deployment
  Apr 29 12:23:40.322: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Apr 29 12:23:40.400: INFO: Deployment "test-recreate-deployment":
  &Deployment{ObjectMeta:{test-recreate-deployment  deployment-2404  bb6e5bfb-b86b-429f-afee-009550809c41 12760 2 2023-04-29 12:23:38 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-29 12:23:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:23:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034768e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-29 12:23:40 +0000 UTC,LastTransitionTime:2023-04-29 12:23:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-54757ffd6c" is progressing.,LastUpdateTime:2023-04-29 12:23:40 +0000 UTC,LastTransitionTime:2023-04-29 12:23:38 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

  Apr 29 12:23:40.403: INFO: New ReplicaSet "test-recreate-deployment-54757ffd6c" of Deployment "test-recreate-deployment":
  &ReplicaSet{ObjectMeta:{test-recreate-deployment-54757ffd6c  deployment-2404  d52f1627-7719-4025-853a-106b54540a5f 12757 1 2023-04-29 12:23:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment bb6e5bfb-b86b-429f-afee-009550809c41 0xc003b0d5e7 0xc003b0d5e8}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:23:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb6e5bfb-b86b-429f-afee-009550809c41\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:23:40 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 54757ffd6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b0d688 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:23:40.403: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Apr 29 12:23:40.404: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-6c99bf8bf6  deployment-2404  203065ea-01e5-406b-a6f3-7ad3576c4480 12748 2 2023-04-29 12:23:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6c99bf8bf6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment bb6e5bfb-b86b-429f-afee-009550809c41 0xc003b0d6f7 0xc003b0d6f8}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:23:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb6e5bfb-b86b-429f-afee-009550809c41\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:23:40 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6c99bf8bf6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6c99bf8bf6] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b0d7b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:23:40.406: INFO: Pod "test-recreate-deployment-54757ffd6c-9lf9s" is not available:
  &Pod{ObjectMeta:{test-recreate-deployment-54757ffd6c-9lf9s test-recreate-deployment-54757ffd6c- deployment-2404  62212b42-2e8c-40ec-8871-d2a980ccabd2 12759 0 2023-04-29 12:23:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[] [{apps/v1 ReplicaSet test-recreate-deployment-54757ffd6c d52f1627-7719-4025-853a-106b54540a5f 0xc003476ee7 0xc003476ee8}] [] [{kube-controller-manager Update v1 2023-04-29 12:23:40 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d52f1627-7719-4025-853a-106b54540a5f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:23:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-thmh9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-thmh9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:23:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:23:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:23:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:23:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:,StartTime:2023-04-29 12:23:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:23:40.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2404" for this suite. @ 04/29/23 12:23:40.411
• [2.149 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 04/29/23 12:23:40.417
  Apr 29 12:23:40.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 12:23:40.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:40.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:40.435
  STEP: creating the pod @ 04/29/23 12:23:40.438
  STEP: setting up watch @ 04/29/23 12:23:40.438
  STEP: submitting the pod to kubernetes @ 04/29/23 12:23:40.542
  STEP: verifying the pod is in kubernetes @ 04/29/23 12:23:40.55
  STEP: verifying pod creation was observed @ 04/29/23 12:23:40.553
  STEP: deleting the pod gracefully @ 04/29/23 12:23:42.565
  STEP: verifying pod deletion was observed @ 04/29/23 12:23:42.571
  Apr 29 12:23:43.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5663" for this suite. @ 04/29/23 12:23:43.501
• [3.090 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 04/29/23 12:23:43.508
  Apr 29 12:23:43.508: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:23:43.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:43.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:43.529
  STEP: Creating a pod to test downward api env vars @ 04/29/23 12:23:43.533
  STEP: Saw pod success @ 04/29/23 12:23:47.553
  Apr 29 12:23:47.556: INFO: Trying to get logs from node ip-172-31-41-80 pod downward-api-fbcd9570-c036-4d3f-b02f-782a04647522 container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 12:23:47.563
  Apr 29 12:23:47.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9832" for this suite. @ 04/29/23 12:23:47.582
• [4.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 04/29/23 12:23:47.589
  Apr 29 12:23:47.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 12:23:47.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:47.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:47.609
  STEP: Creating secret with name secret-test-2f56187b-6ebb-4446-b87b-247830493b37 @ 04/29/23 12:23:47.616
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:23:47.62
  STEP: Saw pod success @ 04/29/23 12:23:51.64
  Apr 29 12:23:51.643: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-secrets-e90470dc-b2e9-447b-b39f-021d9e9cb926 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:23:51.65
  Apr 29 12:23:51.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8462" for this suite. @ 04/29/23 12:23:51.669
• [4.087 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 04/29/23 12:23:51.677
  Apr 29 12:23:51.678: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:23:51.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:51.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:51.696
  STEP: Creating secret with name s-test-opt-del-bb7cf147-9953-4dee-98e3-2161ebd4dbcf @ 04/29/23 12:23:51.702
  STEP: Creating secret with name s-test-opt-upd-557e1544-7727-4bb8-9a10-1fec96e86d03 @ 04/29/23 12:23:51.705
  STEP: Creating the pod @ 04/29/23 12:23:51.71
  STEP: Deleting secret s-test-opt-del-bb7cf147-9953-4dee-98e3-2161ebd4dbcf @ 04/29/23 12:23:53.749
  STEP: Updating secret s-test-opt-upd-557e1544-7727-4bb8-9a10-1fec96e86d03 @ 04/29/23 12:23:53.754
  STEP: Creating secret with name s-test-opt-create-76440080-94b0-4e3e-a11a-4e8f7da11376 @ 04/29/23 12:23:53.759
  STEP: waiting to observe update in volume @ 04/29/23 12:23:53.763
  Apr 29 12:23:57.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5135" for this suite. @ 04/29/23 12:23:57.801
• [6.129 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 04/29/23 12:23:57.807
  Apr 29 12:23:57.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename endpointslice @ 04/29/23 12:23:57.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:23:57.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:23:57.826
  Apr 29 12:24:01.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7767" for this suite. @ 04/29/23 12:24:01.881
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 04/29/23 12:24:01.889
  Apr 29 12:24:01.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:24:01.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:24:01.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:24:01.91
  STEP: Creating the pod @ 04/29/23 12:24:01.913
  Apr 29 12:24:04.458: INFO: Successfully updated pod "labelsupdate552c8dd8-0a05-4593-bedd-ff48dcc3aa9b"
  Apr 29 12:24:08.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8528" for this suite. @ 04/29/23 12:24:08.484
• [6.601 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 04/29/23 12:24:08.491
  Apr 29 12:24:08.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-pred @ 04/29/23 12:24:08.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:24:08.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:24:08.51
  Apr 29 12:24:08.513: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 29 12:24:08.521: INFO: Waiting for terminating namespaces to be deleted...
  Apr 29 12:24:08.523: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-25-13 before test
  Apr 29 12:24:08.528: INFO: nginx-ingress-controller-kubernetes-worker-nktfk from ingress-nginx-kubernetes-worker started at 2023-04-29 11:51:02 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.528: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: coredns-5c7f76ccb8-2lgzt from kube-system started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.528: INFO: 	Container coredns ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: kube-state-metrics-5b95b4459c-9469j from kube-system started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.528: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: metrics-server-v0.5.2-6cf8c8b69c-tsmc5 from kube-system started at 2023-04-29 11:50:57 +0000 UTC (2 container statuses recorded)
  Apr 29 12:24:08.528: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: dashboard-metrics-scraper-6b8586b5c9-k9jlf from kubernetes-dashboard started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.528: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: kubernetes-dashboard-6869f4cd5f-w7m8c from kubernetes-dashboard started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.528: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-rvknb from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 12:24:08.528: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 29 12:24:08.528: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-41-80 before test
  Apr 29 12:24:08.533: INFO: labelsupdate552c8dd8-0a05-4593-bedd-ff48dcc3aa9b from downward-api-8528 started at 2023-04-29 12:24:01 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.533: INFO: 	Container client-container ready: true, restart count 0
  Apr 29 12:24:08.533: INFO: nginx-ingress-controller-kubernetes-worker-bt9hj from ingress-nginx-kubernetes-worker started at 2023-04-29 12:17:54 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.533: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 12:24:08.533: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-6rcvs from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 12:24:08.533: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 12:24:08.533: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 29 12:24:08.533: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-82-46 before test
  Apr 29 12:24:08.537: INFO: default-http-backend-kubernetes-worker-65fc475d49-mlbzp from ingress-nginx-kubernetes-worker started at 2023-04-29 12:11:40 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.537: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Apr 29 12:24:08.537: INFO: nginx-ingress-controller-kubernetes-worker-m8hc4 from ingress-nginx-kubernetes-worker started at 2023-04-29 11:54:52 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.537: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 12:24:08.537: INFO: calico-kube-controllers-577d5b7f57-d6csn from kube-system started at 2023-04-29 12:11:40 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.537: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  Apr 29 12:24:08.537: INFO: sonobuoy from sonobuoy started at 2023-04-29 12:00:46 +0000 UTC (1 container statuses recorded)
  Apr 29 12:24:08.537: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 29 12:24:08.537: INFO: sonobuoy-e2e-job-819b1466a92240b6 from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 12:24:08.537: INFO: 	Container e2e ready: true, restart count 0
  Apr 29 12:24:08.537: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 12:24:08.537: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-hpjk5 from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 12:24:08.537: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 12:24:08.537: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-25-13 @ 04/29/23 12:24:08.549
  STEP: verifying the node has the label node ip-172-31-41-80 @ 04/29/23 12:24:08.562
  STEP: verifying the node has the label node ip-172-31-82-46 @ 04/29/23 12:24:08.579
  Apr 29 12:24:08.595: INFO: Pod labelsupdate552c8dd8-0a05-4593-bedd-ff48dcc3aa9b requesting resource cpu=0m on Node ip-172-31-41-80
  Apr 29 12:24:08.595: INFO: Pod default-http-backend-kubernetes-worker-65fc475d49-mlbzp requesting resource cpu=10m on Node ip-172-31-82-46
  Apr 29 12:24:08.595: INFO: Pod nginx-ingress-controller-kubernetes-worker-bt9hj requesting resource cpu=0m on Node ip-172-31-41-80
  Apr 29 12:24:08.595: INFO: Pod nginx-ingress-controller-kubernetes-worker-m8hc4 requesting resource cpu=0m on Node ip-172-31-82-46
  Apr 29 12:24:08.595: INFO: Pod nginx-ingress-controller-kubernetes-worker-nktfk requesting resource cpu=0m on Node ip-172-31-25-13
  Apr 29 12:24:08.595: INFO: Pod calico-kube-controllers-577d5b7f57-d6csn requesting resource cpu=0m on Node ip-172-31-82-46
  Apr 29 12:24:08.595: INFO: Pod coredns-5c7f76ccb8-2lgzt requesting resource cpu=100m on Node ip-172-31-25-13
  Apr 29 12:24:08.595: INFO: Pod kube-state-metrics-5b95b4459c-9469j requesting resource cpu=0m on Node ip-172-31-25-13
  Apr 29 12:24:08.595: INFO: Pod metrics-server-v0.5.2-6cf8c8b69c-tsmc5 requesting resource cpu=5m on Node ip-172-31-25-13
  Apr 29 12:24:08.595: INFO: Pod dashboard-metrics-scraper-6b8586b5c9-k9jlf requesting resource cpu=0m on Node ip-172-31-25-13
  Apr 29 12:24:08.595: INFO: Pod kubernetes-dashboard-6869f4cd5f-w7m8c requesting resource cpu=0m on Node ip-172-31-25-13
  Apr 29 12:24:08.595: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-82-46
  Apr 29 12:24:08.596: INFO: Pod sonobuoy-e2e-job-819b1466a92240b6 requesting resource cpu=0m on Node ip-172-31-82-46
  Apr 29 12:24:08.596: INFO: Pod sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-6rcvs requesting resource cpu=0m on Node ip-172-31-41-80
  Apr 29 12:24:08.596: INFO: Pod sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-hpjk5 requesting resource cpu=0m on Node ip-172-31-82-46
  Apr 29 12:24:08.596: INFO: Pod sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-rvknb requesting resource cpu=0m on Node ip-172-31-25-13
  STEP: Starting Pods to consume most of the cluster CPU. @ 04/29/23 12:24:08.596
  Apr 29 12:24:08.596: INFO: Creating a pod which consumes cpu=1326m on Node ip-172-31-25-13
  Apr 29 12:24:08.603: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-41-80
  Apr 29 12:24:08.609: INFO: Creating a pod which consumes cpu=1393m on Node ip-172-31-82-46
  STEP: Creating another pod that requires unavailable amount of CPU. @ 04/29/23 12:24:10.63
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-15c43af6-2688-4924-b281-c051c28c8aa2.175a675a5f5e125e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3733/filler-pod-15c43af6-2688-4924-b281-c051c28c8aa2 to ip-172-31-41-80] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-15c43af6-2688-4924-b281-c051c28c8aa2.175a675a8532f244], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-15c43af6-2688-4924-b281-c051c28c8aa2.175a675a862978b0], Reason = [Created], Message = [Created container filler-pod-15c43af6-2688-4924-b281-c051c28c8aa2] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-15c43af6-2688-4924-b281-c051c28c8aa2.175a675a898c212f], Reason = [Started], Message = [Started container filler-pod-15c43af6-2688-4924-b281-c051c28c8aa2] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-6aae379c-58c8-47e8-bdae-6819f0af544b.175a675a5f5e125a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3733/filler-pod-6aae379c-58c8-47e8-bdae-6819f0af544b to ip-172-31-82-46] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-6aae379c-58c8-47e8-bdae-6819f0af544b.175a675a84e50163], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-6aae379c-58c8-47e8-bdae-6819f0af544b.175a675a85efc94b], Reason = [Created], Message = [Created container filler-pod-6aae379c-58c8-47e8-bdae-6819f0af544b] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-6aae379c-58c8-47e8-bdae-6819f0af544b.175a675a89ae1c5a], Reason = [Started], Message = [Started container filler-pod-6aae379c-58c8-47e8-bdae-6819f0af544b] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce1b31c7-52d3-4761-b67d-f12dece477a7.175a675a5ebfb149], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3733/filler-pod-ce1b31c7-52d3-4761-b67d-f12dece477a7 to ip-172-31-25-13] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce1b31c7-52d3-4761-b67d-f12dece477a7.175a675a85e923cd], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.9"] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce1b31c7-52d3-4761-b67d-f12dece477a7.175a675a9666a9e7], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.9" in 276.635204ms (276.642825ms including waiting)] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce1b31c7-52d3-4761-b67d-f12dece477a7.175a675a975e2131], Reason = [Created], Message = [Created container filler-pod-ce1b31c7-52d3-4761-b67d-f12dece477a7] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ce1b31c7-52d3-4761-b67d-f12dece477a7.175a675a9ad40de5], Reason = [Started], Message = [Started container filler-pod-ce1b31c7-52d3-4761-b67d-f12dece477a7] @ 04/29/23 12:24:10.634
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.175a675ad7b9a4d8], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod..] @ 04/29/23 12:24:10.646
  STEP: removing the label node off the node ip-172-31-25-13 @ 04/29/23 12:24:11.644
  STEP: verifying the node doesn't have the label node @ 04/29/23 12:24:11.653
  STEP: removing the label node off the node ip-172-31-41-80 @ 04/29/23 12:24:11.657
  STEP: verifying the node doesn't have the label node @ 04/29/23 12:24:11.669
  STEP: removing the label node off the node ip-172-31-82-46 @ 04/29/23 12:24:11.673
  STEP: verifying the node doesn't have the label node @ 04/29/23 12:24:11.685
  Apr 29 12:24:11.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3733" for this suite. @ 04/29/23 12:24:11.695
• [3.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 04/29/23 12:24:11.708
  Apr 29 12:24:11.708: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 12:24:11.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:24:11.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:24:11.728
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5491 @ 04/29/23 12:24:11.732
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/29/23 12:24:11.743
  STEP: creating service externalsvc in namespace services-5491 @ 04/29/23 12:24:11.743
  STEP: creating replication controller externalsvc in namespace services-5491 @ 04/29/23 12:24:11.757
  I0429 12:24:11.766638      18 runners.go:194] Created replication controller with name: externalsvc, namespace: services-5491, replica count: 2
  I0429 12:24:14.818159      18 runners.go:194] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 04/29/23 12:24:14.821
  Apr 29 12:24:14.834: INFO: Creating new exec pod
  Apr 29 12:24:16.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-5491 exec execpod8szrk -- /bin/sh -x -c nslookup clusterip-service.services-5491.svc.cluster.local'
  Apr 29 12:24:17.012: INFO: stderr: "+ nslookup clusterip-service.services-5491.svc.cluster.local\n"
  Apr 29 12:24:17.012: INFO: stdout: "Server:\t\t10.152.183.88\nAddress:\t10.152.183.88#53\n\nclusterip-service.services-5491.svc.cluster.local\tcanonical name = externalsvc.services-5491.svc.cluster.local.\nName:\texternalsvc.services-5491.svc.cluster.local\nAddress: 10.152.183.190\n\n"
  Apr 29 12:24:17.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-5491, will wait for the garbage collector to delete the pods @ 04/29/23 12:24:17.018
  Apr 29 12:24:17.078: INFO: Deleting ReplicationController externalsvc took: 6.268279ms
  Apr 29 12:24:17.179: INFO: Terminating ReplicationController externalsvc pods took: 100.990754ms
  Apr 29 12:24:19.095: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-5491" for this suite. @ 04/29/23 12:24:19.106
• [7.415 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:106
  STEP: Creating a kubernetes client @ 04/29/23 12:24:19.132
  Apr 29 12:24:19.132: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename subpath @ 04/29/23 12:24:19.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:24:19.149
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:24:19.152
  STEP: Setting up data @ 04/29/23 12:24:19.155
  STEP: Creating pod pod-subpath-test-projected-kpvh @ 04/29/23 12:24:19.163
  STEP: Creating a pod to test atomic-volume-subpath @ 04/29/23 12:24:19.163
  STEP: Saw pod success @ 04/29/23 12:24:43.225
  Apr 29 12:24:43.228: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-subpath-test-projected-kpvh container test-container-subpath-projected-kpvh: <nil>
  STEP: delete the pod @ 04/29/23 12:24:43.235
  STEP: Deleting pod pod-subpath-test-projected-kpvh @ 04/29/23 12:24:43.25
  Apr 29 12:24:43.250: INFO: Deleting pod "pod-subpath-test-projected-kpvh" in namespace "subpath-3138"
  Apr 29 12:24:43.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3138" for this suite. @ 04/29/23 12:24:43.257
• [24.131 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 04/29/23 12:24:43.263
  Apr 29 12:24:43.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/29/23 12:24:43.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:24:43.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:24:43.284
  STEP: create the container to handle the HTTPGet hook request. @ 04/29/23 12:24:43.291
  STEP: create the pod with lifecycle hook @ 04/29/23 12:24:45.313
  STEP: check poststart hook @ 04/29/23 12:24:47.334
  STEP: delete the pod with lifecycle hook @ 04/29/23 12:24:47.356
  Apr 29 12:24:49.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5010" for this suite. @ 04/29/23 12:24:49.375
• [6.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 04/29/23 12:24:49.382
  Apr 29 12:24:49.382: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 12:24:49.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:24:49.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:24:49.403
  STEP: Creating pod busybox-2713a19f-e17b-4a9a-8964-8e68eec64550 in namespace container-probe-9799 @ 04/29/23 12:24:49.407
  Apr 29 12:24:51.428: INFO: Started pod busybox-2713a19f-e17b-4a9a-8964-8e68eec64550 in namespace container-probe-9799
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/29/23 12:24:51.428
  Apr 29 12:24:51.431: INFO: Initial restart count of pod busybox-2713a19f-e17b-4a9a-8964-8e68eec64550 is 0
  Apr 29 12:28:51.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 12:28:51.972
  STEP: Destroying namespace "container-probe-9799" for this suite. @ 04/29/23 12:28:51.986
• [242.624 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 04/29/23 12:28:52.011
  Apr 29 12:28:52.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename endpointslice @ 04/29/23 12:28:52.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:28:52.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:28:52.038
  STEP: getting /apis @ 04/29/23 12:28:52.045
  STEP: getting /apis/discovery.k8s.io @ 04/29/23 12:28:52.051
  STEP: getting /apis/discovery.k8s.iov1 @ 04/29/23 12:28:52.053
  STEP: creating @ 04/29/23 12:28:52.054
  STEP: getting @ 04/29/23 12:28:52.07
  STEP: listing @ 04/29/23 12:28:52.073
  STEP: watching @ 04/29/23 12:28:52.077
  Apr 29 12:28:52.077: INFO: starting watch
  STEP: cluster-wide listing @ 04/29/23 12:28:52.079
  STEP: cluster-wide watching @ 04/29/23 12:28:52.082
  Apr 29 12:28:52.082: INFO: starting watch
  STEP: patching @ 04/29/23 12:28:52.084
  STEP: updating @ 04/29/23 12:28:52.09
  Apr 29 12:28:52.099: INFO: waiting for watch events with expected annotations
  Apr 29 12:28:52.099: INFO: saw patched and updated annotations
  STEP: deleting @ 04/29/23 12:28:52.099
  STEP: deleting a collection @ 04/29/23 12:28:52.112
  Apr 29 12:28:52.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-754" for this suite. @ 04/29/23 12:28:52.14
• [0.137 seconds]
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 04/29/23 12:28:52.148
  Apr 29 12:28:52.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:28:52.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:28:52.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:28:52.17
  STEP: Creating a pod to test downward api env vars @ 04/29/23 12:28:52.175
  STEP: Saw pod success @ 04/29/23 12:28:56.198
  Apr 29 12:28:56.202: INFO: Trying to get logs from node ip-172-31-41-80 pod downward-api-c13d3f75-4641-4f9c-ab74-264186914704 container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 12:28:56.222
  Apr 29 12:28:56.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9609" for this suite. @ 04/29/23 12:28:56.241
• [4.098 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 04/29/23 12:28:56.25
  Apr 29 12:28:56.250: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:28:56.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:28:56.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:28:56.271
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:28:56.275
  STEP: Saw pod success @ 04/29/23 12:29:00.298
  Apr 29 12:29:00.302: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-9689d5a3-83ab-4b4e-81fd-122015c61632 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:29:00.308
  Apr 29 12:29:00.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9671" for this suite. @ 04/29/23 12:29:00.324
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 04/29/23 12:29:00.333
  Apr 29 12:29:00.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 12:29:00.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:00.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:00.354
  Apr 29 12:29:22.421: INFO: Container started at 2023-04-29 12:29:01 +0000 UTC, pod became ready at 2023-04-29 12:29:20 +0000 UTC
  Apr 29 12:29:22.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-872" for this suite. @ 04/29/23 12:29:22.425
• [22.098 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 04/29/23 12:29:22.431
  Apr 29 12:29:22.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename namespaces @ 04/29/23 12:29:22.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:22.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:22.452
  STEP: Creating a test namespace @ 04/29/23 12:29:22.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:22.471
  STEP: Creating a service in the namespace @ 04/29/23 12:29:22.474
  STEP: Deleting the namespace @ 04/29/23 12:29:22.484
  STEP: Waiting for the namespace to be removed. @ 04/29/23 12:29:22.49
  STEP: Recreating the namespace @ 04/29/23 12:29:28.494
  STEP: Verifying there is no service in the namespace @ 04/29/23 12:29:28.509
  Apr 29 12:29:28.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2503" for this suite. @ 04/29/23 12:29:28.516
  STEP: Destroying namespace "nsdeletetest-9837" for this suite. @ 04/29/23 12:29:28.522
  Apr 29 12:29:28.524: INFO: Namespace nsdeletetest-9837 was already deleted
  STEP: Destroying namespace "nsdeletetest-4907" for this suite. @ 04/29/23 12:29:28.524
• [6.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 04/29/23 12:29:28.533
  Apr 29 12:29:28.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/29/23 12:29:28.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:28.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:28.554
  STEP: create the container to handle the HTTPGet hook request. @ 04/29/23 12:29:28.56
  STEP: create the pod with lifecycle hook @ 04/29/23 12:29:30.578
  STEP: delete the pod with lifecycle hook @ 04/29/23 12:29:32.596
  STEP: check prestop hook @ 04/29/23 12:29:34.609
  Apr 29 12:29:34.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5410" for this suite. @ 04/29/23 12:29:34.624
• [6.096 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 04/29/23 12:29:34.629
  Apr 29 12:29:34.629: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename security-context-test @ 04/29/23 12:29:34.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:34.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:34.649
  Apr 29 12:29:38.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-405" for this suite. @ 04/29/23 12:29:38.677
• [4.054 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 04/29/23 12:29:38.685
  Apr 29 12:29:38.685: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:29:38.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:38.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:38.705
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/29/23 12:29:38.708
  STEP: Saw pod success @ 04/29/23 12:29:42.728
  Apr 29 12:29:42.732: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-0c3d057f-2aae-47c1-be5e-919532963bb7 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:29:42.738
  Apr 29 12:29:42.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9590" for this suite. @ 04/29/23 12:29:42.757
• [4.078 seconds]
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 04/29/23 12:29:42.763
  Apr 29 12:29:42.763: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl-logs @ 04/29/23 12:29:42.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:42.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:42.782
  STEP: creating an pod @ 04/29/23 12:29:42.785
  Apr 29 12:29:42.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-logs-6545 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.43 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Apr 29 12:29:42.854: INFO: stderr: ""
  Apr 29 12:29:42.854: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 04/29/23 12:29:42.854
  Apr 29 12:29:42.854: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  Apr 29 12:29:44.862: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 04/29/23 12:29:44.862
  Apr 29 12:29:44.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-logs-6545 logs logs-generator logs-generator'
  Apr 29 12:29:44.929: INFO: stderr: ""
  Apr 29 12:29:44.929: INFO: stdout: "I0429 12:29:43.536766       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/sxx5 520\nI0429 12:29:43.736863       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/g5w 399\nI0429 12:29:43.936908       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/bt7 535\nI0429 12:29:44.137193       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/mrrw 413\nI0429 12:29:44.337465       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/fhsp 240\nI0429 12:29:44.537756       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/g4l2 401\nI0429 12:29:44.736987       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/4wgf 465\n"
  STEP: limiting log lines @ 04/29/23 12:29:44.929
  Apr 29 12:29:44.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-logs-6545 logs logs-generator logs-generator --tail=1'
  Apr 29 12:29:45.003: INFO: stderr: ""
  Apr 29 12:29:45.003: INFO: stdout: "I0429 12:29:44.937278       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/5qt 280\n"
  Apr 29 12:29:45.003: INFO: got output "I0429 12:29:44.937278       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/5qt 280\n"
  STEP: limiting log bytes @ 04/29/23 12:29:45.003
  Apr 29 12:29:45.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-logs-6545 logs logs-generator logs-generator --limit-bytes=1'
  Apr 29 12:29:45.070: INFO: stderr: ""
  Apr 29 12:29:45.070: INFO: stdout: "I"
  Apr 29 12:29:45.070: INFO: got output "I"
  STEP: exposing timestamps @ 04/29/23 12:29:45.07
  Apr 29 12:29:45.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-logs-6545 logs logs-generator logs-generator --tail=1 --timestamps'
  Apr 29 12:29:45.135: INFO: stderr: ""
  Apr 29 12:29:45.135: INFO: stdout: "2023-04-29T12:29:44.937358480Z I0429 12:29:44.937278       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/5qt 280\n"
  Apr 29 12:29:45.135: INFO: got output "2023-04-29T12:29:44.937358480Z I0429 12:29:44.937278       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/5qt 280\n"
  STEP: restricting to a time range @ 04/29/23 12:29:45.135
  Apr 29 12:29:47.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-logs-6545 logs logs-generator logs-generator --since=1s'
  Apr 29 12:29:47.702: INFO: stderr: ""
  Apr 29 12:29:47.702: INFO: stdout: "I0429 12:29:46.737462       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/jkz6 359\nI0429 12:29:46.937768       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/ql6 538\nI0429 12:29:47.136982       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/vg9 405\nI0429 12:29:47.337273       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/tgrx 389\nI0429 12:29:47.537462       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/z824 392\n"
  Apr 29 12:29:47.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-logs-6545 logs logs-generator logs-generator --since=24h'
  Apr 29 12:29:47.770: INFO: stderr: ""
  Apr 29 12:29:47.770: INFO: stdout: "I0429 12:29:43.536766       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/sxx5 520\nI0429 12:29:43.736863       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/g5w 399\nI0429 12:29:43.936908       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/bt7 535\nI0429 12:29:44.137193       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/mrrw 413\nI0429 12:29:44.337465       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/fhsp 240\nI0429 12:29:44.537756       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/g4l2 401\nI0429 12:29:44.736987       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/4wgf 465\nI0429 12:29:44.937278       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/5qt 280\nI0429 12:29:45.137464       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/r4c 553\nI0429 12:29:45.337757       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/trd4 588\nI0429 12:29:45.536986       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/2tb 424\nI0429 12:29:45.737273       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/bm9m 598\nI0429 12:29:45.937461       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/w7r 306\nI0429 12:29:46.137751       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/nfx 451\nI0429 12:29:46.336979       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/w49l 410\nI0429 12:29:46.537270       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/2wk2 396\nI0429 12:29:46.737462       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/jkz6 359\nI0429 12:29:46.937768       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/ql6 538\nI0429 12:29:47.136982       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/vg9 405\nI0429 12:29:47.337273       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/tgrx 389\nI0429 12:29:47.537462       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/z824 392\nI0429 12:29:47.737734       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/csr 584\n"
  Apr 29 12:29:47.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-logs-6545 delete pod logs-generator'
  Apr 29 12:29:48.528: INFO: stderr: ""
  Apr 29 12:29:48.528: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Apr 29 12:29:48.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-6545" for this suite. @ 04/29/23 12:29:48.532
• [5.775 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 04/29/23 12:29:48.538
  Apr 29 12:29:48.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:29:48.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:48.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:48.561
  STEP: Creating projection with secret that has name projected-secret-test-3bb81432-0649-42f1-a462-71de40096096 @ 04/29/23 12:29:48.564
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:29:48.568
  STEP: Saw pod success @ 04/29/23 12:29:52.586
  Apr 29 12:29:52.589: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-secrets-d62884ca-9fb9-4a8a-b8b8-8772800f6852 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:29:52.597
  Apr 29 12:29:52.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3915" for this suite. @ 04/29/23 12:29:52.615
• [4.083 seconds]
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 04/29/23 12:29:52.621
  Apr 29 12:29:52.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replication-controller @ 04/29/23 12:29:52.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:52.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:52.642
  STEP: Given a ReplicationController is created @ 04/29/23 12:29:52.645
  STEP: When the matched label of one of its pods change @ 04/29/23 12:29:52.65
  Apr 29 12:29:52.653: INFO: Pod name pod-release: Found 0 pods out of 1
  Apr 29 12:29:57.657: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/29/23 12:29:57.668
  Apr 29 12:29:58.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2079" for this suite. @ 04/29/23 12:29:58.679
• [6.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:316
  STEP: Creating a kubernetes client @ 04/29/23 12:29:58.688
  Apr 29 12:29:58.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename statefulset @ 04/29/23 12:29:58.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:29:58.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:29:58.708
  STEP: Creating service test in namespace statefulset-673 @ 04/29/23 12:29:58.71
  STEP: Creating a new StatefulSet @ 04/29/23 12:29:58.715
  Apr 29 12:29:58.725: INFO: Found 0 stateful pods, waiting for 3
  Apr 29 12:30:08.730: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 12:30:08.730: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 12:30:08.730: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 12:30:08.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-673 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:30:08.870: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:30:08.870: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:30:08.870: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/29/23 12:30:18.888
  Apr 29 12:30:18.907: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/29/23 12:30:18.907
  STEP: Updating Pods in reverse ordinal order @ 04/29/23 12:30:28.922
  Apr 29 12:30:28.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-673 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:30:29.043: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 29 12:30:29.043: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:30:29.043: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  STEP: Rolling back to a previous revision @ 04/29/23 12:30:49.067
  Apr 29 12:30:49.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-673 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:30:49.197: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:30:49.197: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:30:49.197: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:30:59.234: INFO: Updating stateful set ss2
  STEP: Rolling back update in reverse ordinal order @ 04/29/23 12:31:09.252
  Apr 29 12:31:09.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-673 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:31:09.379: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 29 12:31:09.380: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:31:09.380: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 29 12:31:19.403: INFO: Deleting all statefulset in ns statefulset-673
  Apr 29 12:31:19.406: INFO: Scaling statefulset ss2 to 0
  Apr 29 12:31:29.423: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:31:29.426: INFO: Deleting statefulset ss2
  Apr 29 12:31:29.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-673" for this suite. @ 04/29/23 12:31:29.441
• [90.758 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 04/29/23 12:31:29.448
  Apr 29 12:31:29.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename disruption @ 04/29/23 12:31:29.448
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:31:29.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:31:29.469
  STEP: Creating a kubernetes client @ 04/29/23 12:31:29.472
  Apr 29 12:31:29.472: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename disruption-2 @ 04/29/23 12:31:29.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:31:29.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:31:29.492
  STEP: Waiting for the pdb to be processed @ 04/29/23 12:31:29.5
  STEP: Waiting for the pdb to be processed @ 04/29/23 12:31:31.511
  STEP: Waiting for the pdb to be processed @ 04/29/23 12:31:33.523
  STEP: listing a collection of PDBs across all namespaces @ 04/29/23 12:31:35.529
  STEP: listing a collection of PDBs in namespace disruption-2918 @ 04/29/23 12:31:35.534
  STEP: deleting a collection of PDBs @ 04/29/23 12:31:35.536
  STEP: Waiting for the PDB collection to be deleted @ 04/29/23 12:31:35.549
  Apr 29 12:31:35.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 12:31:35.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-2407" for this suite. @ 04/29/23 12:31:35.563
  STEP: Destroying namespace "disruption-2918" for this suite. @ 04/29/23 12:31:35.569
• [6.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 04/29/23 12:31:35.577
  Apr 29 12:31:35.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-preemption @ 04/29/23 12:31:35.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:31:35.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:31:35.599
  Apr 29 12:31:35.613: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 29 12:32:35.630: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/29/23 12:32:35.634
  Apr 29 12:32:35.654: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 29 12:32:35.660: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 29 12:32:35.679: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 29 12:32:35.684: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Apr 29 12:32:35.699: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Apr 29 12:32:35.707: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/29/23 12:32:35.707
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 04/29/23 12:32:37.729
  Apr 29 12:32:41.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3064" for this suite. @ 04/29/23 12:32:41.803
• [66.232 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 04/29/23 12:32:41.809
  Apr 29 12:32:41.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 12:32:41.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:32:41.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:32:41.83
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 04/29/23 12:32:41.833
  Apr 29 12:32:41.834: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 04/29/23 12:32:47.433
  Apr 29 12:32:47.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:32:48.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:32:54.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8630" for this suite. @ 04/29/23 12:32:54.134
• [12.332 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 04/29/23 12:32:54.142
  Apr 29 12:32:54.142: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:32:54.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:32:54.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:32:54.164
  STEP: Creating configMap with name configmap-test-volume-map-6a0b6a4d-a0f3-453f-975e-370c5495a2b8 @ 04/29/23 12:32:54.168
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:32:54.173
  STEP: Saw pod success @ 04/29/23 12:32:58.196
  Apr 29 12:32:58.199: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-ccdaa70c-7bcb-4d48-9568-d7d6047b1046 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 12:32:58.215
  Apr 29 12:32:58.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7519" for this suite. @ 04/29/23 12:32:58.235
• [4.100 seconds]
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 04/29/23 12:32:58.242
  Apr 29 12:32:58.242: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename var-expansion @ 04/29/23 12:32:58.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:32:58.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:32:58.26
  STEP: Creating a pod to test substitution in container's args @ 04/29/23 12:32:58.264
  STEP: Saw pod success @ 04/29/23 12:33:02.286
  Apr 29 12:33:02.290: INFO: Trying to get logs from node ip-172-31-41-80 pod var-expansion-b89fef62-4340-4a46-b755-5560c28497aa container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 12:33:02.297
  Apr 29 12:33:02.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4572" for this suite. @ 04/29/23 12:33:02.318
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 04/29/23 12:33:02.328
  Apr 29 12:33:02.328: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:33:02.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:33:02.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:33:02.346
  STEP: Creating a pod to test downward api env vars @ 04/29/23 12:33:02.35
  STEP: Saw pod success @ 04/29/23 12:33:06.37
  Apr 29 12:33:06.374: INFO: Trying to get logs from node ip-172-31-41-80 pod downward-api-cc85d46e-8ae5-4165-b1b8-89cc20fb3caa container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 12:33:06.383
  Apr 29 12:33:06.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4476" for this suite. @ 04/29/23 12:33:06.406
• [4.085 seconds]
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3548
  STEP: Creating a kubernetes client @ 04/29/23 12:33:06.413
  Apr 29 12:33:06.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 12:33:06.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:33:06.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:33:06.432
  STEP: creating a collection of services @ 04/29/23 12:33:06.439
  Apr 29 12:33:06.439: INFO: Creating e2e-svc-a-x4hhl
  Apr 29 12:33:06.463: INFO: Creating e2e-svc-b-nv8fb
  Apr 29 12:33:06.476: INFO: Creating e2e-svc-c-2l7d6
  STEP: deleting service collection @ 04/29/23 12:33:06.492
  Apr 29 12:33:06.522: INFO: Collection of services has been deleted
  Apr 29 12:33:06.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1600" for this suite. @ 04/29/23 12:33:06.527
• [0.121 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3113
  STEP: Creating a kubernetes client @ 04/29/23 12:33:06.534
  Apr 29 12:33:06.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 12:33:06.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:33:06.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:33:06.554
  STEP: fetching services @ 04/29/23 12:33:06.559
  Apr 29 12:33:06.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3652" for this suite. @ 04/29/23 12:33:06.571
• [0.045 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1480
  STEP: Creating a kubernetes client @ 04/29/23 12:33:06.579
  Apr 29 12:33:06.580: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 12:33:06.58
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:33:06.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:33:06.599
  STEP: creating Agnhost RC @ 04/29/23 12:33:06.604
  Apr 29 12:33:06.604: INFO: namespace kubectl-6393
  Apr 29 12:33:06.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-6393 create -f -'
  Apr 29 12:33:06.853: INFO: stderr: ""
  Apr 29 12:33:06.853: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/29/23 12:33:06.853
  Apr 29 12:33:07.858: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 29 12:33:07.858: INFO: Found 1 / 1
  Apr 29 12:33:07.858: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 29 12:33:07.862: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 29 12:33:07.862: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 29 12:33:07.862: INFO: wait on agnhost-primary startup in kubectl-6393 
  Apr 29 12:33:07.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-6393 logs agnhost-primary-c7qd8 agnhost-primary'
  Apr 29 12:33:07.927: INFO: stderr: ""
  Apr 29 12:33:07.927: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 04/29/23 12:33:07.927
  Apr 29 12:33:07.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-6393 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Apr 29 12:33:08.002: INFO: stderr: ""
  Apr 29 12:33:08.002: INFO: stdout: "service/rm2 exposed\n"
  Apr 29 12:33:08.008: INFO: Service rm2 in namespace kubectl-6393 found.
  STEP: exposing service @ 04/29/23 12:33:10.016
  Apr 29 12:33:10.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-6393 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Apr 29 12:33:10.100: INFO: stderr: ""
  Apr 29 12:33:10.100: INFO: stdout: "service/rm3 exposed\n"
  Apr 29 12:33:10.105: INFO: Service rm3 in namespace kubectl-6393 found.
  Apr 29 12:33:12.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6393" for this suite. @ 04/29/23 12:33:12.118
• [5.546 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 04/29/23 12:33:12.126
  Apr 29 12:33:12.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename cronjob @ 04/29/23 12:33:12.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:33:12.14
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:33:12.144
  STEP: Creating a suspended cronjob @ 04/29/23 12:33:12.148
  STEP: Ensuring no jobs are scheduled @ 04/29/23 12:33:12.154
  STEP: Ensuring no job exists by listing jobs explicitly @ 04/29/23 12:38:12.162
  STEP: Removing cronjob @ 04/29/23 12:38:12.166
  Apr 29 12:38:12.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6811" for this suite. @ 04/29/23 12:38:12.176
• [300.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 04/29/23 12:38:12.186
  Apr 29 12:38:12.186: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename proxy @ 04/29/23 12:38:12.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:12.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:12.214
  STEP: starting an echo server on multiple ports @ 04/29/23 12:38:12.234
  STEP: creating replication controller proxy-service-tnzsk in namespace proxy-6633 @ 04/29/23 12:38:12.234
  I0429 12:38:12.245463      18 runners.go:194] Created replication controller with name: proxy-service-tnzsk, namespace: proxy-6633, replica count: 1
  I0429 12:38:13.296047      18 runners.go:194] proxy-service-tnzsk Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 12:38:13.300: INFO: setup took 1.082563106s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 04/29/23 12:38:13.3
  Apr 29 12:38:13.311: INFO: (0) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 11.040257ms)
  Apr 29 12:38:13.316: INFO: (0) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 15.334994ms)
  Apr 29 12:38:13.317: INFO: (0) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 17.182129ms)
  Apr 29 12:38:13.320: INFO: (0) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 19.097499ms)
  Apr 29 12:38:13.320: INFO: (0) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 19.962933ms)
  Apr 29 12:38:13.321: INFO: (0) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 20.34948ms)
  Apr 29 12:38:13.321: INFO: (0) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 20.821781ms)
  Apr 29 12:38:13.322: INFO: (0) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 21.196996ms)
  Apr 29 12:38:13.322: INFO: (0) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 21.495558ms)
  Apr 29 12:38:13.322: INFO: (0) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 21.733394ms)
  Apr 29 12:38:13.322: INFO: (0) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 21.807507ms)
  Apr 29 12:38:13.322: INFO: (0) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 22.208408ms)
  Apr 29 12:38:13.322: INFO: (0) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 22.199406ms)
  Apr 29 12:38:13.323: INFO: (0) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 22.248769ms)
  Apr 29 12:38:13.323: INFO: (0) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 22.681354ms)
  Apr 29 12:38:13.325: INFO: (0) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 24.679066ms)
  Apr 29 12:38:13.330: INFO: (1) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 4.308909ms)
  Apr 29 12:38:13.332: INFO: (1) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 6.125295ms)
  Apr 29 12:38:13.335: INFO: (1) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 9.573737ms)
  Apr 29 12:38:13.335: INFO: (1) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 9.584631ms)
  Apr 29 12:38:13.335: INFO: (1) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 9.687471ms)
  Apr 29 12:38:13.336: INFO: (1) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 10.322502ms)
  Apr 29 12:38:13.336: INFO: (1) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 10.654478ms)
  Apr 29 12:38:13.336: INFO: (1) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 9.880242ms)
  Apr 29 12:38:13.336: INFO: (1) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 10.365861ms)
  Apr 29 12:38:13.336: INFO: (1) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 10.161115ms)
  Apr 29 12:38:13.336: INFO: (1) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 9.759197ms)
  Apr 29 12:38:13.336: INFO: (1) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 9.818421ms)
  Apr 29 12:38:13.336: INFO: (1) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 10.898222ms)
  Apr 29 12:38:13.337: INFO: (1) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.372013ms)
  Apr 29 12:38:13.338: INFO: (1) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 11.384532ms)
  Apr 29 12:38:13.338: INFO: (1) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 11.987331ms)
  Apr 29 12:38:13.342: INFO: (2) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 4.283771ms)
  Apr 29 12:38:13.345: INFO: (2) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 6.349687ms)
  Apr 29 12:38:13.345: INFO: (2) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 6.774309ms)
  Apr 29 12:38:13.347: INFO: (2) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 8.612525ms)
  Apr 29 12:38:13.349: INFO: (2) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 10.518331ms)
  Apr 29 12:38:13.349: INFO: (2) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 10.489664ms)
  Apr 29 12:38:13.349: INFO: (2) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 10.406291ms)
  Apr 29 12:38:13.349: INFO: (2) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 10.704464ms)
  Apr 29 12:38:13.349: INFO: (2) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 10.859017ms)
  Apr 29 12:38:13.350: INFO: (2) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 11.365486ms)
  Apr 29 12:38:13.350: INFO: (2) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 11.332161ms)
  Apr 29 12:38:13.350: INFO: (2) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 11.457856ms)
  Apr 29 12:38:13.350: INFO: (2) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 11.850223ms)
  Apr 29 12:38:13.350: INFO: (2) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 11.731239ms)
  Apr 29 12:38:13.351: INFO: (2) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.966555ms)
  Apr 29 12:38:13.351: INFO: (2) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 12.228471ms)
  Apr 29 12:38:13.357: INFO: (3) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 6.30987ms)
  Apr 29 12:38:13.359: INFO: (3) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 7.997574ms)
  Apr 29 12:38:13.359: INFO: (3) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 8.537863ms)
  Apr 29 12:38:13.360: INFO: (3) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 8.46109ms)
  Apr 29 12:38:13.360: INFO: (3) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 8.358191ms)
  Apr 29 12:38:13.360: INFO: (3) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 9.43394ms)
  Apr 29 12:38:13.361: INFO: (3) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 9.977657ms)
  Apr 29 12:38:13.361: INFO: (3) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 9.795673ms)
  Apr 29 12:38:13.361: INFO: (3) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 10.229994ms)
  Apr 29 12:38:13.361: INFO: (3) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 10.349363ms)
  Apr 29 12:38:13.362: INFO: (3) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 10.687387ms)
  Apr 29 12:38:13.362: INFO: (3) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.301282ms)
  Apr 29 12:38:13.362: INFO: (3) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 11.789705ms)
  Apr 29 12:38:13.363: INFO: (3) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 11.658482ms)
  Apr 29 12:38:13.363: INFO: (3) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 12.15821ms)
  Apr 29 12:38:13.363: INFO: (3) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 12.568499ms)
  Apr 29 12:38:13.369: INFO: (4) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 5.144172ms)
  Apr 29 12:38:13.370: INFO: (4) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 6.136583ms)
  Apr 29 12:38:13.370: INFO: (4) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 6.504929ms)
  Apr 29 12:38:13.371: INFO: (4) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 7.306731ms)
  Apr 29 12:38:13.371: INFO: (4) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 7.961709ms)
  Apr 29 12:38:13.373: INFO: (4) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 8.653892ms)
  Apr 29 12:38:13.373: INFO: (4) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 9.040332ms)
  Apr 29 12:38:13.373: INFO: (4) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 9.349557ms)
  Apr 29 12:38:13.374: INFO: (4) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 9.795597ms)
  Apr 29 12:38:13.374: INFO: (4) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 10.461297ms)
  Apr 29 12:38:13.374: INFO: (4) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 11.071666ms)
  Apr 29 12:38:13.374: INFO: (4) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 10.633021ms)
  Apr 29 12:38:13.375: INFO: (4) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 11.438503ms)
  Apr 29 12:38:13.375: INFO: (4) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 11.519468ms)
  Apr 29 12:38:13.375: INFO: (4) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 11.546838ms)
  Apr 29 12:38:13.375: INFO: (4) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.913254ms)
  Apr 29 12:38:13.380: INFO: (5) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 4.082898ms)
  Apr 29 12:38:13.385: INFO: (5) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 8.980799ms)
  Apr 29 12:38:13.385: INFO: (5) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 9.145552ms)
  Apr 29 12:38:13.386: INFO: (5) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 10.339629ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 10.93161ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 10.860428ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 10.624337ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 10.654599ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.816611ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 11.037376ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 11.078087ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 11.011093ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 11.140862ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.206548ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 11.56738ms)
  Apr 29 12:38:13.387: INFO: (5) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 11.779107ms)
  Apr 29 12:38:13.392: INFO: (6) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 4.141535ms)
  Apr 29 12:38:13.394: INFO: (6) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 6.072012ms)
  Apr 29 12:38:13.394: INFO: (6) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 6.430554ms)
  Apr 29 12:38:13.395: INFO: (6) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 7.096141ms)
  Apr 29 12:38:13.395: INFO: (6) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 7.528718ms)
  Apr 29 12:38:13.396: INFO: (6) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 8.572236ms)
  Apr 29 12:38:13.396: INFO: (6) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 8.312041ms)
  Apr 29 12:38:13.396: INFO: (6) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 8.425559ms)
  Apr 29 12:38:13.397: INFO: (6) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 9.085518ms)
  Apr 29 12:38:13.397: INFO: (6) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 8.881808ms)
  Apr 29 12:38:13.398: INFO: (6) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 9.635231ms)
  Apr 29 12:38:13.398: INFO: (6) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 9.946577ms)
  Apr 29 12:38:13.398: INFO: (6) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.100374ms)
  Apr 29 12:38:13.399: INFO: (6) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.719914ms)
  Apr 29 12:38:13.399: INFO: (6) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 10.722857ms)
  Apr 29 12:38:13.399: INFO: (6) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 10.867834ms)
  Apr 29 12:38:13.403: INFO: (7) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 4.365003ms)
  Apr 29 12:38:13.406: INFO: (7) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 6.923323ms)
  Apr 29 12:38:13.408: INFO: (7) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 8.858948ms)
  Apr 29 12:38:13.408: INFO: (7) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 8.989066ms)
  Apr 29 12:38:13.408: INFO: (7) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 9.094972ms)
  Apr 29 12:38:13.409: INFO: (7) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 9.541213ms)
  Apr 29 12:38:13.409: INFO: (7) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 9.663328ms)
  Apr 29 12:38:13.409: INFO: (7) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.228371ms)
  Apr 29 12:38:13.409: INFO: (7) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 10.302681ms)
  Apr 29 12:38:13.410: INFO: (7) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 10.562169ms)
  Apr 29 12:38:13.410: INFO: (7) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 10.660988ms)
  Apr 29 12:38:13.410: INFO: (7) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 10.509952ms)
  Apr 29 12:38:13.410: INFO: (7) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 10.630618ms)
  Apr 29 12:38:13.410: INFO: (7) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.114349ms)
  Apr 29 12:38:13.411: INFO: (7) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 11.572289ms)
  Apr 29 12:38:13.411: INFO: (7) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 11.806435ms)
  Apr 29 12:38:13.416: INFO: (8) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 4.455122ms)
  Apr 29 12:38:13.416: INFO: (8) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 5.018279ms)
  Apr 29 12:38:13.416: INFO: (8) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 5.223137ms)
  Apr 29 12:38:13.418: INFO: (8) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 6.52191ms)
  Apr 29 12:38:13.418: INFO: (8) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 6.485473ms)
  Apr 29 12:38:13.419: INFO: (8) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 7.617851ms)
  Apr 29 12:38:13.419: INFO: (8) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 8.063713ms)
  Apr 29 12:38:13.419: INFO: (8) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 7.766133ms)
  Apr 29 12:38:13.420: INFO: (8) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 8.586211ms)
  Apr 29 12:38:13.421: INFO: (8) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 9.590714ms)
  Apr 29 12:38:13.421: INFO: (8) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 9.267455ms)
  Apr 29 12:38:13.421: INFO: (8) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 9.564022ms)
  Apr 29 12:38:13.421: INFO: (8) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 10.174047ms)
  Apr 29 12:38:13.422: INFO: (8) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 10.487869ms)
  Apr 29 12:38:13.422: INFO: (8) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 10.309801ms)
  Apr 29 12:38:13.422: INFO: (8) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.611787ms)
  Apr 29 12:38:13.426: INFO: (9) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 4.338414ms)
  Apr 29 12:38:13.428: INFO: (9) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 5.887428ms)
  Apr 29 12:38:13.429: INFO: (9) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 6.736059ms)
  Apr 29 12:38:13.429: INFO: (9) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 6.583507ms)
  Apr 29 12:38:13.430: INFO: (9) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 7.747856ms)
  Apr 29 12:38:13.430: INFO: (9) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 8.088199ms)
  Apr 29 12:38:13.431: INFO: (9) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 8.949433ms)
  Apr 29 12:38:13.432: INFO: (9) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 9.478341ms)
  Apr 29 12:38:13.432: INFO: (9) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 9.195066ms)
  Apr 29 12:38:13.432: INFO: (9) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 9.885386ms)
  Apr 29 12:38:13.433: INFO: (9) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 10.448053ms)
  Apr 29 12:38:13.433: INFO: (9) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 10.168727ms)
  Apr 29 12:38:13.433: INFO: (9) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.680156ms)
  Apr 29 12:38:13.433: INFO: (9) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 10.961113ms)
  Apr 29 12:38:13.434: INFO: (9) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 11.483214ms)
  Apr 29 12:38:13.434: INFO: (9) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 11.232812ms)
  Apr 29 12:38:13.438: INFO: (10) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 3.664746ms)
  Apr 29 12:38:13.440: INFO: (10) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 5.60593ms)
  Apr 29 12:38:13.441: INFO: (10) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 6.63432ms)
  Apr 29 12:38:13.443: INFO: (10) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 8.763037ms)
  Apr 29 12:38:13.443: INFO: (10) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 8.651252ms)
  Apr 29 12:38:13.443: INFO: (10) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 9.13667ms)
  Apr 29 12:38:13.444: INFO: (10) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 9.270689ms)
  Apr 29 12:38:13.444: INFO: (10) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 9.173331ms)
  Apr 29 12:38:13.444: INFO: (10) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 9.792948ms)
  Apr 29 12:38:13.444: INFO: (10) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 9.929296ms)
  Apr 29 12:38:13.444: INFO: (10) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 10.078264ms)
  Apr 29 12:38:13.444: INFO: (10) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 9.866612ms)
  Apr 29 12:38:13.444: INFO: (10) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 9.871616ms)
  Apr 29 12:38:13.445: INFO: (10) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 10.649077ms)
  Apr 29 12:38:13.445: INFO: (10) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.026686ms)
  Apr 29 12:38:13.445: INFO: (10) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.743064ms)
  Apr 29 12:38:13.451: INFO: (11) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 5.904088ms)
  Apr 29 12:38:13.451: INFO: (11) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 5.871302ms)
  Apr 29 12:38:13.452: INFO: (11) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 6.555588ms)
  Apr 29 12:38:13.453: INFO: (11) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 7.809856ms)
  Apr 29 12:38:13.454: INFO: (11) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 7.967989ms)
  Apr 29 12:38:13.454: INFO: (11) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 7.879579ms)
  Apr 29 12:38:13.454: INFO: (11) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 9.317133ms)
  Apr 29 12:38:13.455: INFO: (11) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.04191ms)
  Apr 29 12:38:13.456: INFO: (11) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 10.009945ms)
  Apr 29 12:38:13.456: INFO: (11) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 10.572816ms)
  Apr 29 12:38:13.456: INFO: (11) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 10.94663ms)
  Apr 29 12:38:13.457: INFO: (11) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 11.135464ms)
  Apr 29 12:38:13.457: INFO: (11) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.273948ms)
  Apr 29 12:38:13.457: INFO: (11) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 11.384385ms)
  Apr 29 12:38:13.457: INFO: (11) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 11.24095ms)
  Apr 29 12:38:13.458: INFO: (11) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 12.188189ms)
  Apr 29 12:38:13.462: INFO: (12) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 4.373988ms)
  Apr 29 12:38:13.462: INFO: (12) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 4.401227ms)
  Apr 29 12:38:13.463: INFO: (12) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 5.217963ms)
  Apr 29 12:38:13.464: INFO: (12) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 6.262574ms)
  Apr 29 12:38:13.466: INFO: (12) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 7.889336ms)
  Apr 29 12:38:13.466: INFO: (12) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 7.96733ms)
  Apr 29 12:38:13.466: INFO: (12) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 8.693519ms)
  Apr 29 12:38:13.466: INFO: (12) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 8.436716ms)
  Apr 29 12:38:13.466: INFO: (12) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 8.502894ms)
  Apr 29 12:38:13.467: INFO: (12) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 8.75537ms)
  Apr 29 12:38:13.467: INFO: (12) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 9.234724ms)
  Apr 29 12:38:13.467: INFO: (12) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 9.369089ms)
  Apr 29 12:38:13.467: INFO: (12) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 9.474835ms)
  Apr 29 12:38:13.468: INFO: (12) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 9.629194ms)
  Apr 29 12:38:13.468: INFO: (12) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 9.775319ms)
  Apr 29 12:38:13.468: INFO: (12) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 9.988044ms)
  Apr 29 12:38:13.473: INFO: (13) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 4.636712ms)
  Apr 29 12:38:13.473: INFO: (13) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 4.608446ms)
  Apr 29 12:38:13.475: INFO: (13) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 6.685936ms)
  Apr 29 12:38:13.475: INFO: (13) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 6.911443ms)
  Apr 29 12:38:13.475: INFO: (13) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 7.035953ms)
  Apr 29 12:38:13.476: INFO: (13) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 7.053353ms)
  Apr 29 12:38:13.476: INFO: (13) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 7.649678ms)
  Apr 29 12:38:13.477: INFO: (13) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 8.046713ms)
  Apr 29 12:38:13.477: INFO: (13) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 8.335505ms)
  Apr 29 12:38:13.477: INFO: (13) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 8.872875ms)
  Apr 29 12:38:13.478: INFO: (13) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 9.279481ms)
  Apr 29 12:38:13.478: INFO: (13) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 9.31654ms)
  Apr 29 12:38:13.479: INFO: (13) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 9.9101ms)
  Apr 29 12:38:13.479: INFO: (13) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.0687ms)
  Apr 29 12:38:13.479: INFO: (13) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 10.311022ms)
  Apr 29 12:38:13.479: INFO: (13) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 10.604576ms)
  Apr 29 12:38:13.484: INFO: (14) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 4.274967ms)
  Apr 29 12:38:13.484: INFO: (14) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 4.131239ms)
  Apr 29 12:38:13.485: INFO: (14) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 5.220211ms)
  Apr 29 12:38:13.486: INFO: (14) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 6.07778ms)
  Apr 29 12:38:13.486: INFO: (14) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 6.710418ms)
  Apr 29 12:38:13.487: INFO: (14) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 7.543135ms)
  Apr 29 12:38:13.487: INFO: (14) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 7.599034ms)
  Apr 29 12:38:13.488: INFO: (14) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 8.33024ms)
  Apr 29 12:38:13.488: INFO: (14) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 8.343157ms)
  Apr 29 12:38:13.489: INFO: (14) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 9.08914ms)
  Apr 29 12:38:13.490: INFO: (14) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 9.855771ms)
  Apr 29 12:38:13.490: INFO: (14) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 9.958381ms)
  Apr 29 12:38:13.490: INFO: (14) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.072873ms)
  Apr 29 12:38:13.490: INFO: (14) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 10.463007ms)
  Apr 29 12:38:13.490: INFO: (14) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.613013ms)
  Apr 29 12:38:13.490: INFO: (14) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 11.041031ms)
  Apr 29 12:38:13.495: INFO: (15) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 4.474359ms)
  Apr 29 12:38:13.495: INFO: (15) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 4.801525ms)
  Apr 29 12:38:13.496: INFO: (15) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 5.625737ms)
  Apr 29 12:38:13.497: INFO: (15) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 6.358773ms)
  Apr 29 12:38:13.498: INFO: (15) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 7.358257ms)
  Apr 29 12:38:13.500: INFO: (15) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 9.36926ms)
  Apr 29 12:38:13.501: INFO: (15) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 10.240544ms)
  Apr 29 12:38:13.501: INFO: (15) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.298417ms)
  Apr 29 12:38:13.501: INFO: (15) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 10.657651ms)
  Apr 29 12:38:13.501: INFO: (15) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 10.709706ms)
  Apr 29 12:38:13.501: INFO: (15) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 10.584353ms)
  Apr 29 12:38:13.501: INFO: (15) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 10.642641ms)
  Apr 29 12:38:13.501: INFO: (15) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 10.502884ms)
  Apr 29 12:38:13.501: INFO: (15) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 10.675957ms)
  Apr 29 12:38:13.502: INFO: (15) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 10.77641ms)
  Apr 29 12:38:13.502: INFO: (15) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 10.982265ms)
  Apr 29 12:38:13.509: INFO: (16) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 6.445434ms)
  Apr 29 12:38:13.509: INFO: (16) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 6.502808ms)
  Apr 29 12:38:13.511: INFO: (16) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 8.033002ms)
  Apr 29 12:38:13.512: INFO: (16) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 9.450507ms)
  Apr 29 12:38:13.513: INFO: (16) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.104245ms)
  Apr 29 12:38:13.513: INFO: (16) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 10.354706ms)
  Apr 29 12:38:13.513: INFO: (16) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 10.216403ms)
  Apr 29 12:38:13.513: INFO: (16) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 10.723426ms)
  Apr 29 12:38:13.513: INFO: (16) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 10.65376ms)
  Apr 29 12:38:13.514: INFO: (16) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 11.191747ms)
  Apr 29 12:38:13.514: INFO: (16) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 11.428843ms)
  Apr 29 12:38:13.514: INFO: (16) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.990098ms)
  Apr 29 12:38:13.514: INFO: (16) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 11.671795ms)
  Apr 29 12:38:13.514: INFO: (16) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.67683ms)
  Apr 29 12:38:13.514: INFO: (16) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 12.00129ms)
  Apr 29 12:38:13.514: INFO: (16) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 11.967569ms)
  Apr 29 12:38:13.521: INFO: (17) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 6.288607ms)
  Apr 29 12:38:13.522: INFO: (17) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 7.508019ms)
  Apr 29 12:38:13.522: INFO: (17) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 7.281792ms)
  Apr 29 12:38:13.523: INFO: (17) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 7.880822ms)
  Apr 29 12:38:13.523: INFO: (17) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 8.103977ms)
  Apr 29 12:38:13.523: INFO: (17) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 8.004643ms)
  Apr 29 12:38:13.525: INFO: (17) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 10.246766ms)
  Apr 29 12:38:13.525: INFO: (17) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 10.299171ms)
  Apr 29 12:38:13.526: INFO: (17) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.721214ms)
  Apr 29 12:38:13.526: INFO: (17) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 11.137047ms)
  Apr 29 12:38:13.526: INFO: (17) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 11.056446ms)
  Apr 29 12:38:13.526: INFO: (17) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 11.260139ms)
  Apr 29 12:38:13.526: INFO: (17) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 11.551825ms)
  Apr 29 12:38:13.527: INFO: (17) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 11.967805ms)
  Apr 29 12:38:13.527: INFO: (17) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 11.687358ms)
  Apr 29 12:38:13.527: INFO: (17) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 12.040398ms)
  Apr 29 12:38:13.534: INFO: (18) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 7.266436ms)
  Apr 29 12:38:13.535: INFO: (18) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 7.934451ms)
  Apr 29 12:38:13.536: INFO: (18) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 7.914045ms)
  Apr 29 12:38:13.537: INFO: (18) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 9.727497ms)
  Apr 29 12:38:13.538: INFO: (18) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 10.362419ms)
  Apr 29 12:38:13.538: INFO: (18) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 10.486147ms)
  Apr 29 12:38:13.538: INFO: (18) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 10.673501ms)
  Apr 29 12:38:13.538: INFO: (18) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 10.560485ms)
  Apr 29 12:38:13.538: INFO: (18) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 11.107215ms)
  Apr 29 12:38:13.538: INFO: (18) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.780801ms)
  Apr 29 12:38:13.539: INFO: (18) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 12.090436ms)
  Apr 29 12:38:13.542: INFO: (18) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 14.166435ms)
  Apr 29 12:38:13.542: INFO: (18) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 14.300928ms)
  Apr 29 12:38:13.542: INFO: (18) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 14.047887ms)
  Apr 29 12:38:13.542: INFO: (18) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 14.221022ms)
  Apr 29 12:38:13.542: INFO: (18) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 14.438871ms)
  Apr 29 12:38:13.547: INFO: (19) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:460/proxy/: tls baz (200; 4.63603ms)
  Apr 29 12:38:13.551: INFO: (19) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h/proxy/rewriteme">test</a> (200; 8.007862ms)
  Apr 29 12:38:13.552: INFO: (19) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">... (200; 9.714298ms)
  Apr 29 12:38:13.552: INFO: (19) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname1/proxy/: tls baz (200; 9.815328ms)
  Apr 29 12:38:13.552: INFO: (19) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 9.856867ms)
  Apr 29 12:38:13.552: INFO: (19) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:462/proxy/: tls qux (200; 9.895859ms)
  Apr 29 12:38:13.553: INFO: (19) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname1/proxy/: foo (200; 10.201023ms)
  Apr 29 12:38:13.553: INFO: (19) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:160/proxy/: foo (200; 10.107158ms)
  Apr 29 12:38:13.553: INFO: (19) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:1080/proxy/rewriteme">test<... (200; 10.216032ms)
  Apr 29 12:38:13.553: INFO: (19) /api/v1/namespaces/proxy-6633/pods/http:proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 10.406922ms)
  Apr 29 12:38:13.554: INFO: (19) /api/v1/namespaces/proxy-6633/services/http:proxy-service-tnzsk:portname2/proxy/: bar (200; 11.297501ms)
  Apr 29 12:38:13.554: INFO: (19) /api/v1/namespaces/proxy-6633/pods/proxy-service-tnzsk-d7q9h:162/proxy/: bar (200; 11.651658ms)
  Apr 29 12:38:13.554: INFO: (19) /api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/: <a href="/api/v1/namespaces/proxy-6633/pods/https:proxy-service-tnzsk-d7q9h:443/proxy/tlsrewritem... (200; 11.983648ms)
  Apr 29 12:38:13.555: INFO: (19) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname1/proxy/: foo (200; 12.464731ms)
  Apr 29 12:38:13.555: INFO: (19) /api/v1/namespaces/proxy-6633/services/proxy-service-tnzsk:portname2/proxy/: bar (200; 12.363283ms)
  Apr 29 12:38:13.556: INFO: (19) /api/v1/namespaces/proxy-6633/services/https:proxy-service-tnzsk:tlsportname2/proxy/: tls qux (200; 13.174081ms)
  Apr 29 12:38:13.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-tnzsk in namespace proxy-6633, will wait for the garbage collector to delete the pods @ 04/29/23 12:38:13.56
  Apr 29 12:38:13.622: INFO: Deleting ReplicationController proxy-service-tnzsk took: 7.849033ms
  Apr 29 12:38:13.723: INFO: Terminating ReplicationController proxy-service-tnzsk pods took: 100.648458ms
  STEP: Destroying namespace "proxy-6633" for this suite. @ 04/29/23 12:38:16.224
• [4.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 04/29/23 12:38:16.232
  Apr 29 12:38:16.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:38:16.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:16.249
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:16.254
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:38:16.257
  STEP: Saw pod success @ 04/29/23 12:38:20.284
  Apr 29 12:38:20.287: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-42928576-ad1e-49d5-ba0b-e34bcf69cb2f container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:38:20.304
  Apr 29 12:38:20.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6192" for this suite. @ 04/29/23 12:38:20.326
• [4.099 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 04/29/23 12:38:20.332
  Apr 29 12:38:20.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename podtemplate @ 04/29/23 12:38:20.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:20.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:20.351
  Apr 29 12:38:20.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2763" for this suite. @ 04/29/23 12:38:20.388
• [0.062 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 04/29/23 12:38:20.395
  Apr 29 12:38:20.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 12:38:20.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:20.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:20.416
  STEP: creating service in namespace services-8084 @ 04/29/23 12:38:20.419
  STEP: creating service affinity-nodeport-transition in namespace services-8084 @ 04/29/23 12:38:20.419
  STEP: creating replication controller affinity-nodeport-transition in namespace services-8084 @ 04/29/23 12:38:20.435
  I0429 12:38:20.447560      18 runners.go:194] Created replication controller with name: affinity-nodeport-transition, namespace: services-8084, replica count: 3
  I0429 12:38:23.498236      18 runners.go:194] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 12:38:23.509: INFO: Creating new exec pod
  Apr 29 12:38:26.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-8084 exec execpod-affinityzfblv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Apr 29 12:38:26.665: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Apr 29 12:38:26.665: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 12:38:26.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-8084 exec execpod-affinityzfblv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.248 80'
  Apr 29 12:38:26.786: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.248 80\nConnection to 10.152.183.248 80 port [tcp/http] succeeded!\n"
  Apr 29 12:38:26.786: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 12:38:26.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-8084 exec execpod-affinityzfblv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.80 31920'
  Apr 29 12:38:26.912: INFO: stderr: "+ nc -v -t -w 2 172.31.41.80 31920\n+ echo hostName\nConnection to 172.31.41.80 31920 port [tcp/*] succeeded!\n"
  Apr 29 12:38:26.912: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 12:38:26.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-8084 exec execpod-affinityzfblv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.13 31920'
  Apr 29 12:38:27.036: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.13 31920\nConnection to 172.31.25.13 31920 port [tcp/*] succeeded!\n"
  Apr 29 12:38:27.036: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 12:38:27.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-8084 exec execpod-affinityzfblv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.25.13:31920/ ; done'
  Apr 29 12:38:27.267: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n"
  Apr 29 12:38:27.267: INFO: stdout: "\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-67fc6\naffinity-nodeport-transition-67fc6\naffinity-nodeport-transition-dgmmq\naffinity-nodeport-transition-dgmmq\naffinity-nodeport-transition-67fc6\naffinity-nodeport-transition-67fc6\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-dgmmq\naffinity-nodeport-transition-67fc6\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-67fc6\naffinity-nodeport-transition-67fc6\naffinity-nodeport-transition-dgmmq\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-67fc6"
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-67fc6
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-67fc6
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-dgmmq
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-dgmmq
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-67fc6
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-67fc6
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-dgmmq
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-67fc6
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-67fc6
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-67fc6
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-dgmmq
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.267: INFO: Received response from host: affinity-nodeport-transition-67fc6
  Apr 29 12:38:27.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-8084 exec execpod-affinityzfblv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.25.13:31920/ ; done'
  Apr 29 12:38:27.485: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31920/\n"
  Apr 29 12:38:27.485: INFO: stdout: "\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c\naffinity-nodeport-transition-t627c"
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Received response from host: affinity-nodeport-transition-t627c
  Apr 29 12:38:27.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 12:38:27.490: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-8084, will wait for the garbage collector to delete the pods @ 04/29/23 12:38:27.502
  Apr 29 12:38:27.563: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.439246ms
  Apr 29 12:38:27.664: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.961647ms
  STEP: Destroying namespace "services-8084" for this suite. @ 04/29/23 12:38:29.889
• [9.500 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:272
  STEP: Creating a kubernetes client @ 04/29/23 12:38:29.896
  Apr 29 12:38:29.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:38:29.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:29.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:29.917
  STEP: Setting up server cert @ 04/29/23 12:38:29.941
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:38:30.518
  STEP: Deploying the webhook pod @ 04/29/23 12:38:30.527
  STEP: Wait for the deployment to be ready @ 04/29/23 12:38:30.537
  Apr 29 12:38:30.544: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/29/23 12:38:32.556
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:38:32.57
  Apr 29 12:38:33.570: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/29/23 12:38:33.575
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/29/23 12:38:33.591
  STEP: Creating a dummy validating-webhook-configuration object @ 04/29/23 12:38:33.605
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 04/29/23 12:38:33.613
  STEP: Creating a dummy mutating-webhook-configuration object @ 04/29/23 12:38:33.62
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 04/29/23 12:38:33.628
  Apr 29 12:38:33.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2291" for this suite. @ 04/29/23 12:38:33.698
  STEP: Destroying namespace "webhook-markers-937" for this suite. @ 04/29/23 12:38:33.705
• [3.815 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 04/29/23 12:38:33.714
  Apr 29 12:38:33.714: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-runtime @ 04/29/23 12:38:33.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:33.73
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:33.733
  STEP: create the container @ 04/29/23 12:38:33.736
  W0429 12:38:33.747577      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/29/23 12:38:33.748
  STEP: get the container status @ 04/29/23 12:38:36.768
  STEP: the container should be terminated @ 04/29/23 12:38:36.771
  STEP: the termination message should be set @ 04/29/23 12:38:36.771
  Apr 29 12:38:36.771: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 04/29/23 12:38:36.771
  Apr 29 12:38:36.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6099" for this suite. @ 04/29/23 12:38:36.793
• [3.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 04/29/23 12:38:36.803
  Apr 29 12:38:36.804: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 12:38:36.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:36.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:36.825
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 04/29/23 12:38:36.828
  Apr 29 12:38:36.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:38:38.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:38:43.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5643" for this suite. @ 04/29/23 12:38:43.54
• [6.743 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 04/29/23 12:38:43.548
  Apr 29 12:38:43.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename endpointslicemirroring @ 04/29/23 12:38:43.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:43.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:43.571
  STEP: mirroring a new custom Endpoint @ 04/29/23 12:38:43.586
  Apr 29 12:38:43.597: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  STEP: mirroring an update to a custom Endpoint @ 04/29/23 12:38:45.601
  Apr 29 12:38:45.609: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  STEP: mirroring deletion of a custom Endpoint @ 04/29/23 12:38:47.613
  Apr 29 12:38:47.625: INFO: Waiting for 0 EndpointSlices to exist, got 1
  Apr 29 12:38:49.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-69" for this suite. @ 04/29/23 12:38:49.633
• [6.092 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 04/29/23 12:38:49.64
  Apr 29 12:38:49.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename events @ 04/29/23 12:38:49.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:49.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:49.658
  STEP: creating a test event @ 04/29/23 12:38:49.662
  STEP: listing all events in all namespaces @ 04/29/23 12:38:49.667
  STEP: patching the test event @ 04/29/23 12:38:49.68
  STEP: fetching the test event @ 04/29/23 12:38:49.689
  STEP: updating the test event @ 04/29/23 12:38:49.692
  STEP: getting the test event @ 04/29/23 12:38:49.702
  STEP: deleting the test event @ 04/29/23 12:38:49.705
  STEP: listing all events in all namespaces @ 04/29/23 12:38:49.713
  Apr 29 12:38:49.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7835" for this suite. @ 04/29/23 12:38:49.725
• [0.090 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 04/29/23 12:38:49.731
  Apr 29 12:38:49.731: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 12:38:49.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:49.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:49.749
  STEP: Saw pod success @ 04/29/23 12:38:55.817
  Apr 29 12:38:55.821: INFO: Trying to get logs from node ip-172-31-41-80 pod client-envvars-08652d2e-8323-424e-bed4-893e954bfd6e container env3cont: <nil>
  STEP: delete the pod @ 04/29/23 12:38:55.83
  Apr 29 12:38:55.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-562" for this suite. @ 04/29/23 12:38:55.846
• [6.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 04/29/23 12:38:55.854
  Apr 29 12:38:55.854: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 12:38:55.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:55.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:55.872
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/29/23 12:38:55.875
  STEP: Saw pod success @ 04/29/23 12:38:59.898
  Apr 29 12:38:59.901: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-80da7336-8ed3-479a-ab28-059a8c63659d container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:38:59.908
  Apr 29 12:38:59.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1992" for this suite. @ 04/29/23 12:38:59.928
• [4.081 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 04/29/23 12:38:59.936
  Apr 29 12:38:59.936: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:38:59.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:38:59.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:38:59.955
  STEP: Creating the pod @ 04/29/23 12:38:59.958
  Apr 29 12:39:02.500: INFO: Successfully updated pod "labelsupdatec696f5df-6698-4d20-bd37-d06422fbc8aa"
  Apr 29 12:39:04.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9759" for this suite. @ 04/29/23 12:39:04.52
• [4.592 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:118
  STEP: Creating a kubernetes client @ 04/29/23 12:39:04.528
  Apr 29 12:39:04.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:39:04.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:04.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:04.547
  STEP: Setting up server cert @ 04/29/23 12:39:04.568
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:39:04.707
  STEP: Deploying the webhook pod @ 04/29/23 12:39:04.715
  STEP: Wait for the deployment to be ready @ 04/29/23 12:39:04.726
  Apr 29 12:39:04.736: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:39:06.748
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:39:06.758
  Apr 29 12:39:07.759: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 04/29/23 12:39:07.762
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 04/29/23 12:39:07.764
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 04/29/23 12:39:07.764
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 04/29/23 12:39:07.764
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 04/29/23 12:39:07.765
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/29/23 12:39:07.765
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/29/23 12:39:07.767
  Apr 29 12:39:07.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9686" for this suite. @ 04/29/23 12:39:07.815
  STEP: Destroying namespace "webhook-markers-1103" for this suite. @ 04/29/23 12:39:07.824
• [3.303 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 04/29/23 12:39:07.831
  Apr 29 12:39:07.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:39:07.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:07.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:07.853
  STEP: Creating projection with secret that has name projected-secret-test-6d4298b5-d16c-42f9-9636-90f3d675e535 @ 04/29/23 12:39:07.856
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:39:07.861
  STEP: Saw pod success @ 04/29/23 12:39:11.883
  Apr 29 12:39:11.886: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-secrets-be20cd8c-a5fe-46f7-847a-375ef2cd32cf container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:39:11.893
  Apr 29 12:39:11.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2415" for this suite. @ 04/29/23 12:39:11.913
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 04/29/23 12:39:11.922
  Apr 29 12:39:11.922: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 12:39:11.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:11.934
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:11.938
  STEP: set up a multi version CRD @ 04/29/23 12:39:11.942
  Apr 29 12:39:11.942: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: mark a version not serverd @ 04/29/23 12:39:15.312
  STEP: check the unserved version gets removed @ 04/29/23 12:39:15.334
  STEP: check the other version is not changed @ 04/29/23 12:39:16.711
  Apr 29 12:39:19.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3887" for this suite. @ 04/29/23 12:39:19.356
• [7.442 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 04/29/23 12:39:19.364
  Apr 29 12:39:19.364: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename watch @ 04/29/23 12:39:19.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:19.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:19.382
  STEP: creating a watch on configmaps with a certain label @ 04/29/23 12:39:19.386
  STEP: creating a new configmap @ 04/29/23 12:39:19.387
  STEP: modifying the configmap once @ 04/29/23 12:39:19.392
  STEP: changing the label value of the configmap @ 04/29/23 12:39:19.399
  STEP: Expecting to observe a delete notification for the watched object @ 04/29/23 12:39:19.408
  Apr 29 12:39:19.408: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4887  5c396f8e-bdbf-4c7c-adea-466aa026ef88 17298 0 2023-04-29 12:39:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-29 12:39:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:39:19.408: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4887  5c396f8e-bdbf-4c7c-adea-466aa026ef88 17299 0 2023-04-29 12:39:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-29 12:39:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:39:19.408: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4887  5c396f8e-bdbf-4c7c-adea-466aa026ef88 17300 0 2023-04-29 12:39:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-29 12:39:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 04/29/23 12:39:19.408
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 04/29/23 12:39:19.415
  STEP: changing the label value of the configmap back @ 04/29/23 12:39:29.417
  STEP: modifying the configmap a third time @ 04/29/23 12:39:29.427
  STEP: deleting the configmap @ 04/29/23 12:39:29.435
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 04/29/23 12:39:29.442
  Apr 29 12:39:29.442: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4887  5c396f8e-bdbf-4c7c-adea-466aa026ef88 17328 0 2023-04-29 12:39:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-29 12:39:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:39:29.443: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4887  5c396f8e-bdbf-4c7c-adea-466aa026ef88 17329 0 2023-04-29 12:39:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-29 12:39:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:39:29.443: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4887  5c396f8e-bdbf-4c7c-adea-466aa026ef88 17330 0 2023-04-29 12:39:19 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-29 12:39:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:39:29.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4887" for this suite. @ 04/29/23 12:39:29.447
• [10.090 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 04/29/23 12:39:29.454
  Apr 29 12:39:29.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename svcaccounts @ 04/29/23 12:39:29.455
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:29.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:29.474
  Apr 29 12:39:29.481: INFO: Got root ca configmap in namespace "svcaccounts-5585"
  Apr 29 12:39:29.486: INFO: Deleted root ca configmap in namespace "svcaccounts-5585"
  STEP: waiting for a new root ca configmap created @ 04/29/23 12:39:29.987
  Apr 29 12:39:29.991: INFO: Recreated root ca configmap in namespace "svcaccounts-5585"
  Apr 29 12:39:29.995: INFO: Updated root ca configmap in namespace "svcaccounts-5585"
  STEP: waiting for the root ca configmap reconciled @ 04/29/23 12:39:30.496
  Apr 29 12:39:30.500: INFO: Reconciled root ca configmap in namespace "svcaccounts-5585"
  Apr 29 12:39:30.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5585" for this suite. @ 04/29/23 12:39:30.505
• [1.057 seconds]
------------------------------
S
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 04/29/23 12:39:30.512
  Apr 29 12:39:30.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 12:39:30.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:30.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:30.53
  STEP: Creating secret with name secret-test-0d10b208-f38e-4fc8-b1c8-aa3cb79aa9c9 @ 04/29/23 12:39:30.534
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:39:30.538
  STEP: Saw pod success @ 04/29/23 12:39:34.558
  Apr 29 12:39:34.563: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-secrets-37bc209b-e61a-406c-a1fb-e526942342fb container secret-env-test: <nil>
  STEP: delete the pod @ 04/29/23 12:39:34.57
  Apr 29 12:39:34.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4745" for this suite. @ 04/29/23 12:39:34.592
• [4.086 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 04/29/23 12:39:34.598
  Apr 29 12:39:34.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename namespaces @ 04/29/23 12:39:34.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:34.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:34.621
  STEP: Read namespace status @ 04/29/23 12:39:34.625
  Apr 29 12:39:34.629: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 04/29/23 12:39:34.629
  Apr 29 12:39:34.633: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 04/29/23 12:39:34.634
  Apr 29 12:39:34.647: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Apr 29 12:39:34.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8195" for this suite. @ 04/29/23 12:39:34.656
• [0.068 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 04/29/23 12:39:34.675
  Apr 29 12:39:34.675: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:39:34.679
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:34.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:34.713
  STEP: Creating configMap that has name configmap-test-emptyKey-a39f37e3-c198-4fac-94d1-5adaccb1fbb4 @ 04/29/23 12:39:34.716
  Apr 29 12:39:34.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3444" for this suite. @ 04/29/23 12:39:34.723
• [0.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 04/29/23 12:39:34.735
  Apr 29 12:39:34.735: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename dns @ 04/29/23 12:39:34.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:34.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:34.753
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 04/29/23 12:39:34.76
  Apr 29 12:39:34.768: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7534  3d102fb4-a8c8-4995-b4cf-24475177ee6f 17402 0 2023-04-29 12:39:34 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-29 12:39:34 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-289bc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-289bc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 04/29/23 12:39:36.777
  Apr 29 12:39:36.777: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7534 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:39:36.777: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:39:36.778: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:39:36.778: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7534/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 04/29/23 12:39:36.849
  Apr 29 12:39:36.849: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7534 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:39:36.849: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:39:36.850: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:39:36.850: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7534/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 29 12:39:36.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 12:39:36.922: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-7534" for this suite. @ 04/29/23 12:39:36.936
• [2.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 04/29/23 12:39:36.943
  Apr 29 12:39:36.943: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename svcaccounts @ 04/29/23 12:39:36.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:39:36.958
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:39:36.961
  Apr 29 12:39:36.978: INFO: created pod
  STEP: Saw pod success @ 04/29/23 12:39:40.994
  Apr 29 12:40:10.994: INFO: polling logs
  Apr 29 12:40:11.002: INFO: Pod logs: 
  I0429 12:39:37.741504       1 log.go:198] OK: Got token
  I0429 12:39:37.742637       1 log.go:198] validating with in-cluster discovery
  I0429 12:39:37.743294       1 log.go:198] OK: got issuer https://kubernetes.default.svc
  I0429 12:39:37.743442       1 log.go:198] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-6514:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682772577, NotBefore:1682771977, IssuedAt:1682771977, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-6514", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"7d17a68c-f0fe-4aab-ac37-e43448835c9b"}}}
  I0429 12:39:37.756583       1 log.go:198] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I0429 12:39:37.764806       1 log.go:198] OK: Validated signature on JWT
  I0429 12:39:37.764924       1 log.go:198] OK: Got valid claims from token!
  I0429 12:39:37.764953       1 log.go:198] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-6514:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682772577, NotBefore:1682771977, IssuedAt:1682771977, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-6514", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"7d17a68c-f0fe-4aab-ac37-e43448835c9b"}}}

  Apr 29 12:40:11.002: INFO: completed pod
  Apr 29 12:40:11.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6514" for this suite. @ 04/29/23 12:40:11.013
• [34.077 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 04/29/23 12:40:11.02
  Apr 29 12:40:11.021: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:40:11.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:40:11.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:40:11.041
  STEP: Creating configMap with name configmap-test-volume-ee60366b-8dce-493e-8f26-fd6b11dc0543 @ 04/29/23 12:40:11.044
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:40:11.048
  STEP: Saw pod success @ 04/29/23 12:40:15.067
  Apr 29 12:40:15.071: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-431a5032-501b-4abd-8747-1db8e64c43ca container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 12:40:15.078
  Apr 29 12:40:15.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1927" for this suite. @ 04/29/23 12:40:15.101
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 04/29/23 12:40:15.109
  Apr 29 12:40:15.109: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename security-context @ 04/29/23 12:40:15.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:40:15.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:40:15.126
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/29/23 12:40:15.13
  STEP: Saw pod success @ 04/29/23 12:40:19.152
  Apr 29 12:40:19.156: INFO: Trying to get logs from node ip-172-31-41-80 pod security-context-b74da8ee-4d38-4563-9fef-94b7347a75cd container test-container: <nil>
  STEP: delete the pod @ 04/29/23 12:40:19.162
  Apr 29 12:40:19.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6252" for this suite. @ 04/29/23 12:40:19.183
• [4.080 seconds]
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 04/29/23 12:40:19.189
  Apr 29 12:40:19.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename events @ 04/29/23 12:40:19.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:40:19.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:40:19.208
  STEP: Create set of events @ 04/29/23 12:40:19.212
  STEP: get a list of Events with a label in the current namespace @ 04/29/23 12:40:19.229
  STEP: delete a list of events @ 04/29/23 12:40:19.233
  Apr 29 12:40:19.233: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/29/23 12:40:19.254
  Apr 29 12:40:19.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1053" for this suite. @ 04/29/23 12:40:19.262
• [0.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 04/29/23 12:40:19.27
  Apr 29 12:40:19.270: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename var-expansion @ 04/29/23 12:40:19.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:40:19.284
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:40:19.288
  STEP: creating the pod with failed condition @ 04/29/23 12:40:19.291
  STEP: updating the pod @ 04/29/23 12:42:19.3
  Apr 29 12:42:19.812: INFO: Successfully updated pod "var-expansion-72d3cf6e-20b0-4d46-ae1d-30b6b0b47ed1"
  STEP: waiting for pod running @ 04/29/23 12:42:19.812
  STEP: deleting the pod gracefully @ 04/29/23 12:42:21.822
  Apr 29 12:42:21.822: INFO: Deleting pod "var-expansion-72d3cf6e-20b0-4d46-ae1d-30b6b0b47ed1" in namespace "var-expansion-7813"
  Apr 29 12:42:21.829: INFO: Wait up to 5m0s for pod "var-expansion-72d3cf6e-20b0-4d46-ae1d-30b6b0b47ed1" to be fully deleted
  Apr 29 12:42:53.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7813" for this suite. @ 04/29/23 12:42:53.91
• [154.646 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 04/29/23 12:42:53.917
  Apr 29 12:42:53.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename svcaccounts @ 04/29/23 12:42:53.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:42:53.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:42:53.944
  STEP: reading a file in the container @ 04/29/23 12:42:55.971
  Apr 29 12:42:55.971: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8579 pod-service-account-75843046-41f8-425f-8c92-3063ecd2ee4a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 04/29/23 12:42:56.101
  Apr 29 12:42:56.101: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8579 pod-service-account-75843046-41f8-425f-8c92-3063ecd2ee4a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 04/29/23 12:42:56.217
  Apr 29 12:42:56.217: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8579 pod-service-account-75843046-41f8-425f-8c92-3063ecd2ee4a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Apr 29 12:42:56.336: INFO: Got root ca configmap in namespace "svcaccounts-8579"
  Apr 29 12:42:56.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8579" for this suite. @ 04/29/23 12:42:56.343
• [2.433 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 04/29/23 12:42:56.35
  Apr 29 12:42:56.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:42:56.351
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:42:56.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:42:56.37
  STEP: Creating configMap with name projected-configmap-test-volume-map-1d921604-d55c-4edd-82e6-60b46b38fd04 @ 04/29/23 12:42:56.373
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:42:56.377
  STEP: Saw pod success @ 04/29/23 12:43:00.399
  Apr 29 12:43:00.403: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-configmaps-1534fdb0-5ad6-4329-b79c-baa51ec6ac9f container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 12:43:00.417
  Apr 29 12:43:00.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1186" for this suite. @ 04/29/23 12:43:00.438
• [4.094 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 04/29/23 12:43:00.445
  Apr 29 12:43:00.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubelet-test @ 04/29/23 12:43:00.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:43:00.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:43:00.463
  Apr 29 12:43:00.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8703" for this suite. @ 04/29/23 12:43:00.494
• [0.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 04/29/23 12:43:00.503
  Apr 29 12:43:00.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 12:43:00.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:43:00.52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:43:00.523
  Apr 29 12:43:00.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: creating the pod @ 04/29/23 12:43:00.527
  STEP: submitting the pod to kubernetes @ 04/29/23 12:43:00.527
  Apr 29 12:43:02.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3816" for this suite. @ 04/29/23 12:43:02.668
• [2.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 04/29/23 12:43:02.677
  Apr 29 12:43:02.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 12:43:02.678
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:43:02.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:43:02.696
  STEP: creating service multi-endpoint-test in namespace services-897 @ 04/29/23 12:43:02.703
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-897 to expose endpoints map[] @ 04/29/23 12:43:02.717
  Apr 29 12:43:02.724: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  Apr 29 12:43:03.734: INFO: successfully validated that service multi-endpoint-test in namespace services-897 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-897 @ 04/29/23 12:43:03.734
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-897 to expose endpoints map[pod1:[100]] @ 04/29/23 12:43:05.754
  Apr 29 12:43:05.766: INFO: successfully validated that service multi-endpoint-test in namespace services-897 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-897 @ 04/29/23 12:43:05.766
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-897 to expose endpoints map[pod1:[100] pod2:[101]] @ 04/29/23 12:43:07.786
  Apr 29 12:43:07.801: INFO: successfully validated that service multi-endpoint-test in namespace services-897 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 04/29/23 12:43:07.801
  Apr 29 12:43:07.801: INFO: Creating new exec pod
  Apr 29 12:43:10.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-897 exec execpoddgxj6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Apr 29 12:43:10.969: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Apr 29 12:43:10.969: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 12:43:10.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-897 exec execpoddgxj6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.238 80'
  Apr 29 12:43:11.098: INFO: stderr: "+ nc -v -t -w 2 10.152.183.238 80\nConnection to 10.152.183.238 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Apr 29 12:43:11.098: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 12:43:11.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-897 exec execpoddgxj6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Apr 29 12:43:11.216: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Apr 29 12:43:11.216: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 12:43:11.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-897 exec execpoddgxj6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.238 81'
  Apr 29 12:43:11.335: INFO: stderr: "+ nc -v -t -w 2 10.152.183.238 81\n+ echo hostName\nConnection to 10.152.183.238 81 port [tcp/*] succeeded!\n"
  Apr 29 12:43:11.335: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-897 @ 04/29/23 12:43:11.335
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-897 to expose endpoints map[pod2:[101]] @ 04/29/23 12:43:11.357
  Apr 29 12:43:11.368: INFO: successfully validated that service multi-endpoint-test in namespace services-897 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-897 @ 04/29/23 12:43:11.368
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-897 to expose endpoints map[] @ 04/29/23 12:43:11.383
  Apr 29 12:43:11.397: INFO: successfully validated that service multi-endpoint-test in namespace services-897 exposes endpoints map[]
  Apr 29 12:43:11.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-897" for this suite. @ 04/29/23 12:43:11.42
• [8.750 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:610
  STEP: Creating a kubernetes client @ 04/29/23 12:43:11.428
  Apr 29 12:43:11.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename field-validation @ 04/29/23 12:43:11.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:43:11.445
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:43:11.449
  Apr 29 12:43:11.452: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  W0429 12:43:14.003717      18 warnings.go:70] unknown field "alpha"
  W0429 12:43:14.003737      18 warnings.go:70] unknown field "beta"
  W0429 12:43:14.003743      18 warnings.go:70] unknown field "delta"
  W0429 12:43:14.003749      18 warnings.go:70] unknown field "epsilon"
  W0429 12:43:14.003755      18 warnings.go:70] unknown field "gamma"
  Apr 29 12:43:14.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2222" for this suite. @ 04/29/23 12:43:14.035
• [2.613 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 04/29/23 12:43:14.043
  Apr 29 12:43:14.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 12:43:14.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:43:14.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:43:14.061
  STEP: Creating configMap configmap-579/configmap-test-48e88d76-6c5f-42db-b14f-d8deba5634f0 @ 04/29/23 12:43:14.064
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:43:14.068
  STEP: Saw pod success @ 04/29/23 12:43:18.092
  Apr 29 12:43:18.096: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-58d32880-4a4c-45a2-8f68-5576811c0281 container env-test: <nil>
  STEP: delete the pod @ 04/29/23 12:43:18.103
  Apr 29 12:43:18.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-579" for this suite. @ 04/29/23 12:43:18.125
• [4.091 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:701
  STEP: Creating a kubernetes client @ 04/29/23 12:43:18.138
  Apr 29 12:43:18.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename statefulset @ 04/29/23 12:43:18.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:43:18.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:43:18.158
  STEP: Creating service test in namespace statefulset-8033 @ 04/29/23 12:43:18.162
  STEP: Creating stateful set ss in namespace statefulset-8033 @ 04/29/23 12:43:18.172
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8033 @ 04/29/23 12:43:18.179
  Apr 29 12:43:18.182: INFO: Found 0 stateful pods, waiting for 1
  Apr 29 12:43:28.190: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 04/29/23 12:43:28.19
  Apr 29 12:43:28.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-8033 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:43:28.317: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:43:28.317: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:43:28.317: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:43:28.321: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Apr 29 12:43:38.327: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 29 12:43:38.327: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:43:38.347: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
  Apr 29 12:43:38.347: INFO: ss-0  ip-172-31-41-80  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:18 +0000 UTC  }]
  Apr 29 12:43:38.347: INFO: 
  Apr 29 12:43:38.347: INFO: StatefulSet ss has not reached scale 3, at 1
  Apr 29 12:43:39.352: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99374927s
  Apr 29 12:43:40.356: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989013353s
  Apr 29 12:43:41.362: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984305565s
  Apr 29 12:43:42.367: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978909086s
  Apr 29 12:43:43.371: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974489353s
  Apr 29 12:43:44.375: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970606606s
  Apr 29 12:43:45.380: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965088659s
  Apr 29 12:43:46.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961139406s
  Apr 29 12:43:47.389: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.764281ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8033 @ 04/29/23 12:43:48.389
  Apr 29 12:43:48.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-8033 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:43:48.515: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 29 12:43:48.515: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:43:48.515: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 29 12:43:48.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-8033 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:43:48.635: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 29 12:43:48.635: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:43:48.635: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 29 12:43:48.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-8033 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 29 12:43:48.774: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 29 12:43:48.774: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 29 12:43:48.774: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 29 12:43:48.777: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 12:43:48.777: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 12:43:48.777: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 04/29/23 12:43:48.777
  Apr 29 12:43:48.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-8033 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:43:48.901: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:43:48.901: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:43:48.901: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:43:48.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-8033 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:43:49.021: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:43:49.021: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:43:49.021: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:43:49.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=statefulset-8033 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 29 12:43:49.143: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 29 12:43:49.143: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 29 12:43:49.143: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 29 12:43:49.143: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:43:49.146: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
  Apr 29 12:43:59.158: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 29 12:43:59.158: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 29 12:43:59.158: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 29 12:43:59.173: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
  Apr 29 12:43:59.173: INFO: ss-0  ip-172-31-41-80  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:18 +0000 UTC  }]
  Apr 29 12:43:59.173: INFO: ss-1  ip-172-31-82-46  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:38 +0000 UTC  }]
  Apr 29 12:43:59.173: INFO: ss-2  ip-172-31-25-13  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:38 +0000 UTC  }]
  Apr 29 12:43:59.173: INFO: 
  Apr 29 12:43:59.173: INFO: StatefulSet ss has not reached scale 0, at 3
  Apr 29 12:44:00.177: INFO: POD   NODE             PHASE      GRACE  CONDITIONS
  Apr 29 12:44:00.177: INFO: ss-2  ip-172-31-25-13  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:38 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:49 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:49 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 12:43:38 +0000 UTC  }]
  Apr 29 12:44:00.177: INFO: 
  Apr 29 12:44:00.177: INFO: StatefulSet ss has not reached scale 0, at 1
  Apr 29 12:44:01.181: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.991138562s
  Apr 29 12:44:02.186: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.986646255s
  Apr 29 12:44:03.191: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.981705411s
  Apr 29 12:44:04.194: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.977693317s
  Apr 29 12:44:05.199: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.97390595s
  Apr 29 12:44:06.202: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.969757478s
  Apr 29 12:44:07.207: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.965668621s
  Apr 29 12:44:08.211: INFO: Verifying statefulset ss doesn't scale past 0 for another 961.354306ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8033 @ 04/29/23 12:44:09.212
  Apr 29 12:44:09.216: INFO: Scaling statefulset ss to 0
  Apr 29 12:44:09.228: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:44:09.232: INFO: Deleting all statefulset in ns statefulset-8033
  Apr 29 12:44:09.235: INFO: Scaling statefulset ss to 0
  Apr 29 12:44:09.246: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 12:44:09.249: INFO: Deleting statefulset ss
  Apr 29 12:44:09.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8033" for this suite. @ 04/29/23 12:44:09.266
• [51.134 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 04/29/23 12:44:09.273
  Apr 29 12:44:09.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename security-context-test @ 04/29/23 12:44:09.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:44:09.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:44:09.291
  Apr 29 12:44:13.326: INFO: Got logs for pod "busybox-privileged-false-afe262cb-7add-4c66-b120-3999faf0885f": "ip: RTNETLINK answers: Operation not permitted\n"
  Apr 29 12:44:13.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8490" for this suite. @ 04/29/23 12:44:13.33
• [4.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 04/29/23 12:44:13.338
  Apr 29 12:44:13.338: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename deployment @ 04/29/23 12:44:13.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:44:13.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:44:13.362
  Apr 29 12:44:13.365: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Apr 29 12:44:13.373: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 29 12:44:18.377: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/29/23 12:44:18.377
  Apr 29 12:44:18.377: INFO: Creating deployment "test-rolling-update-deployment"
  Apr 29 12:44:18.384: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Apr 29 12:44:18.394: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  Apr 29 12:44:20.402: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Apr 29 12:44:20.406: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Apr 29 12:44:20.416: INFO: Deployment "test-rolling-update-deployment":
  &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7562  bd8b5031-fbf2-485f-92e7-3f887cef61b5 18755 1 2023-04-29 12:44:18 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-29 12:44:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:44:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003095b78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-29 12:44:18 +0000 UTC,LastTransitionTime:2023-04-29 12:44:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-656d657cd8" has successfully progressed.,LastUpdateTime:2023-04-29 12:44:19 +0000 UTC,LastTransitionTime:2023-04-29 12:44:18 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 29 12:44:20.421: INFO: New ReplicaSet "test-rolling-update-deployment-656d657cd8" of Deployment "test-rolling-update-deployment":
  &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-656d657cd8  deployment-7562  3f7dbbd3-8255-4bda-8f5b-0fb59b9a585c 18745 1 2023-04-29 12:44:18 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment bd8b5031-fbf2-485f-92e7-3f887cef61b5 0xc004250077 0xc004250078}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:44:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bd8b5031-fbf2-485f-92e7-3f887cef61b5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:44:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 656d657cd8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004250128 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:44:20.421: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Apr 29 12:44:20.421: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7562  73715b12-8453-458e-8911-e1623bb4e92c 18754 2 2023-04-29 12:44:13 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment bd8b5031-fbf2-485f-92e7-3f887cef61b5 0xc003095f47 0xc003095f48}] [] [{e2e.test Update apps/v1 2023-04-29 12:44:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:44:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bd8b5031-fbf2-485f-92e7-3f887cef61b5\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:44:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004250008 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:44:20.425: INFO: Pod "test-rolling-update-deployment-656d657cd8-vj5cr" is available:
  &Pod{ObjectMeta:{test-rolling-update-deployment-656d657cd8-vj5cr test-rolling-update-deployment-656d657cd8- deployment-7562  749457e5-a7ae-4bf3-99d4-14dd68f4d4ad 18744 0 2023-04-29 12:44:18 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-656d657cd8 3f7dbbd3-8255-4bda-8f5b-0fb59b9a585c 0xc004250597 0xc004250598}] [] [{kube-controller-manager Update v1 2023-04-29 12:44:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3f7dbbd3-8255-4bda-8f5b-0fb59b9a585c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:44:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.35\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nnc6x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nnc6x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:44:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:44:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:44:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:44:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:192.168.226.35,StartTime:2023-04-29 12:44:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:44:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://d0629cdbde923d576f5e6413bd1c6213b4591026d3e20fb3e5f1c20a37b604fd,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.226.35,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:44:20.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7562" for this suite. @ 04/29/23 12:44:20.43
• [7.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 04/29/23 12:44:20.445
  Apr 29 12:44:20.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-preemption @ 04/29/23 12:44:20.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:44:20.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:44:20.469
  Apr 29 12:44:20.487: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 29 12:45:20.509: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/29/23 12:45:20.512
  Apr 29 12:45:20.532: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 29 12:45:20.541: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 29 12:45:20.557: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 29 12:45:20.565: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Apr 29 12:45:20.583: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Apr 29 12:45:20.591: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/29/23 12:45:20.591
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 04/29/23 12:45:22.623
  Apr 29 12:45:26.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3008" for this suite. @ 04/29/23 12:45:26.736
• [66.299 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 04/29/23 12:45:26.745
  Apr 29 12:45:26.745: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename security-context-test @ 04/29/23 12:45:26.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:45:26.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:45:26.765
  Apr 29 12:45:30.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-27" for this suite. @ 04/29/23 12:45:30.796
• [4.057 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 04/29/23 12:45:30.803
  Apr 29 12:45:30.803: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename cronjob @ 04/29/23 12:45:30.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:45:30.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:45:30.824
  STEP: Creating a ReplaceConcurrent cronjob @ 04/29/23 12:45:30.827
  STEP: Ensuring a job is scheduled @ 04/29/23 12:45:30.832
  STEP: Ensuring exactly one is scheduled @ 04/29/23 12:46:00.836
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/29/23 12:46:00.84
  STEP: Ensuring the job is replaced with a new one @ 04/29/23 12:46:00.843
  STEP: Removing cronjob @ 04/29/23 12:47:00.849
  Apr 29 12:47:00.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7505" for this suite. @ 04/29/23 12:47:00.863
• [90.066 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 04/29/23 12:47:00.87
  Apr 29 12:47:00.870: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-webhook @ 04/29/23 12:47:00.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:47:00.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:47:00.897
  STEP: Setting up server cert @ 04/29/23 12:47:00.9
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/29/23 12:47:01.092
  STEP: Deploying the custom resource conversion webhook pod @ 04/29/23 12:47:01.1
  STEP: Wait for the deployment to be ready @ 04/29/23 12:47:01.112
  Apr 29 12:47:01.120: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:47:03.131
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:47:03.143
  Apr 29 12:47:04.143: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 29 12:47:04.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Creating a v1 custom resource @ 04/29/23 12:47:06.713
  STEP: Create a v2 custom resource @ 04/29/23 12:47:06.732
  STEP: List CRs in v1 @ 04/29/23 12:47:06.741
  STEP: List CRs in v2 @ 04/29/23 12:47:06.788
  Apr 29 12:47:06.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-8589" for this suite. @ 04/29/23 12:47:07.371
• [6.510 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:571
  STEP: Creating a kubernetes client @ 04/29/23 12:47:07.381
  Apr 29 12:47:07.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:47:07.382
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:47:07.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:47:07.419
  STEP: Setting up server cert @ 04/29/23 12:47:07.448
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:47:07.82
  STEP: Deploying the webhook pod @ 04/29/23 12:47:07.827
  STEP: Wait for the deployment to be ready @ 04/29/23 12:47:07.841
  Apr 29 12:47:07.857: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:47:09.87
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:47:09.898
  Apr 29 12:47:10.899: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/29/23 12:47:10.98
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/29/23 12:47:11.024
  STEP: Deleting the collection of validation webhooks @ 04/29/23 12:47:11.07
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/29/23 12:47:11.139
  Apr 29 12:47:11.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6171" for this suite. @ 04/29/23 12:47:11.329
  STEP: Destroying namespace "webhook-markers-2027" for this suite. @ 04/29/23 12:47:11.351
• [3.996 seconds]
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:92
  STEP: Creating a kubernetes client @ 04/29/23 12:47:11.377
  Apr 29 12:47:11.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename subpath @ 04/29/23 12:47:11.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:47:11.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:47:11.423
  STEP: Setting up data @ 04/29/23 12:47:11.427
  STEP: Creating pod pod-subpath-test-downwardapi-m6zw @ 04/29/23 12:47:11.439
  STEP: Creating a pod to test atomic-volume-subpath @ 04/29/23 12:47:11.439
  STEP: Saw pod success @ 04/29/23 12:47:35.512
  Apr 29 12:47:35.515: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-subpath-test-downwardapi-m6zw container test-container-subpath-downwardapi-m6zw: <nil>
  STEP: delete the pod @ 04/29/23 12:47:35.529
  STEP: Deleting pod pod-subpath-test-downwardapi-m6zw @ 04/29/23 12:47:35.547
  Apr 29 12:47:35.547: INFO: Deleting pod "pod-subpath-test-downwardapi-m6zw" in namespace "subpath-5429"
  Apr 29 12:47:35.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5429" for this suite. @ 04/29/23 12:47:35.554
• [24.184 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:60
  STEP: Creating a kubernetes client @ 04/29/23 12:47:35.562
  Apr 29 12:47:35.562: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename subpath @ 04/29/23 12:47:35.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:47:35.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:47:35.581
  STEP: Setting up data @ 04/29/23 12:47:35.585
  STEP: Creating pod pod-subpath-test-secret-bp8k @ 04/29/23 12:47:35.594
  STEP: Creating a pod to test atomic-volume-subpath @ 04/29/23 12:47:35.594
  STEP: Saw pod success @ 04/29/23 12:47:59.664
  Apr 29 12:47:59.668: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-subpath-test-secret-bp8k container test-container-subpath-secret-bp8k: <nil>
  STEP: delete the pod @ 04/29/23 12:47:59.675
  STEP: Deleting pod pod-subpath-test-secret-bp8k @ 04/29/23 12:47:59.691
  Apr 29 12:47:59.691: INFO: Deleting pod "pod-subpath-test-secret-bp8k" in namespace "subpath-5276"
  Apr 29 12:47:59.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5276" for this suite. @ 04/29/23 12:47:59.699
• [24.143 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 04/29/23 12:47:59.707
  Apr 29 12:47:59.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename var-expansion @ 04/29/23 12:47:59.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:47:59.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:47:59.726
  STEP: Creating a pod to test env composition @ 04/29/23 12:47:59.729
  STEP: Saw pod success @ 04/29/23 12:48:03.751
  Apr 29 12:48:03.755: INFO: Trying to get logs from node ip-172-31-41-80 pod var-expansion-4c8f88d2-ae5a-4a30-ad54-350f05f036ff container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 12:48:03.763
  Apr 29 12:48:03.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7190" for this suite. @ 04/29/23 12:48:03.785
• [4.085 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:220
  STEP: Creating a kubernetes client @ 04/29/23 12:48:03.793
  Apr 29 12:48:03.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:48:03.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:48:03.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:48:03.815
  STEP: Setting up server cert @ 04/29/23 12:48:03.84
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:48:04.128
  STEP: Deploying the webhook pod @ 04/29/23 12:48:04.136
  STEP: Wait for the deployment to be ready @ 04/29/23 12:48:04.147
  Apr 29 12:48:04.154: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:48:06.165
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:48:06.174
  Apr 29 12:48:07.175: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 29 12:48:07.178: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 04/29/23 12:48:07.689
  STEP: Creating a custom resource that should be denied by the webhook @ 04/29/23 12:48:07.703
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 04/29/23 12:48:09.712
  STEP: Updating the custom resource with disallowed data should be denied @ 04/29/23 12:48:09.718
  STEP: Deleting the custom resource should be denied @ 04/29/23 12:48:09.727
  STEP: Remove the offending key and value from the custom resource data @ 04/29/23 12:48:09.734
  STEP: Deleting the updated custom resource should be successful @ 04/29/23 12:48:09.744
  Apr 29 12:48:09.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1535" for this suite. @ 04/29/23 12:48:10.323
  STEP: Destroying namespace "webhook-markers-8282" for this suite. @ 04/29/23 12:48:10.33
• [6.544 seconds]
------------------------------
S
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 04/29/23 12:48:10.337
  Apr 29 12:48:10.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename ingress @ 04/29/23 12:48:10.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:48:10.353
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:48:10.356
  STEP: getting /apis @ 04/29/23 12:48:10.359
  STEP: getting /apis/networking.k8s.io @ 04/29/23 12:48:10.363
  STEP: getting /apis/networking.k8s.iov1 @ 04/29/23 12:48:10.365
  STEP: creating @ 04/29/23 12:48:10.366
  STEP: getting @ 04/29/23 12:48:10.388
  STEP: listing @ 04/29/23 12:48:10.393
  STEP: watching @ 04/29/23 12:48:10.396
  Apr 29 12:48:10.396: INFO: starting watch
  STEP: cluster-wide listing @ 04/29/23 12:48:10.398
  STEP: cluster-wide watching @ 04/29/23 12:48:10.403
  Apr 29 12:48:10.403: INFO: starting watch
  STEP: patching @ 04/29/23 12:48:10.405
  STEP: updating @ 04/29/23 12:48:10.409
  Apr 29 12:48:10.432: INFO: waiting for watch events with expected annotations
  Apr 29 12:48:10.432: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/29/23 12:48:10.433
  STEP: updating /status @ 04/29/23 12:48:10.439
  STEP: get /status @ 04/29/23 12:48:10.46
  STEP: deleting @ 04/29/23 12:48:10.464
  STEP: deleting a collection @ 04/29/23 12:48:10.479
  Apr 29 12:48:10.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-2627" for this suite. @ 04/29/23 12:48:10.499
• [0.168 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 04/29/23 12:48:10.506
  Apr 29 12:48:10.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename disruption @ 04/29/23 12:48:10.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:48:10.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:48:10.526
  STEP: Waiting for the pdb to be processed @ 04/29/23 12:48:10.54
  STEP: Updating PodDisruptionBudget status @ 04/29/23 12:48:12.559
  STEP: Waiting for all pods to be running @ 04/29/23 12:48:12.567
  Apr 29 12:48:12.571: INFO: running pods: 0 < 1
  STEP: locating a running pod @ 04/29/23 12:48:14.575
  STEP: Waiting for the pdb to be processed @ 04/29/23 12:48:14.587
  STEP: Patching PodDisruptionBudget status @ 04/29/23 12:48:14.594
  STEP: Waiting for the pdb to be processed @ 04/29/23 12:48:14.603
  Apr 29 12:48:14.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1312" for this suite. @ 04/29/23 12:48:14.611
• [4.111 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 04/29/23 12:48:14.619
  Apr 29 12:48:14.619: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename watch @ 04/29/23 12:48:14.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:48:14.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:48:14.637
  STEP: creating a watch on configmaps with label A @ 04/29/23 12:48:14.64
  STEP: creating a watch on configmaps with label B @ 04/29/23 12:48:14.642
  STEP: creating a watch on configmaps with label A or B @ 04/29/23 12:48:14.643
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 04/29/23 12:48:14.645
  Apr 29 12:48:14.649: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2739  d8c4d21f-aec7-43a2-abf5-a34389ab1092 19965 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:48:14.650: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2739  d8c4d21f-aec7-43a2-abf5-a34389ab1092 19965 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 04/29/23 12:48:14.65
  Apr 29 12:48:14.658: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2739  d8c4d21f-aec7-43a2-abf5-a34389ab1092 19966 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:48:14.658: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2739  d8c4d21f-aec7-43a2-abf5-a34389ab1092 19966 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 04/29/23 12:48:14.658
  Apr 29 12:48:14.666: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2739  d8c4d21f-aec7-43a2-abf5-a34389ab1092 19967 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:48:14.666: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2739  d8c4d21f-aec7-43a2-abf5-a34389ab1092 19967 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 04/29/23 12:48:14.667
  Apr 29 12:48:14.673: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2739  d8c4d21f-aec7-43a2-abf5-a34389ab1092 19968 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:48:14.673: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2739  d8c4d21f-aec7-43a2-abf5-a34389ab1092 19968 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 04/29/23 12:48:14.673
  Apr 29 12:48:14.678: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2739  445ce40b-fda1-45af-9957-0c596f537fc3 19969 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:48:14.678: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2739  445ce40b-fda1-45af-9957-0c596f537fc3 19969 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 04/29/23 12:48:24.682
  Apr 29 12:48:24.689: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2739  445ce40b-fda1-45af-9957-0c596f537fc3 20042 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:48:24.690: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2739  445ce40b-fda1-45af-9957-0c596f537fc3 20042 0 2023-04-29 12:48:14 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-29 12:48:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 12:48:34.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2739" for this suite. @ 04/29/23 12:48:34.699
• [20.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 04/29/23 12:48:34.707
  Apr 29 12:48:34.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 12:48:34.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:48:34.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:48:34.726
  STEP: creating a replication controller @ 04/29/23 12:48:34.729
  Apr 29 12:48:34.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 create -f -'
  Apr 29 12:48:35.475: INFO: stderr: ""
  Apr 29 12:48:35.475: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/29/23 12:48:35.475
  Apr 29 12:48:35.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 29 12:48:35.543: INFO: stderr: ""
  Apr 29 12:48:35.543: INFO: stdout: "update-demo-nautilus-bt5dh update-demo-nautilus-zll7q "
  Apr 29 12:48:35.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-bt5dh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:48:35.602: INFO: stderr: ""
  Apr 29 12:48:35.602: INFO: stdout: ""
  Apr 29 12:48:35.602: INFO: update-demo-nautilus-bt5dh is created but not running
  Apr 29 12:48:40.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 29 12:48:40.664: INFO: stderr: ""
  Apr 29 12:48:40.664: INFO: stdout: "update-demo-nautilus-bt5dh update-demo-nautilus-zll7q "
  Apr 29 12:48:40.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-bt5dh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:48:40.724: INFO: stderr: ""
  Apr 29 12:48:40.724: INFO: stdout: "true"
  Apr 29 12:48:40.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-bt5dh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 29 12:48:40.784: INFO: stderr: ""
  Apr 29 12:48:40.784: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 29 12:48:40.784: INFO: validating pod update-demo-nautilus-bt5dh
  Apr 29 12:48:40.790: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 29 12:48:40.790: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 29 12:48:40.790: INFO: update-demo-nautilus-bt5dh is verified up and running
  Apr 29 12:48:40.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-zll7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:48:40.868: INFO: stderr: ""
  Apr 29 12:48:40.868: INFO: stdout: "true"
  Apr 29 12:48:40.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-zll7q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 29 12:48:40.949: INFO: stderr: ""
  Apr 29 12:48:40.949: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 29 12:48:40.949: INFO: validating pod update-demo-nautilus-zll7q
  Apr 29 12:48:40.955: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 29 12:48:40.955: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 29 12:48:40.955: INFO: update-demo-nautilus-zll7q is verified up and running
  STEP: scaling down the replication controller @ 04/29/23 12:48:40.955
  Apr 29 12:48:40.957: INFO: scanned /root for discovery docs: <nil>
  Apr 29 12:48:40.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  Apr 29 12:48:42.030: INFO: stderr: ""
  Apr 29 12:48:42.030: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/29/23 12:48:42.03
  Apr 29 12:48:42.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 29 12:48:42.095: INFO: stderr: ""
  Apr 29 12:48:42.095: INFO: stdout: "update-demo-nautilus-bt5dh update-demo-nautilus-zll7q "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 04/29/23 12:48:42.095
  Apr 29 12:48:47.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 29 12:48:47.163: INFO: stderr: ""
  Apr 29 12:48:47.163: INFO: stdout: "update-demo-nautilus-zll7q "
  Apr 29 12:48:47.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-zll7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:48:47.224: INFO: stderr: ""
  Apr 29 12:48:47.224: INFO: stdout: "true"
  Apr 29 12:48:47.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-zll7q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 29 12:48:47.282: INFO: stderr: ""
  Apr 29 12:48:47.282: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 29 12:48:47.282: INFO: validating pod update-demo-nautilus-zll7q
  Apr 29 12:48:47.287: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 29 12:48:47.287: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 29 12:48:47.287: INFO: update-demo-nautilus-zll7q is verified up and running
  STEP: scaling up the replication controller @ 04/29/23 12:48:47.287
  Apr 29 12:48:47.288: INFO: scanned /root for discovery docs: <nil>
  Apr 29 12:48:47.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  Apr 29 12:48:48.369: INFO: stderr: ""
  Apr 29 12:48:48.369: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/29/23 12:48:48.369
  Apr 29 12:48:48.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 29 12:48:48.436: INFO: stderr: ""
  Apr 29 12:48:48.436: INFO: stdout: "update-demo-nautilus-mdppd update-demo-nautilus-zll7q "
  Apr 29 12:48:48.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-mdppd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:48:48.497: INFO: stderr: ""
  Apr 29 12:48:48.497: INFO: stdout: "true"
  Apr 29 12:48:48.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-mdppd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 29 12:48:48.555: INFO: stderr: ""
  Apr 29 12:48:48.555: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 29 12:48:48.555: INFO: validating pod update-demo-nautilus-mdppd
  Apr 29 12:48:48.560: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 29 12:48:48.560: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 29 12:48:48.560: INFO: update-demo-nautilus-mdppd is verified up and running
  Apr 29 12:48:48.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-zll7q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 29 12:48:48.619: INFO: stderr: ""
  Apr 29 12:48:48.619: INFO: stdout: "true"
  Apr 29 12:48:48.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods update-demo-nautilus-zll7q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 29 12:48:48.684: INFO: stderr: ""
  Apr 29 12:48:48.684: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 29 12:48:48.684: INFO: validating pod update-demo-nautilus-zll7q
  Apr 29 12:48:48.689: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 29 12:48:48.689: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 29 12:48:48.689: INFO: update-demo-nautilus-zll7q is verified up and running
  STEP: using delete to clean up resources @ 04/29/23 12:48:48.689
  Apr 29 12:48:48.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 delete --grace-period=0 --force -f -'
  Apr 29 12:48:48.752: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 12:48:48.752: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 29 12:48:48.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get rc,svc -l name=update-demo --no-headers'
  Apr 29 12:48:48.851: INFO: stderr: "No resources found in kubectl-1825 namespace.\n"
  Apr 29 12:48:48.851: INFO: stdout: ""
  Apr 29 12:48:48.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1825 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 29 12:48:48.945: INFO: stderr: ""
  Apr 29 12:48:48.945: INFO: stdout: ""
  Apr 29 12:48:48.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1825" for this suite. @ 04/29/23 12:48:48.949
• [14.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 04/29/23 12:48:48.957
  Apr 29 12:48:48.957: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename namespaces @ 04/29/23 12:48:48.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:48:48.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:48:48.979
  STEP: Creating a test namespace @ 04/29/23 12:48:48.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:48:48.998
  STEP: Creating a pod in the namespace @ 04/29/23 12:48:49.002
  STEP: Waiting for the pod to have running status @ 04/29/23 12:48:49.011
  STEP: Deleting the namespace @ 04/29/23 12:48:51.02
  STEP: Waiting for the namespace to be removed. @ 04/29/23 12:48:51.026
  STEP: Recreating the namespace @ 04/29/23 12:49:02.031
  STEP: Verifying there are no pods in the namespace @ 04/29/23 12:49:02.044
  Apr 29 12:49:02.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6966" for this suite. @ 04/29/23 12:49:02.053
  STEP: Destroying namespace "nsdeletetest-5280" for this suite. @ 04/29/23 12:49:02.059
  Apr 29 12:49:02.062: INFO: Namespace nsdeletetest-5280 was already deleted
  STEP: Destroying namespace "nsdeletetest-5642" for this suite. @ 04/29/23 12:49:02.062
• [13.115 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 04/29/23 12:49:02.072
  Apr 29 12:49:02.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:49:02.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:49:02.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:49:02.094
  STEP: Creating configMap with name projected-configmap-test-volume-1d549b1a-c7b1-4c86-9b88-9b28503fd6a3 @ 04/29/23 12:49:02.098
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:49:02.102
  STEP: Saw pod success @ 04/29/23 12:49:06.124
  Apr 29 12:49:06.128: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-configmaps-214413f2-12d7-4615-8edd-eacbce50d141 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 12:49:06.135
  Apr 29 12:49:06.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7238" for this suite. @ 04/29/23 12:49:06.153
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 04/29/23 12:49:06.161
  Apr 29 12:49:06.161: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replication-controller @ 04/29/23 12:49:06.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:49:06.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:49:06.179
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 04/29/23 12:49:06.183
  STEP: When a replication controller with a matching selector is created @ 04/29/23 12:49:08.205
  STEP: Then the orphan pod is adopted @ 04/29/23 12:49:08.211
  Apr 29 12:49:09.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5150" for this suite. @ 04/29/23 12:49:09.226
• [3.073 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:497
  STEP: Creating a kubernetes client @ 04/29/23 12:49:09.235
  Apr 29 12:49:09.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:49:09.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:49:09.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:49:09.257
  STEP: Setting up server cert @ 04/29/23 12:49:09.291
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:49:09.597
  STEP: Deploying the webhook pod @ 04/29/23 12:49:09.603
  STEP: Wait for the deployment to be ready @ 04/29/23 12:49:09.614
  Apr 29 12:49:09.623: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:49:11.635
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:49:11.649
  Apr 29 12:49:12.651: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 04/29/23 12:49:12.656
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 04/29/23 12:49:12.678
  STEP: Creating a configMap that should not be mutated @ 04/29/23 12:49:12.686
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 04/29/23 12:49:12.699
  STEP: Creating a configMap that should be mutated @ 04/29/23 12:49:12.711
  Apr 29 12:49:12.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6694" for this suite. @ 04/29/23 12:49:12.8
  STEP: Destroying namespace "webhook-markers-2651" for this suite. @ 04/29/23 12:49:12.813
• [3.586 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 04/29/23 12:49:12.822
  Apr 29 12:49:12.822: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename deployment @ 04/29/23 12:49:12.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:49:12.838
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:49:12.841
  Apr 29 12:49:12.853: INFO: Pod name rollover-pod: Found 0 pods out of 1
  Apr 29 12:49:17.857: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/29/23 12:49:17.857
  Apr 29 12:49:17.857: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  Apr 29 12:49:19.862: INFO: Creating deployment "test-rollover-deployment"
  Apr 29 12:49:19.871: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  Apr 29 12:49:21.878: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Apr 29 12:49:21.885: INFO: Ensure that both replica sets have 1 created replica
  Apr 29 12:49:21.892: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Apr 29 12:49:21.902: INFO: Updating deployment test-rollover-deployment
  Apr 29 12:49:21.902: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  Apr 29 12:49:23.910: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Apr 29 12:49:23.917: INFO: Make sure deployment "test-rollover-deployment" is complete
  Apr 29 12:49:23.923: INFO: all replica sets need to contain the pod-template-hash label
  Apr 29 12:49:23.923: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:49:25.932: INFO: all replica sets need to contain the pod-template-hash label
  Apr 29 12:49:25.932: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:49:27.932: INFO: all replica sets need to contain the pod-template-hash label
  Apr 29 12:49:27.932: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:49:29.931: INFO: all replica sets need to contain the pod-template-hash label
  Apr 29 12:49:29.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:49:31.932: INFO: all replica sets need to contain the pod-template-hash label
  Apr 29 12:49:31.932: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 29, 12, 49, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 29, 12, 49, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 29 12:49:33.933: INFO: 
  Apr 29 12:49:33.933: INFO: Ensure that both old replica sets have no replicas
  Apr 29 12:49:33.944: INFO: Deployment "test-rollover-deployment":
  &Deployment{ObjectMeta:{test-rollover-deployment  deployment-5874  850f0084-d01b-46ec-995a-65ee9ad35de5 20597 2 2023-04-29 12:49:19 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-29 12:49:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049d4608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-29 12:49:19 +0000 UTC,LastTransitionTime:2023-04-29 12:49:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-57777854c9" has successfully progressed.,LastUpdateTime:2023-04-29 12:49:33 +0000 UTC,LastTransitionTime:2023-04-29 12:49:19 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 29 12:49:33.948: INFO: New ReplicaSet "test-rollover-deployment-57777854c9" of Deployment "test-rollover-deployment":
  &ReplicaSet{ObjectMeta:{test-rollover-deployment-57777854c9  deployment-5874  5f689bcc-e4f4-4d80-bfc4-ceee163ab5d5 20586 2 2023-04-29 12:49:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 850f0084-d01b-46ec-995a-65ee9ad35de5 0xc003b0c117 0xc003b0c118}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:49:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"850f0084-d01b-46ec-995a-65ee9ad35de5\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:49:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 57777854c9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b0c1c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:49:33.948: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Apr 29 12:49:33.948: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5874  79df0242-1add-4b36-bae8-6936f83de373 20596 2 2023-04-29 12:49:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 850f0084-d01b-46ec-995a-65ee9ad35de5 0xc003cd7fe7 0xc003cd7fe8}] [] [{e2e.test Update apps/v1 2023-04-29 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:49:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"850f0084-d01b-46ec-995a-65ee9ad35de5\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:49:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003b0c0a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:49:33.948: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-58779b56b4  deployment-5874  077cee5a-2366-4576-9e3a-325e0b4362d9 20550 2 2023-04-29 12:49:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:58779b56b4] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 850f0084-d01b-46ec-995a-65ee9ad35de5 0xc003b0c237 0xc003b0c238}] [] [{kube-controller-manager Update apps/v1 2023-04-29 12:49:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"850f0084-d01b-46ec-995a-65ee9ad35de5\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 12:49:21 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 58779b56b4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:58779b56b4] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b0c2e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 12:49:33.952: INFO: Pod "test-rollover-deployment-57777854c9-rp2lk" is available:
  &Pod{ObjectMeta:{test-rollover-deployment-57777854c9-rp2lk test-rollover-deployment-57777854c9- deployment-5874  cf8f2e7c-4233-4695-a3d3-34abefb1f067 20564 0 2023-04-29 12:49:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[] [{apps/v1 ReplicaSet test-rollover-deployment-57777854c9 5f689bcc-e4f4-4d80-bfc4-ceee163ab5d5 0xc003b0c8b7 0xc003b0c8b8}] [] [{kube-controller-manager Update v1 2023-04-29 12:49:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5f689bcc-e4f4-4d80-bfc4-ceee163ab5d5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 12:49:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.2\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-84n92,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-84n92,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:49:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:49:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:49:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 12:49:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:192.168.226.2,StartTime:2023-04-29 12:49:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 12:49:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://5bb965f93a583eaf8cd2d20b7c72592a61cbd95ab402e54847615cc4cafacde1,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.226.2,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 12:49:33.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5874" for this suite. @ 04/29/23 12:49:33.956
• [21.140 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 04/29/23 12:49:33.963
  Apr 29 12:49:33.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 12:49:33.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:49:33.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:49:33.981
  STEP: Creating secret with name secret-test-d63f1d34-4331-46ed-a82c-908d1293cae1 @ 04/29/23 12:49:33.984
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:49:33.99
  STEP: Saw pod success @ 04/29/23 12:49:38.015
  Apr 29 12:49:38.019: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-secrets-4be39789-f7b0-4728-a74c-9db2b59d8dcb container secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:49:38.029
  Apr 29 12:49:38.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3545" for this suite. @ 04/29/23 12:49:38.048
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 04/29/23 12:49:38.057
  Apr 29 12:49:38.057: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename cronjob @ 04/29/23 12:49:38.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:49:38.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:49:38.076
  STEP: Creating a ForbidConcurrent cronjob @ 04/29/23 12:49:38.08
  STEP: Ensuring a job is scheduled @ 04/29/23 12:49:38.085
  STEP: Ensuring exactly one is scheduled @ 04/29/23 12:50:02.089
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/29/23 12:50:02.093
  STEP: Ensuring no more jobs are scheduled @ 04/29/23 12:50:02.096
  STEP: Removing cronjob @ 04/29/23 12:55:02.105
  Apr 29 12:55:02.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-672" for this suite. @ 04/29/23 12:55:02.116
• [324.066 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 04/29/23 12:55:02.123
  Apr 29 12:55:02.124: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-preemption @ 04/29/23 12:55:02.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:55:02.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:55:02.148
  Apr 29 12:55:02.166: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 29 12:56:02.187: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/29/23 12:56:02.191
  Apr 29 12:56:02.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/29/23 12:56:02.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:02.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:02.214
  STEP: Finding an available node @ 04/29/23 12:56:02.217
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/29/23 12:56:02.217
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/29/23 12:56:04.239
  Apr 29 12:56:04.254: INFO: found a healthy node: ip-172-31-41-80
  Apr 29 12:56:10.334: INFO: pods created so far: [1 1 1]
  Apr 29 12:56:10.334: INFO: length of pods created so far: 3
  Apr 29 12:56:12.344: INFO: pods created so far: [2 2 1]
  Apr 29 12:56:19.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 12:56:19.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-665" for this suite. @ 04/29/23 12:56:19.421
  STEP: Destroying namespace "sched-preemption-89" for this suite. @ 04/29/23 12:56:19.43
• [77.313 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:177
  STEP: Creating a kubernetes client @ 04/29/23 12:56:19.437
  Apr 29 12:56:19.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename init-container @ 04/29/23 12:56:19.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:19.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:19.456
  STEP: creating the pod @ 04/29/23 12:56:19.459
  Apr 29 12:56:19.459: INFO: PodSpec: initContainers in spec.initContainers
  Apr 29 12:56:23.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9506" for this suite. @ 04/29/23 12:56:23.578
• [4.150 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:284
  STEP: Creating a kubernetes client @ 04/29/23 12:56:23.587
  Apr 29 12:56:23.587: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 12:56:23.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:23.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:23.605
  STEP: Setting up server cert @ 04/29/23 12:56:23.636
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 12:56:24.097
  STEP: Deploying the webhook pod @ 04/29/23 12:56:24.106
  STEP: Wait for the deployment to be ready @ 04/29/23 12:56:24.118
  Apr 29 12:56:24.127: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 12:56:26.138
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 12:56:26.153
  Apr 29 12:56:27.153: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 29 12:56:27.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3124-crds.webhook.example.com via the AdmissionRegistration API @ 04/29/23 12:56:27.667
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/29/23 12:56:27.682
  Apr 29 12:56:29.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8379" for this suite. @ 04/29/23 12:56:30.284
  STEP: Destroying namespace "webhook-markers-4949" for this suite. @ 04/29/23 12:56:30.291
• [6.711 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 04/29/23 12:56:30.301
  Apr 29 12:56:30.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:56:30.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:30.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:30.323
  STEP: Creating a pod to test downward api env vars @ 04/29/23 12:56:30.326
  STEP: Saw pod success @ 04/29/23 12:56:34.35
  Apr 29 12:56:34.354: INFO: Trying to get logs from node ip-172-31-41-80 pod downward-api-1b9b1297-a9cb-422e-8292-d38b1702e7ea container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 12:56:34.372
  Apr 29 12:56:34.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3074" for this suite. @ 04/29/23 12:56:34.393
• [4.099 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 04/29/23 12:56:34.4
  Apr 29 12:56:34.400: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-runtime @ 04/29/23 12:56:34.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:34.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:34.417
  STEP: create the container @ 04/29/23 12:56:34.42
  W0429 12:56:34.433439      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/29/23 12:56:34.433
  STEP: get the container status @ 04/29/23 12:56:37.451
  STEP: the container should be terminated @ 04/29/23 12:56:37.455
  STEP: the termination message should be set @ 04/29/23 12:56:37.455
  Apr 29 12:56:37.455: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/29/23 12:56:37.455
  Apr 29 12:56:37.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6202" for this suite. @ 04/29/23 12:56:37.479
• [3.087 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 04/29/23 12:56:37.487
  Apr 29 12:56:37.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 12:56:37.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:37.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:37.507
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:56:37.51
  STEP: Saw pod success @ 04/29/23 12:56:41.535
  Apr 29 12:56:41.539: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-ce9e2134-0e4e-4b49-9817-8cc67bef433e container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:56:41.545
  Apr 29 12:56:41.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5056" for this suite. @ 04/29/23 12:56:41.565
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 04/29/23 12:56:41.572
  Apr 29 12:56:41.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-runtime @ 04/29/23 12:56:41.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:41.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:41.59
  STEP: create the container @ 04/29/23 12:56:41.594
  W0429 12:56:41.602547      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 04/29/23 12:56:41.602
  STEP: get the container status @ 04/29/23 12:56:45.625
  STEP: the container should be terminated @ 04/29/23 12:56:45.629
  STEP: the termination message should be set @ 04/29/23 12:56:45.629
  Apr 29 12:56:45.629: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/29/23 12:56:45.629
  Apr 29 12:56:45.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7087" for this suite. @ 04/29/23 12:56:45.648
• [4.083 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 04/29/23 12:56:45.655
  Apr 29 12:56:45.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-runtime @ 04/29/23 12:56:45.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:45.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:45.675
  STEP: create the container @ 04/29/23 12:56:45.678
  W0429 12:56:45.687767      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/29/23 12:56:45.687
  STEP: get the container status @ 04/29/23 12:56:48.708
  STEP: the container should be terminated @ 04/29/23 12:56:48.711
  STEP: the termination message should be set @ 04/29/23 12:56:48.711
  Apr 29 12:56:48.711: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 04/29/23 12:56:48.711
  Apr 29 12:56:48.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9136" for this suite. @ 04/29/23 12:56:48.729
• [3.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 04/29/23 12:56:48.737
  Apr 29 12:56:48.737: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename proxy @ 04/29/23 12:56:48.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:48.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:48.755
  Apr 29 12:56:48.759: INFO: Creating pod...
  Apr 29 12:56:50.774: INFO: Creating service...
  Apr 29 12:56:50.784: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/pods/agnhost/proxy?method=DELETE
  Apr 29 12:56:50.790: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 29 12:56:50.790: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/pods/agnhost/proxy?method=OPTIONS
  Apr 29 12:56:50.799: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 29 12:56:50.799: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/pods/agnhost/proxy?method=PATCH
  Apr 29 12:56:50.803: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 29 12:56:50.803: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/pods/agnhost/proxy?method=POST
  Apr 29 12:56:50.807: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 29 12:56:50.807: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/pods/agnhost/proxy?method=PUT
  Apr 29 12:56:50.811: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 29 12:56:50.811: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/services/e2e-proxy-test-service/proxy?method=DELETE
  Apr 29 12:56:50.818: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 29 12:56:50.819: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Apr 29 12:56:50.824: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 29 12:56:50.824: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/services/e2e-proxy-test-service/proxy?method=PATCH
  Apr 29 12:56:50.833: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 29 12:56:50.833: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/services/e2e-proxy-test-service/proxy?method=POST
  Apr 29 12:56:50.838: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 29 12:56:50.838: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/services/e2e-proxy-test-service/proxy?method=PUT
  Apr 29 12:56:50.844: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 29 12:56:50.844: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/pods/agnhost/proxy?method=GET
  Apr 29 12:56:50.847: INFO: http.Client request:GET StatusCode:301
  Apr 29 12:56:50.848: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/services/e2e-proxy-test-service/proxy?method=GET
  Apr 29 12:56:50.853: INFO: http.Client request:GET StatusCode:301
  Apr 29 12:56:50.853: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/pods/agnhost/proxy?method=HEAD
  Apr 29 12:56:50.856: INFO: http.Client request:HEAD StatusCode:301
  Apr 29 12:56:50.856: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1060/services/e2e-proxy-test-service/proxy?method=HEAD
  Apr 29 12:56:50.861: INFO: http.Client request:HEAD StatusCode:301
  Apr 29 12:56:50.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-1060" for this suite. @ 04/29/23 12:56:50.865
• [2.136 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:255
  STEP: Creating a kubernetes client @ 04/29/23 12:56:50.875
  Apr 29 12:56:50.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename init-container @ 04/29/23 12:56:50.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:50.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:50.899
  STEP: creating the pod @ 04/29/23 12:56:50.902
  Apr 29 12:56:50.902: INFO: PodSpec: initContainers in spec.initContainers
  Apr 29 12:56:54.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-4259" for this suite. @ 04/29/23 12:56:54.373
• [3.505 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 04/29/23 12:56:54.381
  Apr 29 12:56:54.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:56:54.382
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:54.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:54.4
  STEP: Creating configMap with name projected-configmap-test-volume-85569dce-adf6-4c07-be60-d1bac0be8286 @ 04/29/23 12:56:54.404
  STEP: Creating a pod to test consume configMaps @ 04/29/23 12:56:54.408
  STEP: Saw pod success @ 04/29/23 12:56:58.434
  Apr 29 12:56:58.438: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-configmaps-1b3b52eb-01ab-4538-9b9c-cee86b921356 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 12:56:58.445
  Apr 29 12:56:58.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8612" for this suite. @ 04/29/23 12:56:58.47
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 04/29/23 12:56:58.478
  Apr 29 12:56:58.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replicaset @ 04/29/23 12:56:58.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:56:58.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:56:58.495
  Apr 29 12:56:58.510: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 29 12:57:03.514: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/29/23 12:57:03.514
  STEP: Scaling up "test-rs" replicaset  @ 04/29/23 12:57:03.514
  Apr 29 12:57:03.525: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 04/29/23 12:57:03.525
  W0429 12:57:03.534380      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 29 12:57:03.538: INFO: observed ReplicaSet test-rs in namespace replicaset-8527 with ReadyReplicas 1, AvailableReplicas 1
  Apr 29 12:57:03.555: INFO: observed ReplicaSet test-rs in namespace replicaset-8527 with ReadyReplicas 1, AvailableReplicas 1
  Apr 29 12:57:03.586: INFO: observed ReplicaSet test-rs in namespace replicaset-8527 with ReadyReplicas 1, AvailableReplicas 1
  Apr 29 12:57:03.599: INFO: observed ReplicaSet test-rs in namespace replicaset-8527 with ReadyReplicas 1, AvailableReplicas 1
  Apr 29 12:57:04.487: INFO: observed ReplicaSet test-rs in namespace replicaset-8527 with ReadyReplicas 2, AvailableReplicas 2
  Apr 29 12:57:04.839: INFO: observed Replicaset test-rs in namespace replicaset-8527 with ReadyReplicas 3 found true
  Apr 29 12:57:04.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8527" for this suite. @ 04/29/23 12:57:04.849
• [6.379 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 04/29/23 12:57:04.86
  Apr 29 12:57:04.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename var-expansion @ 04/29/23 12:57:04.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:57:04.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:57:04.88
  STEP: creating the pod @ 04/29/23 12:57:04.885
  STEP: waiting for pod running @ 04/29/23 12:57:04.915
  STEP: creating a file in subpath @ 04/29/23 12:57:06.935
  Apr 29 12:57:06.938: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-9018 PodName:var-expansion-bd71c8ba-5351-4f2e-9852-d2a3be49b142 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:57:06.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:57:06.939: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:57:06.939: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-9018/pods/var-expansion-bd71c8ba-5351-4f2e-9852-d2a3be49b142/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 04/29/23 12:57:07.012
  Apr 29 12:57:07.015: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-9018 PodName:var-expansion-bd71c8ba-5351-4f2e-9852-d2a3be49b142 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 12:57:07.015: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:57:07.016: INFO: ExecWithOptions: Clientset creation
  Apr 29 12:57:07.016: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-9018/pods/var-expansion-bd71c8ba-5351-4f2e-9852-d2a3be49b142/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 04/29/23 12:57:07.072
  Apr 29 12:57:07.584: INFO: Successfully updated pod "var-expansion-bd71c8ba-5351-4f2e-9852-d2a3be49b142"
  STEP: waiting for annotated pod running @ 04/29/23 12:57:07.584
  STEP: deleting the pod gracefully @ 04/29/23 12:57:07.588
  Apr 29 12:57:07.588: INFO: Deleting pod "var-expansion-bd71c8ba-5351-4f2e-9852-d2a3be49b142" in namespace "var-expansion-9018"
  Apr 29 12:57:07.595: INFO: Wait up to 5m0s for pod "var-expansion-bd71c8ba-5351-4f2e-9852-d2a3be49b142" to be fully deleted
  Apr 29 12:57:39.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9018" for this suite. @ 04/29/23 12:57:39.681
• [34.827 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 04/29/23 12:57:39.689
  Apr 29 12:57:39.689: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 12:57:39.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:57:39.704
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:57:39.708
  STEP: creating pod @ 04/29/23 12:57:39.711
  Apr 29 12:57:41.735: INFO: Pod pod-hostip-04441af4-a490-43d8-8c80-f66dd9fedba0 has hostIP: 172.31.41.80
  Apr 29 12:57:41.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1776" for this suite. @ 04/29/23 12:57:41.739
• [2.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:912
  STEP: Creating a kubernetes client @ 04/29/23 12:57:41.748
  Apr 29 12:57:41.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename statefulset @ 04/29/23 12:57:41.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:57:41.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:57:41.769
  STEP: Creating service test in namespace statefulset-5164 @ 04/29/23 12:57:41.773
  Apr 29 12:57:41.794: INFO: Found 0 stateful pods, waiting for 1
  Apr 29 12:57:51.799: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 04/29/23 12:57:51.806
  W0429 12:57:51.816123      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 29 12:57:51.823: INFO: Found 1 stateful pods, waiting for 2
  Apr 29 12:58:01.829: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 12:58:01.829: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 04/29/23 12:58:01.836
  STEP: Delete all of the StatefulSets @ 04/29/23 12:58:01.839
  STEP: Verify that StatefulSets have been deleted @ 04/29/23 12:58:01.848
  Apr 29 12:58:01.852: INFO: Deleting all statefulset in ns statefulset-5164
  Apr 29 12:58:01.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5164" for this suite. @ 04/29/23 12:58:01.872
• [20.134 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 04/29/23 12:58:01.883
  Apr 29 12:58:01.883: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 12:58:01.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:58:01.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:58:01.901
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 12:58:01.905
  STEP: Saw pod success @ 04/29/23 12:58:05.93
  Apr 29 12:58:05.934: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-fb8dcdb2-4d63-4d80-a43b-3a74dd5526c3 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 12:58:05.941
  Apr 29 12:58:05.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1944" for this suite. @ 04/29/23 12:58:05.961
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1735
  STEP: Creating a kubernetes client @ 04/29/23 12:58:05.969
  Apr 29 12:58:05.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 12:58:05.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:58:05.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:58:05.988
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/29/23 12:58:05.991
  Apr 29 12:58:05.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-3179 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 29 12:58:06.057: INFO: stderr: ""
  Apr 29 12:58:06.057: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 04/29/23 12:58:06.057
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/29/23 12:58:11.108
  Apr 29 12:58:11.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-3179 get pod e2e-test-httpd-pod -o json'
  Apr 29 12:58:11.169: INFO: stderr: ""
  Apr 29 12:58:11.169: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-29T12:58:06Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3179\",\n        \"resourceVersion\": \"22725\",\n        \"uid\": \"09b9d5e6-4d21-4e27-948f-cdcd9e8cd274\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-zrrff\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-41-80\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-zrrff\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-29T12:58:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-29T12:58:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-29T12:58:07Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-29T12:58:06Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://c64a32276f49d12df268df68f3cf1fa2ada24aeb6237573ad658042f9a1bd115\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-29T12:58:06Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.41.80\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.226.17\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.226.17\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-29T12:58:06Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 04/29/23 12:58:11.169
  Apr 29 12:58:11.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-3179 replace -f -'
  Apr 29 12:58:11.414: INFO: stderr: ""
  Apr 29 12:58:11.414: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 @ 04/29/23 12:58:11.414
  Apr 29 12:58:11.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-3179 delete pods e2e-test-httpd-pod'
  Apr 29 12:58:13.609: INFO: stderr: ""
  Apr 29 12:58:13.609: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 29 12:58:13.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3179" for this suite. @ 04/29/23 12:58:13.614
• [7.651 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 04/29/23 12:58:13.621
  Apr 29 12:58:13.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 12:58:13.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:58:13.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:58:13.64
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 04/29/23 12:58:13.644
  Apr 29 12:58:13.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:58:15.054: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 12:58:20.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7989" for this suite. @ 04/29/23 12:58:20.386
• [6.771 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 04/29/23 12:58:20.395
  Apr 29 12:58:20.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename certificates @ 04/29/23 12:58:20.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:58:20.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:58:20.414
  STEP: getting /apis @ 04/29/23 12:58:20.972
  STEP: getting /apis/certificates.k8s.io @ 04/29/23 12:58:20.976
  STEP: getting /apis/certificates.k8s.io/v1 @ 04/29/23 12:58:20.977
  STEP: creating @ 04/29/23 12:58:20.978
  STEP: getting @ 04/29/23 12:58:20.994
  STEP: listing @ 04/29/23 12:58:20.996
  STEP: watching @ 04/29/23 12:58:20.999
  Apr 29 12:58:20.999: INFO: starting watch
  STEP: patching @ 04/29/23 12:58:21
  STEP: updating @ 04/29/23 12:58:21.005
  Apr 29 12:58:21.010: INFO: waiting for watch events with expected annotations
  Apr 29 12:58:21.010: INFO: saw patched and updated annotations
  STEP: getting /approval @ 04/29/23 12:58:21.01
  STEP: patching /approval @ 04/29/23 12:58:21.012
  STEP: updating /approval @ 04/29/23 12:58:21.019
  STEP: getting /status @ 04/29/23 12:58:21.024
  STEP: patching /status @ 04/29/23 12:58:21.026
  STEP: updating /status @ 04/29/23 12:58:21.034
  STEP: deleting @ 04/29/23 12:58:21.039
  STEP: deleting a collection @ 04/29/23 12:58:21.05
  Apr 29 12:58:21.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-4123" for this suite. @ 04/29/23 12:58:21.068
• [0.679 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 04/29/23 12:58:21.074
  Apr 29 12:58:21.074: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 12:58:21.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:58:21.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:58:21.093
  STEP: Creating secret with name secret-test-map-9b7a574e-6497-45d1-8ce9-3b01781b8e11 @ 04/29/23 12:58:21.096
  STEP: Creating a pod to test consume secrets @ 04/29/23 12:58:21.101
  STEP: Saw pod success @ 04/29/23 12:58:25.119
  Apr 29 12:58:25.123: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-secrets-2921fd0d-ae96-4242-882b-de056f0cfc8a container secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 12:58:25.136
  Apr 29 12:58:25.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2032" for this suite. @ 04/29/23 12:58:25.155
• [4.087 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 04/29/23 12:58:25.162
  Apr 29 12:58:25.162: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-watch @ 04/29/23 12:58:25.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:58:25.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:58:25.182
  Apr 29 12:58:25.185: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Creating first CR  @ 04/29/23 12:58:27.777
  Apr 29 12:58:27.782: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-29T12:58:27Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-29T12:58:27Z]] name:name1 resourceVersion:22886 uid:62035863-5277-4275-a087-7d93c24eb281] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Creating second CR @ 04/29/23 12:58:37.785
  Apr 29 12:58:37.791: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-29T12:58:37Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-29T12:58:37Z]] name:name2 resourceVersion:22916 uid:f4349ff6-31b6-42ad-85e8-55b4387a09ac] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying first CR @ 04/29/23 12:58:47.793
  Apr 29 12:58:47.800: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-29T12:58:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-29T12:58:47Z]] name:name1 resourceVersion:22936 uid:62035863-5277-4275-a087-7d93c24eb281] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying second CR @ 04/29/23 12:58:57.801
  Apr 29 12:58:57.808: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-29T12:58:37Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-29T12:58:57Z]] name:name2 resourceVersion:22956 uid:f4349ff6-31b6-42ad-85e8-55b4387a09ac] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting first CR @ 04/29/23 12:59:07.809
  Apr 29 12:59:07.817: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-29T12:58:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-29T12:58:47Z]] name:name1 resourceVersion:22975 uid:62035863-5277-4275-a087-7d93c24eb281] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting second CR @ 04/29/23 12:59:17.818
  Apr 29 12:59:17.824: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-29T12:58:37Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-29T12:58:57Z]] name:name2 resourceVersion:22995 uid:f4349ff6-31b6-42ad-85e8-55b4387a09ac] num:map[num1:9223372036854775807 num2:1000000]]}
  Apr 29 12:59:28.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-7403" for this suite. @ 04/29/23 12:59:28.344
• [63.190 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 04/29/23 12:59:28.352
  Apr 29 12:59:28.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename gc @ 04/29/23 12:59:28.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:59:28.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:59:28.379
  STEP: create the rc1 @ 04/29/23 12:59:28.387
  STEP: create the rc2 @ 04/29/23 12:59:28.392
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 04/29/23 12:59:34.412
  STEP: delete the rc simpletest-rc-to-be-deleted @ 04/29/23 12:59:34.806
  STEP: wait for the rc to be deleted @ 04/29/23 12:59:34.813
  Apr 29 12:59:39.834: INFO: 72 pods remaining
  Apr 29 12:59:39.834: INFO: 72 pods has nil DeletionTimestamp
  Apr 29 12:59:39.834: INFO: 
  STEP: Gathering metrics @ 04/29/23 12:59:44.824
  W0429 12:59:44.827845      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 29 12:59:44.827: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 29 12:59:44.829: INFO: Deleting pod "simpletest-rc-to-be-deleted-278cm" in namespace "gc-7674"
  Apr 29 12:59:44.842: INFO: Deleting pod "simpletest-rc-to-be-deleted-28n8h" in namespace "gc-7674"
  Apr 29 12:59:44.857: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hxc8" in namespace "gc-7674"
  Apr 29 12:59:44.871: INFO: Deleting pod "simpletest-rc-to-be-deleted-2klb7" in namespace "gc-7674"
  Apr 29 12:59:44.885: INFO: Deleting pod "simpletest-rc-to-be-deleted-2nbkl" in namespace "gc-7674"
  Apr 29 12:59:44.895: INFO: Deleting pod "simpletest-rc-to-be-deleted-42bj2" in namespace "gc-7674"
  Apr 29 12:59:44.911: INFO: Deleting pod "simpletest-rc-to-be-deleted-45k2b" in namespace "gc-7674"
  Apr 29 12:59:44.924: INFO: Deleting pod "simpletest-rc-to-be-deleted-4b247" in namespace "gc-7674"
  Apr 29 12:59:44.937: INFO: Deleting pod "simpletest-rc-to-be-deleted-55w2t" in namespace "gc-7674"
  Apr 29 12:59:44.955: INFO: Deleting pod "simpletest-rc-to-be-deleted-582gt" in namespace "gc-7674"
  Apr 29 12:59:44.967: INFO: Deleting pod "simpletest-rc-to-be-deleted-59h4q" in namespace "gc-7674"
  Apr 29 12:59:44.981: INFO: Deleting pod "simpletest-rc-to-be-deleted-59msj" in namespace "gc-7674"
  Apr 29 12:59:44.992: INFO: Deleting pod "simpletest-rc-to-be-deleted-5kd4c" in namespace "gc-7674"
  Apr 29 12:59:45.003: INFO: Deleting pod "simpletest-rc-to-be-deleted-5pq56" in namespace "gc-7674"
  Apr 29 12:59:45.019: INFO: Deleting pod "simpletest-rc-to-be-deleted-644bm" in namespace "gc-7674"
  Apr 29 12:59:45.032: INFO: Deleting pod "simpletest-rc-to-be-deleted-6dlbw" in namespace "gc-7674"
  Apr 29 12:59:45.044: INFO: Deleting pod "simpletest-rc-to-be-deleted-6g668" in namespace "gc-7674"
  Apr 29 12:59:45.056: INFO: Deleting pod "simpletest-rc-to-be-deleted-6r7sp" in namespace "gc-7674"
  Apr 29 12:59:45.074: INFO: Deleting pod "simpletest-rc-to-be-deleted-6zrcs" in namespace "gc-7674"
  Apr 29 12:59:45.086: INFO: Deleting pod "simpletest-rc-to-be-deleted-78gls" in namespace "gc-7674"
  Apr 29 12:59:45.098: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ff2h" in namespace "gc-7674"
  Apr 29 12:59:45.111: INFO: Deleting pod "simpletest-rc-to-be-deleted-7hspv" in namespace "gc-7674"
  Apr 29 12:59:45.124: INFO: Deleting pod "simpletest-rc-to-be-deleted-7pk44" in namespace "gc-7674"
  Apr 29 12:59:45.138: INFO: Deleting pod "simpletest-rc-to-be-deleted-7zbqt" in namespace "gc-7674"
  Apr 29 12:59:45.156: INFO: Deleting pod "simpletest-rc-to-be-deleted-87bh5" in namespace "gc-7674"
  Apr 29 12:59:45.170: INFO: Deleting pod "simpletest-rc-to-be-deleted-8bpzr" in namespace "gc-7674"
  Apr 29 12:59:45.182: INFO: Deleting pod "simpletest-rc-to-be-deleted-8kxbs" in namespace "gc-7674"
  Apr 29 12:59:45.196: INFO: Deleting pod "simpletest-rc-to-be-deleted-8tzfp" in namespace "gc-7674"
  Apr 29 12:59:45.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dmsk" in namespace "gc-7674"
  Apr 29 12:59:45.227: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jcjd" in namespace "gc-7674"
  Apr 29 12:59:45.240: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mz2b" in namespace "gc-7674"
  Apr 29 12:59:45.254: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zwq2" in namespace "gc-7674"
  Apr 29 12:59:45.268: INFO: Deleting pod "simpletest-rc-to-be-deleted-b85g8" in namespace "gc-7674"
  Apr 29 12:59:45.283: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbtkp" in namespace "gc-7674"
  Apr 29 12:59:45.296: INFO: Deleting pod "simpletest-rc-to-be-deleted-bcq6d" in namespace "gc-7674"
  Apr 29 12:59:45.307: INFO: Deleting pod "simpletest-rc-to-be-deleted-bflc7" in namespace "gc-7674"
  Apr 29 12:59:45.319: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnjp7" in namespace "gc-7674"
  Apr 29 12:59:45.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-bt5pd" in namespace "gc-7674"
  Apr 29 12:59:45.346: INFO: Deleting pod "simpletest-rc-to-be-deleted-cgm48" in namespace "gc-7674"
  Apr 29 12:59:45.358: INFO: Deleting pod "simpletest-rc-to-be-deleted-d2mb7" in namespace "gc-7674"
  Apr 29 12:59:45.370: INFO: Deleting pod "simpletest-rc-to-be-deleted-dbb95" in namespace "gc-7674"
  Apr 29 12:59:45.385: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvn4d" in namespace "gc-7674"
  Apr 29 12:59:45.398: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9bz4" in namespace "gc-7674"
  Apr 29 12:59:45.410: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9gl8" in namespace "gc-7674"
  Apr 29 12:59:45.425: INFO: Deleting pod "simpletest-rc-to-be-deleted-fcnnm" in namespace "gc-7674"
  Apr 29 12:59:45.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-fnvcm" in namespace "gc-7674"
  Apr 29 12:59:45.449: INFO: Deleting pod "simpletest-rc-to-be-deleted-fqcvw" in namespace "gc-7674"
  Apr 29 12:59:45.463: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxmgf" in namespace "gc-7674"
  Apr 29 12:59:45.474: INFO: Deleting pod "simpletest-rc-to-be-deleted-g678z" in namespace "gc-7674"
  Apr 29 12:59:45.487: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbvdm" in namespace "gc-7674"
  Apr 29 12:59:45.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7674" for this suite. @ 04/29/23 12:59:45.504
• [17.159 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 04/29/23 12:59:45.512
  Apr 29 12:59:45.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename gc @ 04/29/23 12:59:45.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 12:59:45.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 12:59:45.532
  STEP: create the rc @ 04/29/23 12:59:45.54
  W0429 12:59:45.547772      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 04/29/23 12:59:51.554
  STEP: wait for the rc to be deleted @ 04/29/23 12:59:51.561
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 04/29/23 12:59:56.565
  STEP: Gathering metrics @ 04/29/23 13:00:26.575
  W0429 13:00:26.579231      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 29 13:00:26.579: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 29 13:00:26.579: INFO: Deleting pod "simpletest.rc-252c4" in namespace "gc-8543"
  Apr 29 13:00:26.593: INFO: Deleting pod "simpletest.rc-255x6" in namespace "gc-8543"
  Apr 29 13:00:26.603: INFO: Deleting pod "simpletest.rc-4gbpl" in namespace "gc-8543"
  Apr 29 13:00:26.625: INFO: Deleting pod "simpletest.rc-5gkhv" in namespace "gc-8543"
  Apr 29 13:00:26.641: INFO: Deleting pod "simpletest.rc-5hvvs" in namespace "gc-8543"
  Apr 29 13:00:26.653: INFO: Deleting pod "simpletest.rc-5kz6x" in namespace "gc-8543"
  Apr 29 13:00:26.666: INFO: Deleting pod "simpletest.rc-5sj47" in namespace "gc-8543"
  Apr 29 13:00:26.677: INFO: Deleting pod "simpletest.rc-5t7tj" in namespace "gc-8543"
  Apr 29 13:00:26.692: INFO: Deleting pod "simpletest.rc-5xhnn" in namespace "gc-8543"
  Apr 29 13:00:26.705: INFO: Deleting pod "simpletest.rc-6gtwz" in namespace "gc-8543"
  Apr 29 13:00:26.719: INFO: Deleting pod "simpletest.rc-6hfn8" in namespace "gc-8543"
  Apr 29 13:00:26.733: INFO: Deleting pod "simpletest.rc-6k5sd" in namespace "gc-8543"
  Apr 29 13:00:26.746: INFO: Deleting pod "simpletest.rc-6z7h2" in namespace "gc-8543"
  Apr 29 13:00:26.758: INFO: Deleting pod "simpletest.rc-72fs2" in namespace "gc-8543"
  Apr 29 13:00:26.771: INFO: Deleting pod "simpletest.rc-7blc8" in namespace "gc-8543"
  Apr 29 13:00:26.784: INFO: Deleting pod "simpletest.rc-825z5" in namespace "gc-8543"
  Apr 29 13:00:26.804: INFO: Deleting pod "simpletest.rc-8d6h9" in namespace "gc-8543"
  Apr 29 13:00:26.816: INFO: Deleting pod "simpletest.rc-8xb6h" in namespace "gc-8543"
  Apr 29 13:00:26.829: INFO: Deleting pod "simpletest.rc-8z7sr" in namespace "gc-8543"
  Apr 29 13:00:26.840: INFO: Deleting pod "simpletest.rc-9hvr7" in namespace "gc-8543"
  Apr 29 13:00:26.853: INFO: Deleting pod "simpletest.rc-9wn9g" in namespace "gc-8543"
  Apr 29 13:00:26.871: INFO: Deleting pod "simpletest.rc-bl7jg" in namespace "gc-8543"
  Apr 29 13:00:26.884: INFO: Deleting pod "simpletest.rc-bprfr" in namespace "gc-8543"
  Apr 29 13:00:26.898: INFO: Deleting pod "simpletest.rc-brnmq" in namespace "gc-8543"
  Apr 29 13:00:26.911: INFO: Deleting pod "simpletest.rc-bv4j7" in namespace "gc-8543"
  Apr 29 13:00:26.921: INFO: Deleting pod "simpletest.rc-c6l5n" in namespace "gc-8543"
  Apr 29 13:00:26.934: INFO: Deleting pod "simpletest.rc-cjn5h" in namespace "gc-8543"
  Apr 29 13:00:26.946: INFO: Deleting pod "simpletest.rc-d26mx" in namespace "gc-8543"
  Apr 29 13:00:26.958: INFO: Deleting pod "simpletest.rc-d9gk5" in namespace "gc-8543"
  Apr 29 13:00:26.972: INFO: Deleting pod "simpletest.rc-d9nrk" in namespace "gc-8543"
  Apr 29 13:00:26.984: INFO: Deleting pod "simpletest.rc-dkr42" in namespace "gc-8543"
  Apr 29 13:00:26.998: INFO: Deleting pod "simpletest.rc-dnsfl" in namespace "gc-8543"
  Apr 29 13:00:27.010: INFO: Deleting pod "simpletest.rc-f65v2" in namespace "gc-8543"
  Apr 29 13:00:27.021: INFO: Deleting pod "simpletest.rc-fc7qf" in namespace "gc-8543"
  Apr 29 13:00:27.032: INFO: Deleting pod "simpletest.rc-fh7f6" in namespace "gc-8543"
  Apr 29 13:00:27.046: INFO: Deleting pod "simpletest.rc-fhgsd" in namespace "gc-8543"
  Apr 29 13:00:27.056: INFO: Deleting pod "simpletest.rc-fmb8x" in namespace "gc-8543"
  Apr 29 13:00:27.069: INFO: Deleting pod "simpletest.rc-fvbtx" in namespace "gc-8543"
  Apr 29 13:00:27.080: INFO: Deleting pod "simpletest.rc-ghzqf" in namespace "gc-8543"
  Apr 29 13:00:27.092: INFO: Deleting pod "simpletest.rc-gkkfc" in namespace "gc-8543"
  Apr 29 13:00:27.104: INFO: Deleting pod "simpletest.rc-h2zj8" in namespace "gc-8543"
  Apr 29 13:00:27.116: INFO: Deleting pod "simpletest.rc-h4mmq" in namespace "gc-8543"
  Apr 29 13:00:27.128: INFO: Deleting pod "simpletest.rc-hc2fx" in namespace "gc-8543"
  Apr 29 13:00:27.141: INFO: Deleting pod "simpletest.rc-hjmsp" in namespace "gc-8543"
  Apr 29 13:00:27.153: INFO: Deleting pod "simpletest.rc-hpmzd" in namespace "gc-8543"
  Apr 29 13:00:27.166: INFO: Deleting pod "simpletest.rc-j527n" in namespace "gc-8543"
  Apr 29 13:00:27.185: INFO: Deleting pod "simpletest.rc-jj8xz" in namespace "gc-8543"
  Apr 29 13:00:27.201: INFO: Deleting pod "simpletest.rc-jq446" in namespace "gc-8543"
  Apr 29 13:00:27.214: INFO: Deleting pod "simpletest.rc-jq9lw" in namespace "gc-8543"
  Apr 29 13:00:27.226: INFO: Deleting pod "simpletest.rc-jrct4" in namespace "gc-8543"
  Apr 29 13:00:27.330: INFO: Deleting pod "simpletest.rc-k6q48" in namespace "gc-8543"
  Apr 29 13:00:27.341: INFO: Deleting pod "simpletest.rc-k7jt9" in namespace "gc-8543"
  Apr 29 13:00:27.354: INFO: Deleting pod "simpletest.rc-k98c2" in namespace "gc-8543"
  Apr 29 13:00:27.368: INFO: Deleting pod "simpletest.rc-kd6s7" in namespace "gc-8543"
  Apr 29 13:00:27.379: INFO: Deleting pod "simpletest.rc-kdcg5" in namespace "gc-8543"
  Apr 29 13:00:27.391: INFO: Deleting pod "simpletest.rc-lcntz" in namespace "gc-8543"
  Apr 29 13:00:27.402: INFO: Deleting pod "simpletest.rc-lhffv" in namespace "gc-8543"
  Apr 29 13:00:27.415: INFO: Deleting pod "simpletest.rc-lzglr" in namespace "gc-8543"
  Apr 29 13:00:27.428: INFO: Deleting pod "simpletest.rc-m9vrl" in namespace "gc-8543"
  Apr 29 13:00:27.442: INFO: Deleting pod "simpletest.rc-m9zxn" in namespace "gc-8543"
  Apr 29 13:00:27.457: INFO: Deleting pod "simpletest.rc-mcb86" in namespace "gc-8543"
  Apr 29 13:00:27.468: INFO: Deleting pod "simpletest.rc-mkc2x" in namespace "gc-8543"
  Apr 29 13:00:27.482: INFO: Deleting pod "simpletest.rc-mscgv" in namespace "gc-8543"
  Apr 29 13:00:27.493: INFO: Deleting pod "simpletest.rc-mtjdl" in namespace "gc-8543"
  Apr 29 13:00:27.504: INFO: Deleting pod "simpletest.rc-n4ml8" in namespace "gc-8543"
  Apr 29 13:00:27.518: INFO: Deleting pod "simpletest.rc-n7www" in namespace "gc-8543"
  Apr 29 13:00:27.531: INFO: Deleting pod "simpletest.rc-ndtjz" in namespace "gc-8543"
  Apr 29 13:00:27.542: INFO: Deleting pod "simpletest.rc-ng2fh" in namespace "gc-8543"
  Apr 29 13:00:27.578: INFO: Deleting pod "simpletest.rc-nt7rl" in namespace "gc-8543"
  Apr 29 13:00:27.628: INFO: Deleting pod "simpletest.rc-p6vhg" in namespace "gc-8543"
  Apr 29 13:00:27.678: INFO: Deleting pod "simpletest.rc-p7qgn" in namespace "gc-8543"
  Apr 29 13:00:27.735: INFO: Deleting pod "simpletest.rc-pb9lq" in namespace "gc-8543"
  Apr 29 13:00:27.778: INFO: Deleting pod "simpletest.rc-pwljk" in namespace "gc-8543"
  Apr 29 13:00:27.834: INFO: Deleting pod "simpletest.rc-q7wwc" in namespace "gc-8543"
  Apr 29 13:00:27.881: INFO: Deleting pod "simpletest.rc-qjvp7" in namespace "gc-8543"
  Apr 29 13:00:27.929: INFO: Deleting pod "simpletest.rc-r6vrm" in namespace "gc-8543"
  Apr 29 13:00:27.979: INFO: Deleting pod "simpletest.rc-rfh6k" in namespace "gc-8543"
  Apr 29 13:00:28.031: INFO: Deleting pod "simpletest.rc-rkgjm" in namespace "gc-8543"
  Apr 29 13:00:28.076: INFO: Deleting pod "simpletest.rc-s524q" in namespace "gc-8543"
  Apr 29 13:00:28.139: INFO: Deleting pod "simpletest.rc-s67lk" in namespace "gc-8543"
  Apr 29 13:00:28.179: INFO: Deleting pod "simpletest.rc-s7bfv" in namespace "gc-8543"
  Apr 29 13:00:28.228: INFO: Deleting pod "simpletest.rc-s8h6z" in namespace "gc-8543"
  Apr 29 13:00:28.279: INFO: Deleting pod "simpletest.rc-s8nwm" in namespace "gc-8543"
  Apr 29 13:00:28.329: INFO: Deleting pod "simpletest.rc-td6j8" in namespace "gc-8543"
  Apr 29 13:00:28.380: INFO: Deleting pod "simpletest.rc-tsnsq" in namespace "gc-8543"
  Apr 29 13:00:28.427: INFO: Deleting pod "simpletest.rc-tztzj" in namespace "gc-8543"
  Apr 29 13:00:28.478: INFO: Deleting pod "simpletest.rc-v4zsk" in namespace "gc-8543"
  Apr 29 13:00:28.526: INFO: Deleting pod "simpletest.rc-vbp6k" in namespace "gc-8543"
  Apr 29 13:00:28.582: INFO: Deleting pod "simpletest.rc-vhvlc" in namespace "gc-8543"
  Apr 29 13:00:28.629: INFO: Deleting pod "simpletest.rc-vlf4d" in namespace "gc-8543"
  Apr 29 13:00:28.679: INFO: Deleting pod "simpletest.rc-vr6k9" in namespace "gc-8543"
  Apr 29 13:00:28.729: INFO: Deleting pod "simpletest.rc-vrz57" in namespace "gc-8543"
  Apr 29 13:00:28.779: INFO: Deleting pod "simpletest.rc-vsd2w" in namespace "gc-8543"
  Apr 29 13:00:28.827: INFO: Deleting pod "simpletest.rc-wdl7b" in namespace "gc-8543"
  Apr 29 13:00:28.877: INFO: Deleting pod "simpletest.rc-wggpf" in namespace "gc-8543"
  Apr 29 13:00:28.927: INFO: Deleting pod "simpletest.rc-x7p44" in namespace "gc-8543"
  Apr 29 13:00:28.977: INFO: Deleting pod "simpletest.rc-xc9h6" in namespace "gc-8543"
  Apr 29 13:00:29.028: INFO: Deleting pod "simpletest.rc-zd47r" in namespace "gc-8543"
  Apr 29 13:00:29.079: INFO: Deleting pod "simpletest.rc-zhmsm" in namespace "gc-8543"
  Apr 29 13:00:29.128: INFO: Deleting pod "simpletest.rc-zw5pw" in namespace "gc-8543"
  Apr 29 13:00:29.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8543" for this suite. @ 04/29/23 13:00:29.221
• [43.762 seconds]
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:465
  STEP: Creating a kubernetes client @ 04/29/23 13:00:29.274
  Apr 29 13:00:29.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename field-validation @ 04/29/23 13:00:29.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:00:29.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:00:29.295
  Apr 29 13:00:29.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  W0429 13:00:31.848559      18 warnings.go:70] unknown field "alpha"
  W0429 13:00:31.848705      18 warnings.go:70] unknown field "beta"
  W0429 13:00:31.848765      18 warnings.go:70] unknown field "delta"
  W0429 13:00:31.848815      18 warnings.go:70] unknown field "epsilon"
  W0429 13:00:31.848872      18 warnings.go:70] unknown field "gamma"
  Apr 29 13:00:31.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5801" for this suite. @ 04/29/23 13:00:31.885
• [2.618 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 04/29/23 13:00:31.893
  Apr 29 13:00:31.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename deployment @ 04/29/23 13:00:31.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:00:31.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:00:31.913
  Apr 29 13:00:31.926: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  Apr 29 13:00:36.932: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/29/23 13:00:36.932
  Apr 29 13:00:38.938: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 04/29/23 13:00:38.946
  Apr 29 13:00:38.956: INFO: Deployment "test-cleanup-deployment":
  &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8081  ce5a7776-704e-43ce-bf4c-98f184c9c42a 28165 1 2023-04-29 13:00:38 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-04-29 13:00:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0050216b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

  Apr 29 13:00:38.959: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Apr 29 13:00:38.959: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Apr 29 13:00:38.959: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-8081  4c65b209-d070-4689-a5d0-d80e0db9c946 28166 1 2023-04-29 13:00:31 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment ce5a7776-704e-43ce-bf4c-98f184c9c42a 0xc005021a47 0xc005021a48}] [] [{e2e.test Update apps/v1 2023-04-29 13:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 13:00:37 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-29 13:00:38 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"ce5a7776-704e-43ce-bf4c-98f184c9c42a\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005021b08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 29 13:00:38.963: INFO: Pod "test-cleanup-controller-pkvqv" is available:
  &Pod{ObjectMeta:{test-cleanup-controller-pkvqv test-cleanup-controller- deployment-8081  a5304207-9a49-42f3-80a2-fa7aff2ef40e 28029 0 2023-04-29 13:00:31 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 4c65b209-d070-4689-a5d0-d80e0db9c946 0xc004735f87 0xc004735f88}] [] [{kube-controller-manager Update v1 2023-04-29 13:00:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4c65b209-d070-4689-a5d0-d80e0db9c946\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 13:00:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8wg57,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8wg57,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:00:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:00:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:00:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:00:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:192.168.226.23,StartTime:2023-04-29 13:00:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 13:00:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://d316232d751050487729b518a55882fe29d8c30122af3add9de5de38d544cba9,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.226.23,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 29 13:00:38.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8081" for this suite. @ 04/29/23 13:00:38.97
• [7.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 04/29/23 13:00:38.978
  Apr 29 13:00:38.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename job @ 04/29/23 13:00:38.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:00:39.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:00:39.006
  STEP: Creating a job @ 04/29/23 13:00:39.01
  STEP: Ensuring active pods == parallelism @ 04/29/23 13:00:39.016
  STEP: delete a job @ 04/29/23 13:00:41.02
  STEP: deleting Job.batch foo in namespace job-722, will wait for the garbage collector to delete the pods @ 04/29/23 13:00:41.02
  Apr 29 13:00:41.080: INFO: Deleting Job.batch foo took: 6.086434ms
  Apr 29 13:00:41.181: INFO: Terminating Job.batch foo pods took: 101.326344ms
  STEP: Ensuring job was deleted @ 04/29/23 13:01:12.582
  Apr 29 13:01:12.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-722" for this suite. @ 04/29/23 13:01:12.59
• [33.618 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 04/29/23 13:01:12.597
  Apr 29 13:01:12.597: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename dns @ 04/29/23 13:01:12.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:01:12.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:01:12.618
  STEP: Creating a test headless service @ 04/29/23 13:01:12.622
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9086.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9086.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9086.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9086.svc.cluster.local;sleep 1; done
   @ 04/29/23 13:01:12.627
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9086.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9086.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9086.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9086.svc.cluster.local;sleep 1; done
   @ 04/29/23 13:01:12.627
  STEP: creating a pod to probe DNS @ 04/29/23 13:01:12.628
  STEP: submitting the pod to kubernetes @ 04/29/23 13:01:12.628
  STEP: retrieving the pod @ 04/29/23 13:01:14.647
  STEP: looking for the results for each expected name from probers @ 04/29/23 13:01:14.65
  Apr 29 13:01:14.656: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local from pod dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde: the server could not find the requested resource (get pods dns-test-062abe45-768b-4e5e-b248-600e77be6dde)
  Apr 29 13:01:14.659: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local from pod dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde: the server could not find the requested resource (get pods dns-test-062abe45-768b-4e5e-b248-600e77be6dde)
  Apr 29 13:01:14.662: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9086.svc.cluster.local from pod dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde: the server could not find the requested resource (get pods dns-test-062abe45-768b-4e5e-b248-600e77be6dde)
  Apr 29 13:01:14.667: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9086.svc.cluster.local from pod dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde: the server could not find the requested resource (get pods dns-test-062abe45-768b-4e5e-b248-600e77be6dde)
  Apr 29 13:01:14.670: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local from pod dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde: the server could not find the requested resource (get pods dns-test-062abe45-768b-4e5e-b248-600e77be6dde)
  Apr 29 13:01:14.673: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local from pod dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde: the server could not find the requested resource (get pods dns-test-062abe45-768b-4e5e-b248-600e77be6dde)
  Apr 29 13:01:14.677: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9086.svc.cluster.local from pod dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde: the server could not find the requested resource (get pods dns-test-062abe45-768b-4e5e-b248-600e77be6dde)
  Apr 29 13:01:14.680: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9086.svc.cluster.local from pod dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde: the server could not find the requested resource (get pods dns-test-062abe45-768b-4e5e-b248-600e77be6dde)
  Apr 29 13:01:14.680: INFO: Lookups using dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9086.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9086.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9086.svc.cluster.local jessie_udp@dns-test-service-2.dns-9086.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9086.svc.cluster.local]

  Apr 29 13:01:19.711: INFO: DNS probes using dns-9086/dns-test-062abe45-768b-4e5e-b248-600e77be6dde succeeded

  Apr 29 13:01:19.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:01:19.716
  STEP: deleting the test headless service @ 04/29/23 13:01:19.729
  STEP: Destroying namespace "dns-9086" for this suite. @ 04/29/23 13:01:19.75
• [7.162 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 04/29/23 13:01:19.76
  Apr 29 13:01:19.760: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/29/23 13:01:19.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:01:19.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:01:19.779
  STEP: Creating 50 configmaps @ 04/29/23 13:01:19.783
  STEP: Creating RC which spawns configmap-volume pods @ 04/29/23 13:01:20.015
  Apr 29 13:01:20.126: INFO: Pod name wrapped-volume-race-3079cfd7-020e-4b89-a2da-c8971adb110d: Found 3 pods out of 5
  Apr 29 13:01:25.133: INFO: Pod name wrapped-volume-race-3079cfd7-020e-4b89-a2da-c8971adb110d: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/29/23 13:01:25.133
  STEP: Creating RC which spawns configmap-volume pods @ 04/29/23 13:01:25.154
  Apr 29 13:01:25.178: INFO: Pod name wrapped-volume-race-8f5ef3ae-07ba-477a-8d39-df8e77a850e9: Found 0 pods out of 5
  Apr 29 13:01:30.185: INFO: Pod name wrapped-volume-race-8f5ef3ae-07ba-477a-8d39-df8e77a850e9: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/29/23 13:01:30.185
  STEP: Creating RC which spawns configmap-volume pods @ 04/29/23 13:01:30.205
  Apr 29 13:01:30.218: INFO: Pod name wrapped-volume-race-46c6427d-f7d1-4422-8915-233709da338d: Found 0 pods out of 5
  Apr 29 13:01:35.225: INFO: Pod name wrapped-volume-race-46c6427d-f7d1-4422-8915-233709da338d: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/29/23 13:01:35.225
  Apr 29 13:01:35.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-46c6427d-f7d1-4422-8915-233709da338d in namespace emptydir-wrapper-75, will wait for the garbage collector to delete the pods @ 04/29/23 13:01:35.246
  Apr 29 13:01:35.308: INFO: Deleting ReplicationController wrapped-volume-race-46c6427d-f7d1-4422-8915-233709da338d took: 7.259657ms
  Apr 29 13:01:35.408: INFO: Terminating ReplicationController wrapped-volume-race-46c6427d-f7d1-4422-8915-233709da338d pods took: 100.591951ms
  STEP: deleting ReplicationController wrapped-volume-race-8f5ef3ae-07ba-477a-8d39-df8e77a850e9 in namespace emptydir-wrapper-75, will wait for the garbage collector to delete the pods @ 04/29/23 13:01:37.809
  Apr 29 13:01:37.870: INFO: Deleting ReplicationController wrapped-volume-race-8f5ef3ae-07ba-477a-8d39-df8e77a850e9 took: 6.517359ms
  Apr 29 13:01:37.971: INFO: Terminating ReplicationController wrapped-volume-race-8f5ef3ae-07ba-477a-8d39-df8e77a850e9 pods took: 101.014408ms
  STEP: deleting ReplicationController wrapped-volume-race-3079cfd7-020e-4b89-a2da-c8971adb110d in namespace emptydir-wrapper-75, will wait for the garbage collector to delete the pods @ 04/29/23 13:01:39.772
  Apr 29 13:01:39.834: INFO: Deleting ReplicationController wrapped-volume-race-3079cfd7-020e-4b89-a2da-c8971adb110d took: 8.419174ms
  Apr 29 13:01:39.935: INFO: Terminating ReplicationController wrapped-volume-race-3079cfd7-020e-4b89-a2da-c8971adb110d pods took: 100.673122ms
  STEP: Cleaning up the configMaps @ 04/29/23 13:01:41.836
  STEP: Destroying namespace "emptydir-wrapper-75" for this suite. @ 04/29/23 13:01:42.11
• [22.358 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 04/29/23 13:01:42.119
  Apr 29 13:01:42.119: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 13:01:42.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:01:42.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:01:42.14
  STEP: Creating Pod @ 04/29/23 13:01:42.143
  STEP: Reading file content from the nginx-container @ 04/29/23 13:01:44.158
  Apr 29 13:01:44.158: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-2154 PodName:pod-sharedvolume-fe8e62ef-380a-4ad3-8af3-3787727eb92c ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:44.158: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:44.159: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:44.159: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-2154/pods/pod-sharedvolume-fe8e62ef-380a-4ad3-8af3-3787727eb92c/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Apr 29 13:01:44.219: INFO: Exec stderr: ""
  Apr 29 13:01:44.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2154" for this suite. @ 04/29/23 13:01:44.223
• [2.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 04/29/23 13:01:44.235
  Apr 29 13:01:44.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 04/29/23 13:01:44.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:01:44.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:01:44.257
  STEP: Setting up the test @ 04/29/23 13:01:44.259
  STEP: Creating hostNetwork=false pod @ 04/29/23 13:01:44.259
  STEP: Creating hostNetwork=true pod @ 04/29/23 13:01:46.28
  STEP: Running the test @ 04/29/23 13:01:48.3
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 04/29/23 13:01:48.3
  Apr 29 13:01:48.300: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.301: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.301: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 29 13:01:48.371: INFO: Exec stderr: ""
  Apr 29 13:01:48.371: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.371: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.371: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 29 13:01:48.426: INFO: Exec stderr: ""
  Apr 29 13:01:48.426: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.427: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.427: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 29 13:01:48.491: INFO: Exec stderr: ""
  Apr 29 13:01:48.491: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.492: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.492: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 29 13:01:48.567: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 04/29/23 13:01:48.567
  Apr 29 13:01:48.567: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.568: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.568: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 29 13:01:48.643: INFO: Exec stderr: ""
  Apr 29 13:01:48.643: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.644: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.644: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 29 13:01:48.698: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 04/29/23 13:01:48.699
  Apr 29 13:01:48.699: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.699: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.699: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 29 13:01:48.761: INFO: Exec stderr: ""
  Apr 29 13:01:48.761: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.762: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.762: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 29 13:01:48.825: INFO: Exec stderr: ""
  Apr 29 13:01:48.825: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.825: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.826: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 29 13:01:48.881: INFO: Exec stderr: ""
  Apr 29 13:01:48.881: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2882 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:01:48.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:01:48.881: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:01:48.882: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2882/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 29 13:01:48.953: INFO: Exec stderr: ""
  Apr 29 13:01:48.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-2882" for this suite. @ 04/29/23 13:01:48.958
• [4.728 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 04/29/23 13:01:48.967
  Apr 29 13:01:48.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 13:01:48.968
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:01:48.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:01:48.987
  STEP: Creating configMap with name cm-test-opt-del-2363343b-40b2-48db-ad2f-a841fc52f612 @ 04/29/23 13:01:48.993
  STEP: Creating configMap with name cm-test-opt-upd-fc554ad4-9394-4715-9a9d-5a561267626e @ 04/29/23 13:01:48.996
  STEP: Creating the pod @ 04/29/23 13:01:49.001
  STEP: Deleting configmap cm-test-opt-del-2363343b-40b2-48db-ad2f-a841fc52f612 @ 04/29/23 13:01:51.053
  STEP: Updating configmap cm-test-opt-upd-fc554ad4-9394-4715-9a9d-5a561267626e @ 04/29/23 13:01:51.059
  STEP: Creating configMap with name cm-test-opt-create-9745c91e-492a-4a11-ba4c-d0e36da1b1c1 @ 04/29/23 13:01:51.064
  STEP: waiting to observe update in volume @ 04/29/23 13:01:51.069
  Apr 29 13:03:13.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4419" for this suite. @ 04/29/23 13:03:13.462
• [84.502 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 04/29/23 13:03:13.469
  Apr 29 13:03:13.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:03:13.47
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:13.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:13.494
  STEP: Creating configMap with name projected-configmap-test-volume-21e23571-bdcd-49b7-9a40-ae99b06c2c65 @ 04/29/23 13:03:13.498
  STEP: Creating a pod to test consume configMaps @ 04/29/23 13:03:13.502
  STEP: Saw pod success @ 04/29/23 13:03:17.521
  Apr 29 13:03:17.524: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-configmaps-fb4eb65d-4b26-4bad-abf1-4de03ba382db container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 13:03:17.53
  Apr 29 13:03:17.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6944" for this suite. @ 04/29/23 13:03:17.55
• [4.086 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 04/29/23 13:03:17.556
  Apr 29 13:03:17.556: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:03:17.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:17.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:17.579
  STEP: creating service in namespace services-9194 @ 04/29/23 13:03:17.585
  STEP: creating service affinity-nodeport in namespace services-9194 @ 04/29/23 13:03:17.586
  STEP: creating replication controller affinity-nodeport in namespace services-9194 @ 04/29/23 13:03:17.601
  I0429 13:03:17.608010      18 runners.go:194] Created replication controller with name: affinity-nodeport, namespace: services-9194, replica count: 3
  I0429 13:03:20.658922      18 runners.go:194] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 13:03:20.669: INFO: Creating new exec pod
  Apr 29 13:03:23.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-9194 exec execpod-affinity2zccq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Apr 29 13:03:23.821: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Apr 29 13:03:23.821: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:03:23.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-9194 exec execpod-affinity2zccq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.76 80'
  Apr 29 13:03:23.939: INFO: stderr: "+ nc -v -t -w 2 10.152.183.76 80\n+ echo hostName\nConnection to 10.152.183.76 80 port [tcp/http] succeeded!\n"
  Apr 29 13:03:23.939: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:03:23.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-9194 exec execpod-affinity2zccq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.13 31783'
  Apr 29 13:03:24.060: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.25.13 31783\nConnection to 172.31.25.13 31783 port [tcp/*] succeeded!\n"
  Apr 29 13:03:24.060: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:03:24.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-9194 exec execpod-affinity2zccq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.82.46 31783'
  Apr 29 13:03:24.180: INFO: stderr: "+ nc -v -t -w 2 172.31.82.46 31783\n+ echo hostName\nConnection to 172.31.82.46 31783 port [tcp/*] succeeded!\n"
  Apr 29 13:03:24.180: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:03:24.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-9194 exec execpod-affinity2zccq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.25.13:31783/ ; done'
  Apr 29 13:03:24.391: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.25.13:31783/\n"
  Apr 29 13:03:24.391: INFO: stdout: "\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg\naffinity-nodeport-8zbzg"
  Apr 29 13:03:24.391: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Received response from host: affinity-nodeport-8zbzg
  Apr 29 13:03:24.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 13:03:24.396: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-9194, will wait for the garbage collector to delete the pods @ 04/29/23 13:03:24.409
  Apr 29 13:03:24.470: INFO: Deleting ReplicationController affinity-nodeport took: 5.853538ms
  Apr 29 13:03:24.571: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.883026ms
  STEP: Destroying namespace "services-9194" for this suite. @ 04/29/23 13:03:26.99
• [9.440 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 04/29/23 13:03:26.997
  Apr 29 13:03:26.997: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 13:03:26.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:27.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:27.018
  STEP: creating all guestbook components @ 04/29/23 13:03:27.02
  Apr 29 13:03:27.020: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Apr 29 13:03:27.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 create -f -'
  Apr 29 13:03:27.810: INFO: stderr: ""
  Apr 29 13:03:27.810: INFO: stdout: "service/agnhost-replica created\n"
  Apr 29 13:03:27.810: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Apr 29 13:03:27.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 create -f -'
  Apr 29 13:03:28.071: INFO: stderr: ""
  Apr 29 13:03:28.071: INFO: stdout: "service/agnhost-primary created\n"
  Apr 29 13:03:28.071: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Apr 29 13:03:28.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 create -f -'
  Apr 29 13:03:28.308: INFO: stderr: ""
  Apr 29 13:03:28.308: INFO: stdout: "service/frontend created\n"
  Apr 29 13:03:28.308: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Apr 29 13:03:28.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 create -f -'
  Apr 29 13:03:28.625: INFO: stderr: ""
  Apr 29 13:03:28.625: INFO: stdout: "deployment.apps/frontend created\n"
  Apr 29 13:03:28.625: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 29 13:03:28.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 create -f -'
  Apr 29 13:03:28.893: INFO: stderr: ""
  Apr 29 13:03:28.893: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Apr 29 13:03:28.893: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 29 13:03:28.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 create -f -'
  Apr 29 13:03:29.189: INFO: stderr: ""
  Apr 29 13:03:29.189: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 04/29/23 13:03:29.189
  Apr 29 13:03:29.189: INFO: Waiting for all frontend pods to be Running.
  Apr 29 13:03:34.241: INFO: Waiting for frontend to serve content.
  Apr 29 13:03:34.252: INFO: Trying to add a new entry to the guestbook.
  Apr 29 13:03:34.267: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 04/29/23 13:03:34.277
  Apr 29 13:03:34.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 delete --grace-period=0 --force -f -'
  Apr 29 13:03:34.403: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 13:03:34.403: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 04/29/23 13:03:34.403
  Apr 29 13:03:34.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 delete --grace-period=0 --force -f -'
  Apr 29 13:03:34.526: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 13:03:34.526: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/29/23 13:03:34.526
  Apr 29 13:03:34.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 delete --grace-period=0 --force -f -'
  Apr 29 13:03:34.645: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 13:03:34.645: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/29/23 13:03:34.645
  Apr 29 13:03:34.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 delete --grace-period=0 --force -f -'
  Apr 29 13:03:34.753: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 13:03:34.753: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/29/23 13:03:34.753
  Apr 29 13:03:34.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 delete --grace-period=0 --force -f -'
  Apr 29 13:03:34.884: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 13:03:34.884: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/29/23 13:03:34.884
  Apr 29 13:03:34.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-1343 delete --grace-period=0 --force -f -'
  Apr 29 13:03:35.033: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 13:03:35.033: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Apr 29 13:03:35.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1343" for this suite. @ 04/29/23 13:03:35.037
• [8.047 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 04/29/23 13:03:35.044
  Apr 29 13:03:35.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename runtimeclass @ 04/29/23 13:03:35.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:35.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:35.068
  STEP: getting /apis @ 04/29/23 13:03:35.071
  STEP: getting /apis/node.k8s.io @ 04/29/23 13:03:35.075
  STEP: getting /apis/node.k8s.io/v1 @ 04/29/23 13:03:35.077
  STEP: creating @ 04/29/23 13:03:35.078
  STEP: watching @ 04/29/23 13:03:35.094
  Apr 29 13:03:35.094: INFO: starting watch
  STEP: getting @ 04/29/23 13:03:35.099
  STEP: listing @ 04/29/23 13:03:35.102
  STEP: patching @ 04/29/23 13:03:35.105
  STEP: updating @ 04/29/23 13:03:35.108
  Apr 29 13:03:35.113: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 04/29/23 13:03:35.113
  STEP: deleting a collection @ 04/29/23 13:03:35.124
  Apr 29 13:03:35.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4379" for this suite. @ 04/29/23 13:03:35.141
• [0.103 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:743
  STEP: Creating a kubernetes client @ 04/29/23 13:03:35.147
  Apr 29 13:03:35.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename statefulset @ 04/29/23 13:03:35.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:35.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:35.169
  STEP: Creating service test in namespace statefulset-5922 @ 04/29/23 13:03:35.172
  STEP: Looking for a node to schedule stateful set and pod @ 04/29/23 13:03:35.178
  STEP: Creating pod with conflicting port in namespace statefulset-5922 @ 04/29/23 13:03:35.184
  STEP: Waiting until pod test-pod will start running in namespace statefulset-5922 @ 04/29/23 13:03:35.192
  STEP: Creating statefulset with conflicting port in namespace statefulset-5922 @ 04/29/23 13:03:37.199
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5922 @ 04/29/23 13:03:37.207
  Apr 29 13:03:37.222: INFO: Observed stateful pod in namespace: statefulset-5922, name: ss-0, uid: a3e7ac1b-4ea6-4eab-905d-c1bbdef57c61, status phase: Pending. Waiting for statefulset controller to delete.
  Apr 29 13:03:37.250: INFO: Observed stateful pod in namespace: statefulset-5922, name: ss-0, uid: a3e7ac1b-4ea6-4eab-905d-c1bbdef57c61, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 29 13:03:37.262: INFO: Observed stateful pod in namespace: statefulset-5922, name: ss-0, uid: a3e7ac1b-4ea6-4eab-905d-c1bbdef57c61, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 29 13:03:37.268: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5922
  STEP: Removing pod with conflicting port in namespace statefulset-5922 @ 04/29/23 13:03:37.268
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5922 and will be in running state @ 04/29/23 13:03:37.281
  Apr 29 13:03:39.291: INFO: Deleting all statefulset in ns statefulset-5922
  Apr 29 13:03:39.293: INFO: Scaling statefulset ss to 0
  Apr 29 13:03:49.309: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 13:03:49.313: INFO: Deleting statefulset ss
  Apr 29 13:03:49.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5922" for this suite. @ 04/29/23 13:03:49.336
• [14.195 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 04/29/23 13:03:49.344
  Apr 29 13:03:49.344: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename server-version @ 04/29/23 13:03:49.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:49.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:49.362
  STEP: Request ServerVersion @ 04/29/23 13:03:49.369
  STEP: Confirm major version @ 04/29/23 13:03:49.37
  Apr 29 13:03:49.370: INFO: Major version: 1
  STEP: Confirm minor version @ 04/29/23 13:03:49.37
  Apr 29 13:03:49.370: INFO: cleanMinorVersion: 27
  Apr 29 13:03:49.370: INFO: Minor version: 27
  Apr 29 13:03:49.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-8639" for this suite. @ 04/29/23 13:03:49.373
• [0.036 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 04/29/23 13:03:49.381
  Apr 29 13:03:49.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename field-validation @ 04/29/23 13:03:49.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:49.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:49.402
  Apr 29 13:03:49.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  W0429 13:03:51.963035      18 warnings.go:70] unknown field "alpha"
  W0429 13:03:51.963054      18 warnings.go:70] unknown field "beta"
  W0429 13:03:51.963060      18 warnings.go:70] unknown field "delta"
  W0429 13:03:51.963065      18 warnings.go:70] unknown field "epsilon"
  W0429 13:03:51.963094      18 warnings.go:70] unknown field "gamma"
  Apr 29 13:03:51.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2092" for this suite. @ 04/29/23 13:03:51.994
• [2.620 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 04/29/23 13:03:52.001
  Apr 29 13:03:52.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename containers @ 04/29/23 13:03:52.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:52.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:52.018
  STEP: Creating a pod to test override all @ 04/29/23 13:03:52.021
  STEP: Saw pod success @ 04/29/23 13:03:56.042
  Apr 29 13:03:56.045: INFO: Trying to get logs from node ip-172-31-41-80 pod client-containers-a979e9d7-d95b-4124-9764-9f9e04be60d3 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 13:03:56.052
  Apr 29 13:03:56.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9329" for this suite. @ 04/29/23 13:03:56.07
• [4.075 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 04/29/23 13:03:56.076
  Apr 29 13:03:56.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename svcaccounts @ 04/29/23 13:03:56.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:56.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:56.096
  Apr 29 13:03:56.120: INFO: created pod pod-service-account-defaultsa
  Apr 29 13:03:56.120: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Apr 29 13:03:56.125: INFO: created pod pod-service-account-mountsa
  Apr 29 13:03:56.125: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Apr 29 13:03:56.130: INFO: created pod pod-service-account-nomountsa
  Apr 29 13:03:56.130: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Apr 29 13:03:56.137: INFO: created pod pod-service-account-defaultsa-mountspec
  Apr 29 13:03:56.137: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Apr 29 13:03:56.144: INFO: created pod pod-service-account-mountsa-mountspec
  Apr 29 13:03:56.144: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Apr 29 13:03:56.149: INFO: created pod pod-service-account-nomountsa-mountspec
  Apr 29 13:03:56.149: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Apr 29 13:03:56.153: INFO: created pod pod-service-account-defaultsa-nomountspec
  Apr 29 13:03:56.153: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Apr 29 13:03:56.162: INFO: created pod pod-service-account-mountsa-nomountspec
  Apr 29 13:03:56.162: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Apr 29 13:03:56.168: INFO: created pod pod-service-account-nomountsa-nomountspec
  Apr 29 13:03:56.169: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Apr 29 13:03:56.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5173" for this suite. @ 04/29/23 13:03:56.175
• [0.111 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 04/29/23 13:03:56.187
  Apr 29 13:03:56.188: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 13:03:56.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:03:56.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:03:56.207
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/29/23 13:03:56.211
  STEP: Saw pod success @ 04/29/23 13:04:00.232
  Apr 29 13:04:00.236: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-9dd68118-40cf-4429-8558-7101ae2eaee1 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 13:04:00.242
  Apr 29 13:04:00.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2629" for this suite. @ 04/29/23 13:04:00.262
• [4.080 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 04/29/23 13:04:00.268
  Apr 29 13:04:00.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename security-context @ 04/29/23 13:04:00.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:04:00.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:04:00.286
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/29/23 13:04:00.289
  STEP: Saw pod success @ 04/29/23 13:04:04.308
  Apr 29 13:04:04.310: INFO: Trying to get logs from node ip-172-31-41-80 pod security-context-0040b53f-db46-4c6b-8609-649bcad79ed6 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 13:04:04.317
  Apr 29 13:04:04.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-8203" for this suite. @ 04/29/23 13:04:04.336
• [4.073 seconds]
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 04/29/23 13:04:04.342
  Apr 29 13:04:04.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename dns @ 04/29/23 13:04:04.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:04:04.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:04:04.363
  STEP: Creating a test headless service @ 04/29/23 13:04:04.366
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9558.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9558.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 04/29/23 13:04:04.371
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9558.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9558.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 04/29/23 13:04:04.371
  STEP: creating a pod to probe DNS @ 04/29/23 13:04:04.371
  STEP: submitting the pod to kubernetes @ 04/29/23 13:04:04.371
  STEP: retrieving the pod @ 04/29/23 13:04:06.39
  STEP: looking for the results for each expected name from probers @ 04/29/23 13:04:06.393
  Apr 29 13:04:06.410: INFO: DNS probes using dns-9558/dns-test-25441e56-1bf5-406d-8012-a41dfe8f90a9 succeeded

  Apr 29 13:04:06.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:04:06.414
  STEP: deleting the test headless service @ 04/29/23 13:04:06.427
  STEP: Destroying namespace "dns-9558" for this suite. @ 04/29/23 13:04:06.439
• [2.103 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 04/29/23 13:04:06.445
  Apr 29 13:04:06.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 13:04:06.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:04:06.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:04:06.469
  STEP: Creating resourceQuota "e2e-rq-status-dfvsk" @ 04/29/23 13:04:06.475
  Apr 29 13:04:06.482: INFO: Resource quota "e2e-rq-status-dfvsk" reports spec: hard cpu limit of 500m
  Apr 29 13:04:06.482: INFO: Resource quota "e2e-rq-status-dfvsk" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-dfvsk" /status @ 04/29/23 13:04:06.482
  STEP: Confirm /status for "e2e-rq-status-dfvsk" resourceQuota via watch @ 04/29/23 13:04:06.512
  Apr 29 13:04:06.514: INFO: observed resourceQuota "e2e-rq-status-dfvsk" in namespace "resourcequota-6350" with hard status: v1.ResourceList(nil)
  Apr 29 13:04:06.514: INFO: Found resourceQuota "e2e-rq-status-dfvsk" in namespace "resourcequota-6350" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 29 13:04:06.514: INFO: ResourceQuota "e2e-rq-status-dfvsk" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 04/29/23 13:04:06.519
  Apr 29 13:04:06.529: INFO: Resource quota "e2e-rq-status-dfvsk" reports spec: hard cpu limit of 1
  Apr 29 13:04:06.529: INFO: Resource quota "e2e-rq-status-dfvsk" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-dfvsk" /status @ 04/29/23 13:04:06.53
  STEP: Confirm /status for "e2e-rq-status-dfvsk" resourceQuota via watch @ 04/29/23 13:04:06.538
  Apr 29 13:04:06.540: INFO: observed resourceQuota "e2e-rq-status-dfvsk" in namespace "resourcequota-6350" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 29 13:04:06.540: INFO: Found resourceQuota "e2e-rq-status-dfvsk" in namespace "resourcequota-6350" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Apr 29 13:04:06.540: INFO: ResourceQuota "e2e-rq-status-dfvsk" /status was patched
  STEP: Get "e2e-rq-status-dfvsk" /status @ 04/29/23 13:04:06.54
  Apr 29 13:04:06.545: INFO: Resourcequota "e2e-rq-status-dfvsk" reports status: hard cpu of 1
  Apr 29 13:04:06.545: INFO: Resourcequota "e2e-rq-status-dfvsk" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-dfvsk" /status before checking Spec is unchanged @ 04/29/23 13:04:06.551
  Apr 29 13:04:06.557: INFO: Resourcequota "e2e-rq-status-dfvsk" reports status: hard cpu of 2
  Apr 29 13:04:06.557: INFO: Resourcequota "e2e-rq-status-dfvsk" reports status: hard memory of 2Gi
  Apr 29 13:04:06.558: INFO: Found resourceQuota "e2e-rq-status-dfvsk" in namespace "resourcequota-6350" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Apr 29 13:04:36.572: INFO: ResourceQuota "e2e-rq-status-dfvsk" Spec was unchanged and /status reset
  Apr 29 13:04:36.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6350" for this suite. @ 04/29/23 13:04:36.577
• [30.138 seconds]
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 04/29/23 13:04:36.583
  Apr 29 13:04:36.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename limitrange @ 04/29/23 13:04:36.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:04:36.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:04:36.601
  STEP: Creating LimitRange "e2e-limitrange-fc9vd" in namespace "limitrange-7208" @ 04/29/23 13:04:36.603
  STEP: Creating another limitRange in another namespace @ 04/29/23 13:04:36.609
  Apr 29 13:04:36.625: INFO: Namespace "e2e-limitrange-fc9vd-909" created
  Apr 29 13:04:36.626: INFO: Creating LimitRange "e2e-limitrange-fc9vd" in namespace "e2e-limitrange-fc9vd-909"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-fc9vd" @ 04/29/23 13:04:36.631
  Apr 29 13:04:36.634: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-fc9vd" in "limitrange-7208" namespace @ 04/29/23 13:04:36.634
  Apr 29 13:04:36.639: INFO: LimitRange "e2e-limitrange-fc9vd" has been patched
  STEP: Delete LimitRange "e2e-limitrange-fc9vd" by Collection with labelSelector: "e2e-limitrange-fc9vd=patched" @ 04/29/23 13:04:36.64
  STEP: Confirm that the limitRange "e2e-limitrange-fc9vd" has been deleted @ 04/29/23 13:04:36.647
  Apr 29 13:04:36.647: INFO: Requesting list of LimitRange to confirm quantity
  Apr 29 13:04:36.650: INFO: Found 0 LimitRange with label "e2e-limitrange-fc9vd=patched"
  Apr 29 13:04:36.650: INFO: LimitRange "e2e-limitrange-fc9vd" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-fc9vd" @ 04/29/23 13:04:36.65
  Apr 29 13:04:36.653: INFO: Found 1 limitRange
  Apr 29 13:04:36.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-7208" for this suite. @ 04/29/23 13:04:36.656
  STEP: Destroying namespace "e2e-limitrange-fc9vd-909" for this suite. @ 04/29/23 13:04:36.662
• [0.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 04/29/23 13:04:36.671
  Apr 29 13:04:36.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:04:36.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:04:36.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:04:36.691
  STEP: creating service in namespace services-7097 @ 04/29/23 13:04:36.694
  STEP: creating service affinity-clusterip-transition in namespace services-7097 @ 04/29/23 13:04:36.694
  STEP: creating replication controller affinity-clusterip-transition in namespace services-7097 @ 04/29/23 13:04:36.705
  I0429 13:04:36.712987      18 runners.go:194] Created replication controller with name: affinity-clusterip-transition, namespace: services-7097, replica count: 3
  I0429 13:04:39.764569      18 runners.go:194] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 13:04:39.772: INFO: Creating new exec pod
  Apr 29 13:04:42.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-7097 exec execpod-affinityb45zg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Apr 29 13:04:42.921: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Apr 29 13:04:42.921: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:04:42.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-7097 exec execpod-affinityb45zg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.86 80'
  Apr 29 13:04:43.040: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.86 80\nConnection to 10.152.183.86 80 port [tcp/http] succeeded!\n"
  Apr 29 13:04:43.040: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:04:43.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-7097 exec execpod-affinityb45zg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.86:80/ ; done'
  Apr 29 13:04:43.243: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n"
  Apr 29 13:04:43.244: INFO: stdout: "\naffinity-clusterip-transition-xj245\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-xj245\naffinity-clusterip-transition-flbqt\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-flbqt\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-xj245\naffinity-clusterip-transition-flbqt\naffinity-clusterip-transition-xj245\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-xj245\naffinity-clusterip-transition-xj245"
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-xj245
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-xj245
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-flbqt
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-flbqt
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-xj245
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-flbqt
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-xj245
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-xj245
  Apr 29 13:04:43.244: INFO: Received response from host: affinity-clusterip-transition-xj245
  Apr 29 13:04:43.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-7097 exec execpod-affinityb45zg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.86:80/ ; done'
  Apr 29 13:04:43.468: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.86:80/\n"
  Apr 29 13:04:43.468: INFO: stdout: "\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn\naffinity-clusterip-transition-mqhkn"
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.468: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.469: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.469: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.469: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.469: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.469: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.469: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.469: INFO: Received response from host: affinity-clusterip-transition-mqhkn
  Apr 29 13:04:43.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 13:04:43.472: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-7097, will wait for the garbage collector to delete the pods @ 04/29/23 13:04:43.483
  Apr 29 13:04:43.545: INFO: Deleting ReplicationController affinity-clusterip-transition took: 7.558551ms
  Apr 29 13:04:43.645: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.712422ms
  STEP: Destroying namespace "services-7097" for this suite. @ 04/29/23 13:04:45.961
• [9.297 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 04/29/23 13:04:45.969
  Apr 29 13:04:45.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 13:04:45.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:04:45.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:04:45.99
  STEP: Creating pod liveness-0a006327-4310-4dfc-96d5-fe2072e6b70d in namespace container-probe-5571 @ 04/29/23 13:04:45.993
  Apr 29 13:04:48.012: INFO: Started pod liveness-0a006327-4310-4dfc-96d5-fe2072e6b70d in namespace container-probe-5571
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/29/23 13:04:48.012
  Apr 29 13:04:48.015: INFO: Initial restart count of pod liveness-0a006327-4310-4dfc-96d5-fe2072e6b70d is 0
  Apr 29 13:05:08.063: INFO: Restart count of pod container-probe-5571/liveness-0a006327-4310-4dfc-96d5-fe2072e6b70d is now 1 (20.04747327s elapsed)
  Apr 29 13:05:28.108: INFO: Restart count of pod container-probe-5571/liveness-0a006327-4310-4dfc-96d5-fe2072e6b70d is now 2 (40.092719459s elapsed)
  Apr 29 13:05:48.149: INFO: Restart count of pod container-probe-5571/liveness-0a006327-4310-4dfc-96d5-fe2072e6b70d is now 3 (1m0.134177305s elapsed)
  Apr 29 13:06:08.191: INFO: Restart count of pod container-probe-5571/liveness-0a006327-4310-4dfc-96d5-fe2072e6b70d is now 4 (1m20.176087773s elapsed)
  Apr 29 13:07:10.322: INFO: Restart count of pod container-probe-5571/liveness-0a006327-4310-4dfc-96d5-fe2072e6b70d is now 5 (2m22.306500727s elapsed)
  Apr 29 13:07:10.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:07:10.325
  STEP: Destroying namespace "container-probe-5571" for this suite. @ 04/29/23 13:07:10.337
• [144.375 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 04/29/23 13:07:10.346
  Apr 29 13:07:10.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/29/23 13:07:10.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:07:10.363
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:07:10.366
  Apr 29 13:07:10.369: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:07:11.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-8565" for this suite. @ 04/29/23 13:07:11.4
• [1.060 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 04/29/23 13:07:11.407
  Apr 29 13:07:11.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-pred @ 04/29/23 13:07:11.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:07:11.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:07:11.426
  Apr 29 13:07:11.429: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 29 13:07:11.437: INFO: Waiting for terminating namespaces to be deleted...
  Apr 29 13:07:11.440: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-25-13 before test
  Apr 29 13:07:11.445: INFO: nginx-ingress-controller-kubernetes-worker-nktfk from ingress-nginx-kubernetes-worker started at 2023-04-29 11:51:02 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.445: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: coredns-5c7f76ccb8-2lgzt from kube-system started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.445: INFO: 	Container coredns ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: kube-state-metrics-5b95b4459c-9469j from kube-system started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.445: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: metrics-server-v0.5.2-6cf8c8b69c-tsmc5 from kube-system started at 2023-04-29 11:50:57 +0000 UTC (2 container statuses recorded)
  Apr 29 13:07:11.445: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: dashboard-metrics-scraper-6b8586b5c9-k9jlf from kubernetes-dashboard started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.445: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: kubernetes-dashboard-6869f4cd5f-w7m8c from kubernetes-dashboard started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.445: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-rvknb from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 13:07:11.445: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 29 13:07:11.445: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-41-80 before test
  Apr 29 13:07:11.449: INFO: nginx-ingress-controller-kubernetes-worker-bt9hj from ingress-nginx-kubernetes-worker started at 2023-04-29 12:17:54 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.449: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 13:07:11.449: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-6rcvs from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 13:07:11.449: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 13:07:11.449: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 29 13:07:11.449: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-82-46 before test
  Apr 29 13:07:11.453: INFO: default-http-backend-kubernetes-worker-65fc475d49-mlbzp from ingress-nginx-kubernetes-worker started at 2023-04-29 12:11:40 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.453: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Apr 29 13:07:11.453: INFO: nginx-ingress-controller-kubernetes-worker-m8hc4 from ingress-nginx-kubernetes-worker started at 2023-04-29 11:54:52 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.454: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 13:07:11.454: INFO: calico-kube-controllers-577d5b7f57-d6csn from kube-system started at 2023-04-29 12:11:40 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.454: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  Apr 29 13:07:11.454: INFO: sonobuoy from sonobuoy started at 2023-04-29 12:00:46 +0000 UTC (1 container statuses recorded)
  Apr 29 13:07:11.454: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 29 13:07:11.454: INFO: sonobuoy-e2e-job-819b1466a92240b6 from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 13:07:11.454: INFO: 	Container e2e ready: true, restart count 0
  Apr 29 13:07:11.454: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 13:07:11.454: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-hpjk5 from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 13:07:11.454: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 13:07:11.454: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/29/23 13:07:11.454
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/29/23 13:07:13.474
  STEP: Trying to apply a random label on the found node. @ 04/29/23 13:07:13.49
  STEP: verifying the node has the label kubernetes.io/e2e-df3b20ba-c07f-4e7a-b32d-f1bad1f641fb 95 @ 04/29/23 13:07:13.497
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 04/29/23 13:07:13.5
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.41.80 on the node which pod4 resides and expect not scheduled @ 04/29/23 13:07:15.518
  STEP: removing the label kubernetes.io/e2e-df3b20ba-c07f-4e7a-b32d-f1bad1f641fb off the node ip-172-31-41-80 @ 04/29/23 13:12:15.524
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-df3b20ba-c07f-4e7a-b32d-f1bad1f641fb @ 04/29/23 13:12:15.536
  Apr 29 13:12:15.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2226" for this suite. @ 04/29/23 13:12:15.542
• [304.141 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 04/29/23 13:12:15.548
  Apr 29 13:12:15.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replicaset @ 04/29/23 13:12:15.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:12:15.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:12:15.57
  STEP: Create a Replicaset @ 04/29/23 13:12:15.576
  STEP: Verify that the required pods have come up. @ 04/29/23 13:12:15.583
  Apr 29 13:12:15.585: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 29 13:12:20.591: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/29/23 13:12:20.591
  STEP: Getting /status @ 04/29/23 13:12:20.591
  Apr 29 13:12:20.594: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 04/29/23 13:12:20.594
  Apr 29 13:12:20.604: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 04/29/23 13:12:20.604
  Apr 29 13:12:20.606: INFO: Observed &ReplicaSet event: ADDED
  Apr 29 13:12:20.606: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 29 13:12:20.606: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 29 13:12:20.606: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 29 13:12:20.606: INFO: Found replicaset test-rs in namespace replicaset-5971 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 29 13:12:20.606: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 04/29/23 13:12:20.606
  Apr 29 13:12:20.606: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 29 13:12:20.612: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 04/29/23 13:12:20.612
  Apr 29 13:12:20.613: INFO: Observed &ReplicaSet event: ADDED
  Apr 29 13:12:20.613: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 29 13:12:20.613: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 29 13:12:20.614: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 29 13:12:20.614: INFO: Observed replicaset test-rs in namespace replicaset-5971 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 29 13:12:20.614: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 29 13:12:20.614: INFO: Found replicaset test-rs in namespace replicaset-5971 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Apr 29 13:12:20.614: INFO: Replicaset test-rs has a patched status
  Apr 29 13:12:20.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5971" for this suite. @ 04/29/23 13:12:20.618
• [5.077 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 04/29/23 13:12:20.625
  Apr 29 13:12:20.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename controllerrevisions @ 04/29/23 13:12:20.626
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:12:20.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:12:20.646
  STEP: Creating DaemonSet "e2e-6bwpk-daemon-set" @ 04/29/23 13:12:20.666
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/29/23 13:12:20.672
  Apr 29 13:12:20.676: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:12:20.676: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:12:20.679: INFO: Number of nodes with available pods controlled by daemonset e2e-6bwpk-daemon-set: 0
  Apr 29 13:12:20.679: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 13:12:21.683: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:12:21.683: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:12:21.686: INFO: Number of nodes with available pods controlled by daemonset e2e-6bwpk-daemon-set: 1
  Apr 29 13:12:21.686: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 13:12:22.683: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:12:22.683: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:12:22.687: INFO: Number of nodes with available pods controlled by daemonset e2e-6bwpk-daemon-set: 3
  Apr 29 13:12:22.687: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-6bwpk-daemon-set
  STEP: Confirm DaemonSet "e2e-6bwpk-daemon-set" successfully created with "daemonset-name=e2e-6bwpk-daemon-set" label @ 04/29/23 13:12:22.69
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-6bwpk-daemon-set" @ 04/29/23 13:12:22.696
  Apr 29 13:12:22.699: INFO: Located ControllerRevision: "e2e-6bwpk-daemon-set-57b9965dc7"
  STEP: Patching ControllerRevision "e2e-6bwpk-daemon-set-57b9965dc7" @ 04/29/23 13:12:22.701
  Apr 29 13:12:22.708: INFO: e2e-6bwpk-daemon-set-57b9965dc7 has been patched
  STEP: Create a new ControllerRevision @ 04/29/23 13:12:22.708
  Apr 29 13:12:22.713: INFO: Created ControllerRevision: e2e-6bwpk-daemon-set-65695d9469
  STEP: Confirm that there are two ControllerRevisions @ 04/29/23 13:12:22.713
  Apr 29 13:12:22.713: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 29 13:12:22.716: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-6bwpk-daemon-set-57b9965dc7" @ 04/29/23 13:12:22.716
  STEP: Confirm that there is only one ControllerRevision @ 04/29/23 13:12:22.723
  Apr 29 13:12:22.723: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 29 13:12:22.726: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-6bwpk-daemon-set-65695d9469" @ 04/29/23 13:12:22.729
  Apr 29 13:12:22.737: INFO: e2e-6bwpk-daemon-set-65695d9469 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 04/29/23 13:12:22.737
  W0429 13:12:22.745679      18 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 04/29/23 13:12:22.745
  Apr 29 13:12:22.745: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 29 13:12:23.751: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 29 13:12:23.754: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-6bwpk-daemon-set-65695d9469=updated" @ 04/29/23 13:12:23.755
  STEP: Confirm that there is only one ControllerRevision @ 04/29/23 13:12:23.762
  Apr 29 13:12:23.762: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 29 13:12:23.765: INFO: Found 1 ControllerRevisions
  Apr 29 13:12:23.768: INFO: ControllerRevision "e2e-6bwpk-daemon-set-78fb5fd588" has revision 3
  STEP: Deleting DaemonSet "e2e-6bwpk-daemon-set" @ 04/29/23 13:12:23.772
  STEP: deleting DaemonSet.extensions e2e-6bwpk-daemon-set in namespace controllerrevisions-8025, will wait for the garbage collector to delete the pods @ 04/29/23 13:12:23.772
  Apr 29 13:12:23.832: INFO: Deleting DaemonSet.extensions e2e-6bwpk-daemon-set took: 6.628358ms
  Apr 29 13:12:23.932: INFO: Terminating DaemonSet.extensions e2e-6bwpk-daemon-set pods took: 100.130099ms
  Apr 29 13:12:25.736: INFO: Number of nodes with available pods controlled by daemonset e2e-6bwpk-daemon-set: 0
  Apr 29 13:12:25.736: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-6bwpk-daemon-set
  Apr 29 13:12:25.739: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31739"},"items":null}

  Apr 29 13:12:25.743: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31739"},"items":null}

  Apr 29 13:12:25.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-8025" for this suite. @ 04/29/23 13:12:25.763
• [5.146 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 04/29/23 13:12:25.772
  Apr 29 13:12:25.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename var-expansion @ 04/29/23 13:12:25.773
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:12:25.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:12:25.796
  Apr 29 13:12:27.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 13:12:27.822: INFO: Deleting pod "var-expansion-360a8b8f-0276-4fd5-9614-476ed4b1f2f7" in namespace "var-expansion-4829"
  Apr 29 13:12:27.832: INFO: Wait up to 5m0s for pod "var-expansion-360a8b8f-0276-4fd5-9614-476ed4b1f2f7" to be fully deleted
  STEP: Destroying namespace "var-expansion-4829" for this suite. @ 04/29/23 13:12:29.84
• [4.074 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 04/29/23 13:12:29.846
  Apr 29 13:12:29.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 13:12:29.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:12:29.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:12:29.867
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/29/23 13:12:29.87
  STEP: Saw pod success @ 04/29/23 13:12:33.892
  Apr 29 13:12:33.896: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-52424405-bbd9-41cd-a85f-2c8c1c8cb234 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 13:12:33.917
  Apr 29 13:12:33.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1615" for this suite. @ 04/29/23 13:12:33.938
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 04/29/23 13:12:33.945
  Apr 29 13:12:33.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename disruption @ 04/29/23 13:12:33.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:12:33.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:12:33.964
  STEP: creating the pdb @ 04/29/23 13:12:33.967
  STEP: Waiting for the pdb to be processed @ 04/29/23 13:12:33.975
  STEP: updating the pdb @ 04/29/23 13:12:35.983
  STEP: Waiting for the pdb to be processed @ 04/29/23 13:12:35.992
  STEP: patching the pdb @ 04/29/23 13:12:37.999
  STEP: Waiting for the pdb to be processed @ 04/29/23 13:12:38.009
  STEP: Waiting for the pdb to be deleted @ 04/29/23 13:12:40.023
  Apr 29 13:12:40.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6656" for this suite. @ 04/29/23 13:12:40.032
• [6.094 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 04/29/23 13:12:40.04
  Apr 29 13:12:40.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 13:12:40.041
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:12:40.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:12:40.06
  STEP: Creating secret with name s-test-opt-del-5fa92c3d-7b5b-43fb-b255-f727dde82750 @ 04/29/23 13:12:40.067
  STEP: Creating secret with name s-test-opt-upd-c261363c-2bd6-4fbd-b7d1-e55cf8a78440 @ 04/29/23 13:12:40.072
  STEP: Creating the pod @ 04/29/23 13:12:40.076
  STEP: Deleting secret s-test-opt-del-5fa92c3d-7b5b-43fb-b255-f727dde82750 @ 04/29/23 13:12:42.12
  STEP: Updating secret s-test-opt-upd-c261363c-2bd6-4fbd-b7d1-e55cf8a78440 @ 04/29/23 13:12:42.126
  STEP: Creating secret with name s-test-opt-create-b5d59f69-d814-4131-93f4-4725dc14399d @ 04/29/23 13:12:42.133
  STEP: waiting to observe update in volume @ 04/29/23 13:12:42.138
  Apr 29 13:14:12.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9736" for this suite. @ 04/29/23 13:14:12.541
• [92.507 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 04/29/23 13:14:12.548
  Apr 29 13:14:12.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubelet-test @ 04/29/23 13:14:12.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:12.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:12.568
  STEP: Waiting for pod completion @ 04/29/23 13:14:12.578
  Apr 29 13:14:16.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6190" for this suite. @ 04/29/23 13:14:16.6
• [4.058 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 04/29/23 13:14:16.606
  Apr 29 13:14:16.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename conformance-tests @ 04/29/23 13:14:16.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:16.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:16.627
  STEP: Getting node addresses @ 04/29/23 13:14:16.629
  Apr 29 13:14:16.629: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Apr 29 13:14:16.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-4499" for this suite. @ 04/29/23 13:14:16.638
• [0.037 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 04/29/23 13:14:16.643
  Apr 29 13:14:16.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:14:16.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:16.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:16.665
  STEP: Creating configMap with name projected-configmap-test-volume-map-d4da1103-df58-4a22-be9b-b7c3ade1e8f2 @ 04/29/23 13:14:16.668
  STEP: Creating a pod to test consume configMaps @ 04/29/23 13:14:16.672
  STEP: Saw pod success @ 04/29/23 13:14:20.69
  Apr 29 13:14:20.693: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-configmaps-7a7c6ac9-cb37-4908-a385-f5f9e210f241 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 13:14:20.702
  Apr 29 13:14:20.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6201" for this suite. @ 04/29/23 13:14:20.721
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 04/29/23 13:14:20.728
  Apr 29 13:14:20.728: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:14:20.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:20.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:20.747
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 13:14:20.75
  STEP: Saw pod success @ 04/29/23 13:14:24.771
  Apr 29 13:14:24.774: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-b61435ae-0897-4d5d-a9be-dc570ecc2bcb container client-container: <nil>
  STEP: delete the pod @ 04/29/23 13:14:24.78
  Apr 29 13:14:24.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-122" for this suite. @ 04/29/23 13:14:24.807
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3138
  STEP: Creating a kubernetes client @ 04/29/23 13:14:24.821
  Apr 29 13:14:24.822: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:14:24.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:24.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:24.851
  STEP: creating an Endpoint @ 04/29/23 13:14:24.859
  STEP: waiting for available Endpoint @ 04/29/23 13:14:24.865
  STEP: listing all Endpoints @ 04/29/23 13:14:24.871
  STEP: updating the Endpoint @ 04/29/23 13:14:24.881
  STEP: fetching the Endpoint @ 04/29/23 13:14:24.888
  STEP: patching the Endpoint @ 04/29/23 13:14:24.892
  STEP: fetching the Endpoint @ 04/29/23 13:14:24.905
  STEP: deleting the Endpoint by Collection @ 04/29/23 13:14:24.908
  STEP: waiting for Endpoint deletion @ 04/29/23 13:14:24.915
  STEP: fetching the Endpoint @ 04/29/23 13:14:24.917
  Apr 29 13:14:24.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4002" for this suite. @ 04/29/23 13:14:24.923
• [0.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3322
  STEP: Creating a kubernetes client @ 04/29/23 13:14:24.93
  Apr 29 13:14:24.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:14:24.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:24.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:24.95
  STEP: creating a Service @ 04/29/23 13:14:24.955
  STEP: watching for the Service to be added @ 04/29/23 13:14:24.965
  Apr 29 13:14:24.967: INFO: Found Service test-service-6zx98 in namespace services-4349 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Apr 29 13:14:24.967: INFO: Service test-service-6zx98 created
  STEP: Getting /status @ 04/29/23 13:14:24.967
  Apr 29 13:14:24.972: INFO: Service test-service-6zx98 has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 04/29/23 13:14:24.972
  STEP: watching for the Service to be patched @ 04/29/23 13:14:24.977
  Apr 29 13:14:24.979: INFO: observed Service test-service-6zx98 in namespace services-4349 with annotations: map[] & LoadBalancer: {[]}
  Apr 29 13:14:24.979: INFO: Found Service test-service-6zx98 in namespace services-4349 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Apr 29 13:14:24.979: INFO: Service test-service-6zx98 has service status patched
  STEP: updating the ServiceStatus @ 04/29/23 13:14:24.979
  Apr 29 13:14:24.988: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 04/29/23 13:14:24.988
  Apr 29 13:14:24.990: INFO: Observed Service test-service-6zx98 in namespace services-4349 with annotations: map[] & Conditions: {[]}
  Apr 29 13:14:24.990: INFO: Observed event: &Service{ObjectMeta:{test-service-6zx98  services-4349  1fbe18ca-b5ba-41ba-a125-83fa1f6eb40c 32278 0 2023-04-29 13:14:24 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-29 13:14:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-29 13:14:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.250,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.250],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Apr 29 13:14:24.990: INFO: Found Service test-service-6zx98 in namespace services-4349 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 29 13:14:24.991: INFO: Service test-service-6zx98 has service status updated
  STEP: patching the service @ 04/29/23 13:14:24.991
  STEP: watching for the Service to be patched @ 04/29/23 13:14:25.005
  Apr 29 13:14:25.006: INFO: observed Service test-service-6zx98 in namespace services-4349 with labels: map[test-service-static:true]
  Apr 29 13:14:25.006: INFO: observed Service test-service-6zx98 in namespace services-4349 with labels: map[test-service-static:true]
  Apr 29 13:14:25.006: INFO: observed Service test-service-6zx98 in namespace services-4349 with labels: map[test-service-static:true]
  Apr 29 13:14:25.006: INFO: Found Service test-service-6zx98 in namespace services-4349 with labels: map[test-service:patched test-service-static:true]
  Apr 29 13:14:25.006: INFO: Service test-service-6zx98 patched
  STEP: deleting the service @ 04/29/23 13:14:25.006
  STEP: watching for the Service to be deleted @ 04/29/23 13:14:25.019
  Apr 29 13:14:25.021: INFO: Observed event: ADDED
  Apr 29 13:14:25.021: INFO: Observed event: MODIFIED
  Apr 29 13:14:25.021: INFO: Observed event: MODIFIED
  Apr 29 13:14:25.021: INFO: Observed event: MODIFIED
  Apr 29 13:14:25.021: INFO: Found Service test-service-6zx98 in namespace services-4349 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Apr 29 13:14:25.021: INFO: Service test-service-6zx98 deleted
  Apr 29 13:14:25.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4349" for this suite. @ 04/29/23 13:14:25.024
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 04/29/23 13:14:25.03
  Apr 29 13:14:25.030: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename var-expansion @ 04/29/23 13:14:25.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:25.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:25.05
  STEP: Creating a pod to test substitution in container's command @ 04/29/23 13:14:25.052
  STEP: Saw pod success @ 04/29/23 13:14:29.074
  Apr 29 13:14:29.077: INFO: Trying to get logs from node ip-172-31-41-80 pod var-expansion-ee818921-3256-415d-9018-2f93590e4857 container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 13:14:29.083
  Apr 29 13:14:29.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8802" for this suite. @ 04/29/23 13:14:29.101
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 04/29/23 13:14:29.111
  Apr 29 13:14:29.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/29/23 13:14:29.111
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:29.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:29.131
  Apr 29 13:14:31.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 04/29/23 13:14:31.163
  STEP: Cleaning up the configmap @ 04/29/23 13:14:31.168
  STEP: Cleaning up the pod @ 04/29/23 13:14:31.177
  STEP: Destroying namespace "emptydir-wrapper-8706" for this suite. @ 04/29/23 13:14:31.188
• [2.085 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 04/29/23 13:14:31.196
  Apr 29 13:14:31.196: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/29/23 13:14:31.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:31.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:31.213
  Apr 29 13:14:31.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:14:34.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7520" for this suite. @ 04/29/23 13:14:34.429
• [3.239 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 04/29/23 13:14:34.437
  Apr 29 13:14:34.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:14:34.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:34.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:34.455
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 13:14:34.458
  STEP: Saw pod success @ 04/29/23 13:14:38.474
  Apr 29 13:14:38.478: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-babe1f6b-d5d9-4c74-a82e-8a4ec57ba460 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 13:14:38.484
  Apr 29 13:14:38.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4008" for this suite. @ 04/29/23 13:14:38.504
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 04/29/23 13:14:38.511
  Apr 29 13:14:38.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 13:14:38.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:38.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:38.531
  STEP: Creating projection with secret that has name secret-emptykey-test-739e8918-351d-4dab-b8db-fb02c2942fc8 @ 04/29/23 13:14:38.533
  Apr 29 13:14:38.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1472" for this suite. @ 04/29/23 13:14:38.54
• [0.034 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 04/29/23 13:14:38.545
  Apr 29 13:14:38.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 13:14:38.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:38.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:38.569
  Apr 29 13:14:38.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/29/23 13:14:39.994
  Apr 29 13:14:39.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-384 --namespace=crd-publish-openapi-384 create -f -'
  Apr 29 13:14:40.621: INFO: stderr: ""
  Apr 29 13:14:40.621: INFO: stdout: "e2e-test-crd-publish-openapi-217-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 29 13:14:40.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-384 --namespace=crd-publish-openapi-384 delete e2e-test-crd-publish-openapi-217-crds test-cr'
  Apr 29 13:14:40.706: INFO: stderr: ""
  Apr 29 13:14:40.706: INFO: stdout: "e2e-test-crd-publish-openapi-217-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Apr 29 13:14:40.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-384 --namespace=crd-publish-openapi-384 apply -f -'
  Apr 29 13:14:40.949: INFO: stderr: ""
  Apr 29 13:14:40.950: INFO: stdout: "e2e-test-crd-publish-openapi-217-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 29 13:14:40.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-384 --namespace=crd-publish-openapi-384 delete e2e-test-crd-publish-openapi-217-crds test-cr'
  Apr 29 13:14:41.016: INFO: stderr: ""
  Apr 29 13:14:41.016: INFO: stdout: "e2e-test-crd-publish-openapi-217-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/29/23 13:14:41.016
  Apr 29 13:14:41.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-384 explain e2e-test-crd-publish-openapi-217-crds'
  Apr 29 13:14:41.480: INFO: stderr: ""
  Apr 29 13:14:41.480: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-217-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Apr 29 13:14:42.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-384" for this suite. @ 04/29/23 13:14:42.873
• [4.334 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 04/29/23 13:14:42.88
  Apr 29 13:14:42.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 13:14:42.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:42.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:42.899
  STEP: Counting existing ResourceQuota @ 04/29/23 13:14:42.902
  STEP: Creating a ResourceQuota @ 04/29/23 13:14:47.906
  STEP: Ensuring resource quota status is calculated @ 04/29/23 13:14:47.911
  STEP: Creating a ReplicaSet @ 04/29/23 13:14:49.916
  STEP: Ensuring resource quota status captures replicaset creation @ 04/29/23 13:14:49.928
  STEP: Deleting a ReplicaSet @ 04/29/23 13:14:51.933
  STEP: Ensuring resource quota status released usage @ 04/29/23 13:14:51.939
  Apr 29 13:14:53.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3880" for this suite. @ 04/29/23 13:14:53.949
• [11.075 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 04/29/23 13:14:53.955
  Apr 29 13:14:53.955: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 13:14:53.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:53.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:53.975
  STEP: Creating configMap with name configmap-test-volume-map-bc7d755d-bdfe-48bb-8dc7-02a3eee00960 @ 04/29/23 13:14:53.978
  STEP: Creating a pod to test consume configMaps @ 04/29/23 13:14:53.983
  STEP: Saw pod success @ 04/29/23 13:14:58.006
  Apr 29 13:14:58.010: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-2d2c837b-f0c5-4724-9c94-c70ece36f9e7 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 13:14:58.023
  Apr 29 13:14:58.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9192" for this suite. @ 04/29/23 13:14:58.043
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 04/29/23 13:14:58.051
  Apr 29 13:14:58.051: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:14:58.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:14:58.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:14:58.071
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-303 @ 04/29/23 13:14:58.074
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/29/23 13:14:58.087
  STEP: creating service externalsvc in namespace services-303 @ 04/29/23 13:14:58.087
  STEP: creating replication controller externalsvc in namespace services-303 @ 04/29/23 13:14:58.107
  I0429 13:14:58.115307      18 runners.go:194] Created replication controller with name: externalsvc, namespace: services-303, replica count: 2
  I0429 13:15:01.166132      18 runners.go:194] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 04/29/23 13:15:01.171
  Apr 29 13:15:01.191: INFO: Creating new exec pod
  Apr 29 13:15:03.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-303 exec execpodzsmcb -- /bin/sh -x -c nslookup nodeport-service.services-303.svc.cluster.local'
  Apr 29 13:15:03.374: INFO: stderr: "+ nslookup nodeport-service.services-303.svc.cluster.local\n"
  Apr 29 13:15:03.374: INFO: stdout: "Server:\t\t10.152.183.88\nAddress:\t10.152.183.88#53\n\nnodeport-service.services-303.svc.cluster.local\tcanonical name = externalsvc.services-303.svc.cluster.local.\nName:\texternalsvc.services-303.svc.cluster.local\nAddress: 10.152.183.74\n\n"
  Apr 29 13:15:03.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-303, will wait for the garbage collector to delete the pods @ 04/29/23 13:15:03.379
  Apr 29 13:15:03.439: INFO: Deleting ReplicationController externalsvc took: 6.34928ms
  Apr 29 13:15:03.540: INFO: Terminating ReplicationController externalsvc pods took: 100.965906ms
  Apr 29 13:15:05.359: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-303" for this suite. @ 04/29/23 13:15:05.373
• [7.329 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 04/29/23 13:15:05.381
  Apr 29 13:15:05.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 13:15:05.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:05.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:05.405
  STEP: creating a Pod with a static label @ 04/29/23 13:15:05.413
  STEP: watching for Pod to be ready @ 04/29/23 13:15:05.421
  Apr 29 13:15:05.423: INFO: observed Pod pod-test in namespace pods-7493 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Apr 29 13:15:05.428: INFO: observed Pod pod-test in namespace pods-7493 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:05 +0000 UTC  }]
  Apr 29 13:15:05.442: INFO: observed Pod pod-test in namespace pods-7493 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:05 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:05 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:05 +0000 UTC  }]
  Apr 29 13:15:07.254: INFO: Found Pod pod-test in namespace pods-7493 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-29 13:15:05 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 04/29/23 13:15:07.258
  STEP: getting the Pod and ensuring that it's patched @ 04/29/23 13:15:07.269
  STEP: replacing the Pod's status Ready condition to False @ 04/29/23 13:15:07.274
  STEP: check the Pod again to ensure its Ready conditions are False @ 04/29/23 13:15:07.285
  STEP: deleting the Pod via a Collection with a LabelSelector @ 04/29/23 13:15:07.285
  STEP: watching for the Pod to be deleted @ 04/29/23 13:15:07.295
  Apr 29 13:15:07.297: INFO: observed event type MODIFIED
  Apr 29 13:15:08.612: INFO: observed event type MODIFIED
  Apr 29 13:15:09.635: INFO: observed event type MODIFIED
  Apr 29 13:15:10.260: INFO: observed event type MODIFIED
  Apr 29 13:15:10.275: INFO: observed event type MODIFIED
  Apr 29 13:15:10.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7493" for this suite. @ 04/29/23 13:15:10.287
• [4.913 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 04/29/23 13:15:10.295
  Apr 29 13:15:10.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 13:15:10.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:10.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:10.315
  Apr 29 13:15:10.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: creating the pod @ 04/29/23 13:15:10.319
  STEP: submitting the pod to kubernetes @ 04/29/23 13:15:10.319
  Apr 29 13:15:12.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2536" for this suite. @ 04/29/23 13:15:12.358
• [2.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 04/29/23 13:15:12.366
  Apr 29 13:15:12.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:15:12.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:12.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:12.383
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-4008 @ 04/29/23 13:15:12.386
  STEP: changing the ExternalName service to type=NodePort @ 04/29/23 13:15:12.391
  STEP: creating replication controller externalname-service in namespace services-4008 @ 04/29/23 13:15:12.413
  I0429 13:15:12.419398      18 runners.go:194] Created replication controller with name: externalname-service, namespace: services-4008, replica count: 2
  I0429 13:15:15.470606      18 runners.go:194] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 13:15:15.470: INFO: Creating new exec pod
  Apr 29 13:15:18.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-4008 exec execpodrh9m5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 29 13:15:18.621: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 29 13:15:18.621: INFO: stdout: "externalname-service-4wscc"
  Apr 29 13:15:18.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-4008 exec execpodrh9m5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.29 80'
  Apr 29 13:15:18.747: INFO: stderr: "+ nc -v -t -w 2 10.152.183.29 80\n+ echo hostName\nConnection to 10.152.183.29 80 port [tcp/http] succeeded!\n"
  Apr 29 13:15:18.747: INFO: stdout: ""
  Apr 29 13:15:19.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-4008 exec execpodrh9m5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.29 80'
  Apr 29 13:15:19.874: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.29 80\nConnection to 10.152.183.29 80 port [tcp/http] succeeded!\n"
  Apr 29 13:15:19.874: INFO: stdout: ""
  Apr 29 13:15:20.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-4008 exec execpodrh9m5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.29 80'
  Apr 29 13:15:20.880: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.29 80\nConnection to 10.152.183.29 80 port [tcp/http] succeeded!\n"
  Apr 29 13:15:20.881: INFO: stdout: "externalname-service-4wscc"
  Apr 29 13:15:20.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-4008 exec execpodrh9m5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.13 31700'
  Apr 29 13:15:21.007: INFO: stderr: "+ nc -v -t -w 2 172.31.25.13 31700\n+ echo hostName\nConnection to 172.31.25.13 31700 port [tcp/*] succeeded!\n"
  Apr 29 13:15:21.007: INFO: stdout: "externalname-service-4wscc"
  Apr 29 13:15:21.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-4008 exec execpodrh9m5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.82.46 31700'
  Apr 29 13:15:21.140: INFO: stderr: "+ nc -v -t -w 2 172.31.82.46 31700\n+ echo hostName\nConnection to 172.31.82.46 31700 port [tcp/*] succeeded!\n"
  Apr 29 13:15:21.140: INFO: stdout: "externalname-service-s48sf"
  Apr 29 13:15:21.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 13:15:21.144: INFO: Cleaning up the ExternalName to NodePort test service
  STEP: Destroying namespace "services-4008" for this suite. @ 04/29/23 13:15:21.173
• [8.814 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 04/29/23 13:15:21.181
  Apr 29 13:15:21.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 13:15:21.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:21.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:21.202
  Apr 29 13:15:21.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/29/23 13:15:22.559
  Apr 29 13:15:22.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-5241 --namespace=crd-publish-openapi-5241 create -f -'
  Apr 29 13:15:23.111: INFO: stderr: ""
  Apr 29 13:15:23.111: INFO: stdout: "e2e-test-crd-publish-openapi-4534-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 29 13:15:23.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-5241 --namespace=crd-publish-openapi-5241 delete e2e-test-crd-publish-openapi-4534-crds test-cr'
  Apr 29 13:15:23.192: INFO: stderr: ""
  Apr 29 13:15:23.192: INFO: stdout: "e2e-test-crd-publish-openapi-4534-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Apr 29 13:15:23.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-5241 --namespace=crd-publish-openapi-5241 apply -f -'
  Apr 29 13:15:23.665: INFO: stderr: ""
  Apr 29 13:15:23.665: INFO: stdout: "e2e-test-crd-publish-openapi-4534-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 29 13:15:23.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-5241 --namespace=crd-publish-openapi-5241 delete e2e-test-crd-publish-openapi-4534-crds test-cr'
  Apr 29 13:15:23.733: INFO: stderr: ""
  Apr 29 13:15:23.733: INFO: stdout: "e2e-test-crd-publish-openapi-4534-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 04/29/23 13:15:23.733
  Apr 29 13:15:23.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-5241 explain e2e-test-crd-publish-openapi-4534-crds'
  Apr 29 13:15:23.915: INFO: stderr: ""
  Apr 29 13:15:23.915: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-4534-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  Apr 29 13:15:25.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5241" for this suite. @ 04/29/23 13:15:25.299
• [4.125 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 04/29/23 13:15:25.306
  Apr 29 13:15:25.306: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:15:25.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:25.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:25.326
  STEP: creating service in namespace services-1286 @ 04/29/23 13:15:25.329
  STEP: creating service affinity-clusterip in namespace services-1286 @ 04/29/23 13:15:25.329
  STEP: creating replication controller affinity-clusterip in namespace services-1286 @ 04/29/23 13:15:25.337
  I0429 13:15:25.343211      18 runners.go:194] Created replication controller with name: affinity-clusterip, namespace: services-1286, replica count: 3
  I0429 13:15:28.394000      18 runners.go:194] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 13:15:28.400: INFO: Creating new exec pod
  Apr 29 13:15:31.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-1286 exec execpod-affinitym7nz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Apr 29 13:15:31.537: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Apr 29 13:15:31.537: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:15:31.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-1286 exec execpod-affinitym7nz5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.186 80'
  Apr 29 13:15:31.665: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.186 80\nConnection to 10.152.183.186 80 port [tcp/http] succeeded!\n"
  Apr 29 13:15:31.665: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:15:31.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-1286 exec execpod-affinitym7nz5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.186:80/ ; done'
  Apr 29 13:15:31.858: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.186:80/\n"
  Apr 29 13:15:31.858: INFO: stdout: "\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6\naffinity-clusterip-z4qr6"
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Received response from host: affinity-clusterip-z4qr6
  Apr 29 13:15:31.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 13:15:31.863: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-1286, will wait for the garbage collector to delete the pods @ 04/29/23 13:15:31.875
  Apr 29 13:15:31.935: INFO: Deleting ReplicationController affinity-clusterip took: 6.220137ms
  Apr 29 13:15:32.035: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.134127ms
  STEP: Destroying namespace "services-1286" for this suite. @ 04/29/23 13:15:34.451
• [9.151 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 04/29/23 13:15:34.459
  Apr 29 13:15:34.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename watch @ 04/29/23 13:15:34.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:34.476
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:34.478
  STEP: creating a new configmap @ 04/29/23 13:15:34.482
  STEP: modifying the configmap once @ 04/29/23 13:15:34.485
  STEP: modifying the configmap a second time @ 04/29/23 13:15:34.494
  STEP: deleting the configmap @ 04/29/23 13:15:34.502
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 04/29/23 13:15:34.508
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 04/29/23 13:15:34.509
  Apr 29 13:15:34.509: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6541  3b0ce0df-172d-4886-a47d-f958aef923c7 33113 0 2023-04-29 13:15:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-29 13:15:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 13:15:34.509: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6541  3b0ce0df-172d-4886-a47d-f958aef923c7 33114 0 2023-04-29 13:15:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-29 13:15:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 13:15:34.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6541" for this suite. @ 04/29/23 13:15:34.513
• [0.061 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 04/29/23 13:15:34.52
  Apr 29 13:15:34.520: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename var-expansion @ 04/29/23 13:15:34.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:34.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:34.537
  STEP: Creating a pod to test substitution in volume subpath @ 04/29/23 13:15:34.54
  STEP: Saw pod success @ 04/29/23 13:15:38.562
  Apr 29 13:15:38.565: INFO: Trying to get logs from node ip-172-31-41-80 pod var-expansion-d8658687-3d20-45ff-a005-72282f3c19b3 container dapi-container: <nil>
  STEP: delete the pod @ 04/29/23 13:15:38.572
  Apr 29 13:15:38.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7615" for this suite. @ 04/29/23 13:15:38.593
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1315
  STEP: Creating a kubernetes client @ 04/29/23 13:15:38.6
  Apr 29 13:15:38.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 13:15:38.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:38.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:38.62
  STEP: validating cluster-info @ 04/29/23 13:15:38.623
  Apr 29 13:15:38.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-867 cluster-info'
  Apr 29 13:15:38.688: INFO: stderr: ""
  Apr 29 13:15:38.688: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Apr 29 13:15:38.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-867" for this suite. @ 04/29/23 13:15:38.692
• [0.097 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 04/29/23 13:15:38.698
  Apr 29 13:15:38.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 13:15:38.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:38.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:38.718
  Apr 29 13:15:38.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3948" for this suite. @ 04/29/23 13:15:38.76
• [0.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 04/29/23 13:15:38.768
  Apr 29 13:15:38.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 13:15:38.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:38.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:38.786
  STEP: validating api versions @ 04/29/23 13:15:38.79
  Apr 29 13:15:38.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-5024 api-versions'
  Apr 29 13:15:38.852: INFO: stderr: ""
  Apr 29 13:15:38.852: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nmygroup.example.com/v1\nmygroup.example.com/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Apr 29 13:15:38.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5024" for this suite. @ 04/29/23 13:15:38.857
• [0.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 04/29/23 13:15:38.864
  Apr 29 13:15:38.864: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename limitrange @ 04/29/23 13:15:38.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:38.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:38.886
  STEP: Creating a LimitRange @ 04/29/23 13:15:38.889
  STEP: Setting up watch @ 04/29/23 13:15:38.889
  STEP: Submitting a LimitRange @ 04/29/23 13:15:38.993
  STEP: Verifying LimitRange creation was observed @ 04/29/23 13:15:38.999
  STEP: Fetching the LimitRange to ensure it has proper values @ 04/29/23 13:15:38.999
  Apr 29 13:15:39.001: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 29 13:15:39.002: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 04/29/23 13:15:39.002
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 04/29/23 13:15:39.006
  Apr 29 13:15:39.010: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 29 13:15:39.010: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 04/29/23 13:15:39.01
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 04/29/23 13:15:39.015
  Apr 29 13:15:39.018: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Apr 29 13:15:39.018: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 04/29/23 13:15:39.018
  STEP: Failing to create a Pod with more than max resources @ 04/29/23 13:15:39.02
  STEP: Updating a LimitRange @ 04/29/23 13:15:39.022
  STEP: Verifying LimitRange updating is effective @ 04/29/23 13:15:39.026
  STEP: Creating a Pod with less than former min resources @ 04/29/23 13:15:41.031
  STEP: Failing to create a Pod with more than max resources @ 04/29/23 13:15:41.037
  STEP: Deleting a LimitRange @ 04/29/23 13:15:41.039
  STEP: Verifying the LimitRange was deleted @ 04/29/23 13:15:41.048
  Apr 29 13:15:46.053: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 04/29/23 13:15:46.053
  Apr 29 13:15:46.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-9495" for this suite. @ 04/29/23 13:15:46.064
• [7.207 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:314
  STEP: Creating a kubernetes client @ 04/29/23 13:15:46.072
  Apr 29 13:15:46.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 13:15:46.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:46.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:46.093
  STEP: Setting up server cert @ 04/29/23 13:15:46.12
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 13:15:46.445
  STEP: Deploying the webhook pod @ 04/29/23 13:15:46.453
  STEP: Wait for the deployment to be ready @ 04/29/23 13:15:46.466
  Apr 29 13:15:46.473: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 13:15:48.483
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:15:48.494
  Apr 29 13:15:49.495: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 29 13:15:49.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4682-crds.webhook.example.com via the AdmissionRegistration API @ 04/29/23 13:15:50.01
  STEP: Creating a custom resource while v1 is storage version @ 04/29/23 13:15:50.025
  STEP: Patching Custom Resource Definition to set v2 as storage @ 04/29/23 13:15:52.07
  STEP: Patching the custom resource while v2 is storage version @ 04/29/23 13:15:52.091
  Apr 29 13:15:52.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2527" for this suite. @ 04/29/23 13:15:52.696
  STEP: Destroying namespace "webhook-markers-5461" for this suite. @ 04/29/23 13:15:52.703
• [6.637 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 04/29/23 13:15:52.709
  Apr 29 13:15:52.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename gc @ 04/29/23 13:15:52.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:15:52.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:15:52.729
  STEP: create the rc @ 04/29/23 13:15:52.732
  W0429 13:15:52.737454      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 04/29/23 13:15:57.743
  STEP: wait for all pods to be garbage collected @ 04/29/23 13:15:57.748
  STEP: Gathering metrics @ 04/29/23 13:16:02.758
  W0429 13:16:02.761207      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 29 13:16:02.761: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 29 13:16:02.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5940" for this suite. @ 04/29/23 13:16:02.765
• [10.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 04/29/23 13:16:02.773
  Apr 29 13:16:02.773: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/29/23 13:16:02.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:16:02.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:16:02.795
  STEP: fetching the /apis discovery document @ 04/29/23 13:16:02.798
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 04/29/23 13:16:02.799
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 04/29/23 13:16:02.799
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 04/29/23 13:16:02.799
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 04/29/23 13:16:02.801
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 04/29/23 13:16:02.801
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 04/29/23 13:16:02.802
  Apr 29 13:16:02.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5871" for this suite. @ 04/29/23 13:16:02.806
• [0.039 seconds]
------------------------------
SSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 04/29/23 13:16:02.813
  Apr 29 13:16:02.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename security-context-test @ 04/29/23 13:16:02.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:16:02.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:16:02.83
  Apr 29 13:16:06.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8360" for this suite. @ 04/29/23 13:16:06.867
• [4.064 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:334
  STEP: Creating a kubernetes client @ 04/29/23 13:16:06.881
  Apr 29 13:16:06.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename init-container @ 04/29/23 13:16:06.883
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:16:06.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:16:06.902
  STEP: creating the pod @ 04/29/23 13:16:06.905
  Apr 29 13:16:06.905: INFO: PodSpec: initContainers in spec.initContainers
  Apr 29 13:16:52.504: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e60abc3f-eb11-4096-b2e0-d9d46242e984", GenerateName:"", Namespace:"init-container-2673", SelfLink:"", UID:"0e92be43-04dc-48a7-a5a0-3c6ae86cf8a1", ResourceVersion:"33670", Generation:0, CreationTimestamp:time.Date(2023, time.April, 29, 13, 16, 6, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"905539507"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 29, 13, 16, 6, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055f8030), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 29, 13, 16, 52, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0055f8060), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-76hf7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0087bb1c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-76hf7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-76hf7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-76hf7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0049d4508), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-41-80", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0001563f0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0049d4590)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0049d45c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0049d45c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0049d45cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0087bd840), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 29, 13, 16, 6, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 29, 13, 16, 6, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 29, 13, 16, 6, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 29, 13, 16, 6, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.41.80", PodIP:"192.168.226.21", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.226.21"}}, StartTime:time.Date(2023, time.April, 29, 13, 16, 6, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0001564d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000156540)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"containerd://55981605e8dae99465b74ed96a6bf1867b5e5b056bf6e436e16c682b6c8b4652", Started:(*bool)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0087bb240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0087bb220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0049d464f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:""}}
  Apr 29 13:16:52.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2673" for this suite. @ 04/29/23 13:16:52.51
• [45.637 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 04/29/23 13:16:52.517
  Apr 29 13:16:52.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename containers @ 04/29/23 13:16:52.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:16:52.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:16:52.538
  STEP: Creating a pod to test override command @ 04/29/23 13:16:52.541
  STEP: Saw pod success @ 04/29/23 13:16:56.558
  Apr 29 13:16:56.561: INFO: Trying to get logs from node ip-172-31-41-80 pod client-containers-f6b039a8-8573-45d6-8be3-c01073884409 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 13:16:56.569
  Apr 29 13:16:56.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8093" for this suite. @ 04/29/23 13:16:56.585
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 04/29/23 13:16:56.592
  Apr 29 13:16:56.592: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename var-expansion @ 04/29/23 13:16:56.593
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:16:56.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:16:56.611
  Apr 29 13:16:58.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 29 13:16:58.639: INFO: Deleting pod "var-expansion-346a853c-e5fc-46ee-89db-a02f0b212e6a" in namespace "var-expansion-5613"
  Apr 29 13:16:58.646: INFO: Wait up to 5m0s for pod "var-expansion-346a853c-e5fc-46ee-89db-a02f0b212e6a" to be fully deleted
  STEP: Destroying namespace "var-expansion-5613" for this suite. @ 04/29/23 13:17:00.652
• [4.067 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 04/29/23 13:17:00.661
  Apr 29 13:17:00.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename job @ 04/29/23 13:17:00.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:00.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:00.681
  STEP: Creating a job @ 04/29/23 13:17:00.684
  STEP: Ensuring active pods == parallelism @ 04/29/23 13:17:00.69
  STEP: Orphaning one of the Job's Pods @ 04/29/23 13:17:02.695
  Apr 29 13:17:03.210: INFO: Successfully updated pod "adopt-release-jlqzh"
  STEP: Checking that the Job readopts the Pod @ 04/29/23 13:17:03.21
  STEP: Removing the labels from the Job's Pod @ 04/29/23 13:17:05.218
  Apr 29 13:17:05.730: INFO: Successfully updated pod "adopt-release-jlqzh"
  STEP: Checking that the Job releases the Pod @ 04/29/23 13:17:05.73
  Apr 29 13:17:07.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8062" for this suite. @ 04/29/23 13:17:07.742
• [7.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 04/29/23 13:17:07.751
  Apr 29 13:17:07.751: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename prestop @ 04/29/23 13:17:07.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:07.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:07.772
  STEP: Creating server pod server in namespace prestop-7024 @ 04/29/23 13:17:07.775
  STEP: Waiting for pods to come up. @ 04/29/23 13:17:07.782
  STEP: Creating tester pod tester in namespace prestop-7024 @ 04/29/23 13:17:09.792
  STEP: Deleting pre-stop pod @ 04/29/23 13:17:11.804
  Apr 29 13:17:16.819: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Apr 29 13:17:16.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 04/29/23 13:17:16.823
  STEP: Destroying namespace "prestop-7024" for this suite. @ 04/29/23 13:17:16.834
• [9.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 04/29/23 13:17:16.843
  Apr 29 13:17:16.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replication-controller @ 04/29/23 13:17:16.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:16.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:16.865
  STEP: Creating ReplicationController "e2e-rc-frvvz" @ 04/29/23 13:17:16.868
  Apr 29 13:17:16.873: INFO: Get Replication Controller "e2e-rc-frvvz" to confirm replicas
  Apr 29 13:17:17.877: INFO: Get Replication Controller "e2e-rc-frvvz" to confirm replicas
  Apr 29 13:17:17.881: INFO: Found 1 replicas for "e2e-rc-frvvz" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-frvvz" @ 04/29/23 13:17:17.881
  STEP: Updating a scale subresource @ 04/29/23 13:17:17.884
  STEP: Verifying replicas where modified for replication controller "e2e-rc-frvvz" @ 04/29/23 13:17:17.889
  Apr 29 13:17:17.889: INFO: Get Replication Controller "e2e-rc-frvvz" to confirm replicas
  Apr 29 13:17:18.892: INFO: Get Replication Controller "e2e-rc-frvvz" to confirm replicas
  Apr 29 13:17:18.895: INFO: Found 2 replicas for "e2e-rc-frvvz" replication controller
  Apr 29 13:17:18.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7040" for this suite. @ 04/29/23 13:17:18.9
• [2.064 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:249
  STEP: Creating a kubernetes client @ 04/29/23 13:17:18.907
  Apr 29 13:17:18.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 13:17:18.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:18.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:18.928
  STEP: Setting up server cert @ 04/29/23 13:17:18.954
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 13:17:19.162
  STEP: Deploying the webhook pod @ 04/29/23 13:17:19.17
  STEP: Wait for the deployment to be ready @ 04/29/23 13:17:19.179
  Apr 29 13:17:19.186: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 13:17:21.197
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:17:21.206
  Apr 29 13:17:22.206: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 04/29/23 13:17:22.211
  STEP: create a configmap that should be updated by the webhook @ 04/29/23 13:17:22.227
  Apr 29 13:17:22.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2224" for this suite. @ 04/29/23 13:17:22.292
  STEP: Destroying namespace "webhook-markers-9558" for this suite. @ 04/29/23 13:17:22.298
• [3.397 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 04/29/23 13:17:22.305
  Apr 29 13:17:22.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 13:17:22.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:22.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:22.322
  STEP: Creating a ResourceQuota @ 04/29/23 13:17:22.324
  STEP: Getting a ResourceQuota @ 04/29/23 13:17:22.329
  STEP: Updating a ResourceQuota @ 04/29/23 13:17:22.332
  STEP: Verifying a ResourceQuota was modified @ 04/29/23 13:17:22.35
  STEP: Deleting a ResourceQuota @ 04/29/23 13:17:22.353
  STEP: Verifying the deleted ResourceQuota @ 04/29/23 13:17:22.359
  Apr 29 13:17:22.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1802" for this suite. @ 04/29/23 13:17:22.364
• [0.067 seconds]
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 04/29/23 13:17:22.372
  Apr 29 13:17:22.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/29/23 13:17:22.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:22.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:22.397
  Apr 29 13:17:22.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:17:22.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6517" for this suite. @ 04/29/23 13:17:22.951
• [0.587 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 04/29/23 13:17:22.96
  Apr 29 13:17:22.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 13:17:22.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:22.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:22.981
  STEP: Creating a ResourceQuota with best effort scope @ 04/29/23 13:17:22.987
  STEP: Ensuring ResourceQuota status is calculated @ 04/29/23 13:17:22.992
  STEP: Creating a ResourceQuota with not best effort scope @ 04/29/23 13:17:24.997
  STEP: Ensuring ResourceQuota status is calculated @ 04/29/23 13:17:25.003
  STEP: Creating a best-effort pod @ 04/29/23 13:17:27.009
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 04/29/23 13:17:27.025
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 04/29/23 13:17:29.03
  STEP: Deleting the pod @ 04/29/23 13:17:31.034
  STEP: Ensuring resource quota status released the pod usage @ 04/29/23 13:17:31.047
  STEP: Creating a not best-effort pod @ 04/29/23 13:17:33.05
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 04/29/23 13:17:33.061
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 04/29/23 13:17:35.065
  STEP: Deleting the pod @ 04/29/23 13:17:37.071
  STEP: Ensuring resource quota status released the pod usage @ 04/29/23 13:17:37.09
  Apr 29 13:17:39.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1876" for this suite. @ 04/29/23 13:17:39.097
• [16.146 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 04/29/23 13:17:39.107
  Apr 29 13:17:39.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replication-controller @ 04/29/23 13:17:39.108
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:39.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:39.131
  Apr 29 13:17:39.135: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 04/29/23 13:17:40.147
  STEP: Checking rc "condition-test" has the desired failure condition set @ 04/29/23 13:17:40.153
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 04/29/23 13:17:41.16
  Apr 29 13:17:41.171: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 04/29/23 13:17:41.171
  Apr 29 13:17:42.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6502" for this suite. @ 04/29/23 13:17:42.184
• [3.083 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:374
  STEP: Creating a kubernetes client @ 04/29/23 13:17:42.191
  Apr 29 13:17:42.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename daemonsets @ 04/29/23 13:17:42.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:42.219
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:42.225
  Apr 29 13:17:42.251: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/29/23 13:17:42.258
  Apr 29 13:17:42.261: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:42.262: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:42.267: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:17:42.267: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 13:17:43.272: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:43.272: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:43.277: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 29 13:17:43.277: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 13:17:44.271: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:44.271: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:44.274: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 13:17:44.274: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 04/29/23 13:17:44.286
  STEP: Check that daemon pods images are updated. @ 04/29/23 13:17:44.296
  Apr 29 13:17:44.299: INFO: Wrong image for pod: daemon-set-7cz85. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:44.299: INFO: Wrong image for pod: daemon-set-9ft5j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:44.299: INFO: Wrong image for pod: daemon-set-wbtp8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:44.304: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:44.304: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:45.309: INFO: Wrong image for pod: daemon-set-7cz85. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:45.309: INFO: Wrong image for pod: daemon-set-wbtp8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:45.314: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:45.314: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:46.308: INFO: Wrong image for pod: daemon-set-7cz85. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:46.308: INFO: Pod daemon-set-v8mxq is not available
  Apr 29 13:17:46.308: INFO: Wrong image for pod: daemon-set-wbtp8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:46.313: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:46.313: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:47.309: INFO: Wrong image for pod: daemon-set-wbtp8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:47.314: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:47.314: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:48.308: INFO: Pod daemon-set-p7gw9 is not available
  Apr 29 13:17:48.308: INFO: Wrong image for pod: daemon-set-wbtp8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 29 13:17:48.313: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:48.313: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:49.313: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:49.313: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:50.311: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:50.311: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 04/29/23 13:17:50.311
  Apr 29 13:17:50.314: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:50.314: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:17:50.317: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 13:17:50.317: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/29/23 13:17:50.332
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4568, will wait for the garbage collector to delete the pods @ 04/29/23 13:17:50.332
  Apr 29 13:17:50.391: INFO: Deleting DaemonSet.extensions daemon-set took: 5.425319ms
  Apr 29 13:17:50.491: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.402283ms
  Apr 29 13:17:52.395: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:17:52.395: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 29 13:17:52.399: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34508"},"items":null}

  Apr 29 13:17:52.401: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34508"},"items":null}

  Apr 29 13:17:52.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4568" for this suite. @ 04/29/23 13:17:52.416
• [10.232 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:46
  STEP: Creating a kubernetes client @ 04/29/23 13:17:52.423
  Apr 29 13:17:52.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/29/23 13:17:52.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:52.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:52.447
  STEP: creating a target pod @ 04/29/23 13:17:52.449
  STEP: adding an ephemeral container @ 04/29/23 13:17:54.468
  STEP: checking pod container endpoints @ 04/29/23 13:17:56.487
  Apr 29 13:17:56.487: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5729 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:17:56.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:17:56.487: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:17:56.488: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-5729/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 29 13:17:56.552: INFO: Exec stderr: ""
  Apr 29 13:17:56.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5729" for this suite. @ 04/29/23 13:17:56.566
• [4.149 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 04/29/23 13:17:56.573
  Apr 29 13:17:56.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 13:17:56.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:56.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:56.591
  STEP: create deployment with httpd image @ 04/29/23 13:17:56.594
  Apr 29 13:17:56.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-7720 create -f -'
  Apr 29 13:17:56.839: INFO: stderr: ""
  Apr 29 13:17:56.839: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 04/29/23 13:17:56.839
  Apr 29 13:17:56.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-7720 diff -f -'
  Apr 29 13:17:57.032: INFO: rc: 1
  Apr 29 13:17:57.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-7720 delete -f -'
  Apr 29 13:17:57.098: INFO: stderr: ""
  Apr 29 13:17:57.098: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Apr 29 13:17:57.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7720" for this suite. @ 04/29/23 13:17:57.102
• [0.535 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:458
  STEP: Creating a kubernetes client @ 04/29/23 13:17:57.108
  Apr 29 13:17:57.108: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename init-container @ 04/29/23 13:17:57.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:17:57.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:17:57.137
  STEP: creating the pod @ 04/29/23 13:17:57.14
  Apr 29 13:17:57.141: INFO: PodSpec: initContainers in spec.initContainers
  Apr 29 13:18:01.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5273" for this suite. @ 04/29/23 13:18:01.007
• [3.905 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 04/29/23 13:18:01.014
  Apr 29 13:18:01.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/29/23 13:18:01.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:18:01.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:18:01.032
  Apr 29 13:18:01.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/29/23 13:18:02.869
  Apr 29 13:18:02.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-7633 --namespace=crd-publish-openapi-7633 create -f -'
  Apr 29 13:18:03.547: INFO: stderr: ""
  Apr 29 13:18:03.547: INFO: stdout: "e2e-test-crd-publish-openapi-181-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 29 13:18:03.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-7633 --namespace=crd-publish-openapi-7633 delete e2e-test-crd-publish-openapi-181-crds test-cr'
  Apr 29 13:18:03.614: INFO: stderr: ""
  Apr 29 13:18:03.614: INFO: stdout: "e2e-test-crd-publish-openapi-181-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Apr 29 13:18:03.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-7633 --namespace=crd-publish-openapi-7633 apply -f -'
  Apr 29 13:18:03.808: INFO: stderr: ""
  Apr 29 13:18:03.808: INFO: stdout: "e2e-test-crd-publish-openapi-181-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 29 13:18:03.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-7633 --namespace=crd-publish-openapi-7633 delete e2e-test-crd-publish-openapi-181-crds test-cr'
  Apr 29 13:18:03.875: INFO: stderr: ""
  Apr 29 13:18:03.875: INFO: stdout: "e2e-test-crd-publish-openapi-181-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/29/23 13:18:03.875
  Apr 29 13:18:03.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=crd-publish-openapi-7633 explain e2e-test-crd-publish-openapi-181-crds'
  Apr 29 13:18:04.062: INFO: stderr: ""
  Apr 29 13:18:04.062: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-181-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Apr 29 13:18:05.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7633" for this suite. @ 04/29/23 13:18:05.377
• [4.370 seconds]
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 04/29/23 13:18:05.384
  Apr 29 13:18:05.384: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename runtimeclass @ 04/29/23 13:18:05.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:18:05.401
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:18:05.404
  Apr 29 13:18:07.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6932" for this suite. @ 04/29/23 13:18:07.442
• [2.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 04/29/23 13:18:07.45
  Apr 29 13:18:07.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 13:18:07.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:18:07.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:18:07.47
  STEP: Creating pod test-webserver-20ad12a0-371c-4553-b4d4-6776ae433ce6 in namespace container-probe-2482 @ 04/29/23 13:18:07.474
  Apr 29 13:18:09.493: INFO: Started pod test-webserver-20ad12a0-371c-4553-b4d4-6776ae433ce6 in namespace container-probe-2482
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/29/23 13:18:09.493
  Apr 29 13:18:09.496: INFO: Initial restart count of pod test-webserver-20ad12a0-371c-4553-b4d4-6776ae433ce6 is 0
  Apr 29 13:22:10.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:22:10.058
  STEP: Destroying namespace "container-probe-2482" for this suite. @ 04/29/23 13:22:10.073
• [242.630 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 04/29/23 13:22:10.082
  Apr 29 13:22:10.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename crd-webhook @ 04/29/23 13:22:10.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:22:10.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:22:10.103
  STEP: Setting up server cert @ 04/29/23 13:22:10.107
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/29/23 13:22:10.674
  STEP: Deploying the custom resource conversion webhook pod @ 04/29/23 13:22:10.682
  STEP: Wait for the deployment to be ready @ 04/29/23 13:22:10.694
  Apr 29 13:22:10.701: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 13:22:12.716
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:22:12.735
  Apr 29 13:22:13.735: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 29 13:22:13.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Creating a v1 custom resource @ 04/29/23 13:22:16.305
  STEP: v2 custom resource should be converted @ 04/29/23 13:22:16.31
  Apr 29 13:22:16.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-1234" for this suite. @ 04/29/23 13:22:16.884
• [6.809 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 04/29/23 13:22:16.892
  Apr 29 13:22:16.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 13:22:16.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:22:16.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:22:16.912
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 13:22:16.915
  STEP: Saw pod success @ 04/29/23 13:22:20.94
  Apr 29 13:22:20.944: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-e373724c-4578-48a4-aa32-dfc7c1255b25 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 13:22:20.958
  Apr 29 13:22:20.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6450" for this suite. @ 04/29/23 13:22:20.978
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 04/29/23 13:22:20.99
  Apr 29 13:22:20.990: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename gc @ 04/29/23 13:22:20.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:22:21.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:22:21.011
  STEP: create the rc @ 04/29/23 13:22:21.018
  W0429 13:22:21.024148      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 04/29/23 13:22:27.029
  STEP: wait for the rc to be deleted @ 04/29/23 13:22:27.036
  Apr 29 13:22:28.059: INFO: 80 pods remaining
  Apr 29 13:22:28.059: INFO: 80 pods has nil DeletionTimestamp
  Apr 29 13:22:28.062: INFO: 
  Apr 29 13:22:29.057: INFO: 71 pods remaining
  Apr 29 13:22:29.063: INFO: 70 pods has nil DeletionTimestamp
  Apr 29 13:22:29.063: INFO: 
  Apr 29 13:22:30.050: INFO: 60 pods remaining
  Apr 29 13:22:30.050: INFO: 60 pods has nil DeletionTimestamp
  Apr 29 13:22:30.050: INFO: 
  Apr 29 13:22:31.052: INFO: 40 pods remaining
  Apr 29 13:22:31.052: INFO: 40 pods has nil DeletionTimestamp
  Apr 29 13:22:31.052: INFO: 
  Apr 29 13:22:32.050: INFO: 31 pods remaining
  Apr 29 13:22:32.051: INFO: 30 pods has nil DeletionTimestamp
  Apr 29 13:22:32.051: INFO: 
  Apr 29 13:22:33.046: INFO: 20 pods remaining
  Apr 29 13:22:33.047: INFO: 20 pods has nil DeletionTimestamp
  Apr 29 13:22:33.047: INFO: 
  STEP: Gathering metrics @ 04/29/23 13:22:34.044
  W0429 13:22:34.049026      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 29 13:22:34.049: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 29 13:22:34.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6227" for this suite. @ 04/29/23 13:22:34.059
• [13.075 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:981
  STEP: Creating a kubernetes client @ 04/29/23 13:22:34.066
  Apr 29 13:22:34.066: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename statefulset @ 04/29/23 13:22:34.067
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:22:34.081
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:22:34.084
  STEP: Creating service test in namespace statefulset-1413 @ 04/29/23 13:22:34.088
  STEP: Creating statefulset ss in namespace statefulset-1413 @ 04/29/23 13:22:34.102
  Apr 29 13:22:34.112: INFO: Found 0 stateful pods, waiting for 1
  Apr 29 13:22:44.118: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 04/29/23 13:22:44.126
  STEP: Getting /status @ 04/29/23 13:22:44.131
  Apr 29 13:22:44.136: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 04/29/23 13:22:44.136
  Apr 29 13:22:44.145: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 04/29/23 13:22:44.145
  Apr 29 13:22:44.146: INFO: Observed &StatefulSet event: ADDED
  Apr 29 13:22:44.146: INFO: Found Statefulset ss in namespace statefulset-1413 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 29 13:22:44.147: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 04/29/23 13:22:44.147
  Apr 29 13:22:44.147: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 29 13:22:44.153: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 04/29/23 13:22:44.153
  Apr 29 13:22:44.155: INFO: Observed &StatefulSet event: ADDED
  Apr 29 13:22:44.155: INFO: Observed Statefulset ss in namespace statefulset-1413 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 29 13:22:44.156: INFO: Observed &StatefulSet event: MODIFIED
  Apr 29 13:22:44.156: INFO: Found Statefulset ss in namespace statefulset-1413 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Apr 29 13:22:44.156: INFO: Deleting all statefulset in ns statefulset-1413
  Apr 29 13:22:44.159: INFO: Scaling statefulset ss to 0
  Apr 29 13:22:54.180: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 13:22:54.183: INFO: Deleting statefulset ss
  Apr 29 13:22:54.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1413" for this suite. @ 04/29/23 13:22:54.201
• [20.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 04/29/23 13:22:54.209
  Apr 29 13:22:54.209: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename runtimeclass @ 04/29/23 13:22:54.21
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:22:54.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:22:54.23
  Apr 29 13:22:54.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-619" for this suite. @ 04/29/23 13:22:54.243
• [0.040 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 04/29/23 13:22:54.255
  Apr 29 13:22:54.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename events @ 04/29/23 13:22:54.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:22:54.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:22:54.274
  STEP: creating a test event @ 04/29/23 13:22:54.277
  STEP: listing events in all namespaces @ 04/29/23 13:22:54.285
  STEP: listing events in test namespace @ 04/29/23 13:22:54.289
  STEP: listing events with field selection filtering on source @ 04/29/23 13:22:54.292
  STEP: listing events with field selection filtering on reportingController @ 04/29/23 13:22:54.295
  STEP: getting the test event @ 04/29/23 13:22:54.299
  STEP: patching the test event @ 04/29/23 13:22:54.301
  STEP: getting the test event @ 04/29/23 13:22:54.329
  STEP: updating the test event @ 04/29/23 13:22:54.333
  STEP: getting the test event @ 04/29/23 13:22:54.348
  STEP: deleting the test event @ 04/29/23 13:22:54.351
  STEP: listing events in all namespaces @ 04/29/23 13:22:54.364
  STEP: listing events in test namespace @ 04/29/23 13:22:54.368
  Apr 29 13:22:54.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5751" for this suite. @ 04/29/23 13:22:54.382
• [0.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 04/29/23 13:22:54.393
  Apr 29 13:22:54.393: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replicaset @ 04/29/23 13:22:54.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:22:54.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:22:54.422
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 04/29/23 13:22:54.427
  Apr 29 13:22:54.437: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 29 13:22:59.445: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/29/23 13:22:59.445
  STEP: getting scale subresource @ 04/29/23 13:22:59.445
  STEP: updating a scale subresource @ 04/29/23 13:22:59.449
  STEP: verifying the replicaset Spec.Replicas was modified @ 04/29/23 13:22:59.456
  STEP: Patch a scale subresource @ 04/29/23 13:22:59.461
  Apr 29 13:22:59.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-439" for this suite. @ 04/29/23 13:22:59.48
• [5.103 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 04/29/23 13:22:59.497
  Apr 29 13:22:59.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename hostport @ 04/29/23 13:22:59.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:22:59.516
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:22:59.521
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 04/29/23 13:22:59.531
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.82.46 on the node which pod1 resides and expect scheduled @ 04/29/23 13:23:01.55
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.82.46 but use UDP protocol on the node which pod2 resides @ 04/29/23 13:23:03.566
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 04/29/23 13:23:07.601
  Apr 29 13:23:07.601: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.82.46 http://127.0.0.1:54323/hostname] Namespace:hostport-524 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:23:07.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:23:07.602: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:23:07.602: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-524/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.82.46+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.82.46, port: 54323 @ 04/29/23 13:23:07.673
  Apr 29 13:23:07.673: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.82.46:54323/hostname] Namespace:hostport-524 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:23:07.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:23:07.674: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:23:07.674: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-524/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.82.46%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.82.46, port: 54323 UDP @ 04/29/23 13:23:07.738
  Apr 29 13:23:07.739: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.82.46 54323] Namespace:hostport-524 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:23:07.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:23:07.739: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:23:07.740: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-524/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.82.46+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  Apr 29 13:23:12.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-524" for this suite. @ 04/29/23 13:23:12.811
• [13.322 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:327
  STEP: Creating a kubernetes client @ 04/29/23 13:23:12.82
  Apr 29 13:23:12.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename statefulset @ 04/29/23 13:23:12.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:23:12.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:23:12.858
  STEP: Creating service test in namespace statefulset-7545 @ 04/29/23 13:23:12.862
  STEP: Creating a new StatefulSet @ 04/29/23 13:23:12.869
  Apr 29 13:23:12.894: INFO: Found 0 stateful pods, waiting for 3
  Apr 29 13:23:22.898: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 13:23:22.898: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 13:23:22.898: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/29/23 13:23:22.908
  Apr 29 13:23:22.930: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/29/23 13:23:22.93
  STEP: Not applying an update when the partition is greater than the number of replicas @ 04/29/23 13:23:32.946
  STEP: Performing a canary update @ 04/29/23 13:23:32.946
  Apr 29 13:23:32.965: INFO: Updating stateful set ss2
  Apr 29 13:23:33.044: INFO: Waiting for Pod statefulset-7545/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  STEP: Restoring Pods to the correct revision when they are deleted @ 04/29/23 13:23:43.055
  Apr 29 13:23:43.215: INFO: Found 2 stateful pods, waiting for 3
  Apr 29 13:23:53.222: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 13:23:53.222: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 29 13:23:53.222: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 04/29/23 13:23:53.229
  Apr 29 13:23:53.249: INFO: Updating stateful set ss2
  Apr 29 13:23:53.260: INFO: Waiting for Pod statefulset-7545/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Apr 29 13:24:03.292: INFO: Updating stateful set ss2
  Apr 29 13:24:03.308: INFO: Waiting for StatefulSet statefulset-7545/ss2 to complete update
  Apr 29 13:24:03.308: INFO: Waiting for Pod statefulset-7545/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Apr 29 13:24:13.318: INFO: Deleting all statefulset in ns statefulset-7545
  Apr 29 13:24:13.321: INFO: Scaling statefulset ss2 to 0
  Apr 29 13:24:23.341: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 29 13:24:23.344: INFO: Deleting statefulset ss2
  Apr 29 13:24:23.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7545" for this suite. @ 04/29/23 13:24:23.376
• [70.566 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:331
  STEP: Creating a kubernetes client @ 04/29/23 13:24:23.387
  Apr 29 13:24:23.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 13:24:23.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:24:23.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:24:23.411
  STEP: Setting up server cert @ 04/29/23 13:24:23.449
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 13:24:23.877
  STEP: Deploying the webhook pod @ 04/29/23 13:24:23.885
  STEP: Wait for the deployment to be ready @ 04/29/23 13:24:23.898
  Apr 29 13:24:23.906: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 13:24:25.917
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:24:25.933
  Apr 29 13:24:26.933: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 29 13:24:26.937: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-698-crds.webhook.example.com via the AdmissionRegistration API @ 04/29/23 13:24:27.451
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/29/23 13:24:27.466
  Apr 29 13:24:29.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4104" for this suite. @ 04/29/23 13:24:30.083
  STEP: Destroying namespace "webhook-markers-7099" for this suite. @ 04/29/23 13:24:30.09
• [6.711 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 04/29/23 13:24:30.101
  Apr 29 13:24:30.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 13:24:30.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:24:30.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:24:30.122
  STEP: Creating a pod to test emptydir volume type on node default medium @ 04/29/23 13:24:30.125
  STEP: Saw pod success @ 04/29/23 13:24:34.147
  Apr 29 13:24:34.151: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-4ef7b7bf-3793-4f04-8b47-b0337effdb54 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 13:24:34.171
  Apr 29 13:24:34.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3665" for this suite. @ 04/29/23 13:24:34.192
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:432
  STEP: Creating a kubernetes client @ 04/29/23 13:24:34.2
  Apr 29 13:24:34.200: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename daemonsets @ 04/29/23 13:24:34.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:24:34.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:24:34.219
  Apr 29 13:24:34.255: INFO: Create a RollingUpdate DaemonSet
  Apr 29 13:24:34.261: INFO: Check that daemon pods launch on every node of the cluster
  Apr 29 13:24:34.265: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:34.265: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:34.269: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:24:34.269: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 13:24:35.276: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:35.276: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:35.281: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 29 13:24:35.281: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 13:24:36.275: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:36.275: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:36.278: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 13:24:36.278: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Apr 29 13:24:36.278: INFO: Update the DaemonSet to trigger a rollout
  Apr 29 13:24:36.289: INFO: Updating DaemonSet daemon-set
  Apr 29 13:24:38.307: INFO: Roll back the DaemonSet before rollout is complete
  Apr 29 13:24:38.317: INFO: Updating DaemonSet daemon-set
  Apr 29 13:24:38.317: INFO: Make sure DaemonSet rollback is complete
  Apr 29 13:24:38.321: INFO: Wrong image for pod: daemon-set-8t5gg. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Apr 29 13:24:38.321: INFO: Pod daemon-set-8t5gg is not available
  Apr 29 13:24:38.325: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:38.325: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:39.334: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:39.334: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:40.330: INFO: Pod daemon-set-cfcnn is not available
  Apr 29 13:24:40.334: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:24:40.334: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 04/29/23 13:24:40.341
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3970, will wait for the garbage collector to delete the pods @ 04/29/23 13:24:40.341
  Apr 29 13:24:40.403: INFO: Deleting DaemonSet.extensions daemon-set took: 7.595353ms
  Apr 29 13:24:40.504: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.643571ms
  Apr 29 13:24:42.108: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:24:42.108: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 29 13:24:42.112: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38740"},"items":null}

  Apr 29 13:24:42.115: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38740"},"items":null}

  Apr 29 13:24:42.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3970" for this suite. @ 04/29/23 13:24:42.133
• [7.940 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 04/29/23 13:24:42.141
  Apr 29 13:24:42.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename runtimeclass @ 04/29/23 13:24:42.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:24:42.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:24:42.162
  Apr 29 13:24:42.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4827" for this suite. @ 04/29/23 13:24:42.197
• [0.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 04/29/23 13:24:42.204
  Apr 29 13:24:42.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 13:24:42.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:24:42.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:24:42.225
  STEP: Creating secret with name secret-test-c3f1acc5-3151-472d-bd0c-0bfbbb99a118 @ 04/29/23 13:24:42.249
  STEP: Creating a pod to test consume secrets @ 04/29/23 13:24:42.253
  STEP: Saw pod success @ 04/29/23 13:24:46.278
  Apr 29 13:24:46.281: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-secrets-e3b37d80-fcd8-4208-8021-15d57686358a container secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 13:24:46.288
  Apr 29 13:24:46.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2308" for this suite. @ 04/29/23 13:24:46.309
  STEP: Destroying namespace "secret-namespace-3583" for this suite. @ 04/29/23 13:24:46.315
• [4.117 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 04/29/23 13:24:46.322
  Apr 29 13:24:46.322: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename dns @ 04/29/23 13:24:46.323
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:24:46.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:24:46.344
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/29/23 13:24:46.347
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/29/23 13:24:46.347
  STEP: creating a pod to probe DNS @ 04/29/23 13:24:46.347
  STEP: submitting the pod to kubernetes @ 04/29/23 13:24:46.348
  STEP: retrieving the pod @ 04/29/23 13:24:48.367
  STEP: looking for the results for each expected name from probers @ 04/29/23 13:24:48.37
  Apr 29 13:24:48.385: INFO: DNS probes using dns-8792/dns-test-e36cdf08-a318-44bb-a6b4-931a184cbd8b succeeded

  Apr 29 13:24:48.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:24:48.39
  STEP: Destroying namespace "dns-8792" for this suite. @ 04/29/23 13:24:48.404
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 04/29/23 13:24:48.412
  Apr 29 13:24:48.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename namespaces @ 04/29/23 13:24:48.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:24:48.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:24:48.43
  STEP: Creating namespace "e2e-ns-nrz66" @ 04/29/23 13:24:48.434
  Apr 29 13:24:48.450: INFO: Namespace "e2e-ns-nrz66-4164" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-nrz66-4164" @ 04/29/23 13:24:48.45
  Apr 29 13:24:48.459: INFO: Namespace "e2e-ns-nrz66-4164" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-nrz66-4164" @ 04/29/23 13:24:48.459
  Apr 29 13:24:48.467: INFO: Namespace "e2e-ns-nrz66-4164" has []v1.FinalizerName{"kubernetes"}
  Apr 29 13:24:48.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4342" for this suite. @ 04/29/23 13:24:48.471
  STEP: Destroying namespace "e2e-ns-nrz66-4164" for this suite. @ 04/29/23 13:24:48.479
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 04/29/23 13:24:48.486
  Apr 29 13:24:48.486: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 13:24:48.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:24:48.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:24:48.506
  STEP: Counting existing ResourceQuota @ 04/29/23 13:25:05.515
  STEP: Creating a ResourceQuota @ 04/29/23 13:25:10.518
  STEP: Ensuring resource quota status is calculated @ 04/29/23 13:25:10.523
  STEP: Creating a ConfigMap @ 04/29/23 13:25:12.529
  STEP: Ensuring resource quota status captures configMap creation @ 04/29/23 13:25:12.54
  STEP: Deleting a ConfigMap @ 04/29/23 13:25:14.545
  STEP: Ensuring resource quota status released usage @ 04/29/23 13:25:14.554
  Apr 29 13:25:16.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5260" for this suite. @ 04/29/23 13:25:16.564
• [28.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 04/29/23 13:25:16.573
  Apr 29 13:25:16.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:25:16.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:25:16.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:25:16.603
  STEP: creating service nodeport-test with type=NodePort in namespace services-1436 @ 04/29/23 13:25:16.607
  STEP: creating replication controller nodeport-test in namespace services-1436 @ 04/29/23 13:25:16.626
  I0429 13:25:16.639006      18 runners.go:194] Created replication controller with name: nodeport-test, namespace: services-1436, replica count: 2
  I0429 13:25:19.690185      18 runners.go:194] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 29 13:25:19.690: INFO: Creating new exec pod
  Apr 29 13:25:22.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-1436 exec execpod4sxvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 29 13:25:22.836: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 29 13:25:22.836: INFO: stdout: "nodeport-test-s5sqp"
  Apr 29 13:25:22.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-1436 exec execpod4sxvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.231 80'
  Apr 29 13:25:22.963: INFO: stderr: "+ nc -v -t -w 2 10.152.183.231 80\n+ echo hostName\nConnection to 10.152.183.231 80 port [tcp/http] succeeded!\n"
  Apr 29 13:25:22.963: INFO: stdout: "nodeport-test-s5sqp"
  Apr 29 13:25:22.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-1436 exec execpod4sxvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.80 32149'
  Apr 29 13:25:23.078: INFO: stderr: "+ nc -v -t -w 2 172.31.41.80 32149\nConnection to 172.31.41.80 32149 port [tcp/*] succeeded!\n+ echo hostName\n"
  Apr 29 13:25:23.078: INFO: stdout: ""
  Apr 29 13:25:24.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-1436 exec execpod4sxvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.80 32149'
  Apr 29 13:25:24.203: INFO: stderr: "+ nc -v -t -w 2 172.31.41.80 32149\n+ echo hostName\nConnection to 172.31.41.80 32149 port [tcp/*] succeeded!\n"
  Apr 29 13:25:24.203: INFO: stdout: "nodeport-test-s5sqp"
  Apr 29 13:25:24.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-1436 exec execpod4sxvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.25.13 32149'
  Apr 29 13:25:24.328: INFO: stderr: "+ nc -v -t -w 2 172.31.25.13 32149\n+ echo hostName\nConnection to 172.31.25.13 32149 port [tcp/*] succeeded!\n"
  Apr 29 13:25:24.329: INFO: stdout: "nodeport-test-9cgtw"
  Apr 29 13:25:24.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1436" for this suite. @ 04/29/23 13:25:24.333
• [7.768 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 04/29/23 13:25:24.341
  Apr 29 13:25:24.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 13:25:24.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:25:24.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:25:24.378
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/29/23 13:25:24.381
  STEP: Saw pod success @ 04/29/23 13:25:28.426
  Apr 29 13:25:28.430: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-54acc814-4d8f-4d4c-8b86-bc86fcb88f72 container test-container: <nil>
  STEP: delete the pod @ 04/29/23 13:25:28.437
  Apr 29 13:25:28.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1940" for this suite. @ 04/29/23 13:25:28.502
• [4.194 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:546
  STEP: Creating a kubernetes client @ 04/29/23 13:25:28.536
  Apr 29 13:25:28.536: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 13:25:28.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:25:28.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:25:28.583
  STEP: Creating pod test-grpc-b5aef9ef-6afe-4a43-838a-05155002bf59 in namespace container-probe-7786 @ 04/29/23 13:25:28.587
  Apr 29 13:25:30.652: INFO: Started pod test-grpc-b5aef9ef-6afe-4a43-838a-05155002bf59 in namespace container-probe-7786
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/29/23 13:25:30.652
  Apr 29 13:25:30.656: INFO: Initial restart count of pod test-grpc-b5aef9ef-6afe-4a43-838a-05155002bf59 is 0
  Apr 29 13:26:44.848: INFO: Restart count of pod container-probe-7786/test-grpc-b5aef9ef-6afe-4a43-838a-05155002bf59 is now 1 (1m14.191830225s elapsed)
  Apr 29 13:26:44.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:26:44.852
  STEP: Destroying namespace "container-probe-7786" for this suite. @ 04/29/23 13:26:44.866
• [76.337 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 04/29/23 13:26:44.876
  Apr 29 13:26:44.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename emptydir @ 04/29/23 13:26:44.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:26:44.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:26:44.907
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/29/23 13:26:44.911
  STEP: Saw pod success @ 04/29/23 13:26:48.931
  Apr 29 13:26:48.935: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-00791f25-d8d9-4e96-816e-a9a1f51b78ee container test-container: <nil>
  STEP: delete the pod @ 04/29/23 13:26:48.941
  Apr 29 13:26:48.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4000" for this suite. @ 04/29/23 13:26:48.96
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 04/29/23 13:26:48.968
  Apr 29 13:26:48.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 13:26:48.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:26:48.982
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:26:48.985
  STEP: Creating secret with name secret-test-9e7c004b-4251-49b7-8fbb-4feea50fd58d @ 04/29/23 13:26:48.989
  STEP: Creating a pod to test consume secrets @ 04/29/23 13:26:48.993
  STEP: Saw pod success @ 04/29/23 13:26:53.016
  Apr 29 13:26:53.019: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-secrets-ee4b17be-a100-40a0-bcd7-3580e05d23ed container secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 13:26:53.026
  Apr 29 13:26:53.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5547" for this suite. @ 04/29/23 13:26:53.047
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 04/29/23 13:26:53.057
  Apr 29 13:26:53.057: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename containers @ 04/29/23 13:26:53.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:26:53.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:26:53.076
  STEP: Creating a pod to test override arguments @ 04/29/23 13:26:53.079
  STEP: Saw pod success @ 04/29/23 13:26:57.099
  Apr 29 13:26:57.103: INFO: Trying to get logs from node ip-172-31-41-80 pod client-containers-ec968cf8-d51d-414f-bc5b-3cabbc9b962d container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 13:26:57.11
  Apr 29 13:26:57.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9963" for this suite. @ 04/29/23 13:26:57.132
• [4.081 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:294
  STEP: Creating a kubernetes client @ 04/29/23 13:26:57.139
  Apr 29 13:26:57.139: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename daemonsets @ 04/29/23 13:26:57.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:26:57.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:26:57.157
  STEP: Creating a simple DaemonSet "daemon-set" @ 04/29/23 13:26:57.179
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/29/23 13:26:57.184
  Apr 29 13:26:57.188: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:26:57.189: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:26:57.192: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:26:57.192: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 13:26:58.196: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:26:58.196: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:26:58.200: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:26:58.200: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 13:26:59.197: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:26:59.197: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:26:59.201: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 13:26:59.201: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 04/29/23 13:26:59.204
  Apr 29 13:26:59.220: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:26:59.221: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:26:59.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 29 13:26:59.225: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 13:27:00.230: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:00.230: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:00.234: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 29 13:27:00.234: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 13:27:01.229: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:01.229: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:01.233: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 13:27:01.233: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 04/29/23 13:27:01.233
  STEP: Deleting DaemonSet "daemon-set" @ 04/29/23 13:27:01.24
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1407, will wait for the garbage collector to delete the pods @ 04/29/23 13:27:01.24
  Apr 29 13:27:01.299: INFO: Deleting DaemonSet.extensions daemon-set took: 5.960697ms
  Apr 29 13:27:01.400: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.948974ms
  Apr 29 13:27:02.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:27:02.604: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 29 13:27:02.608: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39594"},"items":null}

  Apr 29 13:27:02.611: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39594"},"items":null}

  Apr 29 13:27:02.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1407" for this suite. @ 04/29/23 13:27:02.629
• [5.496 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 04/29/23 13:27:02.637
  Apr 29 13:27:02.637: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:27:02.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:02.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:02.654
  Apr 29 13:27:02.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3682" for this suite. @ 04/29/23 13:27:02.668
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 04/29/23 13:27:02.68
  Apr 29 13:27:02.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 13:27:02.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:02.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:02.698
  STEP: Counting existing ResourceQuota @ 04/29/23 13:27:02.701
  STEP: Creating a ResourceQuota @ 04/29/23 13:27:07.705
  STEP: Ensuring resource quota status is calculated @ 04/29/23 13:27:07.711
  STEP: Creating a Service @ 04/29/23 13:27:09.716
  STEP: Creating a NodePort Service @ 04/29/23 13:27:09.734
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 04/29/23 13:27:09.756
  STEP: Ensuring resource quota status captures service creation @ 04/29/23 13:27:09.775
  STEP: Deleting Services @ 04/29/23 13:27:11.78
  STEP: Ensuring resource quota status released usage @ 04/29/23 13:27:11.821
  Apr 29 13:27:13.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-671" for this suite. @ 04/29/23 13:27:13.83
• [11.157 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:300
  STEP: Creating a kubernetes client @ 04/29/23 13:27:13.837
  Apr 29 13:27:13.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 13:27:13.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:13.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:13.856
  STEP: Setting up server cert @ 04/29/23 13:27:13.884
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 13:27:14.191
  STEP: Deploying the webhook pod @ 04/29/23 13:27:14.2
  STEP: Wait for the deployment to be ready @ 04/29/23 13:27:14.213
  Apr 29 13:27:14.220: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/29/23 13:27:16.232
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:27:16.244
  Apr 29 13:27:17.245: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 04/29/23 13:27:17.249
  STEP: Creating a custom resource definition that should be denied by the webhook @ 04/29/23 13:27:17.263
  Apr 29 13:27:17.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:27:17.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5705" for this suite. @ 04/29/23 13:27:17.33
  STEP: Destroying namespace "webhook-markers-2968" for this suite. @ 04/29/23 13:27:17.338
• [3.507 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 04/29/23 13:27:17.345
  Apr 29 13:27:17.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 13:27:17.346
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:17.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:17.366
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 13:27:17.37
  STEP: Saw pod success @ 04/29/23 13:27:21.393
  Apr 29 13:27:21.397: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-58867e44-3869-476a-b9e6-488bbec12881 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 13:27:21.403
  Apr 29 13:27:21.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-292" for this suite. @ 04/29/23 13:27:21.42
• [4.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 04/29/23 13:27:21.427
  Apr 29 13:27:21.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename field-validation @ 04/29/23 13:27:21.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:21.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:21.446
  STEP: apply creating a deployment @ 04/29/23 13:27:21.449
  Apr 29 13:27:21.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5839" for this suite. @ 04/29/23 13:27:21.468
• [0.047 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:260
  STEP: Creating a kubernetes client @ 04/29/23 13:27:21.475
  Apr 29 13:27:21.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 13:27:21.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:21.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:21.492
  STEP: Setting up server cert @ 04/29/23 13:27:21.516
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 13:27:21.624
  STEP: Deploying the webhook pod @ 04/29/23 13:27:21.63
  STEP: Wait for the deployment to be ready @ 04/29/23 13:27:21.642
  Apr 29 13:27:21.657: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 13:27:23.667
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:27:23.683
  Apr 29 13:27:24.683: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 04/29/23 13:27:24.687
  STEP: create a pod that should be updated by the webhook @ 04/29/23 13:27:24.701
  Apr 29 13:27:24.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3532" for this suite. @ 04/29/23 13:27:24.769
  STEP: Destroying namespace "webhook-markers-5372" for this suite. @ 04/29/23 13:27:24.779
• [3.323 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 04/29/23 13:27:24.799
  Apr 29 13:27:24.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename podtemplate @ 04/29/23 13:27:24.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:24.832
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:24.836
  STEP: Create a pod template @ 04/29/23 13:27:24.84
  STEP: Replace a pod template @ 04/29/23 13:27:24.845
  Apr 29 13:27:24.855: INFO: Found updated podtemplate annotation: "true"

  Apr 29 13:27:24.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-32" for this suite. @ 04/29/23 13:27:24.86
• [0.069 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 04/29/23 13:27:24.868
  Apr 29 13:27:24.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-runtime @ 04/29/23 13:27:24.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:24.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:24.891
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 04/29/23 13:27:24.914
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 04/29/23 13:27:42.005
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 04/29/23 13:27:42.008
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 04/29/23 13:27:42.015
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 04/29/23 13:27:42.015
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 04/29/23 13:27:42.037
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 04/29/23 13:27:45.054
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 04/29/23 13:27:46.061
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 04/29/23 13:27:46.068
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 04/29/23 13:27:46.068
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 04/29/23 13:27:46.091
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 04/29/23 13:27:47.101
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 04/29/23 13:27:49.113
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 04/29/23 13:27:49.12
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 04/29/23 13:27:49.12
  Apr 29 13:27:49.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5896" for this suite. @ 04/29/23 13:27:49.153
• [24.291 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 04/29/23 13:27:49.16
  Apr 29 13:27:49.160: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replicaset @ 04/29/23 13:27:49.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:49.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:49.179
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 04/29/23 13:27:49.185
  STEP: When a replicaset with a matching selector is created @ 04/29/23 13:27:51.205
  STEP: Then the orphan pod is adopted @ 04/29/23 13:27:51.21
  STEP: When the matched label of one of its pods change @ 04/29/23 13:27:52.218
  Apr 29 13:27:52.221: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/29/23 13:27:52.232
  Apr 29 13:27:53.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9229" for this suite. @ 04/29/23 13:27:53.246
• [4.094 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:237
  STEP: Creating a kubernetes client @ 04/29/23 13:27:53.254
  Apr 29 13:27:53.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 13:27:53.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:53.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:53.273
  STEP: Setting up server cert @ 04/29/23 13:27:53.295
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 13:27:53.488
  STEP: Deploying the webhook pod @ 04/29/23 13:27:53.496
  STEP: Wait for the deployment to be ready @ 04/29/23 13:27:53.508
  Apr 29 13:27:53.516: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 13:27:55.529
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:27:55.541
  Apr 29 13:27:56.541: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 04/29/23 13:27:56.544
  STEP: create a namespace for the webhook @ 04/29/23 13:27:56.557
  STEP: create a configmap should be unconditionally rejected by the webhook @ 04/29/23 13:27:56.567
  Apr 29 13:27:56.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8854" for this suite. @ 04/29/23 13:27:56.674
  STEP: Destroying namespace "webhook-markers-9911" for this suite. @ 04/29/23 13:27:56.683
  STEP: Destroying namespace "fail-closed-namespace-1926" for this suite. @ 04/29/23 13:27:56.689
• [3.441 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:166
  STEP: Creating a kubernetes client @ 04/29/23 13:27:56.696
  Apr 29 13:27:56.696: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename daemonsets @ 04/29/23 13:27:56.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:27:56.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:27:56.717
  STEP: Creating simple DaemonSet "daemon-set" @ 04/29/23 13:27:56.74
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/29/23 13:27:56.746
  Apr 29 13:27:56.749: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:56.749: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:56.753: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:27:56.753: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 13:27:57.757: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:57.757: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:57.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 29 13:27:57.761: INFO: Node ip-172-31-25-13 is running 0 daemon pod, expected 1
  Apr 29 13:27:58.757: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:58.757: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:58.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 13:27:58.761: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 04/29/23 13:27:58.765
  Apr 29 13:27:58.783: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:58.783: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:58.787: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 29 13:27:58.787: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 13:27:59.793: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:59.793: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:27:59.797: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 29 13:27:59.797: INFO: Node ip-172-31-41-80 is running 0 daemon pod, expected 1
  Apr 29 13:28:00.793: INFO: DaemonSet pods can't tolerate node ip-172-31-11-190 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:28:00.793: INFO: DaemonSet pods can't tolerate node ip-172-31-34-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 29 13:28:00.799: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 29 13:28:00.799: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/29/23 13:28:00.804
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-279, will wait for the garbage collector to delete the pods @ 04/29/23 13:28:00.804
  Apr 29 13:28:00.866: INFO: Deleting DaemonSet.extensions daemon-set took: 7.691655ms
  Apr 29 13:28:00.966: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.108992ms
  Apr 29 13:28:02.771: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 29 13:28:02.771: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 29 13:28:02.774: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"40343"},"items":null}

  Apr 29 13:28:02.777: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"40343"},"items":null}

  Apr 29 13:28:02.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-279" for this suite. @ 04/29/23 13:28:02.796
• [6.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1341
  STEP: Creating a kubernetes client @ 04/29/23 13:28:02.807
  Apr 29 13:28:02.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 13:28:02.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:28:02.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:28:02.826
  Apr 29 13:28:02.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-5253 create -f -'
  Apr 29 13:28:03.538: INFO: stderr: ""
  Apr 29 13:28:03.538: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Apr 29 13:28:03.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-5253 create -f -'
  Apr 29 13:28:03.789: INFO: stderr: ""
  Apr 29 13:28:03.789: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/29/23 13:28:03.789
  Apr 29 13:28:04.792: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 29 13:28:04.792: INFO: Found 1 / 1
  Apr 29 13:28:04.792: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 29 13:28:04.798: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 29 13:28:04.798: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 29 13:28:04.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-5253 describe pod agnhost-primary-bnf8j'
  Apr 29 13:28:04.878: INFO: stderr: ""
  Apr 29 13:28:04.878: INFO: stdout: "Name:             agnhost-primary-bnf8j\nNamespace:        kubectl-5253\nPriority:         0\nService Account:  default\nNode:             ip-172-31-41-80/172.31.41.80\nStart Time:       Sat, 29 Apr 2023 13:28:03 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.226.38\nIPs:\n  IP:           192.168.226.38\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://6a59eca5ed1043d9b684b0c9f681985077fac928d60b4ce54bd8899ecff9d6bd\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.43\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 29 Apr 2023 13:28:04 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-txd5d (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-txd5d:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-5253/agnhost-primary-bnf8j to ip-172-31-41-80\n  Normal  Pulled     0s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.43\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
  Apr 29 13:28:04.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-5253 describe rc agnhost-primary'
  Apr 29 13:28:04.949: INFO: stderr: ""
  Apr 29 13:28:04.949: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5253\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.43\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-bnf8j\n"
  Apr 29 13:28:04.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-5253 describe service agnhost-primary'
  Apr 29 13:28:05.019: INFO: stderr: ""
  Apr 29 13:28:05.019: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5253\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.177\nIPs:               10.152.183.177\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.226.38:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Apr 29 13:28:05.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-5253 describe node ip-172-31-11-190'
  Apr 29 13:28:05.115: INFO: stderr: ""
  Apr 29 13:28:05.115: INFO: stdout: "Name:               ip-172-31-11-190\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-control-plane\n                    juju-charm=kubernetes-control-plane\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-11-190\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 29 Apr 2023 11:50:42 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-11-190\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 29 Apr 2023 13:28:02 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 29 Apr 2023 13:23:05 +0000   Sat, 29 Apr 2023 11:54:06 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 29 Apr 2023 13:23:05 +0000   Sat, 29 Apr 2023 11:54:06 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 29 Apr 2023 13:23:05 +0000   Sat, 29 Apr 2023 11:54:06 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 29 Apr 2023 13:23:05 +0000   Sat, 29 Apr 2023 11:54:06 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.11.190\n  Hostname:    ip-172-31-11-190\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7923256Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7820856Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2c79b7c9c404ab92d8e6dc3f4b8caf\n  System UUID:                ec2c79b7-c9c4-04ab-92d8-e6dc3f4b8caf\n  Boot ID:                    1462828a-9d39-4534-9be2-64475f6d22ae\n  Kernel Version:             5.19.0-1024-aws\n  OS Image:                   Ubuntu 22.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.27.1\n  Kube-Proxy Version:         v1.27.1\nNon-terminated Pods:          (1 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-78b9s    0 (0%)        0 (0%)      0 (0%)           0 (0%)         87m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\n  hugepages-1Gi      0 (0%)    0 (0%)\n  hugepages-2Mi      0 (0%)    0 (0%)\nEvents:              <none>\n"
  Apr 29 13:28:05.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-5253 describe namespace kubectl-5253'
  Apr 29 13:28:05.184: INFO: stderr: ""
  Apr 29 13:28:05.184: INFO: stdout: "Name:         kubectl-5253\nLabels:       e2e-framework=kubectl\n              e2e-run=8fb8af36-3b1e-465f-a851-9fb2f1b1d225\n              kubernetes.io/metadata.name=kubectl-5253\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Apr 29 13:28:05.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5253" for this suite. @ 04/29/23 13:28:05.188
• [2.387 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:286
  STEP: Creating a kubernetes client @ 04/29/23 13:28:05.195
  Apr 29 13:28:05.195: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename field-validation @ 04/29/23 13:28:05.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:28:05.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:28:05.214
  Apr 29 13:28:05.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:28:07.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1285" for this suite. @ 04/29/23 13:28:07.811
• [2.623 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 04/29/23 13:28:07.819
  Apr 29 13:28:07.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename deployment @ 04/29/23 13:28:07.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:28:07.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:28:07.842
  STEP: creating a Deployment @ 04/29/23 13:28:07.852
  STEP: waiting for Deployment to be created @ 04/29/23 13:28:07.858
  STEP: waiting for all Replicas to be Ready @ 04/29/23 13:28:07.861
  Apr 29 13:28:07.862: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 29 13:28:07.862: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 29 13:28:07.872: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 29 13:28:07.872: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 29 13:28:07.889: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 29 13:28:07.889: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 29 13:28:07.914: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 29 13:28:07.914: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 29 13:28:08.754: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 29 13:28:08.754: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 29 13:28:09.452: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 04/29/23 13:28:09.452
  W0429 13:28:09.463484      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 29 13:28:09.465: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 04/29/23 13:28:09.465
  Apr 29 13:28:09.467: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0
  Apr 29 13:28:09.467: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0
  Apr 29 13:28:09.467: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0
  Apr 29 13:28:09.467: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 0
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:09.468: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:09.480: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:09.480: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:09.504: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:09.504: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:09.517: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:09.517: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:10.774: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:10.774: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:10.832: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  STEP: listing Deployments @ 04/29/23 13:28:10.832
  Apr 29 13:28:10.837: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 04/29/23 13:28:10.837
  Apr 29 13:28:10.873: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 04/29/23 13:28:10.873
  Apr 29 13:28:10.926: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:10.926: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:10.926: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:10.953: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:10.979: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:11.774: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:11.795: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:11.807: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:11.836: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 29 13:28:13.479: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 04/29/23 13:28:13.502
  STEP: fetching the DeploymentStatus @ 04/29/23 13:28:13.509
  Apr 29 13:28:13.515: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:13.515: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:13.515: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:13.515: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:13.515: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 1
  Apr 29 13:28:13.515: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:13.515: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:13.516: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:13.516: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 2
  Apr 29 13:28:13.516: INFO: observed Deployment test-deployment in namespace deployment-8933 with ReadyReplicas 3
  STEP: deleting the Deployment @ 04/29/23 13:28:13.516
  Apr 29 13:28:13.525: INFO: observed event type MODIFIED
  Apr 29 13:28:13.525: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.526: INFO: observed event type MODIFIED
  Apr 29 13:28:13.531: INFO: Log out all the ReplicaSets if there is no deployment created
  Apr 29 13:28:13.536: INFO: ReplicaSet "test-deployment-6fc78d85c6":
  &ReplicaSet{ObjectMeta:{test-deployment-6fc78d85c6  deployment-8933  d4c64c82-2d26-49f3-9594-2bf38e782eef 40636 2 2023-04-29 13:28:10 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 72124612-2daa-4327-95e0-b1b2869e4b88 0xc00436f1a7 0xc00436f1a8}] [] [{kube-controller-manager Update apps/v1 2023-04-29 13:28:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72124612-2daa-4327-95e0-b1b2869e4b88\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-29 13:28:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6fc78d85c6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00436f310 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

  Apr 29 13:28:13.541: INFO: pod: "test-deployment-6fc78d85c6-9cgg6":
  &Pod{ObjectMeta:{test-deployment-6fc78d85c6-9cgg6 test-deployment-6fc78d85c6- deployment-8933  dcbb3e2e-6223-4d17-8e1d-4b4f01067203 40584 0 2023-04-29 13:28:10 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-6fc78d85c6 d4c64c82-2d26-49f3-9594-2bf38e782eef 0xc0056c3ea7 0xc0056c3ea8}] [] [{kube-controller-manager Update v1 2023-04-29 13:28:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d4c64c82-2d26-49f3-9594-2bf38e782eef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 13:28:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.226.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ql94h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ql94h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-80,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:28:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:28:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:28:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:28:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.80,PodIP:192.168.226.48,StartTime:2023-04-29 13:28:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 13:28:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://d5a4db43a88c65aff96e03fa9623686f2cf835b1f6c872175fe052055d193882,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.226.48,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 29 13:28:13.541: INFO: pod: "test-deployment-6fc78d85c6-vnst5":
  &Pod{ObjectMeta:{test-deployment-6fc78d85c6-vnst5 test-deployment-6fc78d85c6- deployment-8933  1a8c9274-cf9c-4446-834c-5f809f2add97 40635 0 2023-04-29 13:28:11 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-6fc78d85c6 d4c64c82-2d26-49f3-9594-2bf38e782eef 0xc00342c097 0xc00342c098}] [] [{kube-controller-manager Update v1 2023-04-29 13:28:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d4c64c82-2d26-49f3-9594-2bf38e782eef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-29 13:28:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.69.255\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nmdht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nmdht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-82-46,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:28:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:28:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:28:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-29 13:28:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.82.46,PodIP:192.168.69.255,StartTime:2023-04-29 13:28:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-29 13:28:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://5f57c5577bc1b362f7224e78c3d11dcce25cbfe7157db5a818ad07c94253280a,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.69.255,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 29 13:28:13.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8933" for this suite. @ 04/29/23 13:28:13.547
• [5.736 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 04/29/23 13:28:13.555
  Apr 29 13:28:13.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 13:28:13.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:28:13.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:28:13.573
  STEP: Creating pod liveness-556263d7-d282-4239-8b3e-e2785177fbe4 in namespace container-probe-4628 @ 04/29/23 13:28:13.577
  Apr 29 13:28:15.594: INFO: Started pod liveness-556263d7-d282-4239-8b3e-e2785177fbe4 in namespace container-probe-4628
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/29/23 13:28:15.594
  Apr 29 13:28:15.598: INFO: Initial restart count of pod liveness-556263d7-d282-4239-8b3e-e2785177fbe4 is 0
  Apr 29 13:32:16.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:32:16.16
  STEP: Destroying namespace "container-probe-4628" for this suite. @ 04/29/23 13:32:16.175
• [242.628 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 04/29/23 13:32:16.189
  Apr 29 13:32:16.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename cronjob @ 04/29/23 13:32:16.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:32:16.207
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:32:16.21
  STEP: Creating a cronjob @ 04/29/23 13:32:16.214
  STEP: Ensuring more than one job is running at a time @ 04/29/23 13:32:16.219
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 04/29/23 13:34:00.224
  STEP: Removing cronjob @ 04/29/23 13:34:00.228
  Apr 29 13:34:00.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7224" for this suite. @ 04/29/23 13:34:00.241
• [104.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 04/29/23 13:34:00.252
  Apr 29 13:34:00.252: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:34:00.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:34:00.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:34:00.277
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 13:34:00.281
  STEP: Saw pod success @ 04/29/23 13:34:04.304
  Apr 29 13:34:04.307: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-798969f5-0218-405f-b595-cc042b78f07e container client-container: <nil>
  STEP: delete the pod @ 04/29/23 13:34:04.325
  Apr 29 13:34:04.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-824" for this suite. @ 04/29/23 13:34:04.346
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 04/29/23 13:34:04.353
  Apr 29 13:34:04.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename secrets @ 04/29/23 13:34:04.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:34:04.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:34:04.37
  STEP: creating a secret @ 04/29/23 13:34:04.373
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 04/29/23 13:34:04.381
  STEP: patching the secret @ 04/29/23 13:34:04.385
  STEP: deleting the secret using a LabelSelector @ 04/29/23 13:34:04.415
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 04/29/23 13:34:04.428
  Apr 29 13:34:04.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-742" for this suite. @ 04/29/23 13:34:04.435
• [0.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 04/29/23 13:34:04.444
  Apr 29 13:34:04.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename dns @ 04/29/23 13:34:04.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:34:04.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:34:04.465
  STEP: Creating a test headless service @ 04/29/23 13:34:04.468
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1536.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1536.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1536.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1536.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1536.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1536.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1536.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1536.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1536.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1536.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 192.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.192_udp@PTR;check="$$(dig +tcp +noall +answer +search 192.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.192_tcp@PTR;sleep 1; done
   @ 04/29/23 13:34:04.493
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1536.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1536.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1536.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1536.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1536.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1536.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1536.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1536.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1536.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1536.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 192.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.192_udp@PTR;check="$$(dig +tcp +noall +answer +search 192.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.192_tcp@PTR;sleep 1; done
   @ 04/29/23 13:34:04.493
  STEP: creating a pod to probe DNS @ 04/29/23 13:34:04.493
  STEP: submitting the pod to kubernetes @ 04/29/23 13:34:04.493
  STEP: retrieving the pod @ 04/29/23 13:34:06.517
  STEP: looking for the results for each expected name from probers @ 04/29/23 13:34:06.52
  Apr 29 13:34:06.525: INFO: Unable to read wheezy_udp@dns-test-service.dns-1536.svc.cluster.local from pod dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c: the server could not find the requested resource (get pods dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c)
  Apr 29 13:34:06.528: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1536.svc.cluster.local from pod dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c: the server could not find the requested resource (get pods dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c)
  Apr 29 13:34:06.533: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local from pod dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c: the server could not find the requested resource (get pods dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c)
  Apr 29 13:34:06.537: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local from pod dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c: the server could not find the requested resource (get pods dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c)
  Apr 29 13:34:06.554: INFO: Unable to read jessie_udp@dns-test-service.dns-1536.svc.cluster.local from pod dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c: the server could not find the requested resource (get pods dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c)
  Apr 29 13:34:06.558: INFO: Unable to read jessie_tcp@dns-test-service.dns-1536.svc.cluster.local from pod dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c: the server could not find the requested resource (get pods dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c)
  Apr 29 13:34:06.562: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local from pod dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c: the server could not find the requested resource (get pods dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c)
  Apr 29 13:34:06.565: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local from pod dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c: the server could not find the requested resource (get pods dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c)
  Apr 29 13:34:06.579: INFO: Lookups using dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c failed for: [wheezy_udp@dns-test-service.dns-1536.svc.cluster.local wheezy_tcp@dns-test-service.dns-1536.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local jessie_udp@dns-test-service.dns-1536.svc.cluster.local jessie_tcp@dns-test-service.dns-1536.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1536.svc.cluster.local]

  Apr 29 13:34:11.636: INFO: DNS probes using dns-1536/dns-test-36ea0891-b972-4a97-8e0f-f78103790f9c succeeded

  Apr 29 13:34:11.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:34:11.64
  STEP: deleting the test service @ 04/29/23 13:34:11.655
  STEP: deleting the test headless service @ 04/29/23 13:34:11.679
  STEP: Destroying namespace "dns-1536" for this suite. @ 04/29/23 13:34:11.694
• [7.263 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1574
  STEP: Creating a kubernetes client @ 04/29/23 13:34:11.707
  Apr 29 13:34:11.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 13:34:11.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:34:11.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:34:11.726
  STEP: creating the pod @ 04/29/23 13:34:11.73
  Apr 29 13:34:11.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8505 create -f -'
  Apr 29 13:34:12.841: INFO: stderr: ""
  Apr 29 13:34:12.841: INFO: stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 04/29/23 13:34:14.851
  Apr 29 13:34:14.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8505 label pods pause testing-label=testing-label-value'
  Apr 29 13:34:14.920: INFO: stderr: ""
  Apr 29 13:34:14.920: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 04/29/23 13:34:14.92
  Apr 29 13:34:14.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8505 get pod pause -L testing-label'
  Apr 29 13:34:14.981: INFO: stderr: ""
  Apr 29 13:34:14.981: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 04/29/23 13:34:14.981
  Apr 29 13:34:14.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8505 label pods pause testing-label-'
  Apr 29 13:34:15.050: INFO: stderr: ""
  Apr 29 13:34:15.050: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 04/29/23 13:34:15.05
  Apr 29 13:34:15.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8505 get pod pause -L testing-label'
  Apr 29 13:34:15.109: INFO: stderr: ""
  Apr 29 13:34:15.109: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 04/29/23 13:34:15.109
  Apr 29 13:34:15.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8505 delete --grace-period=0 --force -f -'
  Apr 29 13:34:15.178: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 29 13:34:15.178: INFO: stdout: "pod \"pause\" force deleted\n"
  Apr 29 13:34:15.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8505 get rc,svc -l name=pause --no-headers'
  Apr 29 13:34:15.244: INFO: stderr: "No resources found in kubectl-8505 namespace.\n"
  Apr 29 13:34:15.244: INFO: stdout: ""
  Apr 29 13:34:15.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8505 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 29 13:34:15.302: INFO: stderr: ""
  Apr 29 13:34:15.302: INFO: stdout: ""
  Apr 29 13:34:15.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8505" for this suite. @ 04/29/23 13:34:15.307
• [3.606 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 04/29/23 13:34:15.314
  Apr 29 13:34:15.314: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pod-network-test @ 04/29/23 13:34:15.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:34:15.33
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:34:15.334
  STEP: Performing setup for networking test in namespace pod-network-test-5385 @ 04/29/23 13:34:15.34
  STEP: creating a selector @ 04/29/23 13:34:15.34
  STEP: Creating the service pods in kubernetes @ 04/29/23 13:34:15.34
  Apr 29 13:34:15.340: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/29/23 13:34:37.447
  Apr 29 13:34:39.463: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 29 13:34:39.463: INFO: Breadth first check of 192.168.189.150 on host 172.31.25.13...
  Apr 29 13:34:39.467: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.226.43:9080/dial?request=hostname&protocol=udp&host=192.168.189.150&port=8081&tries=1'] Namespace:pod-network-test-5385 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:34:39.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:34:39.467: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:34:39.467: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5385/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.226.43%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.189.150%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 29 13:34:39.545: INFO: Waiting for responses: map[]
  Apr 29 13:34:39.545: INFO: reached 192.168.189.150 after 0/1 tries
  Apr 29 13:34:39.545: INFO: Breadth first check of 192.168.226.44 on host 172.31.41.80...
  Apr 29 13:34:39.549: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.226.43:9080/dial?request=hostname&protocol=udp&host=192.168.226.44&port=8081&tries=1'] Namespace:pod-network-test-5385 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:34:39.549: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:34:39.549: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:34:39.549: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5385/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.226.43%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.226.44%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 29 13:34:39.603: INFO: Waiting for responses: map[]
  Apr 29 13:34:39.603: INFO: reached 192.168.226.44 after 0/1 tries
  Apr 29 13:34:39.603: INFO: Breadth first check of 192.168.69.248 on host 172.31.82.46...
  Apr 29 13:34:39.607: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.226.43:9080/dial?request=hostname&protocol=udp&host=192.168.69.248&port=8081&tries=1'] Namespace:pod-network-test-5385 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 29 13:34:39.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  Apr 29 13:34:39.607: INFO: ExecWithOptions: Clientset creation
  Apr 29 13:34:39.607: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5385/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.226.43%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.69.248%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 29 13:34:39.668: INFO: Waiting for responses: map[]
  Apr 29 13:34:39.668: INFO: reached 192.168.69.248 after 0/1 tries
  Apr 29 13:34:39.668: INFO: Going to retry 0 out of 3 pods....
  Apr 29 13:34:39.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-5385" for this suite. @ 04/29/23 13:34:39.673
• [24.366 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 04/29/23 13:34:39.68
  Apr 29 13:34:39.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replication-controller @ 04/29/23 13:34:39.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:34:39.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:34:39.699
  STEP: Creating replication controller my-hostname-basic-bdbc5933-ddf8-4dea-9cfa-2a4aff3d7975 @ 04/29/23 13:34:39.703
  Apr 29 13:34:39.711: INFO: Pod name my-hostname-basic-bdbc5933-ddf8-4dea-9cfa-2a4aff3d7975: Found 0 pods out of 1
  Apr 29 13:34:44.718: INFO: Pod name my-hostname-basic-bdbc5933-ddf8-4dea-9cfa-2a4aff3d7975: Found 1 pods out of 1
  Apr 29 13:34:44.718: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-bdbc5933-ddf8-4dea-9cfa-2a4aff3d7975" are running
  Apr 29 13:34:44.722: INFO: Pod "my-hostname-basic-bdbc5933-ddf8-4dea-9cfa-2a4aff3d7975-bwkcg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-29 13:34:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-29 13:34:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-29 13:34:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-29 13:34:39 +0000 UTC Reason: Message:}])
  Apr 29 13:34:44.722: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/29/23 13:34:44.722
  Apr 29 13:34:44.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7398" for this suite. @ 04/29/23 13:34:44.74
• [5.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 04/29/23 13:34:44.752
  Apr 29 13:34:44.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename dns @ 04/29/23 13:34:44.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:34:44.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:34:44.775
  STEP: Creating a test headless service @ 04/29/23 13:34:44.781
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7676 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7676;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7676 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7676;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7676.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7676.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7676.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7676.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7676.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7676.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7676.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7676.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7676.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7676.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7676.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7676.svc;check="$$(dig +notcp +noall +answer +search 231.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.231_udp@PTR;check="$$(dig +tcp +noall +answer +search 231.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.231_tcp@PTR;sleep 1; done
   @ 04/29/23 13:34:44.813
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7676 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7676;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7676 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7676;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7676.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7676.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7676.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7676.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7676.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7676.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7676.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7676.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7676.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7676.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7676.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7676.svc;check="$$(dig +notcp +noall +answer +search 231.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.231_udp@PTR;check="$$(dig +tcp +noall +answer +search 231.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.231_tcp@PTR;sleep 1; done
   @ 04/29/23 13:34:44.814
  STEP: creating a pod to probe DNS @ 04/29/23 13:34:44.814
  STEP: submitting the pod to kubernetes @ 04/29/23 13:34:44.814
  STEP: retrieving the pod @ 04/29/23 13:34:46.85
  STEP: looking for the results for each expected name from probers @ 04/29/23 13:34:46.853
  Apr 29 13:34:46.858: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.861: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.865: INFO: Unable to read wheezy_udp@dns-test-service.dns-7676 from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.868: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7676 from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.872: INFO: Unable to read wheezy_udp@dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.875: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.879: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.882: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.900: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.903: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.907: INFO: Unable to read jessie_udp@dns-test-service.dns-7676 from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.910: INFO: Unable to read jessie_tcp@dns-test-service.dns-7676 from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.914: INFO: Unable to read jessie_udp@dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.917: INFO: Unable to read jessie_tcp@dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.921: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.924: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:46.938: INFO: Lookups using dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7676 wheezy_tcp@dns-test-service.dns-7676 wheezy_udp@dns-test-service.dns-7676.svc wheezy_tcp@dns-test-service.dns-7676.svc wheezy_udp@_http._tcp.dns-test-service.dns-7676.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7676.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7676 jessie_tcp@dns-test-service.dns-7676 jessie_udp@dns-test-service.dns-7676.svc jessie_tcp@dns-test-service.dns-7676.svc jessie_udp@_http._tcp.dns-test-service.dns-7676.svc jessie_tcp@_http._tcp.dns-test-service.dns-7676.svc]

  Apr 29 13:34:51.968: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:51.988: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:51.992: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:51.995: INFO: Unable to read jessie_udp@dns-test-service.dns-7676 from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:51.999: INFO: Unable to read jessie_tcp@dns-test-service.dns-7676 from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:52.002: INFO: Unable to read jessie_udp@dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:52.006: INFO: Unable to read jessie_tcp@dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:52.009: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:52.013: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7676.svc from pod dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd: the server could not find the requested resource (get pods dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd)
  Apr 29 13:34:52.028: INFO: Lookups using dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-7676.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7676 jessie_tcp@dns-test-service.dns-7676 jessie_udp@dns-test-service.dns-7676.svc jessie_tcp@dns-test-service.dns-7676.svc jessie_udp@_http._tcp.dns-test-service.dns-7676.svc jessie_tcp@_http._tcp.dns-test-service.dns-7676.svc]

  Apr 29 13:34:57.026: INFO: DNS probes using dns-7676/dns-test-88907ca7-d9d4-4676-86d6-7e7fbe7388bd succeeded

  Apr 29 13:34:57.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:34:57.03
  STEP: deleting the test service @ 04/29/23 13:34:57.056
  STEP: deleting the test headless service @ 04/29/23 13:34:57.08
  STEP: Destroying namespace "dns-7676" for this suite. @ 04/29/23 13:34:57.096
• [12.351 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 04/29/23 13:34:57.104
  Apr 29 13:34:57.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:34:57.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:34:57.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:34:57.122
  STEP: Creating configMap with name configmap-projected-all-test-volume-a10db3f7-6fa1-4c3d-88ee-cabf804a31ca @ 04/29/23 13:34:57.125
  STEP: Creating secret with name secret-projected-all-test-volume-e48b4db5-d6a8-46a0-94e0-38b137ee1ad4 @ 04/29/23 13:34:57.13
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 04/29/23 13:34:57.134
  STEP: Saw pod success @ 04/29/23 13:35:01.158
  Apr 29 13:35:01.162: INFO: Trying to get logs from node ip-172-31-41-80 pod projected-volume-3001865a-beb7-45a8-9c16-4bfec06b1726 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 13:35:01.169
  Apr 29 13:35:01.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2250" for this suite. @ 04/29/23 13:35:01.189
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 04/29/23 13:35:01.199
  Apr 29 13:35:01.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename disruption @ 04/29/23 13:35:01.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:35:01.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:35:01.217
  STEP: Creating a pdb that targets all three pods in a test replica set @ 04/29/23 13:35:01.22
  STEP: Waiting for the pdb to be processed @ 04/29/23 13:35:01.226
  STEP: First trying to evict a pod which shouldn't be evictable @ 04/29/23 13:35:03.239
  STEP: Waiting for all pods to be running @ 04/29/23 13:35:03.239
  Apr 29 13:35:03.243: INFO: pods: 0 < 3
  STEP: locating a running pod @ 04/29/23 13:35:05.248
  STEP: Updating the pdb to allow a pod to be evicted @ 04/29/23 13:35:05.258
  STEP: Waiting for the pdb to be processed @ 04/29/23 13:35:05.268
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/29/23 13:35:07.277
  STEP: Waiting for all pods to be running @ 04/29/23 13:35:07.277
  STEP: Waiting for the pdb to observed all healthy pods @ 04/29/23 13:35:07.281
  STEP: Patching the pdb to disallow a pod to be evicted @ 04/29/23 13:35:07.308
  STEP: Waiting for the pdb to be processed @ 04/29/23 13:35:07.332
  STEP: Waiting for all pods to be running @ 04/29/23 13:35:07.337
  Apr 29 13:35:07.343: INFO: running pods: 2 < 3
  STEP: locating a running pod @ 04/29/23 13:35:09.348
  STEP: Deleting the pdb to allow a pod to be evicted @ 04/29/23 13:35:09.359
  STEP: Waiting for the pdb to be deleted @ 04/29/23 13:35:09.366
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/29/23 13:35:09.369
  STEP: Waiting for all pods to be running @ 04/29/23 13:35:09.369
  Apr 29 13:35:09.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-976" for this suite. @ 04/29/23 13:35:09.392
• [8.204 seconds]
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 04/29/23 13:35:09.403
  Apr 29 13:35:09.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:35:09.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:35:09.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:35:09.428
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-37f557cd-fd61-47dd-aacc-40c6d10598ab @ 04/29/23 13:35:09.439
  STEP: Creating the pod @ 04/29/23 13:35:09.443
  STEP: Updating configmap projected-configmap-test-upd-37f557cd-fd61-47dd-aacc-40c6d10598ab @ 04/29/23 13:35:11.473
  STEP: waiting to observe update in volume @ 04/29/23 13:35:11.478
  Apr 29 13:36:13.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8500" for this suite. @ 04/29/23 13:36:13.755
• [64.358 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 04/29/23 13:36:13.765
  Apr 29 13:36:13.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:36:13.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:13.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:13.788
  STEP: Creating secret with name projected-secret-test-1ebabb95-0e99-403d-bdf3-780cee31909f @ 04/29/23 13:36:13.791
  STEP: Creating a pod to test consume secrets @ 04/29/23 13:36:13.797
  STEP: Saw pod success @ 04/29/23 13:36:17.82
  Apr 29 13:36:17.824: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-secrets-b3d2f773-ae66-4378-9563-d58cc463235f container secret-volume-test: <nil>
  STEP: delete the pod @ 04/29/23 13:36:17.831
  Apr 29 13:36:17.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2481" for this suite. @ 04/29/23 13:36:17.852
• [4.093 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 04/29/23 13:36:17.858
  Apr 29 13:36:17.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 13:36:17.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:17.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:17.877
  STEP: Creating the pod @ 04/29/23 13:36:17.881
  Apr 29 13:36:20.421: INFO: Successfully updated pod "annotationupdateb348511d-cd48-41c3-b870-39251472fd8a"
  Apr 29 13:36:22.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7941" for this suite. @ 04/29/23 13:36:22.44
• [4.589 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 04/29/23 13:36:22.448
  Apr 29 13:36:22.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 13:36:22.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:22.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:22.469
  STEP: creating the pod @ 04/29/23 13:36:22.472
  STEP: submitting the pod to kubernetes @ 04/29/23 13:36:22.473
  STEP: verifying QOS class is set on the pod @ 04/29/23 13:36:22.48
  Apr 29 13:36:22.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8441" for this suite. @ 04/29/23 13:36:22.488
• [0.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 04/29/23 13:36:22.499
  Apr 29 13:36:22.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename services @ 04/29/23 13:36:22.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:22.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:22.518
  STEP: creating service endpoint-test2 in namespace services-5216 @ 04/29/23 13:36:22.521
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5216 to expose endpoints map[] @ 04/29/23 13:36:22.533
  Apr 29 13:36:22.539: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  Apr 29 13:36:23.550: INFO: successfully validated that service endpoint-test2 in namespace services-5216 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-5216 @ 04/29/23 13:36:23.55
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5216 to expose endpoints map[pod1:[80]] @ 04/29/23 13:36:25.574
  Apr 29 13:36:25.585: INFO: successfully validated that service endpoint-test2 in namespace services-5216 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 04/29/23 13:36:25.585
  Apr 29 13:36:25.585: INFO: Creating new exec pod
  Apr 29 13:36:28.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-5216 exec execpods4hk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 29 13:36:28.715: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 29 13:36:28.715: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:36:28.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-5216 exec execpods4hk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.249 80'
  Apr 29 13:36:28.846: INFO: stderr: "+ nc -v -t -w 2 10.152.183.249 80\nConnection to 10.152.183.249 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Apr 29 13:36:28.846: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-5216 @ 04/29/23 13:36:28.846
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5216 to expose endpoints map[pod1:[80] pod2:[80]] @ 04/29/23 13:36:30.869
  Apr 29 13:36:30.890: INFO: successfully validated that service endpoint-test2 in namespace services-5216 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 04/29/23 13:36:30.89
  Apr 29 13:36:31.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-5216 exec execpods4hk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 29 13:36:32.016: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 29 13:36:32.016: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:36:32.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-5216 exec execpods4hk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.249 80'
  Apr 29 13:36:32.134: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.249 80\nConnection to 10.152.183.249 80 port [tcp/http] succeeded!\n"
  Apr 29 13:36:32.134: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-5216 @ 04/29/23 13:36:32.134
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5216 to expose endpoints map[pod2:[80]] @ 04/29/23 13:36:32.152
  Apr 29 13:36:33.179: INFO: successfully validated that service endpoint-test2 in namespace services-5216 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 04/29/23 13:36:33.179
  Apr 29 13:36:34.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-5216 exec execpods4hk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 29 13:36:34.304: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 29 13:36:34.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 29 13:36:34.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=services-5216 exec execpods4hk2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.249 80'
  Apr 29 13:36:34.427: INFO: stderr: "+ nc -v -t -w 2 10.152.183.249 80\n+ echo hostName\nConnection to 10.152.183.249 80 port [tcp/http] succeeded!\n"
  Apr 29 13:36:34.427: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-5216 @ 04/29/23 13:36:34.427
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5216 to expose endpoints map[] @ 04/29/23 13:36:34.448
  Apr 29 13:36:35.481: INFO: successfully validated that service endpoint-test2 in namespace services-5216 exposes endpoints map[]
  Apr 29 13:36:35.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5216" for this suite. @ 04/29/23 13:36:35.514
• [13.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 04/29/23 13:36:35.523
  Apr 29 13:36:35.523: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename configmap @ 04/29/23 13:36:35.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:35.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:35.547
  STEP: Creating configMap with name configmap-test-volume-85bdaa00-01e4-4ba0-b8a8-865163eca07d @ 04/29/23 13:36:35.55
  STEP: Creating a pod to test consume configMaps @ 04/29/23 13:36:35.556
  STEP: Saw pod success @ 04/29/23 13:36:39.583
  Apr 29 13:36:39.587: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-configmaps-298be571-a1be-49c7-96fc-aae80685f806 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 13:36:39.599
  Apr 29 13:36:39.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3974" for this suite. @ 04/29/23 13:36:39.621
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 04/29/23 13:36:39.631
  Apr 29 13:36:39.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename pods @ 04/29/23 13:36:39.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:39.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:39.652
  STEP: Create set of pods @ 04/29/23 13:36:39.656
  Apr 29 13:36:39.666: INFO: created test-pod-1
  Apr 29 13:36:39.675: INFO: created test-pod-2
  Apr 29 13:36:39.682: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 04/29/23 13:36:39.682
  STEP: waiting for all pods to be deleted @ 04/29/23 13:36:43.745
  Apr 29 13:36:43.748: INFO: Pod quantity 3 is different from expected quantity 0
  Apr 29 13:36:44.753: INFO: Pod quantity 3 is different from expected quantity 0
  Apr 29 13:36:45.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4216" for this suite. @ 04/29/23 13:36:45.757
• [6.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 04/29/23 13:36:45.767
  Apr 29 13:36:45.767: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:36:45.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:45.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:45.803
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 13:36:45.807
  STEP: Saw pod success @ 04/29/23 13:36:49.826
  Apr 29 13:36:49.830: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-3957eafa-41bf-4a57-9247-833929a5829b container client-container: <nil>
  STEP: delete the pod @ 04/29/23 13:36:49.843
  Apr 29 13:36:49.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3449" for this suite. @ 04/29/23 13:36:49.864
• [4.103 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 04/29/23 13:36:49.87
  Apr 29 13:36:49.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename resourcequota @ 04/29/23 13:36:49.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:49.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:49.89
  STEP: Counting existing ResourceQuota @ 04/29/23 13:36:49.894
  STEP: Creating a ResourceQuota @ 04/29/23 13:36:54.898
  STEP: Ensuring resource quota status is calculated @ 04/29/23 13:36:54.902
  Apr 29 13:36:56.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6357" for this suite. @ 04/29/23 13:36:56.912
• [7.048 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 04/29/23 13:36:56.919
  Apr 29 13:36:56.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 13:36:56.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:36:56.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:36:56.938
  STEP: Creating pod liveness-76d8b551-e875-4a1f-9ebe-3f5141c13b39 in namespace container-probe-7347 @ 04/29/23 13:36:56.942
  Apr 29 13:36:58.958: INFO: Started pod liveness-76d8b551-e875-4a1f-9ebe-3f5141c13b39 in namespace container-probe-7347
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/29/23 13:36:58.958
  Apr 29 13:36:58.961: INFO: Initial restart count of pod liveness-76d8b551-e875-4a1f-9ebe-3f5141c13b39 is 0
  Apr 29 13:37:19.009: INFO: Restart count of pod container-probe-7347/liveness-76d8b551-e875-4a1f-9ebe-3f5141c13b39 is now 1 (20.04835672s elapsed)
  Apr 29 13:37:19.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:37:19.014
  STEP: Destroying namespace "container-probe-7347" for this suite. @ 04/29/23 13:37:19.027
• [22.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 04/29/23 13:37:19.036
  Apr 29 13:37:19.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:37:19.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:37:19.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:37:19.055
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 13:37:19.061
  STEP: Saw pod success @ 04/29/23 13:37:23.084
  Apr 29 13:37:23.087: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-ad191be9-7a6f-444c-a35a-f3f2dfeb9535 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 13:37:23.094
  Apr 29 13:37:23.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3598" for this suite. @ 04/29/23 13:37:23.115
• [4.085 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 04/29/23 13:37:23.122
  Apr 29 13:37:23.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename runtimeclass @ 04/29/23 13:37:23.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:37:23.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:37:23.139
  STEP: Deleting RuntimeClass runtimeclass-5034-delete-me @ 04/29/23 13:37:23.147
  STEP: Waiting for the RuntimeClass to disappear @ 04/29/23 13:37:23.153
  Apr 29 13:37:23.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5034" for this suite. @ 04/29/23 13:37:23.167
• [0.053 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
test/e2e/storage/csi_inline.go:46
  STEP: Creating a kubernetes client @ 04/29/23 13:37:23.175
  Apr 29 13:37:23.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/29/23 13:37:23.176
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:37:23.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:37:23.206
  STEP: creating @ 04/29/23 13:37:23.213
  STEP: getting @ 04/29/23 13:37:23.228
  STEP: listing @ 04/29/23 13:37:23.234
  STEP: deleting @ 04/29/23 13:37:23.238
  Apr 29 13:37:23.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-3111" for this suite. @ 04/29/23 13:37:23.261
• [0.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:370
  STEP: Creating a kubernetes client @ 04/29/23 13:37:23.27
  Apr 29 13:37:23.270: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 13:37:23.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:37:23.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:37:23.289
  STEP: Setting up server cert @ 04/29/23 13:37:23.311
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 13:37:23.541
  STEP: Deploying the webhook pod @ 04/29/23 13:37:23.55
  STEP: Wait for the deployment to be ready @ 04/29/23 13:37:23.562
  Apr 29 13:37:23.572: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/29/23 13:37:25.585
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:37:25.601
  Apr 29 13:37:26.601: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 04/29/23 13:37:26.605
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/29/23 13:37:26.605
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 04/29/23 13:37:26.619
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 04/29/23 13:37:27.631
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/29/23 13:37:27.631
  STEP: Having no error when timeout is longer than webhook latency @ 04/29/23 13:37:28.659
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/29/23 13:37:28.659
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 04/29/23 13:37:33.702
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/29/23 13:37:33.702
  Apr 29 13:37:38.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4197" for this suite. @ 04/29/23 13:37:38.801
  STEP: Destroying namespace "webhook-markers-3971" for this suite. @ 04/29/23 13:37:38.807
• [15.543 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 04/29/23 13:37:38.814
  Apr 29 13:37:38.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-probe @ 04/29/23 13:37:38.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:37:38.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:37:38.834
  STEP: Creating pod busybox-c793f229-c9c4-442a-998a-91884dfbf16c in namespace container-probe-6997 @ 04/29/23 13:37:38.838
  Apr 29 13:37:40.855: INFO: Started pod busybox-c793f229-c9c4-442a-998a-91884dfbf16c in namespace container-probe-6997
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/29/23 13:37:40.855
  Apr 29 13:37:40.858: INFO: Initial restart count of pod busybox-c793f229-c9c4-442a-998a-91884dfbf16c is 0
  Apr 29 13:38:30.977: INFO: Restart count of pod container-probe-6997/busybox-c793f229-c9c4-442a-998a-91884dfbf16c is now 1 (50.118445212s elapsed)
  Apr 29 13:38:30.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/29/23 13:38:30.981
  STEP: Destroying namespace "container-probe-6997" for this suite. @ 04/29/23 13:38:30.995
• [52.188 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:70
  STEP: Creating a kubernetes client @ 04/29/23 13:38:31.003
  Apr 29 13:38:31.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename subpath @ 04/29/23 13:38:31.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:38:31.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:38:31.022
  STEP: Setting up data @ 04/29/23 13:38:31.026
  STEP: Creating pod pod-subpath-test-configmap-2qt7 @ 04/29/23 13:38:31.035
  STEP: Creating a pod to test atomic-volume-subpath @ 04/29/23 13:38:31.035
  STEP: Saw pod success @ 04/29/23 13:38:55.109
  Apr 29 13:38:55.112: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-subpath-test-configmap-2qt7 container test-container-subpath-configmap-2qt7: <nil>
  STEP: delete the pod @ 04/29/23 13:38:55.127
  STEP: Deleting pod pod-subpath-test-configmap-2qt7 @ 04/29/23 13:38:55.143
  Apr 29 13:38:55.143: INFO: Deleting pod "pod-subpath-test-configmap-2qt7" in namespace "subpath-1449"
  Apr 29 13:38:55.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1449" for this suite. @ 04/29/23 13:38:55.15
• [24.154 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 04/29/23 13:38:55.157
  Apr 29 13:38:55.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replication-controller @ 04/29/23 13:38:55.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:38:55.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:38:55.177
  STEP: creating a ReplicationController @ 04/29/23 13:38:55.183
  STEP: waiting for RC to be added @ 04/29/23 13:38:55.188
  STEP: waiting for available Replicas @ 04/29/23 13:38:55.189
  STEP: patching ReplicationController @ 04/29/23 13:38:56.107
  STEP: waiting for RC to be modified @ 04/29/23 13:38:56.115
  STEP: patching ReplicationController status @ 04/29/23 13:38:56.115
  STEP: waiting for RC to be modified @ 04/29/23 13:38:56.121
  STEP: waiting for available Replicas @ 04/29/23 13:38:56.121
  STEP: fetching ReplicationController status @ 04/29/23 13:38:56.127
  STEP: patching ReplicationController scale @ 04/29/23 13:38:56.131
  STEP: waiting for RC to be modified @ 04/29/23 13:38:56.136
  STEP: waiting for ReplicationController's scale to be the max amount @ 04/29/23 13:38:56.137
  STEP: fetching ReplicationController; ensuring that it's patched @ 04/29/23 13:38:57.587
  STEP: updating ReplicationController status @ 04/29/23 13:38:57.591
  STEP: waiting for RC to be modified @ 04/29/23 13:38:57.598
  STEP: listing all ReplicationControllers @ 04/29/23 13:38:57.598
  STEP: checking that ReplicationController has expected values @ 04/29/23 13:38:57.602
  STEP: deleting ReplicationControllers by collection @ 04/29/23 13:38:57.602
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 04/29/23 13:38:57.61
  Apr 29 13:38:57.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0429 13:38:57.659065      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-6159" for this suite. @ 04/29/23 13:38:57.663
• [2.512 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 04/29/23 13:38:57.67
  Apr 29 13:38:57.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename gc @ 04/29/23 13:38:57.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:38:57.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:38:57.69
  STEP: create the deployment @ 04/29/23 13:38:57.693
  W0429 13:38:57.699818      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/29/23 13:38:57.7
  STEP: delete the deployment @ 04/29/23 13:38:58.218
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 04/29/23 13:38:58.239
  E0429 13:38:58.660026      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/29/23 13:38:58.761
  W0429 13:38:58.765171      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Apr 29 13:38:58.765: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 29 13:38:58.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2164" for this suite. @ 04/29/23 13:38:58.769
• [1.106 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 04/29/23 13:38:58.776
  Apr 29 13:38:58.776: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename replicaset @ 04/29/23 13:38:58.777
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:38:58.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:38:58.795
  Apr 29 13:38:58.799: INFO: Creating ReplicaSet my-hostname-basic-39c464cb-bcce-4a82-b4c3-418f95b94751
  Apr 29 13:38:58.807: INFO: Pod name my-hostname-basic-39c464cb-bcce-4a82-b4c3-418f95b94751: Found 0 pods out of 1
  E0429 13:38:59.660757      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:00.661299      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:01.661525      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:02.661618      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:03.661714      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 29 13:39:03.816: INFO: Pod name my-hostname-basic-39c464cb-bcce-4a82-b4c3-418f95b94751: Found 1 pods out of 1
  Apr 29 13:39:03.816: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-39c464cb-bcce-4a82-b4c3-418f95b94751" is running
  Apr 29 13:39:03.820: INFO: Pod "my-hostname-basic-39c464cb-bcce-4a82-b4c3-418f95b94751-4z747" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-29 13:38:58 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-29 13:39:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-29 13:39:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-29 13:38:58 +0000 UTC Reason: Message:}])
  Apr 29 13:39:03.820: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/29/23 13:39:03.82
  Apr 29 13:39:03.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8862" for this suite. @ 04/29/23 13:39:03.841
• [5.074 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:198
  STEP: Creating a kubernetes client @ 04/29/23 13:39:03.85
  Apr 29 13:39:03.850: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename webhook @ 04/29/23 13:39:03.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:03.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:03.868
  STEP: Setting up server cert @ 04/29/23 13:39:03.944
  E0429 13:39:04.662007      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/29/23 13:39:04.714
  STEP: Deploying the webhook pod @ 04/29/23 13:39:04.721
  STEP: Wait for the deployment to be ready @ 04/29/23 13:39:04.734
  Apr 29 13:39:04.742: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0429 13:39:05.663106      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:06.663325      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/29/23 13:39:06.754
  STEP: Verifying the service has paired with the endpoint @ 04/29/23 13:39:06.772
  E0429 13:39:07.663420      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 29 13:39:07.772: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/29/23 13:39:07.776
  STEP: create a pod that should be denied by the webhook @ 04/29/23 13:39:07.792
  STEP: create a pod that causes the webhook to hang @ 04/29/23 13:39:07.805
  E0429 13:39:08.663488      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:09.663740      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:10.664142      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:11.664496      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:12.664680      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:13.664857      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:14.665053      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:15.665461      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:16.665787      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:17.665879      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 04/29/23 13:39:17.812
  STEP: create a configmap that should be admitted by the webhook @ 04/29/23 13:39:17.821
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/29/23 13:39:17.83
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/29/23 13:39:17.837
  STEP: create a namespace that bypass the webhook @ 04/29/23 13:39:17.842
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 04/29/23 13:39:17.856
  Apr 29 13:39:17.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7146" for this suite. @ 04/29/23 13:39:17.93
  STEP: Destroying namespace "webhook-markers-5875" for this suite. @ 04/29/23 13:39:17.937
  STEP: Destroying namespace "exempted-namespace-8638" for this suite. @ 04/29/23 13:39:17.943
• [14.099 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 04/29/23 13:39:17.951
  Apr 29 13:39:17.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sysctl @ 04/29/23 13:39:17.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:17.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:17.966
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 04/29/23 13:39:17.974
  STEP: Watching for error events or started pod @ 04/29/23 13:39:17.981
  E0429 13:39:18.666029      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:19.667093      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 04/29/23 13:39:19.986
  E0429 13:39:20.667790      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:21.667881      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 04/29/23 13:39:21.997
  STEP: Getting logs from the pod @ 04/29/23 13:39:21.998
  STEP: Checking that the sysctl is actually updated @ 04/29/23 13:39:22.008
  Apr 29 13:39:22.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-6765" for this suite. @ 04/29/23 13:39:22.012
• [4.068 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 04/29/23 13:39:22.02
  Apr 29 13:39:22.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename sched-pred @ 04/29/23 13:39:22.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:22.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:22.038
  Apr 29 13:39:22.041: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 29 13:39:22.049: INFO: Waiting for terminating namespaces to be deleted...
  Apr 29 13:39:22.053: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-25-13 before test
  Apr 29 13:39:22.058: INFO: nginx-ingress-controller-kubernetes-worker-nktfk from ingress-nginx-kubernetes-worker started at 2023-04-29 11:51:02 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.058: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: coredns-5c7f76ccb8-2lgzt from kube-system started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.058: INFO: 	Container coredns ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: kube-state-metrics-5b95b4459c-9469j from kube-system started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.058: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: metrics-server-v0.5.2-6cf8c8b69c-tsmc5 from kube-system started at 2023-04-29 11:50:57 +0000 UTC (2 container statuses recorded)
  Apr 29 13:39:22.058: INFO: 	Container metrics-server ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: dashboard-metrics-scraper-6b8586b5c9-k9jlf from kubernetes-dashboard started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.058: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: kubernetes-dashboard-6869f4cd5f-w7m8c from kubernetes-dashboard started at 2023-04-29 11:50:57 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.058: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-rvknb from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 13:39:22.058: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 29 13:39:22.058: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-41-80 before test
  Apr 29 13:39:22.063: INFO: nginx-ingress-controller-kubernetes-worker-bt9hj from ingress-nginx-kubernetes-worker started at 2023-04-29 12:17:54 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.063: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 13:39:22.063: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-6rcvs from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 13:39:22.063: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 13:39:22.063: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 29 13:39:22.063: INFO: sysctl-12a61363-7a6d-410a-9908-6986b20a2bd6 from sysctl-6765 started at 2023-04-29 13:39:17 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.063: INFO: 	Container test-container ready: false, restart count 0
  Apr 29 13:39:22.063: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-82-46 before test
  Apr 29 13:39:22.068: INFO: default-http-backend-kubernetes-worker-65fc475d49-mlbzp from ingress-nginx-kubernetes-worker started at 2023-04-29 12:11:40 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.068: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Apr 29 13:39:22.068: INFO: nginx-ingress-controller-kubernetes-worker-m8hc4 from ingress-nginx-kubernetes-worker started at 2023-04-29 11:54:52 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.068: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Apr 29 13:39:22.068: INFO: calico-kube-controllers-577d5b7f57-d6csn from kube-system started at 2023-04-29 12:11:40 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.068: INFO: 	Container calico-kube-controllers ready: true, restart count 0
  Apr 29 13:39:22.068: INFO: sonobuoy from sonobuoy started at 2023-04-29 12:00:46 +0000 UTC (1 container statuses recorded)
  Apr 29 13:39:22.068: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 29 13:39:22.068: INFO: sonobuoy-e2e-job-819b1466a92240b6 from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 13:39:22.068: INFO: 	Container e2e ready: true, restart count 0
  Apr 29 13:39:22.068: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 13:39:22.068: INFO: sonobuoy-systemd-logs-daemon-set-19f35592372d4c0d-hpjk5 from sonobuoy started at 2023-04-29 12:00:48 +0000 UTC (2 container statuses recorded)
  Apr 29 13:39:22.068: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 29 13:39:22.068: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 04/29/23 13:39:22.068
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.175a6b753eeac564], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling..] @ 04/29/23 13:39:22.092
  E0429 13:39:22.668947      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 29 13:39:23.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7742" for this suite. @ 04/29/23 13:39:23.1
• [1.089 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 04/29/23 13:39:23.109
  Apr 29 13:39:23.109: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename ingressclass @ 04/29/23 13:39:23.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:23.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:23.132
  STEP: getting /apis @ 04/29/23 13:39:23.137
  STEP: getting /apis/networking.k8s.io @ 04/29/23 13:39:23.142
  STEP: getting /apis/networking.k8s.iov1 @ 04/29/23 13:39:23.144
  STEP: creating @ 04/29/23 13:39:23.146
  STEP: getting @ 04/29/23 13:39:23.166
  STEP: listing @ 04/29/23 13:39:23.171
  STEP: watching @ 04/29/23 13:39:23.175
  Apr 29 13:39:23.175: INFO: starting watch
  STEP: patching @ 04/29/23 13:39:23.177
  STEP: updating @ 04/29/23 13:39:23.186
  Apr 29 13:39:23.192: INFO: waiting for watch events with expected annotations
  Apr 29 13:39:23.192: INFO: saw patched and updated annotations
  STEP: deleting @ 04/29/23 13:39:23.192
  STEP: deleting a collection @ 04/29/23 13:39:23.211
  Apr 29 13:39:23.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-5704" for this suite. @ 04/29/23 13:39:23.234
• [0.131 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 04/29/23 13:39:23.241
  Apr 29 13:39:23.241: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/29/23 13:39:23.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:23.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:23.259
  STEP: create the container to handle the HTTPGet hook request. @ 04/29/23 13:39:23.266
  E0429 13:39:23.669556      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:24.669948      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/29/23 13:39:25.289
  E0429 13:39:25.670710      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:26.670848      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/29/23 13:39:27.307
  E0429 13:39:27.671619      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:28.671695      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/29/23 13:39:29.324
  Apr 29 13:39:29.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7556" for this suite. @ 04/29/23 13:39:29.348
• [6.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 04/29/23 13:39:29.358
  Apr 29 13:39:29.358: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename downward-api @ 04/29/23 13:39:29.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:29.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:29.377
  STEP: Creating a pod to test downward API volume plugin @ 04/29/23 13:39:29.38
  E0429 13:39:29.672552      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:30.672650      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:31.672686      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:32.672793      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/29/23 13:39:33.402
  Apr 29 13:39:33.406: INFO: Trying to get logs from node ip-172-31-41-80 pod downwardapi-volume-6d95ecef-db3e-463e-b77f-6d182b46f9d6 container client-container: <nil>
  STEP: delete the pod @ 04/29/23 13:39:33.412
  Apr 29 13:39:33.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6723" for this suite. @ 04/29/23 13:39:33.43
• [4.080 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1775
  STEP: Creating a kubernetes client @ 04/29/23 13:39:33.438
  Apr 29 13:39:33.438: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 13:39:33.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:33.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:33.455
  STEP: starting the proxy server @ 04/29/23 13:39:33.458
  Apr 29 13:39:33.458: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8384 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 04/29/23 13:39:33.5
  Apr 29 13:39:33.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8384" for this suite. @ 04/29/23 13:39:33.514
• [0.082 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 04/29/23 13:39:33.521
  Apr 29 13:39:33.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename projected @ 04/29/23 13:39:33.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:33.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:33.541
  STEP: Creating configMap with name projected-configmap-test-volume-map-546fe660-0a29-4349-852f-8ed7e16377b4 @ 04/29/23 13:39:33.544
  STEP: Creating a pod to test consume configMaps @ 04/29/23 13:39:33.548
  E0429 13:39:33.673588      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:34.673728      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:35.674597      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0429 13:39:36.674730      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/29/23 13:39:37.57
  Apr 29 13:39:37.573: INFO: Trying to get logs from node ip-172-31-41-80 pod pod-projected-configmaps-70fbc12f-4425-416e-b845-fe3246f3b2d3 container agnhost-container: <nil>
  STEP: delete the pod @ 04/29/23 13:39:37.58
  Apr 29 13:39:37.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4230" for this suite. @ 04/29/23 13:39:37.602
• [4.089 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1800
  STEP: Creating a kubernetes client @ 04/29/23 13:39:37.61
  Apr 29 13:39:37.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename kubectl @ 04/29/23 13:39:37.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:37.623
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:37.627
  STEP: Starting the proxy @ 04/29/23 13:39:37.634
  Apr 29 13:39:37.634: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2192039500 --namespace=kubectl-8203 proxy --unix-socket=/tmp/kubectl-proxy-unix1956804398/test'
  E0429 13:39:37.675611      18 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving proxy /api/ output @ 04/29/23 13:39:37.68
  Apr 29 13:39:37.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8203" for this suite. @ 04/29/23 13:39:37.685
• [0.081 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 04/29/23 13:39:37.691
  Apr 29 13:39:37.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2192039500
  STEP: Building a namespace api object, basename watch @ 04/29/23 13:39:37.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/29/23 13:39:37.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/29/23 13:39:37.71
  STEP: creating a watch on configmaps @ 04/29/23 13:39:37.713
  STEP: creating a new configmap @ 04/29/23 13:39:37.715
  STEP: modifying the configmap once @ 04/29/23 13:39:37.719
  STEP: closing the watch once it receives two notifications @ 04/29/23 13:39:37.728
  Apr 29 13:39:37.728: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7210  0d580e00-e9be-4a50-b069-66e30811d0d7 43893 0 2023-04-29 13:39:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-29 13:39:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 13:39:37.728: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7210  0d580e00-e9be-4a50-b069-66e30811d0d7 43894 0 2023-04-29 13:39:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-29 13:39:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 04/29/23 13:39:37.729
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 04/29/23 13:39:37.736
  STEP: deleting the configmap @ 04/29/23 13:39:37.737
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 04/29/23 13:39:37.744
  Apr 29 13:39:37.744: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7210  0d580e00-e9be-4a50-b069-66e30811d0d7 43895 0 2023-04-29 13:39:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-29 13:39:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 13:39:37.744: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7210  0d580e00-e9be-4a50-b069-66e30811d0d7 43896 0 2023-04-29 13:39:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-29 13:39:37 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 29 13:39:37.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7210" for this suite. @ 04/29/23 13:39:37.748
• [0.064 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Apr 29 13:39:37.756: INFO: Running AfterSuite actions on node 1
  Apr 29 13:39:37.756: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:152
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:593
[ReportAfterSuite] PASSED [0.046 seconds]
------------------------------

Ran 378 of 7207 Specs in 5917.675 seconds
SUCCESS! -- 378 Passed | 0 Failed | 0 Pending | 6829 Skipped
PASS

Ginkgo ran 1 suite in 1h38m38.055823825s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.9.1[0m

