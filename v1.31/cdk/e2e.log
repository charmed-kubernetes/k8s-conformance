  I1130 12:13:46.462621      19 e2e.go:109] Starting e2e run "d87efc80-85e9-45de-a155-d58a801812e9" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1732968825 - will randomize all specs

Will run 404 of 6605 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:154
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I1130 12:13:46.707871 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:13:46.709035 19 helper.go:48] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I1130 12:13:46.747425 19 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I1130 12:13:46.752989 19 e2e.go:153] 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  I1130 12:13:46.753051 19 e2e.go:245] e2e test version: v1.31.3
  I1130 12:13:46.754430 19 e2e.go:254] kube-apiserver version: v1.31.3
  I1130 12:13:46.754586 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:13:46.759551 19 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.052 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 11/30/24 12:13:46.969
  I1130 12:13:46.969529 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename cronjob @ 11/30/24 12:13:46.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:13:46.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:13:46.999
  STEP: Creating a ForbidConcurrent cronjob @ 11/30/24 12:13:47.003
  STEP: Ensuring a job is scheduled @ 11/30/24 12:13:47.009
  STEP: Ensuring exactly one is scheduled @ 11/30/24 12:14:01.016
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 11/30/24 12:14:01.02
  STEP: Ensuring no more jobs are scheduled @ 11/30/24 12:14:01.025
  STEP: Removing cronjob @ 11/30/24 12:14:01.03
  I1130 12:14:01.040163 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9672" for this suite. @ 11/30/24 12:14:01.045
• [14.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 11/30/24 12:14:01.054
  I1130 12:14:01.054157 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 12:14:01.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:14:01.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:14:01.076
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 11/30/24 12:14:01.079
  STEP: Saw pod success @ 11/30/24 12:14:07.114
  I1130 12:14:07.118513 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-746ba619-cde7-4baa-b6ae-04c49d0201fb container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:14:07.135
  I1130 12:14:07.154608 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6119" for this suite. @ 11/30/24 12:14:07.158
• [6.112 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 11/30/24 12:14:07.165
  I1130 12:14:07.165942 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename deployment @ 11/30/24 12:14:07.166
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:14:07.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:14:07.192
  I1130 12:14:07.196301 19 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I1130 12:14:07.207676 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I1130 12:14:12.211851 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 11/30/24 12:14:12.211
  I1130 12:14:12.211928 19 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I1130 12:14:12.217440 19 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I1130 12:14:12.225020 19 deployment.go:222] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  I1130 12:14:14.235440 19 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I1130 12:14:14.240027 19 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I1130 12:14:14.252336 19 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6521",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6e35bab2-22b3-4210-85c2-17d7b7ac91a6",
      ResourceVersion: (string) (len=4) "4842",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868565652,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-56bb5bb765\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1130 12:14:14.257833 19 deployment.go:39] New ReplicaSet "test-rolling-update-deployment-56bb5bb765" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-56bb5bb765",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6521",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "449348be-142a-468a-ad6f-cb297b3ae0db",
      ResourceVersion: (string) (len=4) "4832",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868565652,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "6e35bab2-22b3-4210-85c2-17d7b7ac91a6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 65 33 35 62 61  62 32 2d 32 32 62 33 2d  |\"6e35bab2-22b3-|
              00000120  34 32 31 30 2d 38 35 63  32 2d 31 37 64 37 62 37  |4210-85c2-17d7b7|
              00000130  61 63 39 31 61 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |ac91a6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765",
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:14:14.258312 19 deployment.go:44] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I1130 12:14:14.258649 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6521",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9fb7350f-9ae8-4cc5-86cc-abed5cdd6745",
      ResourceVersion: (string) (len=4) "4841",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868565647,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "6e35bab2-22b3-4210-85c2-17d7b7ac91a6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565647,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 36 65 33 35 62 61 62  |"uid\":\"6e35bab|
              000000b0  32 2d 32 32 62 33 2d 34  32 31 30 2d 38 35 63 32  |2-22b3-4210-85c2|
              000000c0  2d 31 37 64 37 62 37 61  63 39 31 61 36 5c 22 7d  |-17d7b7ac91a6\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:14:14.263162 19 deployment.go:67] Pod "test-rolling-update-deployment-56bb5bb765-4rdkk" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-56bb5bb765-4rdkk",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-56bb5bb765-",
      Namespace: (string) (len=15) "deployment-6521",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4bdbf821-b97c-4d34-91ae-95ad0d8d72da",
      ResourceVersion: (string) (len=4) "4831",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868565652,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-56bb5bb765",
          UID: (types.UID) (len=36) "449348be-142a-468a-ad6f-cb297b3ae0db",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 34  39 33 34 38 62 65 2d 31  |d\":\"449348be-1|
              00000090  34 32 61 2d 34 36 38 61  2d 61 64 36 66 2d 63 62  |42a-468a-ad6f-cb|
              000000a0  32 39 37 62 33 61 65 30  64 62 5c 22 7d 22 3a 7b  |297b3ae0db\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 31 39 36 5c 22 7d  |2.168.244.196\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zxl9f",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zxl9f",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868565652,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.196",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.196"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868565652,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868565652,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6",
          ContainerID: (string) (len=77) "containerd://d2c7b7e2e34208866c7a55ceb6c0407ca7ed28c6fee0692a1f90cf2b530f8581",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-zxl9f",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:14:14.264124 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6521" for this suite. @ 11/30/24 12:14:14.268
• [7.110 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1756
  STEP: Creating a kubernetes client @ 11/30/24 12:14:14.276
  I1130 12:14:14.276465 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 12:14:14.276
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:14:14.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:14:14.316
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 11/30/24 12:14:14.319
  I1130 12:14:14.319201 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-6297 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I1130 12:14:14.384978 19 builder.go:146] stderr: ""
  I1130 12:14:14.385016 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 11/30/24 12:14:14.385
  I1130 12:14:14.389026 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-6297 delete pods e2e-test-httpd-pod'
  I1130 12:14:16.143687 19 builder.go:146] stderr: ""
  I1130 12:14:16.143724 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I1130 12:14:16.143945 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6297" for this suite. @ 11/30/24 12:14:16.148
• [1.885 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 11/30/24 12:14:16.161
  I1130 12:14:16.161490 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-pred @ 11/30/24 12:14:16.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:14:16.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:14:16.193
  I1130 12:14:16.200288 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I1130 12:14:16.210942 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1130 12:14:16.216318 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-4-119 before test
  I1130 12:14:16.223124 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-24r2d from ingress-nginx-kubernetes-worker started at 2024-11-30 12:02:13 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.223404 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1130 12:14:16.223575 19 predicates.go:957] calico-node-m9zjm from kube-system started at 2024-11-30 12:09:48 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.223688 19 predicates.go:959] 	Container calico-node ready: true, restart count 1
  I1130 12:14:16.223799 19 predicates.go:957] sonobuoy-e2e-job-046772c140634943 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 12:14:16.223922 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I1130 12:14:16.224022 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 12:14:16.224135 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-rn6l7 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 12:14:16.224243 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 12:14:16.224347 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1130 12:14:16.224459 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-64-147 before test
  I1130 12:14:16.230779 19 predicates.go:957] forbid-28882814-gw6xp from cronjob-9672 started at 2024-11-30 12:14:00 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.231008 19 predicates.go:959] 	Container c ready: true, restart count 0
  I1130 12:14:16.231226 19 predicates.go:957] test-rolling-update-deployment-56bb5bb765-4rdkk from deployment-6521 started at 2024-11-30 12:14:12 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.231342 19 predicates.go:959] 	Container agnhost ready: true, restart count 0
  I1130 12:14:16.231354 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-g24x9 from ingress-nginx-kubernetes-worker started at 2024-11-30 12:02:44 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.231360 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1130 12:14:16.231384 19 predicates.go:957] calico-node-5dksp from kube-system started at 2024-11-30 12:09:37 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.231389 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1130 12:14:16.231396 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-11-30 12:13:35 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.231400 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I1130 12:14:16.231406 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-sv7v4 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 12:14:16.231412 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 12:14:16.231417 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1130 12:14:16.231423 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-94-166 before test
  I1130 12:14:16.247404 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-5gx7b from ingress-nginx-kubernetes-worker started at 2024-11-30 11:59:40 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.247432 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 2
  I1130 12:14:16.247439 19 predicates.go:957] calico-node-n82d2 from kube-system started at 2024-11-30 12:08:48 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.247444 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1130 12:14:16.247450 19 predicates.go:957] coredns-5b4857d7c8-d9dkl from kube-system started at 2024-11-30 11:59:41 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.247455 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I1130 12:14:16.247465 19 predicates.go:957] kube-state-metrics-5d7bdccd49-hn4gf from kube-system started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.247469 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 5
  I1130 12:14:16.247543 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-w2q4q from kube-system started at 2024-11-30 11:59:41 +0000 UTC (2 container statuses recorded)
  I1130 12:14:16.247552 19 predicates.go:959] 	Container metrics-server ready: true, restart count 0
  I1130 12:14:16.247557 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I1130 12:14:16.247563 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-6hwh9 from kubernetes-dashboard started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.247568 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I1130 12:14:16.247590 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-d5v6d from kubernetes-dashboard started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 12:14:16.247595 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 2
  I1130 12:14:16.247602 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-x97pk from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 12:14:16.247607 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 12:14:16.247613 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 11/30/24 12:14:16.247
  STEP: Explicitly delete pod here to free the resource it takes. @ 11/30/24 12:14:18.275
  STEP: Trying to apply a random label on the found node. @ 11/30/24 12:14:18.294
  STEP: verifying the node has the label kubernetes.io/e2e-e2fff7bd-6dfb-4e9d-a8a2-a42ae71c3c4c 95 @ 11/30/24 12:14:18.304
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 11/30/24 12:14:18.308
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.4.119 on the node which pod4 resides and expect not scheduled @ 11/30/24 12:14:22.329
  STEP: removing the label kubernetes.io/e2e-e2fff7bd-6dfb-4e9d-a8a2-a42ae71c3c4c off the node ip-172-31-4-119 @ 11/30/24 12:19:22.339
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-e2fff7bd-6dfb-4e9d-a8a2-a42ae71c3c4c @ 11/30/24 12:19:22.353
  I1130 12:19:22.357655 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8246" for this suite. @ 11/30/24 12:19:22.366
• [306.215 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 11/30/24 12:19:22.376
  I1130 12:19:22.376569 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replication-controller @ 11/30/24 12:19:22.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:19:22.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:19:22.402
  STEP: Creating ReplicationController "e2e-rc-bspwb" @ 11/30/24 12:19:22.41
  I1130 12:19:22.417041 19 rc.go:792] Get Replication Controller "e2e-rc-bspwb" to confirm replicas
  I1130 12:19:23.417252 19 rc.go:792] Get Replication Controller "e2e-rc-bspwb" to confirm replicas
  I1130 12:19:23.422504 19 rc.go:801] Found 1 replicas for "e2e-rc-bspwb" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-bspwb" @ 11/30/24 12:19:23.422
  STEP: Updating a scale subresource @ 11/30/24 12:19:23.426
  STEP: Verifying replicas where modified for replication controller "e2e-rc-bspwb" @ 11/30/24 12:19:23.433
  I1130 12:19:23.433563 19 rc.go:792] Get Replication Controller "e2e-rc-bspwb" to confirm replicas
  I1130 12:19:24.434408 19 rc.go:792] Get Replication Controller "e2e-rc-bspwb" to confirm replicas
  I1130 12:19:24.439271 19 rc.go:801] Found 2 replicas for "e2e-rc-bspwb" replication controller
  I1130 12:19:24.439444 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5300" for this suite. @ 11/30/24 12:19:24.444
• [2.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:673
  STEP: Creating a kubernetes client @ 11/30/24 12:19:24.452
  I1130 12:19:24.452681 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename validating-admission-policy @ 11/30/24 12:19:24.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:19:24.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:19:24.476
  STEP: getting /apis @ 11/30/24 12:19:24.486
  STEP: getting /apis/admissionregistration.k8s.io @ 11/30/24 12:19:24.49
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 11/30/24 12:19:24.491
  STEP: creating @ 11/30/24 12:19:24.492
  STEP: getting @ 11/30/24 12:19:24.509
  STEP: listing @ 11/30/24 12:19:24.513
  STEP: watching @ 11/30/24 12:19:24.517
  I1130 12:19:24.517463 19 validatingadmissionpolicy.go:768] starting watch
  STEP: patching @ 11/30/24 12:19:24.518
  STEP: updating @ 11/30/24 12:19:24.524
  I1130 12:19:24.532989 19 validatingadmissionpolicy.go:796] waiting for watch events with expected annotations
  STEP: deleting @ 11/30/24 12:19:24.533
  STEP: deleting a collection @ 11/30/24 12:19:24.547
  I1130 12:19:24.571619 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6884" for this suite. @ 11/30/24 12:19:24.575
• [0.130 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 11/30/24 12:19:24.582
  I1130 12:19:24.582339 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 12:19:24.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:19:24.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:19:24.608
  I1130 12:19:24.611585 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: creating the pod @ 11/30/24 12:19:24.612
  STEP: submitting the pod to kubernetes @ 11/30/24 12:19:24.612
  I1130 12:19:26.686621 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7697" for this suite. @ 11/30/24 12:19:26.691
• [2.119 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:750
  STEP: Creating a kubernetes client @ 11/30/24 12:19:26.701
  I1130 12:19:26.701738 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:19:26.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:19:26.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:19:26.727
  I1130 12:19:26.733738 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5636" for this suite. @ 11/30/24 12:19:26.737
• [0.044 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 11/30/24 12:19:26.746
  I1130 12:19:26.746451 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:19:26.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:19:26.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:19:26.79
  STEP: Creating a pod to test downward api env vars @ 11/30/24 12:19:26.793
  STEP: Saw pod success @ 11/30/24 12:19:30.82
  I1130 12:19:30.823692 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downward-api-c7f67fa9-fd6f-4904-841d-ea907f44413f container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 12:19:30.837
  I1130 12:19:30.857085 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7751" for this suite. @ 11/30/24 12:19:30.861
• [4.122 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 11/30/24 12:19:30.868
  I1130 12:19:30.868602 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename certificates @ 11/30/24 12:19:30.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:19:30.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:19:30.892
  STEP: getting /apis @ 11/30/24 12:19:31.384
  STEP: getting /apis/certificates.k8s.io @ 11/30/24 12:19:31.388
  STEP: getting /apis/certificates.k8s.io/v1 @ 11/30/24 12:19:31.389
  STEP: creating @ 11/30/24 12:19:31.39
  STEP: getting @ 11/30/24 12:19:31.413
  STEP: listing @ 11/30/24 12:19:31.417
  STEP: watching @ 11/30/24 12:19:31.421
  I1130 12:19:31.421671 19 certificates.go:316] starting watch
  STEP: patching @ 11/30/24 12:19:31.422
  STEP: updating @ 11/30/24 12:19:31.429
  I1130 12:19:31.436959 19 certificates.go:332] waiting for watch events with expected annotations
  I1130 12:19:31.436994 19 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 11/30/24 12:19:31.437
  STEP: patching /approval @ 11/30/24 12:19:31.441
  STEP: updating /approval @ 11/30/24 12:19:31.448
  STEP: getting /status @ 11/30/24 12:19:31.456
  STEP: patching /status @ 11/30/24 12:19:31.46
  STEP: updating /status @ 11/30/24 12:19:31.467
  STEP: deleting @ 11/30/24 12:19:31.474
  STEP: deleting a collection @ 11/30/24 12:19:31.489
  I1130 12:19:31.508386 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-5898" for this suite. @ 11/30/24 12:19:31.511
• [0.650 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:324
  STEP: Creating a kubernetes client @ 11/30/24 12:19:31.518
  I1130 12:19:31.518949 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename statefulset @ 11/30/24 12:19:31.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:19:31.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:19:31.542
  STEP: Creating service test in namespace statefulset-6565 @ 11/30/24 12:19:31.545
  STEP: Creating a new StatefulSet @ 11/30/24 12:19:31.55
  I1130 12:19:31.562986 19 wait.go:40] Found 0 stateful pods, waiting for 3
  I1130 12:19:41.565316 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I1130 12:19:41.565350 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I1130 12:19:41.565357 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I1130 12:19:41.576960 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-6565 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 12:19:41.676611 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 12:19:41.676656 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 12:19:41.676665 19 statefulset.go:2450] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 11/30/24 12:19:51.687
  I1130 12:19:51.698167 19 statefulset.go:2507] Updating stateful set ss2
  STEP: Creating a new revision @ 11/30/24 12:19:51.698
  STEP: Updating Pods in reverse ordinal order @ 11/30/24 12:20:01.707
  I1130 12:20:01.712510 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-6565 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1130 12:20:01.809044 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1130 12:20:01.809095 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 12:20:01.809107 19 statefulset.go:2474] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 12:20:11.827713 19 wait.go:158] Waiting for StatefulSet statefulset-6565/ss2 to complete update
  STEP: Rolling back to a previous revision @ 11/30/24 12:20:21.829
  I1130 12:20:21.829363 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-6565 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 12:20:21.916347 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 12:20:21.916423 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 12:20:21.916434 19 statefulset.go:2450] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 12:20:31.937280 19 statefulset.go:2507] Updating stateful set ss2
  STEP: Rolling back update in reverse ordinal order @ 11/30/24 12:20:41.946
  I1130 12:20:41.951649 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-6565 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1130 12:20:42.034820 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1130 12:20:42.034867 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 12:20:42.034877 19 statefulset.go:2474] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 12:20:52.051301 19 statefulset.go:138] Deleting all statefulset in ns statefulset-6565
  I1130 12:20:52.056195 19 rest.go:150] Scaling statefulset ss2 to 0
  I1130 12:21:02.072353 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1130 12:21:02.076634 19 rest.go:88] Deleting statefulset ss2
  I1130 12:21:02.092090 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6565" for this suite. @ 11/30/24 12:21:02.096
• [90.583 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 11/30/24 12:21:02.102
  I1130 12:21:02.102489 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:21:02.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:02.124
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:02.127
  STEP: Creating the pod @ 11/30/24 12:21:02.129
  I1130 12:21:04.678447 19 pod_client.go:173] Successfully updated pod "annotationupdate5b18c269-af55-43fe-ac26-34df972a7c88"
  I1130 12:21:06.695175 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-105" for this suite. @ 11/30/24 12:21:06.7
• [4.606 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 11/30/24 12:21:06.708
  I1130 12:21:06.708252 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename runtimeclass @ 11/30/24 12:21:06.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:06.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:06.731
  STEP: getting /apis @ 11/30/24 12:21:06.734
  STEP: getting /apis/node.k8s.io @ 11/30/24 12:21:06.737
  STEP: getting /apis/node.k8s.io/v1 @ 11/30/24 12:21:06.738
  STEP: creating @ 11/30/24 12:21:06.74
  STEP: watching @ 11/30/24 12:21:06.758
  I1130 12:21:06.758725 19 runtimeclass.go:275] starting watch
  STEP: getting @ 11/30/24 12:21:06.764
  STEP: listing @ 11/30/24 12:21:06.767
  STEP: patching @ 11/30/24 12:21:06.771
  STEP: updating @ 11/30/24 12:21:06.777
  I1130 12:21:06.783234 19 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 11/30/24 12:21:06.783
  STEP: deleting a collection @ 11/30/24 12:21:06.797
  I1130 12:21:06.817593 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6691" for this suite. @ 11/30/24 12:21:06.821
• [0.122 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 11/30/24 12:21:06.83
  I1130 12:21:06.830449 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 12:21:06.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:06.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:06.853
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 11/30/24 12:21:06.856
  STEP: Saw pod success @ 11/30/24 12:21:10.883
  I1130 12:21:10.887039 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-557d2488-19b5-4847-ba03-351bf761761b container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:21:10.894
  I1130 12:21:10.915419 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-679" for this suite. @ 11/30/24 12:21:10.92
• [4.100 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 11/30/24 12:21:10.93
  I1130 12:21:10.930412 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename security-context-test @ 11/30/24 12:21:10.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:10.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:10.953
  I1130 12:21:14.982749 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7917" for this suite. @ 11/30/24 12:21:14.987
• [4.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 11/30/24 12:21:14.995
  I1130 12:21:14.995646 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 12:21:14.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:15.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:15.017
  STEP: Creating configMap with name configmap-test-volume-map-3631c2b9-4c8c-4dd8-bf69-08c8268c02fe @ 11/30/24 12:21:15.02
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:21:15.024
  STEP: Saw pod success @ 11/30/24 12:21:19.051
  I1130 12:21:19.055602 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-configmaps-c68164a0-df96-4ca9-a472-801c653fd41e container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:21:19.062
  I1130 12:21:19.082280 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6780" for this suite. @ 11/30/24 12:21:19.086
• [4.099 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1723
  STEP: Creating a kubernetes client @ 11/30/24 12:21:19.094
  I1130 12:21:19.094718 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 12:21:19.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:19.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:19.117
  I1130 12:21:19.120891 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-3346 version'
  I1130 12:21:19.161793 19 builder.go:146] stderr: ""
  I1130 12:21:19.161833 19 builder.go:147] stdout: "Client Version: v1.31.3\nKustomize Version: v5.4.2\nServer Version: v1.31.3\n"
  I1130 12:21:19.162130 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3346" for this suite. @ 11/30/24 12:21:19.167
• [0.083 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 11/30/24 12:21:19.177
  I1130 12:21:19.177793 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 12:21:19.178
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:19.202
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:19.205
  I1130 12:21:19.209239 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 11/30/24 12:21:20.655
  I1130 12:21:20.655572 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-249 --namespace=crd-publish-openapi-249 create -f -'
  I1130 12:21:22.724251 19 builder.go:146] stderr: ""
  I1130 12:21:22.724298 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6095-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I1130 12:21:22.724407 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-249 --namespace=crd-publish-openapi-249 delete e2e-test-crd-publish-openapi-6095-crds test-cr'
  I1130 12:21:22.777444 19 builder.go:146] stderr: ""
  I1130 12:21:22.777496 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6095-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I1130 12:21:22.777563 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-249 --namespace=crd-publish-openapi-249 apply -f -'
  I1130 12:21:22.836999 19 builder.go:146] stderr: ""
  I1130 12:21:22.837036 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6095-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I1130 12:21:22.837086 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-249 --namespace=crd-publish-openapi-249 delete e2e-test-crd-publish-openapi-6095-crds test-cr'
  I1130 12:21:22.888532 19 builder.go:146] stderr: ""
  I1130 12:21:22.888567 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6095-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 11/30/24 12:21:22.888
  I1130 12:21:22.888638 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-249 explain e2e-test-crd-publish-openapi-6095-crds'
  I1130 12:21:22.931823 19 builder.go:146] stderr: ""
  I1130 12:21:22.931891 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-6095-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I1130 12:21:24.162320 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-249" for this suite. @ 11/30/24 12:21:24.168
• [5.000 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 11/30/24 12:21:24.178
  I1130 12:21:24.178623 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename deployment @ 11/30/24 12:21:24.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:24.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:24.205
  I1130 12:21:24.207937 19 deployment.go:792] Creating deployment "test-recreate-deployment"
  I1130 12:21:24.213317 19 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I1130 12:21:24.221047 19 deployment.go:222] deployment "test-recreate-deployment" doesn't have the required revision set
  I1130 12:21:26.231791 19 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I1130 12:21:26.235460 19 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I1130 12:21:26.247865 19 deployment.go:313] Updating deployment test-recreate-deployment
  I1130 12:21:26.247898 19 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I1130 12:21:26.336946 19 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9074",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5005eacf-a062-471b-a3e9-a6c6250c3247",
      ResourceVersion: (string) (len=4) "6690",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868566084,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566084,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-88d47c55d\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1130 12:21:26.342052 19 deployment.go:39] New ReplicaSet "test-recreate-deployment-88d47c55d" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-88d47c55d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9074",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "deaa9298-bf47-4db7-a851-f90ade312faf",
      ResourceVersion: (string) (len=4) "6688",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868566086,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "5005eacf-a062-471b-a3e9-a6c6250c3247",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 30 30 35 65 61  63 66 2d 61 30 36 32 2d  |\"5005eacf-a062-|
              00000120  34 37 31 62 2d 61 33 65  39 2d 61 36 63 36 32 35  |471b-a3e9-a6c625|
              00000130  30 63 33 32 34 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0c3247\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:21:26.342545 19 deployment.go:44] All old ReplicaSets of Deployment "test-recreate-deployment":
  I1130 12:21:26.342816 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-7549bcf47c",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9074",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8356eed9-614c-4d4a-b983-c8d2be9bdb30",
      ResourceVersion: (string) (len=4) "6678",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868566084,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "5005eacf-a062-471b-a3e9-a6c6250c3247",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 30 30 35 65 61  63 66 2d 61 30 36 32 2d  |\"5005eacf-a062-|
              00000120  34 37 31 62 2d 61 33 65  39 2d 61 36 63 36 32 35  |471b-a3e9-a6c625|
              00000130  30 63 33 32 34 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0c3247\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:21:26.349081 19 deployment.go:67] Pod "test-recreate-deployment-88d47c55d-xq4db" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-88d47c55d-xq4db",
      GenerateName: (string) (len=35) "test-recreate-deployment-88d47c55d-",
      Namespace: (string) (len=15) "deployment-9074",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "06b11045-d64b-43cb-9011-fc48d025b5a2",
      ResourceVersion: (string) (len=4) "6689",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868566086,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-88d47c55d",
          UID: (types.UID) (len=36) "deaa9298-bf47-4db7-a851-f90ade312faf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 65  61 61 39 32 39 38 2d 62  |d\":\"deaa9298-b|
              00000090  66 34 37 2d 34 64 62 37  2d 61 38 35 31 2d 66 39  |f47-4db7-a851-f9|
              000000a0  30 61 64 65 33 31 32 66  61 66 5c 22 7d 22 3a 7b  |0ade312faf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4dvs2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4dvs2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868566086,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868566086,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-4dvs2",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:21:26.350194 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9074" for this suite. @ 11/30/24 12:21:26.354
• [2.184 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 11/30/24 12:21:26.362
  I1130 12:21:26.362584 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename svcaccounts @ 11/30/24 12:21:26.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:26.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:26.39
  I1130 12:21:26.414696 19 service_accounts.go:253] created pod pod-service-account-defaultsa
  I1130 12:21:26.414730 19 service_accounts.go:267] pod pod-service-account-defaultsa service account token volume mount: true
  I1130 12:21:26.423423 19 service_accounts.go:253] created pod pod-service-account-mountsa
  I1130 12:21:26.423455 19 service_accounts.go:267] pod pod-service-account-mountsa service account token volume mount: true
  I1130 12:21:26.430317 19 service_accounts.go:253] created pod pod-service-account-nomountsa
  I1130 12:21:26.430341 19 service_accounts.go:267] pod pod-service-account-nomountsa service account token volume mount: false
  I1130 12:21:26.438090 19 service_accounts.go:253] created pod pod-service-account-defaultsa-mountspec
  I1130 12:21:26.438131 19 service_accounts.go:267] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I1130 12:21:26.444036 19 service_accounts.go:253] created pod pod-service-account-mountsa-mountspec
  I1130 12:21:26.444070 19 service_accounts.go:267] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I1130 12:21:26.451003 19 service_accounts.go:253] created pod pod-service-account-nomountsa-mountspec
  I1130 12:21:26.451037 19 service_accounts.go:267] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I1130 12:21:26.459391 19 service_accounts.go:253] created pod pod-service-account-defaultsa-nomountspec
  I1130 12:21:26.459686 19 service_accounts.go:267] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I1130 12:21:26.472551 19 service_accounts.go:253] created pod pod-service-account-mountsa-nomountspec
  I1130 12:21:26.472588 19 service_accounts.go:267] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I1130 12:21:26.478521 19 service_accounts.go:253] created pod pod-service-account-nomountsa-nomountspec
  I1130 12:21:26.478563 19 service_accounts.go:267] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I1130 12:21:26.478700 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-131" for this suite. @ 11/30/24 12:21:26.485
• [0.137 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 11/30/24 12:21:26.499
  I1130 12:21:26.499977 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename gc @ 11/30/24 12:21:26.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:26.526
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:26.53
  STEP: create the rc @ 11/30/24 12:21:26.535
  W1130 12:21:26.545256      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 11/30/24 12:21:31.551
  STEP: wait for all pods to be garbage collected @ 11/30/24 12:21:31.557
  STEP: Gathering metrics @ 11/30/24 12:21:36.567
  W1130 12:21:36.574270      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1130 12:21:36.574302 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1130 12:21:36.574450 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4499" for this suite. @ 11/30/24 12:21:36.579
• [10.090 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:788
  STEP: Creating a kubernetes client @ 11/30/24 12:21:36.59
  I1130 12:21:36.590504 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename job @ 11/30/24 12:21:36.591
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:36.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:36.617
  STEP: Creating a job @ 11/30/24 12:21:36.622
  STEP: Ensuring job reaches completions @ 11/30/24 12:21:36.631
  I1130 12:21:48.643663 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1174" for this suite. @ 11/30/24 12:21:48.648
• [12.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 11/30/24 12:21:48.656
  I1130 12:21:48.656520 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename init-container @ 11/30/24 12:21:48.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:21:48.676
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:21:48.68
  STEP: creating the pod @ 11/30/24 12:21:48.683
  I1130 12:21:48.683588 19 init_container.go:374] PodSpec: initContainers in spec.initContainers
  I1130 12:22:32.508352 19 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-00c8fe8e-00a6-4c75-936a-2684b8a6a59a", GenerateName:"", Namespace:"init-container-3641", SelfLink:"", UID:"9411b1f9-73ed-48f3-b886-ef33f91e16fd", ResourceVersion:"7226", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 21, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"683576811"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 21, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c7b230), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 22, 32, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000c7b278), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-ql4z6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc000d49040), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil), Image:(*v1.ImageVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ql4z6", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ql4z6", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.10", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ql4z6", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002e4d6d0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-64-147", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004749180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002e4d760)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002e4d780)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002e4d788), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002e4d78c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0054da9b0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.November, 30, 12, 21, 49, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.November, 30, 12, 21, 48, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.November, 30, 12, 21, 48, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.November, 30, 12, 21, 48, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.November, 30, 12, 21, 48, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.64.147", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.31.64.147"}}, PodIP:"192.168.244.212", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.244.212"}}, StartTime:time.Date(2024, time.November, 30, 12, 21, 48, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00044d9d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00044dab0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://9d29426b9710096c1aa1de010b0d2c996a57fbf7b55bf2de37d756d60c012f16", Started:(*bool)(0xc002e4d83a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-ql4z6", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0054da9f0)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000d490a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc002e4d84d), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-ql4z6", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0054daa00)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000d49080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.10", ImageID:"", ContainerID:"", Started:(*bool)(0xc002e4d804), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-ql4z6", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0054da9c0)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I1130 12:22:32.508514 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3641" for this suite. @ 11/30/24 12:22:32.512
• [43.865 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:814
  STEP: Creating a kubernetes client @ 11/30/24 12:22:32.521
  I1130 12:22:32.521683 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-preemption @ 11/30/24 12:22:32.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:22:32.573
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:22:32.577
  I1130 12:22:32.597757 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  I1130 12:23:32.604019 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 11/30/24 12:23:32.608
  I1130 12:23:32.608352 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-preemption-path @ 11/30/24 12:23:32.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:23:32.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:23:32.634
  I1130 12:23:32.652589 19 preemption.go:820] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I1130 12:23:32.656944 19 preemption.go:826] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  I1130 12:23:32.733226 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-1458" for this suite. @ 11/30/24 12:23:32.737
  I1130 12:23:32.745567 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-7185" for this suite. @ 11/30/24 12:23:32.749
• [60.239 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 11/30/24 12:23:32.76
  I1130 12:23:32.760850 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:23:32.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:23:32.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:23:32.783
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:23:32.787
  STEP: Saw pod success @ 11/30/24 12:23:34.811
  I1130 12:23:34.816603 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-2ba259e7-3f5b-45ad-9523-78b7a561ec47 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:23:34.83
  I1130 12:23:34.852533 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4489" for this suite. @ 11/30/24 12:23:34.856
• [2.102 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:368
  STEP: Creating a kubernetes client @ 11/30/24 12:23:34.863
  I1130 12:23:34.863342 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:23:34.863
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:23:34.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:23:34.887
  STEP: Setting up server cert @ 11/30/24 12:23:34.914
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:23:35.117
  STEP: Deploying the webhook pod @ 11/30/24 12:23:35.127
  STEP: Wait for the deployment to be ready @ 11/30/24 12:23:35.145
  I1130 12:23:35.154071 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 11/30/24 12:23:37.169
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:23:37.181
  I1130 12:23:38.181317 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 11/30/24 12:23:38.19
  STEP: Registering slow webhook via the AdmissionRegistration API @ 11/30/24 12:23:38.19
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 11/30/24 12:23:38.207
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 11/30/24 12:23:39.22
  STEP: Registering slow webhook via the AdmissionRegistration API @ 11/30/24 12:23:39.22
  STEP: Having no error when timeout is longer than webhook latency @ 11/30/24 12:23:40.255
  STEP: Registering slow webhook via the AdmissionRegistration API @ 11/30/24 12:23:40.255
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 11/30/24 12:23:45.306
  STEP: Registering slow webhook via the AdmissionRegistration API @ 11/30/24 12:23:45.306
  I1130 12:23:50.424628 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4008" for this suite. @ 11/30/24 12:23:50.428
  STEP: Destroying namespace "webhook-markers-2146" for this suite. @ 11/30/24 12:23:50.434
• [15.578 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 11/30/24 12:23:50.441
  I1130 12:23:50.441617 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 12:23:50.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:23:50.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:23:50.466
  STEP: Creating pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733 @ 11/30/24 12:23:50.47
  STEP: checking the pod's current state and verifying that restartCount is present @ 11/30/24 12:23:52.493
  I1130 12:23:52.498207 19 container_probe.go:1749] Initial restart count of pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 is 0
  I1130 12:23:52.502766 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:23:54.508069 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:23:56.514185 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:23:58.520249 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:00.525866 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:02.532217 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:04.537526 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:06.543682 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:08.549155 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:10.554217 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:12.561114 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:14.566756 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:16.572673 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:18.579261 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:20.584842 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:22.591452 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:24.597278 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:26.602744 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:28.609520 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:30.616240 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:32.621581 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:34.626716 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:36.632670 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:38.638543 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:40.644966 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:42.650239 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:44.655677 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:46.662058 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:48.667441 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:50.673885 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:52.680197 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:54.685093 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:56.691181 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:24:58.697362 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:00.703934 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:02.710470 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:04.716283 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:06.722420 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:08.729316 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:10.737314 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:12.743387 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:14.750303 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:16.756661 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:18.761679 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:20.766451 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:22.773058 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:24.779095 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:26.785822 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:28.792315 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:30.797699 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:32.803049 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:34.809754 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:36.814988 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:38.821514 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:40.827277 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:42.832714 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:44.838612 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:46.845395 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:48.852419 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:50.858429 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:52.865226 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:54.870506 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:56.876898 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:25:58.882717 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:00.888424 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:02.894513 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:04.900249 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:06.905150 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:08.911093 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:10.917229 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:12.923355 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:14.930006 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:16.936104 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:18.943483 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:20.950345 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:22.956233 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:24.960661 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:26.966666 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:28.971785 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:30.978655 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:32.984669 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:34.991120 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:36.997588 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:39.004213 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:41.009833 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:43.016213 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:45.021496 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:47.026710 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:49.033146 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:51.038122 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:53.043879 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:55.049922 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:57.055547 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:26:59.060270 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:01.065091 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:03.070129 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:05.075596 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:07.080927 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:09.087553 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:11.094231 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:13.100261 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:15.105431 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:17.111244 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:19.117088 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:21.122937 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:23.128613 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:25.134548 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:27.140319 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:29.146845 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:31.152542 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:33.158708 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:35.163697 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:37.172076 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:39.177228 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:41.183576 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:43.189815 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:45.195637 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:47.201323 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:49.208161 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  I1130 12:27:51.213312 19 container_probe.go:1759] Get pod test-webserver-a56b937f-3dd1-4335-8c47-5ffdf5615166 in namespace container-probe-7733
  STEP: deleting the pod @ 11/30/24 12:27:53.214
  I1130 12:27:53.231885 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7733" for this suite. @ 11/30/24 12:27:53.237
• [242.802 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 11/30/24 12:27:53.243
  I1130 12:27:53.243947 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename svcaccounts @ 11/30/24 12:27:53.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:27:53.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:27:53.264
  STEP: reading a file in the container @ 11/30/24 12:27:55.293
  I1130 12:27:55.293309 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3906 pod-service-account-268bcdc2-a329-4202-bcb8-751c2f858d43 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 11/30/24 12:27:55.388
  I1130 12:27:55.388085 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3906 pod-service-account-268bcdc2-a329-4202-bcb8-751c2f858d43 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 11/30/24 12:27:55.469
  I1130 12:27:55.469993 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3906 pod-service-account-268bcdc2-a329-4202-bcb8-751c2f858d43 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I1130 12:27:55.559270 19 service_accounts.go:114] Got root ca configmap in namespace "svcaccounts-3906"
  I1130 12:27:55.561740 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3906" for this suite. @ 11/30/24 12:27:55.565
• [2.329 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 11/30/24 12:27:55.573
  I1130 12:27:55.573704 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 12:27:55.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:27:55.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:27:55.596
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 11/30/24 12:27:55.598
  STEP: Saw pod success @ 11/30/24 12:27:57.615
  I1130 12:27:57.619540 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-729ac2f1-14c7-4ed6-aab1-54bfcb4ef6d5 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:27:57.639
  I1130 12:27:57.661131 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7571" for this suite. @ 11/30/24 12:27:57.665
• [2.102 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 11/30/24 12:27:57.675
  I1130 12:27:57.675432 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:27:57.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:27:57.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:27:57.699
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:27:57.702
  STEP: Saw pod success @ 11/30/24 12:28:01.733
  I1130 12:28:01.736731 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-e1c293cc-91d1-428d-8fa6-10bd507cf42c container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:28:01.754
  I1130 12:28:01.773599 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9547" for this suite. @ 11/30/24 12:28:01.778
• [4.110 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 11/30/24 12:28:01.785
  I1130 12:28:01.785141 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename security-context-test @ 11/30/24 12:28:01.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:01.805
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:01.808
  I1130 12:28:05.842060 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7112" for this suite. @ 11/30/24 12:28:05.846
• [4.069 seconds]
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:351
  STEP: Creating a kubernetes client @ 11/30/24 12:28:05.854
  I1130 12:28:05.854305 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename disruption @ 11/30/24 12:28:05.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:05.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:05.876
  STEP: Creating a pdb that targets all three pods in a test replica set @ 11/30/24 12:28:05.879
  STEP: Waiting for the pdb to be processed @ 11/30/24 12:28:05.884
  STEP: First trying to evict a pod which shouldn't be evictable @ 11/30/24 12:28:07.896
  STEP: Waiting for all pods to be running @ 11/30/24 12:28:07.896
  I1130 12:28:07.900146 19 disruption.go:680] pods: 0 < 3
  STEP: locating a running pod @ 11/30/24 12:28:09.903
  STEP: Updating the pdb to allow a pod to be evicted @ 11/30/24 12:28:09.913
  STEP: Waiting for the pdb to be processed @ 11/30/24 12:28:09.925
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 11/30/24 12:28:11.931
  STEP: Waiting for all pods to be running @ 11/30/24 12:28:11.931
  STEP: Waiting for the pdb to observed all healthy pods @ 11/30/24 12:28:11.935
  STEP: Patching the pdb to disallow a pod to be evicted @ 11/30/24 12:28:11.961
  STEP: Waiting for the pdb to be processed @ 11/30/24 12:28:11.982
  STEP: Waiting for all pods to be running @ 11/30/24 12:28:13.987
  STEP: locating a running pod @ 11/30/24 12:28:13.992
  STEP: Deleting the pdb to allow a pod to be evicted @ 11/30/24 12:28:14.004
  STEP: Waiting for the pdb to be deleted @ 11/30/24 12:28:14.011
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 11/30/24 12:28:14.015
  STEP: Waiting for all pods to be running @ 11/30/24 12:28:14.015
  I1130 12:28:14.039409 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2752" for this suite. @ 11/30/24 12:28:14.043
• [8.200 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:196
  STEP: Creating a kubernetes client @ 11/30/24 12:28:14.054
  I1130 12:28:14.054787 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:28:14.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:14.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:14.08
  STEP: Setting up server cert @ 11/30/24 12:28:14.107
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:28:14.32
  STEP: Deploying the webhook pod @ 11/30/24 12:28:14.331
  STEP: Wait for the deployment to be ready @ 11/30/24 12:28:14.347
  I1130 12:28:14.358096 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 11/30/24 12:28:16.372
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:28:16.383
  I1130 12:28:17.383868 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 11/30/24 12:28:17.393
  STEP: create a pod that should be denied by the webhook @ 11/30/24 12:28:17.41
  STEP: create a pod that causes the webhook to hang @ 11/30/24 12:28:17.422
  STEP: create a configmap that should be denied by the webhook @ 11/30/24 12:28:27.431
  STEP: create a configmap that should be admitted by the webhook @ 11/30/24 12:28:27.468
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 11/30/24 12:28:27.478
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 11/30/24 12:28:27.489
  STEP: create a namespace that bypass the webhook @ 11/30/24 12:28:27.496
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 11/30/24 12:28:27.516
  I1130 12:28:27.571399 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7137" for this suite. @ 11/30/24 12:28:27.575
  STEP: Destroying namespace "webhook-markers-1236" for this suite. @ 11/30/24 12:28:27.584
  STEP: Destroying namespace "exempted-namespace-2197" for this suite. @ 11/30/24 12:28:27.593
• [13.546 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 11/30/24 12:28:27.6
  I1130 12:28:27.600666 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename namespaces @ 11/30/24 12:28:27.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:27.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:27.622
  STEP: creating a Namespace @ 11/30/24 12:28:27.625
  STEP: patching the Namespace @ 11/30/24 12:28:27.645
  STEP: get the Namespace and ensuring it has the label @ 11/30/24 12:28:27.653
  I1130 12:28:27.657913 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6928" for this suite. @ 11/30/24 12:28:27.662
  STEP: Destroying namespace "nspatchtest-50a45bdd-c75a-45f2-a682-3c0687e7030e-3901" for this suite. @ 11/30/24 12:28:27.67
• [0.079 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:454
  STEP: Creating a kubernetes client @ 11/30/24 12:28:27.679
  I1130 12:28:27.679742 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:28:27.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:27.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:27.704
  STEP: Counting existing ResourceQuota @ 11/30/24 12:28:27.707
  STEP: Creating a ResourceQuota @ 11/30/24 12:28:32.712
  STEP: Ensuring resource quota status is calculated @ 11/30/24 12:28:32.717
  STEP: Creating a ReplicaSet @ 11/30/24 12:28:34.724
  STEP: Ensuring resource quota status captures replicaset creation @ 11/30/24 12:28:34.736
  STEP: Deleting a ReplicaSet @ 11/30/24 12:28:36.742
  STEP: Ensuring resource quota status released usage @ 11/30/24 12:28:36.75
  I1130 12:28:38.756864 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6808" for this suite. @ 11/30/24 12:28:38.761
• [11.089 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 11/30/24 12:28:38.768
  I1130 12:28:38.768612 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-runtime @ 11/30/24 12:28:38.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:38.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:38.795
  STEP: create the container @ 11/30/24 12:28:38.798
  W1130 12:28:38.808674      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 11/30/24 12:28:38.808
  STEP: get the container status @ 11/30/24 12:28:41.832
  STEP: the container should be terminated @ 11/30/24 12:28:41.836
  STEP: the termination message should be set @ 11/30/24 12:28:41.836
  I1130 12:28:41.836650 19 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 11/30/24 12:28:41.836
  I1130 12:28:41.858458 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-682" for this suite. @ 11/30/24 12:28:41.863
• [3.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 11/30/24 12:28:41.872
  I1130 12:28:41.872628 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename events @ 11/30/24 12:28:41.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:41.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:41.897
  STEP: creating a test event @ 11/30/24 12:28:41.901
  STEP: listing all events in all namespaces @ 11/30/24 12:28:41.908
  STEP: patching the test event @ 11/30/24 12:28:41.931
  STEP: fetching the test event @ 11/30/24 12:28:41.954
  STEP: updating the test event @ 11/30/24 12:28:41.962
  STEP: getting the test event @ 11/30/24 12:28:41.976
  STEP: deleting the test event @ 11/30/24 12:28:41.981
  STEP: listing all events in all namespaces @ 11/30/24 12:28:41.992
  I1130 12:28:42.008009 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2477" for this suite. @ 11/30/24 12:28:42.012
• [0.148 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:235
  STEP: Creating a kubernetes client @ 11/30/24 12:28:42.02
  I1130 12:28:42.020527 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:28:42.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:42.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:42.044
  STEP: Counting existing ResourceQuota @ 11/30/24 12:28:42.047
  STEP: Creating a ResourceQuota @ 11/30/24 12:28:47.052
  STEP: Ensuring resource quota status is calculated @ 11/30/24 12:28:47.059
  STEP: Creating a Pod that fits quota @ 11/30/24 12:28:49.065
  STEP: Ensuring ResourceQuota status captures the pod usage @ 11/30/24 12:28:49.085
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 11/30/24 12:28:51.091
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 11/30/24 12:28:51.093
  STEP: Ensuring a pod cannot update its resource requirements @ 11/30/24 12:28:51.096
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 11/30/24 12:28:51.1
  STEP: Deleting the pod @ 11/30/24 12:28:53.106
  STEP: Ensuring resource quota status released the pod usage @ 11/30/24 12:28:53.125
  I1130 12:28:55.131238 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-318" for this suite. @ 11/30/24 12:28:55.136
• [13.126 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 11/30/24 12:28:55.147
  I1130 12:28:55.147025 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename daemonsets @ 11/30/24 12:28:55.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:28:55.17
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:28:55.174
  I1130 12:28:55.203605 19 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 11/30/24 12:28:55.212
  I1130 12:28:55.220438 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:55.220491 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:55.225757 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:28:55.225785 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  I1130 12:28:56.218811 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:56.218861 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:56.223193 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1130 12:28:56.223215 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  I1130 12:28:57.216793 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:57.216851 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:57.221181 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 12:28:57.221209 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 11/30/24 12:28:57.238
  STEP: Check that daemon pods images are updated. @ 11/30/24 12:28:57.255
  I1130 12:28:57.258763 19 daemon_set.go:1193] Wrong image for pod: daemon-set-jb8xk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1130 12:28:57.258806 19 daemon_set.go:1193] Wrong image for pod: daemon-set-vk7g4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1130 12:28:57.258817 19 daemon_set.go:1193] Wrong image for pod: daemon-set-zhd9l. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1130 12:28:57.264818 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:57.264864 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:58.261029 19 daemon_set.go:1198] Pod daemon-set-j59vn is not available
  I1130 12:28:58.261063 19 daemon_set.go:1193] Wrong image for pod: daemon-set-jb8xk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1130 12:28:58.261108 19 daemon_set.go:1193] Wrong image for pod: daemon-set-vk7g4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1130 12:28:58.264888 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:58.264943 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:59.260594 19 daemon_set.go:1198] Pod daemon-set-4wrrg is not available
  I1130 12:28:59.260631 19 daemon_set.go:1193] Wrong image for pod: daemon-set-vk7g4. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1130 12:28:59.265140 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:28:59.265184 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:00.259576 19 daemon_set.go:1198] Pod daemon-set-ck492 is not available
  I1130 12:29:00.264096 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:00.264145 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 11/30/24 12:29:00.264
  I1130 12:29:00.268688 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:00.268724 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:00.272702 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1130 12:29:00.272725 19 fixtures.go:130] Node ip-172-31-64-147 is running 0 daemon pod, expected 1
  I1130 12:29:01.270250 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:01.270301 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:01.274143 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 12:29:01.274162 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 11/30/24 12:29:01.297
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9476, will wait for the garbage collector to delete the pods @ 11/30/24 12:29:01.297
  I1130 12:29:01.361133 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.799361ms
  I1130 12:29:01.462059 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.920095ms
  I1130 12:29:03.267162 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:29:03.267204 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1130 12:29:03.272150 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8843"},"items":null}

  I1130 12:29:03.276049 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8843"},"items":null}

  I1130 12:29:03.292953 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9476" for this suite. @ 11/30/24 12:29:03.297
• [8.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 11/30/24 12:29:03.307
  I1130 12:29:03.307077 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename watch @ 11/30/24 12:29:03.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:03.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:03.332
  STEP: creating a watch on configmaps @ 11/30/24 12:29:03.335
  STEP: creating a new configmap @ 11/30/24 12:29:03.336
  STEP: modifying the configmap once @ 11/30/24 12:29:03.341
  STEP: closing the watch once it receives two notifications @ 11/30/24 12:29:03.351
  I1130 12:29:03.352048 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3224  1eba8b09-5459-496f-ba60-5aed91a4b158 8850 0 2024-11-30 12:29:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-11-30 12:29:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 12:29:03.352162 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3224  1eba8b09-5459-496f-ba60-5aed91a4b158 8851 0 2024-11-30 12:29:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-11-30 12:29:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 11/30/24 12:29:03.352
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 11/30/24 12:29:03.36
  STEP: deleting the configmap @ 11/30/24 12:29:03.362
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 11/30/24 12:29:03.368
  I1130 12:29:03.368800 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3224  1eba8b09-5459-496f-ba60-5aed91a4b158 8852 0 2024-11-30 12:29:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-11-30 12:29:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 12:29:03.368965 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3224  1eba8b09-5459-496f-ba60-5aed91a4b158 8853 0 2024-11-30 12:29:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-11-30 12:29:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 12:29:03.369198 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3224" for this suite. @ 11/30/24 12:29:03.373
• [0.073 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 11/30/24 12:29:03.381
  I1130 12:29:03.381149 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename aggregator @ 11/30/24 12:29:03.382
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:03.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:03.406
  I1130 12:29:03.410059 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Registering the sample API server. @ 11/30/24 12:29:03.41
  I1130 12:29:03.636525 19 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I1130 12:29:03.671758 19 deployment.go:222] deployment "sample-apiserver-deployment" doesn't have the required revision set
  I1130 12:29:05.725989 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:07.732624 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:09.732334 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:11.731302 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:13.732709 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:15.733062 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:17.731859 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:19.732915 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:21.732702 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:23.732663 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:25.733077 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  I1130 12:29:27.856899 19 aggregator.go:755] Waited 117.831281ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 11/30/24 12:29:27.899
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 11/30/24 12:29:27.903
  STEP: List APIServices @ 11/30/24 12:29:27.911
  I1130 12:29:27.916668 19 aggregator.go:556] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 11/30/24 12:29:27.916
  I1130 12:29:27.928661 19 aggregator.go:581] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 11/30/24 12:29:27.928
  I1130 12:29:27.940055 19 aggregator.go:607] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.November, 30, 12, 29, 27, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 11/30/24 12:29:27.94
  I1130 12:29:27.944322 19 aggregator.go:625] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-11-30 12:29:27 +0000 UTC Passed all checks passed}
  I1130 12:29:27.944346 19 aggregator.go:621] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1130 12:29:27.944358 19 aggregator.go:631] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 11/30/24 12:29:27.944
  I1130 12:29:27.955440 19 aggregator.go:647] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-111047882" @ 11/30/24 12:29:27.955
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 11/30/24 12:29:27.966
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 11/30/24 12:29:27.974
  STEP: Patch APIService Status @ 11/30/24 12:29:27.979
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 11/30/24 12:29:27.987
  I1130 12:29:27.991539 19 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-11-30 12:29:27 +0000 UTC Passed all checks passed}
  I1130 12:29:27.991572 19 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1130 12:29:27.991588 19 aggregator.go:721] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I1130 12:29:27.991599 19 aggregator.go:731] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 11/30/24 12:29:27.991
  STEP: Confirm that the generated APIService has been deleted @ 11/30/24 12:29:28.003
  I1130 12:29:28.003199 19 aggregator.go:792] Requesting list of APIServices to confirm quantity
  I1130 12:29:28.008651 19 aggregator.go:802] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I1130 12:29:28.008679 19 aggregator.go:744] APIService v1alpha1.wardle.example.com has been deleted.
  I1130 12:29:28.121717 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-2479" for this suite. @ 11/30/24 12:29:28.125
• [24.751 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1513
  STEP: Creating a kubernetes client @ 11/30/24 12:29:28.132
  I1130 12:29:28.132759 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:29:28.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:28.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:28.157
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-1259 @ 11/30/24 12:29:28.16
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 11/30/24 12:29:28.181
  STEP: creating service externalsvc in namespace services-1259 @ 11/30/24 12:29:28.181
  STEP: creating replication controller externalsvc in namespace services-1259 @ 11/30/24 12:29:28.194
  I1130 12:29:28.202175      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1259, replica count: 2
  I1130 12:29:31.253079      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 11/30/24 12:29:31.258
  I1130 12:29:31.281979 19 resource.go:361] Creating new exec pod
  I1130 12:29:33.301758 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-1259 exec execpodtx9fj -- /bin/sh -x -c nslookup nodeport-service.services-1259.svc.cluster.local'
  I1130 12:29:33.394710 19 builder.go:146] stderr: "+ nslookup nodeport-service.services-1259.svc.cluster.local\n"
  I1130 12:29:33.394755 19 builder.go:147] stdout: "Server:\t\t10.152.183.50\nAddress:\t10.152.183.50#53\n\nnodeport-service.services-1259.svc.cluster.local\tcanonical name = externalsvc.services-1259.svc.cluster.local.\nName:\texternalsvc.services-1259.svc.cluster.local\nAddress: 10.152.183.103\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-1259, will wait for the garbage collector to delete the pods @ 11/30/24 12:29:33.394
  I1130 12:29:33.457592 19 resources.go:139] Deleting ReplicationController externalsvc took: 8.619289ms
  I1130 12:29:33.558401 19 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.797472ms
  I1130 12:29:36.678418 19 service.go:1524] Cleaning up the NodePort to ExternalName test service
  I1130 12:29:36.694318 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1259" for this suite. @ 11/30/24 12:29:36.699
• [8.574 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:851
  STEP: Creating a kubernetes client @ 11/30/24 12:29:36.706
  I1130 12:29:36.706679 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename daemonsets @ 11/30/24 12:29:36.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:36.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:36.729
  STEP: Creating simple DaemonSet "daemon-set" @ 11/30/24 12:29:36.751
  STEP: Check that daemon pods launch on every node of the cluster. @ 11/30/24 12:29:36.759
  I1130 12:29:36.763179 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:36.763212 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:36.766244 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:29:36.766265 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  I1130 12:29:37.764399 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:37.764448 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:37.769130 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1130 12:29:37.769150 19 fixtures.go:130] Node ip-172-31-64-147 is running 0 daemon pod, expected 1
  I1130 12:29:38.764687 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:38.764737 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:29:38.768920 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 12:29:38.768939 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 11/30/24 12:29:38.773
  STEP: DeleteCollection of the DaemonSets @ 11/30/24 12:29:38.777
  STEP: Verify that ReplicaSets have been deleted @ 11/30/24 12:29:38.787
  I1130 12:29:38.806095 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9211"},"items":null}

  I1130 12:29:38.810426 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9214"},"items":[{"metadata":{"name":"daemon-set-ql2jm","generateName":"daemon-set-","namespace":"daemonsets-8358","uid":"4407266d-9862-410c-b3bb-0ce3402c19ca","resourceVersion":"9214","creationTimestamp":"2024-11-30T12:29:36Z","deletionTimestamp":"2024-11-30T12:30:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"0d1686be-ee33-4de6-b328-9028710b5022","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-11-30T12:29:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0d1686be-ee33-4de6-b328-9028710b5022\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-11-30T12:29:38Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.244.227\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-j962q","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-j962q","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-64-147","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-64-147"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:38Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:38Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:38Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:36Z"}],"hostIP":"172.31.64.147","hostIPs":[{"ip":"172.31.64.147"}],"podIP":"192.168.244.227","podIPs":[{"ip":"192.168.244.227"}],"startTime":"2024-11-30T12:29:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-11-30T12:29:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://fbd7cb2d8f6cc750a26401ece4309f1baa3d81fccb1f3da20954195b2fdd9c03","started":true,"volumeMounts":[{"name":"kube-api-access-j962q","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-smwt2","generateName":"daemon-set-","namespace":"daemonsets-8358","uid":"c1587fdd-942e-49e1-b93c-31cafd9f1d75","resourceVersion":"9211","creationTimestamp":"2024-11-30T12:29:36Z","deletionTimestamp":"2024-11-30T12:30:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"0d1686be-ee33-4de6-b328-9028710b5022","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-11-30T12:29:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0d1686be-ee33-4de6-b328-9028710b5022\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-11-30T12:29:38Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.81.141\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bbn79","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bbn79","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-94-166","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-94-166"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:38Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:38Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:38Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:36Z"}],"hostIP":"172.31.94.166","hostIPs":[{"ip":"172.31.94.166"}],"podIP":"192.168.81.141","podIPs":[{"ip":"192.168.81.141"}],"startTime":"2024-11-30T12:29:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-11-30T12:29:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://df026472a0c4bb03c4b8ad22561caab1f986ffaa5d174f2aefc8812ead33e289","started":true,"volumeMounts":[{"name":"kube-api-access-bbn79","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-v27lb","generateName":"daemon-set-","namespace":"daemonsets-8358","uid":"334bbc7d-13c6-4a91-a79b-c5c10d4c79fc","resourceVersion":"9212","creationTimestamp":"2024-11-30T12:29:36Z","deletionTimestamp":"2024-11-30T12:30:08Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"0d1686be-ee33-4de6-b328-9028710b5022","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-11-30T12:29:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0d1686be-ee33-4de6-b328-9028710b5022\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-11-30T12:29:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.62.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-8jvpd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-8jvpd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-4-119","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-4-119"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:37Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:36Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:37Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:37Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-11-30T12:29:36Z"}],"hostIP":"172.31.4.119","hostIPs":[{"ip":"172.31.4.119"}],"podIP":"192.168.62.20","podIPs":[{"ip":"192.168.62.20"}],"startTime":"2024-11-30T12:29:36Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-11-30T12:29:37Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://45e43f18cd3a89650ad94ae3d1e74d35bf87f329dd7003896546e00e873e93b3","started":true,"volumeMounts":[{"name":"kube-api-access-8jvpd","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}}]}

  I1130 12:29:38.827182 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8358" for this suite. @ 11/30/24 12:29:38.83
• [2.133 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 11/30/24 12:29:38.839
  I1130 12:29:38.839798 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 12:29:38.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:38.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:38.865
  STEP: Creating secret with name secret-test-2e3270a8-4824-4cba-937c-2d100b14ad46 @ 11/30/24 12:29:38.895
  STEP: Creating a pod to test consume secrets @ 11/30/24 12:29:38.901
  STEP: Saw pod success @ 11/30/24 12:29:42.93
  I1130 12:29:42.934858 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-secrets-d4d59ad3-7936-4b36-bc30-e1eee587eb6d container secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:29:42.948
  I1130 12:29:42.967507 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8736" for this suite. @ 11/30/24 12:29:42.971
  STEP: Destroying namespace "secret-namespace-2005" for this suite. @ 11/30/24 12:29:42.979
• [4.148 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 11/30/24 12:29:42.988
  I1130 12:29:42.988672 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:29:42.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:43.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:43.013
  STEP: Creating configMap with name projected-configmap-test-volume-c6d44629-7b84-461f-8c35-15a6eca6487e @ 11/30/24 12:29:43.016
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:29:43.022
  STEP: Saw pod success @ 11/30/24 12:29:47.048
  I1130 12:29:47.053333 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-configmaps-8a4e12c9-d47d-43fc-ad03-0f00e81e589d container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:29:47.064
  I1130 12:29:47.095799 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9633" for this suite. @ 11/30/24 12:29:47.108
• [4.138 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 11/30/24 12:29:47.126
  I1130 12:29:47.126452 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename aggregateddiscovery @ 11/30/24 12:29:47.127
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:47.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:47.156
  I1130 12:29:47.161008 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:29:50.223256 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-9365" for this suite. @ 11/30/24 12:29:50.228
• [3.110 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 11/30/24 12:29:50.236
  I1130 12:29:50.236582 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 12:29:50.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:50.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:50.262
  STEP: Creating secret with name secret-test-2f98c8ce-28c3-405b-9606-a60adfca1dc4 @ 11/30/24 12:29:50.265
  STEP: Creating a pod to test consume secrets @ 11/30/24 12:29:50.272
  STEP: Saw pod success @ 11/30/24 12:29:54.298
  I1130 12:29:54.303481 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-secrets-267ed44d-d9a4-4ee0-8eed-1197b4252523 container secret-env-test: <nil>
  STEP: delete the pod @ 11/30/24 12:29:54.312
  I1130 12:29:54.332077 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9171" for this suite. @ 11/30/24 12:29:54.337
• [4.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:796
  STEP: Creating a kubernetes client @ 11/30/24 12:29:54.347
  I1130 12:29:54.347486 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename statefulset @ 11/30/24 12:29:54.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:29:54.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:29:54.373
  STEP: Creating service test in namespace statefulset-4865 @ 11/30/24 12:29:54.377
  STEP: Looking for a node to schedule stateful set and pod @ 11/30/24 12:29:54.383
  STEP: Creating pod with conflicting port in namespace statefulset-4865 @ 11/30/24 12:29:54.39
  STEP: Waiting until pod test-pod will start running in namespace statefulset-4865 @ 11/30/24 12:29:54.4
  STEP: Creating statefulset with conflicting port in namespace statefulset-4865 @ 11/30/24 12:29:56.409
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4865 @ 11/30/24 12:29:56.416
  I1130 12:29:56.431029 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4865, name: ss-0, uid: c098284a-baf9-444c-9244-457686878025, status phase: Pending. Waiting for statefulset controller to delete.
  I1130 12:29:56.451241 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4865, name: ss-0, uid: c098284a-baf9-444c-9244-457686878025, status phase: Failed. Waiting for statefulset controller to delete.
  I1130 12:29:56.468624 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4865, name: ss-0, uid: c098284a-baf9-444c-9244-457686878025, status phase: Failed. Waiting for statefulset controller to delete.
  I1130 12:29:56.473949 19 statefulset.go:863] Observed delete event for stateful pod ss-0 in namespace statefulset-4865
  STEP: Removing pod with conflicting port in namespace statefulset-4865 @ 11/30/24 12:29:56.473
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4865 and will be in running state @ 11/30/24 12:29:56.49
  I1130 12:29:58.502942 19 statefulset.go:138] Deleting all statefulset in ns statefulset-4865
  I1130 12:29:58.507705 19 rest.go:150] Scaling statefulset ss to 0
  I1130 12:30:08.525610 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1130 12:30:08.530477 19 rest.go:88] Deleting statefulset ss
  I1130 12:30:08.544955 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4865" for this suite. @ 11/30/24 12:30:08.548
• [14.209 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 11/30/24 12:30:08.556
  I1130 12:30:08.556541 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 11/30/24 12:30:08.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:30:08.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:30:08.584
  STEP: create the container to handle the HTTPGet hook request. @ 11/30/24 12:30:08.591
  STEP: create the pod with lifecycle hook @ 11/30/24 12:30:10.612
  STEP: delete the pod with lifecycle hook @ 11/30/24 12:30:12.634
  STEP: check prestop hook @ 11/30/24 12:30:14.653
  I1130 12:30:14.671851 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-273" for this suite. @ 11/30/24 12:30:14.676
• [6.128 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:620
  STEP: Creating a kubernetes client @ 11/30/24 12:30:14.684
  I1130 12:30:14.684593 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename field-validation @ 11/30/24 12:30:14.685
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:30:14.704
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:30:14.707
  I1130 12:30:14.710556 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  W1130 12:30:17.249103      19 warnings.go:70] unknown field "alpha"
  W1130 12:30:17.249125      19 warnings.go:70] unknown field "beta"
  W1130 12:30:17.249129      19 warnings.go:70] unknown field "delta"
  W1130 12:30:17.249132      19 warnings.go:70] unknown field "epsilon"
  W1130 12:30:17.249134      19 warnings.go:70] unknown field "gamma"
  I1130 12:30:17.796608 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7556" for this suite. @ 11/30/24 12:30:17.8
• [3.125 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:814
  STEP: Creating a kubernetes client @ 11/30/24 12:30:17.809
  I1130 12:30:17.809503 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:30:17.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:30:17.832
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:30:17.835
  STEP: Setting up server cert @ 11/30/24 12:30:17.864
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:30:17.997
  STEP: Deploying the webhook pod @ 11/30/24 12:30:18.009
  STEP: Wait for the deployment to be ready @ 11/30/24 12:30:18.024
  I1130 12:30:18.032645 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 11/30/24 12:30:20.046
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:30:20.058
  I1130 12:30:21.058178 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 11/30/24 12:30:21.067
  I1130 12:30:21.119009 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5934" for this suite. @ 11/30/24 12:30:21.125
  STEP: Destroying namespace "webhook-markers-320" for this suite. @ 11/30/24 12:30:21.133
• [3.332 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:282
  STEP: Creating a kubernetes client @ 11/30/24 12:30:21.141
  I1130 12:30:21.141216 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:30:21.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:30:21.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:30:21.163
  STEP: Setting up server cert @ 11/30/24 12:30:21.199
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:30:21.489
  STEP: Deploying the webhook pod @ 11/30/24 12:30:21.497
  STEP: Wait for the deployment to be ready @ 11/30/24 12:30:21.511
  I1130 12:30:21.518793 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 11/30/24 12:30:23.533
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:30:23.545
  I1130 12:30:24.545494 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I1130 12:30:24.555215 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1641-crds.webhook.example.com via the AdmissionRegistration API @ 11/30/24 12:30:25.065
  STEP: Creating a custom resource that should be mutated by the webhook @ 11/30/24 12:30:25.082
  I1130 12:30:27.674155 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5367" for this suite. @ 11/30/24 12:30:27.678
  STEP: Destroying namespace "webhook-markers-5402" for this suite. @ 11/30/24 12:30:27.688
• [6.555 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:965
  STEP: Creating a kubernetes client @ 11/30/24 12:30:27.695
  I1130 12:30:27.695993 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename statefulset @ 11/30/24 12:30:27.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:30:27.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:30:27.72
  STEP: Creating service test in namespace statefulset-8115 @ 11/30/24 12:30:27.723
  I1130 12:30:27.741106 19 wait.go:40] Found 0 stateful pods, waiting for 1
  I1130 12:30:37.742495 19 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 11/30/24 12:30:37.75
  I1130 12:30:37.774907 19 wait.go:40] Found 1 stateful pods, waiting for 2
  I1130 12:30:47.775151 19 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I1130 12:30:47.775188 19 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 11/30/24 12:30:47.782
  STEP: Delete all of the StatefulSets @ 11/30/24 12:30:47.787
  STEP: Verify that StatefulSets have been deleted @ 11/30/24 12:30:47.797
  I1130 12:30:47.800931 19 statefulset.go:138] Deleting all statefulset in ns statefulset-8115
  I1130 12:30:47.814715 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8115" for this suite. @ 11/30/24 12:30:47.819
• [20.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 11/30/24 12:30:47.831
  I1130 12:30:47.831911 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename custom-resource-definition @ 11/30/24 12:30:47.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:30:47.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:30:47.855
  I1130 12:30:47.860221 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:30:50.950592 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-545" for this suite. @ 11/30/24 12:30:50.955
• [3.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:221
  STEP: Creating a kubernetes client @ 11/30/24 12:30:50.964
  I1130 12:30:50.964923 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-preemption @ 11/30/24 12:30:50.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:30:50.985
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:30:50.989
  I1130 12:30:51.010106 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  I1130 12:31:51.017262 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 11/30/24 12:31:51.021
  I1130 12:31:51.045295 19 preemption.go:266] Created pod: pod0-0-sched-preemption-low-priority
  I1130 12:31:51.052732 19 preemption.go:266] Created pod: pod0-1-sched-preemption-medium-priority
  I1130 12:31:51.070280 19 preemption.go:266] Created pod: pod1-0-sched-preemption-medium-priority
  I1130 12:31:51.077770 19 preemption.go:266] Created pod: pod1-1-sched-preemption-medium-priority
  I1130 12:31:51.096540 19 preemption.go:266] Created pod: pod2-0-sched-preemption-medium-priority
  I1130 12:31:51.106026 19 preemption.go:266] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 11/30/24 12:31:51.106
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 11/30/24 12:31:53.136
  I1130 12:31:57.255994 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6675" for this suite. @ 11/30/24 12:31:57.259
• [66.302 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 11/30/24 12:31:57.267
  I1130 12:31:57.267282 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename subpath @ 11/30/24 12:31:57.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:31:57.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:31:57.292
  STEP: Setting up data @ 11/30/24 12:31:57.297
  STEP: Creating pod pod-subpath-test-projected-9lmx @ 11/30/24 12:31:57.31
  STEP: Creating a pod to test atomic-volume-subpath @ 11/30/24 12:31:57.31
  STEP: Saw pod success @ 11/30/24 12:32:21.391
  I1130 12:32:21.395947 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-subpath-test-projected-9lmx container test-container-subpath-projected-9lmx: <nil>
  STEP: delete the pod @ 11/30/24 12:32:21.409
  STEP: Deleting pod pod-subpath-test-projected-9lmx @ 11/30/24 12:32:21.437
  I1130 12:32:21.438000 19 delete.go:62] Deleting pod "pod-subpath-test-projected-9lmx" in namespace "subpath-9306"
  I1130 12:32:21.442002 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9306" for this suite. @ 11/30/24 12:32:21.446
• [24.186 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 11/30/24 12:32:21.453
  I1130 12:32:21.453733 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:32:21.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:32:21.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:32:21.48
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:32:21.483
  STEP: Saw pod success @ 11/30/24 12:32:25.51
  I1130 12:32:25.516221 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-321aeeba-7c01-48f8-a369-24277edab9fe container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:32:25.53
  I1130 12:32:25.552268 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1173" for this suite. @ 11/30/24 12:32:25.556
• [4.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 11/30/24 12:32:25.563
  I1130 12:32:25.563498 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename validating-admission-policy @ 11/30/24 12:32:25.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:32:25.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:32:25.586
  STEP: creating the policy @ 11/30/24 12:32:25.594
  STEP: waiting until the marker is denied @ 11/30/24 12:32:25.609
  STEP: testing a replicated Deployment to be allowed @ 11/30/24 12:32:26.423
  STEP: testing a non-replicated ReplicaSet not to be denied @ 11/30/24 12:32:26.443
  I1130 12:32:26.484854 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-3536" for this suite. @ 11/30/24 12:32:26.492
• [0.946 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 11/30/24 12:32:26.509
  I1130 12:32:26.509792 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 12:32:26.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:32:26.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:32:26.534
  STEP: Creating pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178 @ 11/30/24 12:32:26.538
  STEP: checking the pod's current state and verifying that restartCount is present @ 11/30/24 12:32:28.561
  I1130 12:32:28.565707 19 container_probe.go:1749] Initial restart count of pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 is 0
  I1130 12:32:28.570325 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:30.575240 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:32.581211 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:34.587203 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:36.593857 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:38.600835 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:40.606915 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:42.613324 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:44.620520 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:46.626095 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:48.632310 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:50.638515 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:52.644200 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:54.650529 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:56.656233 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:32:58.661537 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:00.667611 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:02.673665 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:04.680716 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:06.686898 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:08.693744 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:10.699305 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:12.705314 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:14.711160 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:16.718526 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:18.725359 19 container_probe.go:1759] Get pod busybox-e8cb7094-c453-457b-81e6-3910226c7472 in namespace container-probe-178
  I1130 12:33:18.725443 19 container_probe.go:1763] Restart count of pod container-probe-178/busybox-e8cb7094-c453-457b-81e6-3910226c7472 is now 1 (50.159711223s elapsed)
  STEP: deleting the pod @ 11/30/24 12:33:18.726
  I1130 12:33:18.745683 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-178" for this suite. @ 11/30/24 12:33:18.75
• [52.251 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 11/30/24 12:33:18.762
  I1130 12:33:18.762191 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename limitrange @ 11/30/24 12:33:18.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:18.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:18.786
  STEP: Creating a LimitRange @ 11/30/24 12:33:18.789
  STEP: Setting up watch @ 11/30/24 12:33:18.789
  STEP: Submitting a LimitRange @ 11/30/24 12:33:18.893
  STEP: Verifying LimitRange creation was observed @ 11/30/24 12:33:18.899
  STEP: Fetching the LimitRange to ensure it has proper values @ 11/30/24 12:33:18.9
  I1130 12:33:18.904806 19 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I1130 12:33:18.904839 19 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 11/30/24 12:33:18.904
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 11/30/24 12:33:18.911
  I1130 12:33:18.916167 19 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I1130 12:33:18.916200 19 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 11/30/24 12:33:18.916
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 11/30/24 12:33:18.921
  I1130 12:33:18.927894 19 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I1130 12:33:18.927922 19 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 11/30/24 12:33:18.927
  STEP: Failing to create a Pod with more than max resources @ 11/30/24 12:33:18.93
  STEP: Updating a LimitRange @ 11/30/24 12:33:18.932
  STEP: Verifying LimitRange updating is effective @ 11/30/24 12:33:18.937
  STEP: Creating a Pod with less than former min resources @ 11/30/24 12:33:20.944
  STEP: Failing to create a Pod with more than max resources @ 11/30/24 12:33:20.953
  STEP: Deleting a LimitRange @ 11/30/24 12:33:20.956
  STEP: Verifying the LimitRange was deleted @ 11/30/24 12:33:20.966
  I1130 12:33:25.975162 19 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 11/30/24 12:33:25.975
  I1130 12:33:25.987258 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-4267" for this suite. @ 11/30/24 12:33:25.992
• [7.239 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 11/30/24 12:33:26.001
  I1130 12:33:26.001427 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 12:33:26.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:26.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:26.024
  STEP: Creating configMap with name configmap-test-volume-9deadafd-df15-4bc7-99d4-50cfed5bc62a @ 11/30/24 12:33:26.027
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:33:26.031
  STEP: Saw pod success @ 11/30/24 12:33:28.049
  I1130 12:33:28.053795 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-configmaps-14a28450-1895-4399-98c4-b25eb231a267 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:33:28.07
  I1130 12:33:28.090529 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-66" for this suite. @ 11/30/24 12:33:28.095
• [2.103 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:821
  STEP: Creating a kubernetes client @ 11/30/24 12:33:28.104
  I1130 12:33:28.104841 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:33:28.105
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:28.124
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:28.128
  STEP: creating service multi-endpoint-test in namespace services-5695 @ 11/30/24 12:33:28.133
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5695 to expose endpoints map[] @ 11/30/24 12:33:28.144
  I1130 12:33:28.155243 19 service.go:4267] Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  I1130 12:33:29.165692 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-5695 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-5695 @ 11/30/24 12:33:29.165
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5695 to expose endpoints map[pod1:[100]] @ 11/30/24 12:33:31.19
  I1130 12:33:31.205847 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-5695 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-5695 @ 11/30/24 12:33:31.205
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5695 to expose endpoints map[pod1:[100] pod2:[101]] @ 11/30/24 12:33:33.23
  I1130 12:33:33.246444 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-5695 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 11/30/24 12:33:33.246
  I1130 12:33:33.246507 19 resource.go:361] Creating new exec pod
  I1130 12:33:36.263681 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-5695 exec execpodrmmwb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I1130 12:33:36.355574 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  I1130 12:33:36.355618 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:33:36.355696 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-5695 exec execpodrmmwb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.175 80'
  I1130 12:33:36.436646 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.175 80\nConnection to 10.152.183.175 80 port [tcp/http] succeeded!\n"
  I1130 12:33:36.436688 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:33:36.436762 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-5695 exec execpodrmmwb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I1130 12:33:36.524518 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  I1130 12:33:36.524570 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:33:36.524680 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-5695 exec execpodrmmwb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.175 81'
  I1130 12:33:36.608381 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.175 81\nConnection to 10.152.183.175 81 port [tcp/*] succeeded!\n"
  I1130 12:33:36.608430 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-5695 @ 11/30/24 12:33:36.608
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5695 to expose endpoints map[pod2:[101]] @ 11/30/24 12:33:36.627
  I1130 12:33:36.642833 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-5695 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-5695 @ 11/30/24 12:33:36.643
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5695 to expose endpoints map[] @ 11/30/24 12:33:36.655
  I1130 12:33:36.672390 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-5695 exposes endpoints map[]
  I1130 12:33:36.690782 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5695" for this suite. @ 11/30/24 12:33:36.695
• [8.598 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2194
  STEP: Creating a kubernetes client @ 11/30/24 12:33:36.703
  I1130 12:33:36.703959 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:33:36.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:36.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:36.725
  STEP: creating service in namespace services-3404 @ 11/30/24 12:33:36.729
  STEP: creating service affinity-nodeport in namespace services-3404 @ 11/30/24 12:33:36.729
  STEP: creating replication controller affinity-nodeport in namespace services-3404 @ 11/30/24 12:33:36.748
  I1130 12:33:36.759665      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-3404, replica count: 3
  I1130 12:33:39.810504      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 12:33:39.823981 19 resource.go:361] Creating new exec pod
  I1130 12:33:42.853574 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3404 exec execpod-affinitypns4g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I1130 12:33:42.938054 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  I1130 12:33:42.938103 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:33:42.938192 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3404 exec execpod-affinitypns4g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.59 80'
  I1130 12:33:43.022634 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.59 80\nConnection to 10.152.183.59 80 port [tcp/http] succeeded!\n"
  I1130 12:33:43.022678 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:33:43.022766 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3404 exec execpod-affinitypns4g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.64.147 31133'
  I1130 12:33:43.106143 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.64.147 31133\nConnection to 172.31.64.147 31133 port [tcp/*] succeeded!\n"
  I1130 12:33:43.106189 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:33:43.106273 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3404 exec execpod-affinitypns4g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.94.166 31133'
  I1130 12:33:43.195229 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.94.166 31133\nConnection to 172.31.94.166 31133 port [tcp/*] succeeded!\n"
  I1130 12:33:43.195281 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:33:43.195361 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3404 exec execpod-affinitypns4g -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.4.119:31133/ ; done'
  I1130 12:33:43.339636 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:31133/\n"
  I1130 12:33:43.339692 19 builder.go:147] stdout: "\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd\naffinity-nodeport-j9cgd"
  I1130 12:33:43.339704 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339712 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339719 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339725 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339732 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339738 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339743 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339750 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339757 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339764 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339770 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339781 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339786 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339791 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339796 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339802 19 service.go:242] Received response from host: affinity-nodeport-j9cgd
  I1130 12:33:43.339872 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-3404, will wait for the garbage collector to delete the pods @ 11/30/24 12:33:43.356
  I1130 12:33:43.420697 19 resources.go:139] Deleting ReplicationController affinity-nodeport took: 9.461266ms
  I1130 12:33:43.521240 19 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 100.538717ms
  I1130 12:33:46.151652 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3404" for this suite. @ 11/30/24 12:33:46.155
• [9.459 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 11/30/24 12:33:46.163
  I1130 12:33:46.163991 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 12:33:46.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:46.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:46.185
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 11/30/24 12:33:46.188
  STEP: Saw pod success @ 11/30/24 12:33:50.219
  I1130 12:33:50.223776 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-b5c55ff2-45b0-441f-855e-0a617fb8df96 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:33:50.232
  I1130 12:33:50.254786 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9017" for this suite. @ 11/30/24 12:33:50.259
• [4.103 seconds]
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 11/30/24 12:33:50.267
  I1130 12:33:50.267309 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:33:50.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:50.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:50.29
  STEP: Creating a pod to test downward api env vars @ 11/30/24 12:33:50.293
  STEP: Saw pod success @ 11/30/24 12:33:54.321
  I1130 12:33:54.325400 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downward-api-781b3c19-d24f-404d-96e3-d59f11fe2d37 container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 12:33:54.334
  I1130 12:33:54.356284 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4078" for this suite. @ 11/30/24 12:33:54.36
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 11/30/24 12:33:54.368
  I1130 12:33:54.368969 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename custom-resource-definition @ 11/30/24 12:33:54.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:54.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:54.391
  STEP: fetching the /apis discovery document @ 11/30/24 12:33:54.393
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 11/30/24 12:33:54.395
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 11/30/24 12:33:54.395
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 11/30/24 12:33:54.395
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 11/30/24 12:33:54.396
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 11/30/24 12:33:54.396
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 11/30/24 12:33:54.397
  I1130 12:33:54.397752 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9894" for this suite. @ 11/30/24 12:33:54.402
• [0.042 seconds]
------------------------------
SSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 11/30/24 12:33:54.411
  I1130 12:33:54.411043 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename podtemplate @ 11/30/24 12:33:54.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:54.429
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:54.432
  STEP: Create set of pod templates @ 11/30/24 12:33:54.435
  I1130 12:33:54.442459 19 podtemplates.go:143] created test-podtemplate-1
  I1130 12:33:54.448404 19 podtemplates.go:143] created test-podtemplate-2
  I1130 12:33:54.454005 19 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 11/30/24 12:33:54.454
  STEP: delete collection of pod templates @ 11/30/24 12:33:54.457
  I1130 12:33:54.457655 19 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 11/30/24 12:33:54.479
  I1130 12:33:54.479631 19 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I1130 12:33:54.483887 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5038" for this suite. @ 11/30/24 12:33:54.487
• [0.087 seconds]
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 11/30/24 12:33:54.497
  I1130 12:33:54.497684 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 12:33:54.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:54.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:54.518
  STEP: Creating configMap configmap-6457/configmap-test-5849759b-11c8-432c-9146-27102caa0b94 @ 11/30/24 12:33:54.522
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:33:54.527
  STEP: Saw pod success @ 11/30/24 12:33:58.551
  I1130 12:33:58.559161 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-configmaps-e4d40ee4-0537-4f48-9973-ae1d3adfc70f container env-test: <nil>
  STEP: delete the pod @ 11/30/24 12:33:58.568
  I1130 12:33:58.589810 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6457" for this suite. @ 11/30/24 12:33:58.594
• [4.105 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 11/30/24 12:33:58.603
  I1130 12:33:58.603098 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename watch @ 11/30/24 12:33:58.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:33:58.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:33:58.625
  STEP: getting a starting resourceVersion @ 11/30/24 12:33:58.627
  STEP: starting a background goroutine to produce watch events @ 11/30/24 12:33:58.63
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 11/30/24 12:33:58.631
  I1130 12:34:01.410256 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9261" for this suite. @ 11/30/24 12:34:01.459
• [2.910 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 11/30/24 12:34:01.513
  I1130 12:34:01.513630 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename subjectreview @ 11/30/24 12:34:01.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:34:01.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:34:01.539
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-1174" @ 11/30/24 12:34:01.542
  I1130 12:34:01.546893 19 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-1174:e2e"
  I1130 12:34:01.546922 19 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-1174"}
  I1130 12:34:01.546932 19 subjectreviews.go:71] saUID: "e6bdb2e5-cd66-461e-972f-a9bda6dc7052"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-1174:e2e" @ 11/30/24 12:34:01.546
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-1174:e2e" @ 11/30/24 12:34:01.547
  I1130 12:34:01.548786 19 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-1174:e2e" api 'list' configmaps in "subjectreview-1174" namespace @ 11/30/24 12:34:01.548
  I1130 12:34:01.550258 19 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-1174:e2e" @ 11/30/24 12:34:01.55
  I1130 12:34:01.552387 19 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I1130 12:34:01.552408 19 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I1130 12:34:01.552517 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-1174" for this suite. @ 11/30/24 12:34:01.556
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:398
  STEP: Creating a kubernetes client @ 11/30/24 12:34:01.563
  I1130 12:34:01.563447 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:34:01.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:34:01.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:34:01.585
  STEP: Counting existing ResourceQuota @ 11/30/24 12:34:01.59
  STEP: Creating a ResourceQuota @ 11/30/24 12:34:06.595
  STEP: Ensuring resource quota status is calculated @ 11/30/24 12:34:06.602
  STEP: Creating a ReplicationController @ 11/30/24 12:34:08.609
  STEP: Ensuring resource quota status captures replication controller creation @ 11/30/24 12:34:08.622
  STEP: Deleting a ReplicationController @ 11/30/24 12:34:10.627
  STEP: Ensuring resource quota status released usage @ 11/30/24 12:34:10.636
  I1130 12:34:12.641414 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4635" for this suite. @ 11/30/24 12:34:12.645
• [11.089 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 11/30/24 12:34:12.652
  I1130 12:34:12.652535 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 12:34:12.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:34:12.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:34:12.675
  I1130 12:34:34.765879 19 container_probe.go:92] Container started at 2024-11-30 12:34:13 +0000 UTC, pod became ready at 2024-11-30 12:34:33 +0000 UTC
  I1130 12:34:34.765999 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9063" for this suite. @ 11/30/24 12:34:34.77
• [22.128 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 11/30/24 12:34:34.78
  I1130 12:34:34.780155 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename var-expansion @ 11/30/24 12:34:34.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:34:34.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:34:34.803
  I1130 12:34:36.827942 19 delete.go:62] Deleting pod "var-expansion-45e2a18a-dbba-4492-be11-640d6ab5e54b" in namespace "var-expansion-6627"
  I1130 12:34:36.837654 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-45e2a18a-dbba-4492-be11-640d6ab5e54b" to be fully deleted
  I1130 12:34:38.848866 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6627" for this suite. @ 11/30/24 12:34:38.854
• [4.083 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 11/30/24 12:34:38.863
  I1130 12:34:38.863228 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:34:38.863
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:34:38.883
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:34:38.886
  STEP: Creating configMap with name projected-configmap-test-volume-329fed46-d3f4-42cc-99ec-ab54054114f2 @ 11/30/24 12:34:38.889
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:34:38.894
  STEP: Saw pod success @ 11/30/24 12:34:42.918
  I1130 12:34:42.923357 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-projected-configmaps-0f6e4982-477c-4c66-8323-690a79c0b6b6 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:34:42.941
  I1130 12:34:42.961856 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-689" for this suite. @ 11/30/24 12:34:42.966
• [4.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 11/30/24 12:34:42.975
  I1130 12:34:42.975144 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:34:42.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:34:42.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:34:42.998
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-c765b0a4-cd3d-49e0-9820-2f934881fe03 @ 11/30/24 12:34:43.006
  STEP: Creating the pod @ 11/30/24 12:34:43.011
  STEP: Updating configmap projected-configmap-test-upd-c765b0a4-cd3d-49e0-9820-2f934881fe03 @ 11/30/24 12:34:45.043
  STEP: waiting to observe update in volume @ 11/30/24 12:34:45.047
  I1130 12:35:55.412495 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-250" for this suite. @ 11/30/24 12:35:55.416
• [72.452 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3703
  STEP: Creating a kubernetes client @ 11/30/24 12:35:55.427
  I1130 12:35:55.427665 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:35:55.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:35:55.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:35:55.452
  STEP: creating service multiprotocol-test in namespace services-401 @ 11/30/24 12:35:55.455
  STEP: creating pod pod1 in namespace services-401 @ 11/30/24 12:35:55.468
  STEP: Creating pod pod1 in namespace services-401 @ 11/30/24 12:35:55.468
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-401 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 11/30/24 12:35:57.497
  I1130 12:35:57.511510 19 service.go:4392] successfully validated that service multiprotocol-test in namespace services-401 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 11/30/24 12:35:57.511
  I1130 12:35:57.511572 19 resource.go:361] Creating new exec pod
  I1130 12:35:59.534324 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80'
  I1130 12:35:59.627885 19 builder.go:146] stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.184 80\nConnection to 10.152.183.184 80 port [tcp/http] succeeded!\n"
  I1130 12:35:59.627930 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:35:59.628077 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.184 80'
  I1130 12:36:03.718939 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.184 80\nConnection to 10.152.183.184 80 port [udp/*] succeeded!\n"
  I1130 12:36:03.718984 19 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 11/30/24 12:36:03.719
  I1130 12:36:03.731964 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80'
  I1130 12:36:03.822073 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.184 80\nConnection to 10.152.183.184 80 port [tcp/http] succeeded!\n"
  I1130 12:36:03.822125 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:36:03.822217 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.184 80'
  I1130 12:36:07.917817 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.184 80\nConnection to 10.152.183.184 80 port [udp/*] succeeded!\n"
  I1130 12:36:07.917863 19 builder.go:147] stdout: ""
  I1130 12:36:07.917922 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.184 80'
  I1130 12:36:12.007994 19 builder.go:146] stderr: "+ + ncecho -v hostName -u\n -w 2 10.152.183.184 80\nConnection to 10.152.183.184 80 port [udp/*] succeeded!\n"
  I1130 12:36:12.008040 19 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 11/30/24 12:36:12.008
  I1130 12:36:12.019802 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.184 80'
  I1130 12:36:16.117491 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.184 80\nConnection to 10.152.183.184 80 port [udp/*] succeeded!\n"
  I1130 12:36:16.117542 19 builder.go:147] stdout: "pod1"
  I1130 12:36:16.117647 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80'
  I1130 12:36:18.202585 19 builder.go:135] rc: 1
  I1130 12:36:18.202658 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.152.183.184 80
  nc: connect to 10.152.183.184 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I1130 12:36:18.202725 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80'
  I1130 12:36:20.346108 19 builder.go:135] rc: 1
  I1130 12:36:20.346163 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.152.183.184 80
  nc: connect to 10.152.183.184 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I1130 12:36:20.346229 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80'
  I1130 12:36:22.433121 19 builder.go:135] rc: 1
  I1130 12:36:22.433178 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-401 exec execpodnll59 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.184 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.152.183.184 80
  nc: connect to 10.152.183.184 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I1130 12:36:22.433385 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-401" for this suite. @ 11/30/24 12:36:22.439
• [27.021 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 11/30/24 12:36:22.448
  I1130 12:36:22.448343 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-runtime @ 11/30/24 12:36:22.448
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:36:22.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:36:22.473
  STEP: create the container @ 11/30/24 12:36:22.476
  W1130 12:36:22.489606      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 11/30/24 12:36:22.489
  STEP: get the container status @ 11/30/24 12:36:25.51
  STEP: the container should be terminated @ 11/30/24 12:36:25.514
  STEP: the termination message should be set @ 11/30/24 12:36:25.514
  I1130 12:36:25.514205 19 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 11/30/24 12:36:25.514
  I1130 12:36:25.536131 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2850" for this suite. @ 11/30/24 12:36:25.541
• [3.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 11/30/24 12:36:25.549
  I1130 12:36:25.549445 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:36:25.55
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:36:25.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:36:25.574
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:36:25.577
  STEP: Saw pod success @ 11/30/24 12:36:29.602
  I1130 12:36:29.606222 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-e2da40ea-f699-49bf-a3c5-6cbc37527f9d container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:36:29.614
  I1130 12:36:29.635620 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8797" for this suite. @ 11/30/24 12:36:29.639
• [4.098 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 11/30/24 12:36:29.647
  I1130 12:36:29.647964 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 12:36:29.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:36:29.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:36:29.669
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 11/30/24 12:36:29.673
  I1130 12:36:29.673419 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:36:30.973351 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:36:35.989961 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7761" for this suite. @ 11/30/24 12:36:35.998
• [6.358 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 11/30/24 12:36:36.006
  I1130 12:36:36.006335 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename subpath @ 11/30/24 12:36:36.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:36:36.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:36:36.028
  STEP: Setting up data @ 11/30/24 12:36:36.031
  STEP: Creating pod pod-subpath-test-downwardapi-xm5d @ 11/30/24 12:36:36.041
  STEP: Creating a pod to test atomic-volume-subpath @ 11/30/24 12:36:36.041
  STEP: Saw pod success @ 11/30/24 12:37:00.123
  I1130 12:37:00.127630 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-subpath-test-downwardapi-xm5d container test-container-subpath-downwardapi-xm5d: <nil>
  STEP: delete the pod @ 11/30/24 12:37:00.14
  STEP: Deleting pod pod-subpath-test-downwardapi-xm5d @ 11/30/24 12:37:00.159
  I1130 12:37:00.159614 19 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-xm5d" in namespace "subpath-3296"
  I1130 12:37:00.163311 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3296" for this suite. @ 11/30/24 12:37:00.167
• [24.168 seconds]
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 11/30/24 12:37:00.174
  I1130 12:37:00.174792 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubelet-test @ 11/30/24 12:37:00.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:00.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:00.196
  STEP: Waiting for pod completion @ 11/30/24 12:37:00.209
  I1130 12:37:04.235878 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9860" for this suite. @ 11/30/24 12:37:04.24
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 11/30/24 12:37:04.247
  I1130 12:37:04.247892 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename gc @ 11/30/24 12:37:04.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:04.268
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:04.271
  STEP: create the rc1 @ 11/30/24 12:37:04.278
  STEP: create the rc2 @ 11/30/24 12:37:04.285
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 11/30/24 12:37:10.317
  STEP: delete the rc simpletest-rc-to-be-deleted @ 11/30/24 12:37:11.224
  STEP: wait for the rc to be deleted @ 11/30/24 12:37:11.233
  I1130 12:37:16.264546 19 garbage_collector.go:762] 68 pods remaining
  I1130 12:37:16.264578 19 garbage_collector.go:769] 68 pods has nil DeletionTimestamp
  I1130 12:37:16.264593 19 garbage_collector.go:770] 
  STEP: Gathering metrics @ 11/30/24 12:37:21.251
  W1130 12:37:21.257556      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1130 12:37:21.257884 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1130 12:37:21.258421 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2c9cj" in namespace "gc-5199"
  I1130 12:37:21.271829 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2xkwl" in namespace "gc-5199"
  I1130 12:37:21.289714 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-44qwf" in namespace "gc-5199"
  I1130 12:37:21.303301 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4bnz7" in namespace "gc-5199"
  I1130 12:37:21.319902 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4ngtp" in namespace "gc-5199"
  I1130 12:37:21.332101 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4v59x" in namespace "gc-5199"
  I1130 12:37:21.349597 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4wnrb" in namespace "gc-5199"
  I1130 12:37:21.361431 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-52mwq" in namespace "gc-5199"
  I1130 12:37:21.376901 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-57djg" in namespace "gc-5199"
  I1130 12:37:21.391664 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5bx7l" in namespace "gc-5199"
  I1130 12:37:21.408743 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5m2h9" in namespace "gc-5199"
  I1130 12:37:21.422983 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5tpgv" in namespace "gc-5199"
  I1130 12:37:21.439654 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-67qws" in namespace "gc-5199"
  I1130 12:37:21.455539 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-69mw2" in namespace "gc-5199"
  I1130 12:37:21.469877 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6czbn" in namespace "gc-5199"
  I1130 12:37:21.485586 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6drqf" in namespace "gc-5199"
  I1130 12:37:21.499807 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6gkmw" in namespace "gc-5199"
  I1130 12:37:21.515389 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6gshg" in namespace "gc-5199"
  I1130 12:37:21.542259 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6ntr7" in namespace "gc-5199"
  I1130 12:37:21.560123 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6zsdb" in namespace "gc-5199"
  I1130 12:37:21.576323 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-74gjj" in namespace "gc-5199"
  I1130 12:37:21.590043 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7m9t7" in namespace "gc-5199"
  I1130 12:37:21.617988 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-82q9b" in namespace "gc-5199"
  I1130 12:37:21.634027 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-929qm" in namespace "gc-5199"
  I1130 12:37:21.648832 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9kkv7" in namespace "gc-5199"
  I1130 12:37:21.661947 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9s88l" in namespace "gc-5199"
  I1130 12:37:21.676636 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9wvwr" in namespace "gc-5199"
  I1130 12:37:21.709642 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b99gk" in namespace "gc-5199"
  I1130 12:37:21.723725 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-brvtt" in namespace "gc-5199"
  I1130 12:37:21.738836 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bshhz" in namespace "gc-5199"
  I1130 12:37:21.752147 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bvwch" in namespace "gc-5199"
  I1130 12:37:21.764174 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bxggn" in namespace "gc-5199"
  I1130 12:37:21.782532 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-c4z5g" in namespace "gc-5199"
  I1130 12:37:21.801652 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-c8msd" in namespace "gc-5199"
  I1130 12:37:21.822608 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dd2vr" in namespace "gc-5199"
  I1130 12:37:21.839273 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dhdfl" in namespace "gc-5199"
  I1130 12:37:21.855843 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dzf9f" in namespace "gc-5199"
  I1130 12:37:21.870518 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f78tg" in namespace "gc-5199"
  I1130 12:37:21.884992 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fjc7f" in namespace "gc-5199"
  I1130 12:37:21.896404 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-flxpc" in namespace "gc-5199"
  I1130 12:37:21.909777 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fsqmh" in namespace "gc-5199"
  I1130 12:37:21.926939 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-g8lk6" in namespace "gc-5199"
  I1130 12:37:21.949364 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gdsnc" in namespace "gc-5199"
  I1130 12:37:21.960707 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gpx8z" in namespace "gc-5199"
  I1130 12:37:21.975892 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hg5tm" in namespace "gc-5199"
  I1130 12:37:21.994937 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hqvnz" in namespace "gc-5199"
  I1130 12:37:22.007288 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j2lkp" in namespace "gc-5199"
  I1130 12:37:22.020017 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jlzhf" in namespace "gc-5199"
  I1130 12:37:22.039573 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jz9mn" in namespace "gc-5199"
  I1130 12:37:22.056000 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-k7tnt" in namespace "gc-5199"
  I1130 12:37:22.066658 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5199" for this suite. @ 11/30/24 12:37:22.071
• [17.832 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:746
  STEP: Creating a kubernetes client @ 11/30/24 12:37:22.08
  I1130 12:37:22.080633 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:37:22.081
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:22.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:22.103
  STEP: Creating a ResourceQuota with terminating scope @ 11/30/24 12:37:22.108
  STEP: Ensuring ResourceQuota status is calculated @ 11/30/24 12:37:22.116
  STEP: Creating a ResourceQuota with not terminating scope @ 11/30/24 12:37:24.121
  STEP: Ensuring ResourceQuota status is calculated @ 11/30/24 12:37:24.127
  STEP: Creating a long running pod @ 11/30/24 12:37:26.132
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 11/30/24 12:37:26.153
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 11/30/24 12:37:28.157
  STEP: Deleting the pod @ 11/30/24 12:37:30.162
  STEP: Ensuring resource quota status released the pod usage @ 11/30/24 12:37:30.178
  STEP: Creating a terminating pod @ 11/30/24 12:37:32.183
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 11/30/24 12:37:32.198
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 11/30/24 12:37:34.204
  STEP: Deleting the pod @ 11/30/24 12:37:36.211
  STEP: Ensuring resource quota status released the pod usage @ 11/30/24 12:37:36.228
  I1130 12:37:38.233654 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5211" for this suite. @ 11/30/24 12:37:38.238
• [16.165 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:258
  STEP: Creating a kubernetes client @ 11/30/24 12:37:38.245
  I1130 12:37:38.245746 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:37:38.246
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:38.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:38.268
  STEP: Setting up server cert @ 11/30/24 12:37:38.293
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:37:38.452
  STEP: Deploying the webhook pod @ 11/30/24 12:37:38.462
  STEP: Wait for the deployment to be ready @ 11/30/24 12:37:38.477
  I1130 12:37:38.493551 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 11/30/24 12:37:40.508
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:37:40.521
  I1130 12:37:41.522759 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 11/30/24 12:37:41.532
  STEP: create a pod that should be updated by the webhook @ 11/30/24 12:37:41.548
  I1130 12:37:41.617132 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7112" for this suite. @ 11/30/24 12:37:41.622
  STEP: Destroying namespace "webhook-markers-5268" for this suite. @ 11/30/24 12:37:41.628
• [3.390 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 11/30/24 12:37:41.636
  I1130 12:37:41.636165 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename limitrange @ 11/30/24 12:37:41.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:41.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:41.657
  STEP: Creating LimitRange "e2e-limitrange-jb6r9" in namespace "limitrange-5764" @ 11/30/24 12:37:41.66
  STEP: Creating another limitRange in another namespace @ 11/30/24 12:37:41.667
  I1130 12:37:41.681096 19 limit_range.go:299] Namespace "e2e-limitrange-jb6r9-7781" created
  I1130 12:37:41.681119 19 limit_range.go:300] Creating LimitRange "e2e-limitrange-jb6r9" in namespace "e2e-limitrange-jb6r9-7781"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-jb6r9" @ 11/30/24 12:37:41.688
  I1130 12:37:41.691378 19 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-jb6r9" in "limitrange-5764" namespace @ 11/30/24 12:37:41.691
  I1130 12:37:41.697231 19 limit_range.go:335] LimitRange "e2e-limitrange-jb6r9" has been patched
  STEP: Delete LimitRange "e2e-limitrange-jb6r9" by Collection with labelSelector: "e2e-limitrange-jb6r9=patched" @ 11/30/24 12:37:41.697
  STEP: Confirm that the limitRange "e2e-limitrange-jb6r9" has been deleted @ 11/30/24 12:37:41.706
  I1130 12:37:41.706543 19 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I1130 12:37:41.710828 19 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-jb6r9=patched"
  I1130 12:37:41.710854 19 limit_range.go:344] LimitRange "e2e-limitrange-jb6r9" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-jb6r9" @ 11/30/24 12:37:41.71
  I1130 12:37:41.714728 19 limit_range.go:350] Found 1 limitRange
  I1130 12:37:41.714834 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-5764" for this suite. @ 11/30/24 12:37:41.718
  STEP: Destroying namespace "e2e-limitrange-jb6r9-7781" for this suite. @ 11/30/24 12:37:41.726
• [0.097 seconds]
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:907
  STEP: Creating a kubernetes client @ 11/30/24 12:37:41.733
  I1130 12:37:41.733417 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename job @ 11/30/24 12:37:41.733
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:41.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:41.753
  STEP: Creating a job @ 11/30/24 12:37:41.757
  STEP: Ensuring active pods == parallelism @ 11/30/24 12:37:41.762
  STEP: Orphaning one of the Job's Pods @ 11/30/24 12:37:43.768
  I1130 12:37:44.285978 19 pod_client.go:173] Successfully updated pod "adopt-release-4j7jw"
  STEP: Checking that the Job readopts the Pod @ 11/30/24 12:37:44.286
  STEP: Removing the labels from the Job's Pod @ 11/30/24 12:37:46.297
  I1130 12:37:46.809598 19 pod_client.go:173] Successfully updated pod "adopt-release-4j7jw"
  STEP: Checking that the Job releases the Pod @ 11/30/24 12:37:46.809
  I1130 12:37:48.823882 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4221" for this suite. @ 11/30/24 12:37:48.828
• [7.103 seconds]
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:246
  STEP: Creating a kubernetes client @ 11/30/24 12:37:48.836
  I1130 12:37:48.836636 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename dns @ 11/30/24 12:37:48.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:48.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:48.86
  STEP: Creating a test headless service @ 11/30/24 12:37:48.864
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8910.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8910.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 11/30/24 12:37:48.869
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8910.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8910.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 11/30/24 12:37:48.869
  STEP: creating a pod to probe DNS @ 11/30/24 12:37:48.869
  STEP: submitting the pod to kubernetes @ 11/30/24 12:37:48.869
  STEP: retrieving the pod @ 11/30/24 12:37:54.901
  STEP: looking for the results for each expected name from probers @ 11/30/24 12:37:54.905
  I1130 12:37:54.924431 19 dns_common.go:527] DNS probes using dns-8910/dns-test-f39faaec-569b-4726-8d90-414bc89473f0 succeeded

  STEP: deleting the pod @ 11/30/24 12:37:54.924
  STEP: deleting the test headless service @ 11/30/24 12:37:54.944
  I1130 12:37:54.960416 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-8910" for this suite. @ 11/30/24 12:37:54.965
• [6.136 seconds]
------------------------------
SS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 11/30/24 12:37:54.972
  I1130 12:37:54.972747 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 12:37:54.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:54.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:54.992
  STEP: creating a secret @ 11/30/24 12:37:54.996
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 11/30/24 12:37:55.001
  STEP: patching the secret @ 11/30/24 12:37:55.004
  STEP: deleting the secret using a LabelSelector @ 11/30/24 12:37:55.015
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 11/30/24 12:37:55.023
  I1130 12:37:55.026714 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7646" for this suite. @ 11/30/24 12:37:55.03
• [0.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 11/30/24 12:37:55.038
  I1130 12:37:55.038539 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename deployment @ 11/30/24 12:37:55.039
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:55.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:55.167
  STEP: creating a Deployment @ 11/30/24 12:37:55.175
  I1130 12:37:55.175573 19 deployment.go:507] Creating simple deployment test-deployment-lxjsf
  I1130 12:37:55.189064 19 deployment.go:222] deployment "test-deployment-lxjsf" doesn't have the required revision set
  STEP: Getting /status @ 11/30/24 12:37:57.206
  I1130 12:37:57.210193 19 deployment.go:532] Deployment test-deployment-lxjsf has Conditions: [{Available True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:56 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-lxjsf-f4dbbbf74" has successfully progressed.}]
  STEP: updating Deployment Status @ 11/30/24 12:37:57.21
  I1130 12:37:57.222111 19 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 37, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 37, 56, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 37, 56, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 37, 55, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-lxjsf-f4dbbbf74\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 11/30/24 12:37:57.222
  I1130 12:37:57.223923 19 deployment.go:579] Observed &Deployment event: ADDED
  I1130 12:37:57.223950 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-lxjsf-f4dbbbf74"}
  I1130 12:37:57.224053 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I1130 12:37:57.224154 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-lxjsf-f4dbbbf74"}
  I1130 12:37:57.224169 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I1130 12:37:57.224355 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I1130 12:37:57.224422 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I1130 12:37:57.224435 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-lxjsf-f4dbbbf74" is progressing.}
  I1130 12:37:57.224571 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I1130 12:37:57.224630 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:56 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I1130 12:37:57.224656 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-lxjsf-f4dbbbf74" has successfully progressed.}
  I1130 12:37:57.224761 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I1130 12:37:57.224796 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:56 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I1130 12:37:57.224806 19 deployment.go:575] Observed Deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-lxjsf-f4dbbbf74" has successfully progressed.}
  I1130 12:37:57.224818 19 deployment.go:572] Found Deployment test-deployment-lxjsf in namespace deployment-4045 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1130 12:37:57.224831 19 deployment.go:583] Deployment test-deployment-lxjsf has an updated status
  STEP: patching the Statefulset Status @ 11/30/24 12:37:57.224
  I1130 12:37:57.224876 19 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I1130 12:37:57.230550 19 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 11/30/24 12:37:57.23
  I1130 12:37:57.232673 19 deployment.go:616] Observed &Deployment event: ADDED
  I1130 12:37:57.232699 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-lxjsf-f4dbbbf74"}
  I1130 12:37:57.232820 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1130 12:37:57.232836 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-lxjsf-f4dbbbf74"}
  I1130 12:37:57.232845 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I1130 12:37:57.232975 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1130 12:37:57.232989 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I1130 12:37:57.233022 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:55 +0000 UTC 2024-11-30 12:37:55 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-lxjsf-f4dbbbf74" is progressing.}
  I1130 12:37:57.233108 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1130 12:37:57.233122 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:56 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I1130 12:37:57.233131 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-lxjsf-f4dbbbf74" has successfully progressed.}
  I1130 12:37:57.233210 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1130 12:37:57.233225 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:56 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I1130 12:37:57.233268 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-11-30 12:37:56 +0000 UTC 2024-11-30 12:37:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-lxjsf-f4dbbbf74" has successfully progressed.}
  I1130 12:37:57.233276 19 deployment.go:612] Observed deployment test-deployment-lxjsf in namespace deployment-4045 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1130 12:37:57.233347 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1130 12:37:57.233381 19 deployment.go:609] Found deployment test-deployment-lxjsf in namespace deployment-4045 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I1130 12:37:57.233393 19 deployment.go:620] Deployment test-deployment-lxjsf has a patched status
  I1130 12:37:57.239341 19 deployment.go:633] Deployment "test-deployment-lxjsf":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-lxjsf",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4045",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8b313631-9e4b-4502-9df3-603376e31898",
      ResourceVersion: (string) (len=5) "15303",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567075,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=55) "Found new replica set \"test-deployment-lxjsf-f4dbbbf74\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1130 12:37:57.243398 19 deployment.go:39] New ReplicaSet "test-deployment-lxjsf-f4dbbbf74" of Deployment "test-deployment-lxjsf":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-lxjsf-f4dbbbf74",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4045",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a974f60c-2e99-4284-b82c-654219fd96c5",
      ResourceVersion: (string) (len=5) "15299",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567075,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74",
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-lxjsf",
          UID: (types.UID) (len=36) "8b313631-9e4b-4502-9df3-603376e31898",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 38 62 33  |k:{\"uid\":\"8b3|
              00000120  31 33 36 33 31 2d 39 65  34 62 2d 34 35 30 32 2d  |13631-9e4b-4502-|
              00000130  39 64 66 33 2d 36 30 33  33 37 36 65 33 31 38 39  |9df3-603376e3189|
              00000140  38 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |8\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74",
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:37:57.250459 19 deployment.go:67] Pod "test-deployment-lxjsf-f4dbbbf74-cgmlc" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "test-deployment-lxjsf-f4dbbbf74-cgmlc",
      GenerateName: (string) (len=32) "test-deployment-lxjsf-f4dbbbf74-",
      Namespace: (string) (len=15) "deployment-4045",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f01cf5b1-e4d4-4b3f-8532-03ad3eaca718",
      ResourceVersion: (string) (len=5) "15298",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567075,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "test-deployment-lxjsf-f4dbbbf74",
          UID: (types.UID) (len=36) "a974f60c-2e99-4284-b82c-654219fd96c5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 61 39 37 34 66 36 30  63 2d 32 65 39 39 2d 34  |"a974f60c-2e99-4|
              000000a0  32 38 34 2d 62 38 32 63  2d 36 35 34 32 31 39 66  |284-b82c-654219f|
              000000b0  64 39 36 63 35 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |d96c5\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 32 32 39 5c 22 7d  |2.168.244.229\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-flz66",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-flz66",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.229",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.229"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567075,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567075,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://23050223e4384d80f07e663a5bbee094a1e237d4e387b4ec0731a292e3e64b8a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-flz66",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:37:57.251519 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4045" for this suite. @ 11/30/24 12:37:57.255
• [2.224 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 11/30/24 12:37:57.263
  I1130 12:37:57.263219 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 11/30/24 12:37:57.263
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:37:57.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:37:57.279
  STEP: create the container to handle the HTTPGet hook request. @ 11/30/24 12:37:57.286
  STEP: create the pod with lifecycle hook @ 11/30/24 12:37:59.312
  STEP: check poststart hook @ 11/30/24 12:38:01.331
  STEP: delete the pod with lifecycle hook @ 11/30/24 12:38:01.337
  I1130 12:38:03.355670 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-2707" for this suite. @ 11/30/24 12:38:03.36
• [6.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 11/30/24 12:38:03.369
  I1130 12:38:03.369363 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 12:38:03.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:03.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:03.389
  STEP: creating a ConfigMap @ 11/30/24 12:38:03.392
  STEP: fetching the ConfigMap @ 11/30/24 12:38:03.396
  STEP: patching the ConfigMap @ 11/30/24 12:38:03.4
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 11/30/24 12:38:03.407
  STEP: deleting the ConfigMap by collection with a label selector @ 11/30/24 12:38:03.41
  STEP: listing all ConfigMaps in test namespace @ 11/30/24 12:38:03.418
  I1130 12:38:03.423509 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-999" for this suite. @ 11/30/24 12:38:03.427
• [0.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:763
  STEP: Creating a kubernetes client @ 11/30/24 12:38:03.434
  I1130 12:38:03.434357 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:38:03.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:03.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:03.453
  STEP: Setting up server cert @ 11/30/24 12:38:03.478
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:38:03.704
  STEP: Deploying the webhook pod @ 11/30/24 12:38:03.711
  STEP: Wait for the deployment to be ready @ 11/30/24 12:38:03.725
  I1130 12:38:03.733948 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 11/30/24 12:38:05.75
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:38:05.761
  I1130 12:38:06.762060 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 11/30/24 12:38:06.77
  STEP: verifying the mutating webhook match conditions @ 11/30/24 12:38:06.783
  STEP: updating the mutating webhook match conditions @ 11/30/24 12:38:06.787
  STEP: verifying the mutating webhook match conditions @ 11/30/24 12:38:06.796
  I1130 12:38:06.853798 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8088" for this suite. @ 11/30/24 12:38:06.857
  STEP: Destroying namespace "webhook-markers-6152" for this suite. @ 11/30/24 12:38:06.865
• [3.437 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 11/30/24 12:38:06.871
  I1130 12:38:06.871910 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 12:38:06.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:06.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:06.892
  STEP: Creating configMap with name configmap-test-volume-map-89d032d9-2d9e-4d69-bf6c-50d7e75aedee @ 11/30/24 12:38:06.895
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:38:06.899
  STEP: Saw pod success @ 11/30/24 12:38:08.916
  I1130 12:38:08.921128 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-configmaps-0fe29cd7-6eae-4bd8-bfc6-d72befe4ad78 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:38:08.933
  I1130 12:38:08.953097 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5702" for this suite. @ 11/30/24 12:38:08.957
• [2.093 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 11/30/24 12:38:08.965
  I1130 12:38:08.965216 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename namespaces @ 11/30/24 12:38:08.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:08.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:08.986
  STEP: Creating namespace "e2e-ns-lw6v6" @ 11/30/24 12:38:08.989
  I1130 12:38:09.004487 19 namespace.go:411] Namespace "e2e-ns-lw6v6-9943" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-lw6v6-9943" @ 11/30/24 12:38:09.004
  I1130 12:38:09.012162 19 namespace.go:434] Namespace "e2e-ns-lw6v6-9943" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-lw6v6-9943" @ 11/30/24 12:38:09.012
  I1130 12:38:09.023342 19 namespace.go:463] Namespace "e2e-ns-lw6v6-9943" has []v1.FinalizerName{"kubernetes"}
  I1130 12:38:09.023520 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5005" for this suite. @ 11/30/24 12:38:09.027
  STEP: Destroying namespace "e2e-ns-lw6v6-9943" for this suite. @ 11/30/24 12:38:09.036
• [0.078 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 11/30/24 12:38:09.043
  I1130 12:38:09.043334 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename discovery @ 11/30/24 12:38:09.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:09.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:09.062
  STEP: Setting up server cert @ 11/30/24 12:38:09.068
  I1130 12:38:09.315667 19 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I1130 12:38:09.317166 19 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I1130 12:38:09.317194 19 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I1130 12:38:09.317201 19 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I1130 12:38:09.317249 19 discovery.go:139] Checking APIGroup: apps
  I1130 12:38:09.318690 19 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I1130 12:38:09.318709 19 discovery.go:148] Versions found [{apps/v1 v1}]
  I1130 12:38:09.318715 19 discovery.go:154] apps/v1 matches apps/v1
  I1130 12:38:09.318723 19 discovery.go:139] Checking APIGroup: events.k8s.io
  I1130 12:38:09.319846 19 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I1130 12:38:09.319857 19 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I1130 12:38:09.319863 19 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I1130 12:38:09.319871 19 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I1130 12:38:09.321243 19 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I1130 12:38:09.321269 19 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I1130 12:38:09.321276 19 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I1130 12:38:09.321282 19 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I1130 12:38:09.322442 19 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I1130 12:38:09.322457 19 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I1130 12:38:09.322464 19 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I1130 12:38:09.322494 19 discovery.go:139] Checking APIGroup: autoscaling
  I1130 12:38:09.323725 19 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I1130 12:38:09.323738 19 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I1130 12:38:09.323744 19 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I1130 12:38:09.323749 19 discovery.go:139] Checking APIGroup: batch
  I1130 12:38:09.324923 19 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I1130 12:38:09.324955 19 discovery.go:148] Versions found [{batch/v1 v1}]
  I1130 12:38:09.324961 19 discovery.go:154] batch/v1 matches batch/v1
  I1130 12:38:09.324968 19 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I1130 12:38:09.326107 19 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I1130 12:38:09.326120 19 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I1130 12:38:09.326126 19 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I1130 12:38:09.326134 19 discovery.go:139] Checking APIGroup: networking.k8s.io
  I1130 12:38:09.327240 19 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I1130 12:38:09.327251 19 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I1130 12:38:09.327257 19 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I1130 12:38:09.327263 19 discovery.go:139] Checking APIGroup: policy
  I1130 12:38:09.328450 19 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I1130 12:38:09.328464 19 discovery.go:148] Versions found [{policy/v1 v1}]
  I1130 12:38:09.328470 19 discovery.go:154] policy/v1 matches policy/v1
  I1130 12:38:09.328485 19 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I1130 12:38:09.329606 19 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I1130 12:38:09.329618 19 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I1130 12:38:09.329624 19 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I1130 12:38:09.329630 19 discovery.go:139] Checking APIGroup: storage.k8s.io
  I1130 12:38:09.330980 19 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I1130 12:38:09.331001 19 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I1130 12:38:09.331007 19 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I1130 12:38:09.331013 19 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I1130 12:38:09.332359 19 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I1130 12:38:09.332408 19 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I1130 12:38:09.332415 19 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I1130 12:38:09.332422 19 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I1130 12:38:09.333891 19 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I1130 12:38:09.333912 19 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I1130 12:38:09.333920 19 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I1130 12:38:09.333926 19 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I1130 12:38:09.335353 19 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I1130 12:38:09.335398 19 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I1130 12:38:09.335404 19 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I1130 12:38:09.335411 19 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I1130 12:38:09.336588 19 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I1130 12:38:09.336601 19 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I1130 12:38:09.336607 19 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I1130 12:38:09.336613 19 discovery.go:139] Checking APIGroup: node.k8s.io
  I1130 12:38:09.337791 19 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I1130 12:38:09.337802 19 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I1130 12:38:09.337807 19 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I1130 12:38:09.337813 19 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I1130 12:38:09.339231 19 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I1130 12:38:09.339252 19 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I1130 12:38:09.339259 19 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I1130 12:38:09.339265 19 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I1130 12:38:09.340695 19 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I1130 12:38:09.340716 19 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  I1130 12:38:09.340722 19 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I1130 12:38:09.340729 19 discovery.go:139] Checking APIGroup: metrics.k8s.io
  I1130 12:38:09.342168 19 discovery.go:147] PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  I1130 12:38:09.342186 19 discovery.go:148] Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  I1130 12:38:09.342193 19 discovery.go:154] metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  I1130 12:38:09.342290 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-5086" for this suite. @ 11/30/24 12:38:09.346
• [0.311 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 11/30/24 12:38:09.354
  I1130 12:38:09.354148 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:38:09.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:09.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:09.375
  STEP: Creating projection with secret that has name projected-secret-test-383b91f2-e172-4054-be51-7d1d33bb830f @ 11/30/24 12:38:09.378
  STEP: Creating a pod to test consume secrets @ 11/30/24 12:38:09.383
  STEP: Saw pod success @ 11/30/24 12:38:13.409
  I1130 12:38:13.413455 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-secrets-b53ca579-33c5-4f1c-bc55-72e69bf184cd container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:38:13.421
  I1130 12:38:13.439636 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1630" for this suite. @ 11/30/24 12:38:13.444
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 11/30/24 12:38:13.451
  I1130 12:38:13.451017 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replicaset @ 11/30/24 12:38:13.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:13.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:13.473
  I1130 12:38:13.490317 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I1130 12:38:18.494651 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 11/30/24 12:38:18.494
  STEP: Scaling up "test-rs" replicaset @ 11/30/24 12:38:18.494
  I1130 12:38:18.504196 19 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 11/30/24 12:38:18.504
  I1130 12:38:18.513861 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6913 with ReadyReplicas 1, AvailableReplicas 1
  I1130 12:38:18.526585 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6913 with ReadyReplicas 1, AvailableReplicas 1
  I1130 12:38:18.555929 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6913 with ReadyReplicas 1, AvailableReplicas 1
  I1130 12:38:18.573089 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6913 with ReadyReplicas 1, AvailableReplicas 1
  I1130 12:38:19.457280 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6913 with ReadyReplicas 2, AvailableReplicas 2
  I1130 12:38:19.572697 19 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-6913 with ReadyReplicas 3 found true
  I1130 12:38:19.572838 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6913" for this suite. @ 11/30/24 12:38:19.577
• [6.136 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 11/30/24 12:38:19.586
  I1130 12:38:19.586766 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename var-expansion @ 11/30/24 12:38:19.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:19.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:19.606
  I1130 12:38:21.631537 19 delete.go:62] Deleting pod "var-expansion-e441b573-2519-4ca0-9d5c-3f77687ec8e1" in namespace "var-expansion-7590"
  I1130 12:38:21.639671 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-e441b573-2519-4ca0-9d5c-3f77687ec8e1" to be fully deleted
  I1130 12:38:23.648395 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7590" for this suite. @ 11/30/24 12:38:23.652
• [4.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:859
  STEP: Creating a kubernetes client @ 11/30/24 12:38:23.662
  I1130 12:38:23.663009 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:38:23.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:23.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:23.682
  STEP: Creating a ResourceQuota with best effort scope @ 11/30/24 12:38:23.685
  STEP: Ensuring ResourceQuota status is calculated @ 11/30/24 12:38:23.69
  STEP: Creating a ResourceQuota with not best effort scope @ 11/30/24 12:38:25.695
  STEP: Ensuring ResourceQuota status is calculated @ 11/30/24 12:38:25.7
  STEP: Creating a best-effort pod @ 11/30/24 12:38:27.706
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 11/30/24 12:38:27.721
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 11/30/24 12:38:29.726
  STEP: Deleting the pod @ 11/30/24 12:38:31.733
  STEP: Ensuring resource quota status released the pod usage @ 11/30/24 12:38:31.749
  STEP: Creating a not best-effort pod @ 11/30/24 12:38:33.755
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 11/30/24 12:38:33.766
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 11/30/24 12:38:35.771
  STEP: Deleting the pod @ 11/30/24 12:38:37.777
  STEP: Ensuring resource quota status released the pod usage @ 11/30/24 12:38:37.79
  I1130 12:38:39.796661 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4622" for this suite. @ 11/30/24 12:38:39.801
• [16.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 11/30/24 12:38:39.809
  I1130 12:38:39.809394 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 11/30/24 12:38:39.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:39.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:39.832
  STEP: creating a target pod @ 11/30/24 12:38:39.835
  STEP: adding an ephemeral container @ 11/30/24 12:38:41.857
  STEP: checking pod container endpoints @ 11/30/24 12:38:43.877
  I1130 12:38:43.877665 19 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2266 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 12:38:43.877699 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:38:43.878120 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 12:38:43.878160 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-2266/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I1130 12:38:43.925711 19 exec_util.go:111] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 11/30/24 12:38:43.942
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 11/30/24 12:38:43.946
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 11/30/24 12:38:43.959
  I1130 12:38:43.963858 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-2266" for this suite. @ 11/30/24 12:38:43.968
• [4.167 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 11/30/24 12:38:43.976
  I1130 12:38:43.976054 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename svcaccounts @ 11/30/24 12:38:43.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:38:43.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:38:43.997
  I1130 12:38:44.015173 19 service_accounts.go:618] created pod
  STEP: Saw pod success @ 11/30/24 12:38:48.038
  I1130 12:39:18.038597 19 service_accounts.go:624] polling logs
  I1130 12:39:18.047719 19 service_accounts.go:634] Pod logs: 
  I1130 12:38:44.549219       1 log.go:245] OK: Got token
  I1130 12:38:44.549266       1 log.go:245] validating with in-cluster discovery
  I1130 12:38:44.549480       1 log.go:245] OK: got issuer https://kubernetes.default.svc
  I1130 12:38:44.549643       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-9524:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000013a80), NotBefore:(*jwt.NumericDate)(0xc000013b70), IssuedAt:(*jwt.NumericDate)(0xc000013a90), ID:"895ac299-517c-40e3-ac84-0e887c51e5cb"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9524", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"28f113b4-0e2b-47ed-bbfb-47211169a544"}}}
  I1130 12:38:44.556959       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I1130 12:38:44.561271       1 log.go:245] OK: Validated signature on JWT
  I1130 12:38:44.561316       1 log.go:245] OK: Got valid claims from token!
  I1130 12:38:44.561329       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-9524:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000101908), NotBefore:(*jwt.NumericDate)(0xc000101930), IssuedAt:(*jwt.NumericDate)(0xc000101910), ID:"895ac299-517c-40e3-ac84-0e887c51e5cb"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9524", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"28f113b4-0e2b-47ed-bbfb-47211169a544"}}}

  I1130 12:39:18.047762 19 service_accounts.go:638] completed pod
  I1130 12:39:18.056045 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9524" for this suite. @ 11/30/24 12:39:18.059
• [34.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 11/30/24 12:39:18.067
  I1130 12:39:18.067580 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 12:39:18.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:18.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:18.088
  STEP: Creating configMap with name configmap-test-volume-e016d2f0-b56c-4141-bed3-1b9a0fbda4f3 @ 11/30/24 12:39:18.092
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:39:18.097
  STEP: Saw pod success @ 11/30/24 12:39:22.124
  I1130 12:39:22.129005 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-configmaps-a598c120-554d-42b9-a0f4-c7fd68071338 container configmap-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:39:22.137
  I1130 12:39:22.155979 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1847" for this suite. @ 11/30/24 12:39:22.16
• [4.103 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 11/30/24 12:39:22.17
  I1130 12:39:22.170397 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 12:39:22.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:22.185
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:22.188
  STEP: creating the pod @ 11/30/24 12:39:22.191
  STEP: setting up watch @ 11/30/24 12:39:22.191
  STEP: submitting the pod to kubernetes @ 11/30/24 12:39:22.295
  STEP: verifying the pod is in kubernetes @ 11/30/24 12:39:22.305
  STEP: verifying pod creation was observed @ 11/30/24 12:39:22.309
  STEP: deleting the pod gracefully @ 11/30/24 12:39:24.322
  STEP: verifying pod deletion was observed @ 11/30/24 12:39:24.331
  I1130 12:39:25.759231 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1240" for this suite. @ 11/30/24 12:39:25.763
• [3.600 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 11/30/24 12:39:25.771
  I1130 12:39:25.771099 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 12:39:25.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:25.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:25.792
  STEP: Creating projection with secret that has name secret-emptykey-test-0bc1bde4-68d1-4ad2-9f23-4fd3d0f0da72 @ 11/30/24 12:39:25.795
  I1130 12:39:25.797035 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3907" for this suite. @ 11/30/24 12:39:25.801
• [0.038 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:490
  STEP: Creating a kubernetes client @ 11/30/24 12:39:25.809
  I1130 12:39:25.809418 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename job @ 11/30/24 12:39:25.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:25.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:25.83
  STEP: Creating Indexed job @ 11/30/24 12:39:25.833
  STEP: Ensuring job reaches completions @ 11/30/24 12:39:25.838
  STEP: Ensuring pods with index for job exist @ 11/30/24 12:39:33.851
  I1130 12:39:33.856564 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9957" for this suite. @ 11/30/24 12:39:33.86
• [8.060 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 11/30/24 12:39:33.869
  I1130 12:39:33.869754 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename containers @ 11/30/24 12:39:33.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:33.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:33.887
  STEP: Creating a pod to test override command @ 11/30/24 12:39:33.891
  STEP: Saw pod success @ 11/30/24 12:39:37.913
  I1130 12:39:37.917311 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod client-containers-75106d01-bc70-4045-b3ab-1b003cebb73d container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:39:37.925
  I1130 12:39:37.945877 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8223" for this suite. @ 11/30/24 12:39:37.949
• [4.089 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 11/30/24 12:39:37.958
  I1130 12:39:37.958889 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename endpointslice @ 11/30/24 12:39:37.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:37.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:37.979
  I1130 12:39:40.035444 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5863" for this suite. @ 11/30/24 12:39:40.04
• [2.091 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 11/30/24 12:39:40.05
  I1130 12:39:40.050150 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-pred @ 11/30/24 12:39:40.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:40.068
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:40.072
  I1130 12:39:40.075319 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I1130 12:39:40.082873 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1130 12:39:40.086579 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-4-119 before test
  I1130 12:39:40.091617 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-24r2d from ingress-nginx-kubernetes-worker started at 2024-11-30 12:02:13 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.091631 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1130 12:39:40.091639 19 predicates.go:957] calico-node-m9zjm from kube-system started at 2024-11-30 12:09:48 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.091646 19 predicates.go:959] 	Container calico-node ready: true, restart count 1
  I1130 12:39:40.091653 19 predicates.go:957] sonobuoy-e2e-job-046772c140634943 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 12:39:40.091658 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I1130 12:39:40.091664 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 12:39:40.091675 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-rn6l7 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 12:39:40.091680 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 12:39:40.091686 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1130 12:39:40.091692 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-64-147 before test
  I1130 12:39:40.096644 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-g24x9 from ingress-nginx-kubernetes-worker started at 2024-11-30 12:02:44 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.096660 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1130 12:39:40.096667 19 predicates.go:957] calico-node-5dksp from kube-system started at 2024-11-30 12:09:37 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.096671 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1130 12:39:40.096677 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-11-30 12:13:35 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.096681 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I1130 12:39:40.096687 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-sv7v4 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 12:39:40.096692 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 12:39:40.096696 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1130 12:39:40.096702 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-94-166 before test
  I1130 12:39:40.102640 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-5gx7b from ingress-nginx-kubernetes-worker started at 2024-11-30 11:59:40 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.102659 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 2
  I1130 12:39:40.102666 19 predicates.go:957] calico-node-n82d2 from kube-system started at 2024-11-30 12:08:48 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.102686 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1130 12:39:40.102692 19 predicates.go:957] coredns-5b4857d7c8-d9dkl from kube-system started at 2024-11-30 11:59:41 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.102698 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I1130 12:39:40.102705 19 predicates.go:957] kube-state-metrics-5d7bdccd49-hn4gf from kube-system started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.102710 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 5
  I1130 12:39:40.102716 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-w2q4q from kube-system started at 2024-11-30 11:59:41 +0000 UTC (2 container statuses recorded)
  I1130 12:39:40.102725 19 predicates.go:959] 	Container metrics-server ready: true, restart count 0
  I1130 12:39:40.102730 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I1130 12:39:40.102735 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-6hwh9 from kubernetes-dashboard started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.102740 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I1130 12:39:40.102754 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-d5v6d from kubernetes-dashboard started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 12:39:40.102781 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 2
  I1130 12:39:40.102787 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-x97pk from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 12:39:40.102793 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 12:39:40.102799 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 11/30/24 12:39:40.102
  STEP: Explicitly delete pod here to free the resource it takes. @ 11/30/24 12:39:42.127
  STEP: Trying to apply a random label on the found node. @ 11/30/24 12:39:42.143
  STEP: verifying the node has the label kubernetes.io/e2e-5c1116c5-d236-4f0f-9750-3e20d2fbe839 42 @ 11/30/24 12:39:42.156
  STEP: Trying to relaunch the pod, now with labels. @ 11/30/24 12:39:42.164
  STEP: removing the label kubernetes.io/e2e-5c1116c5-d236-4f0f-9750-3e20d2fbe839 off the node ip-172-31-64-147 @ 11/30/24 12:39:44.186
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-5c1116c5-d236-4f0f-9750-3e20d2fbe839 @ 11/30/24 12:39:44.201
  I1130 12:39:44.206921 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-1396" for this suite. @ 11/30/24 12:39:44.213
• [4.170 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 11/30/24 12:39:44.22
  I1130 12:39:44.220956 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:39:44.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:44.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:44.247
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:39:44.251
  STEP: Saw pod success @ 11/30/24 12:39:48.281
  I1130 12:39:48.286075 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod downwardapi-volume-8a473311-89f5-4884-9b13-f73dffe0f2f9 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:39:48.301
  I1130 12:39:48.321832 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7415" for this suite. @ 11/30/24 12:39:48.326
• [4.114 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 11/30/24 12:39:48.335
  I1130 12:39:48.335124 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 12:39:48.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:48.347
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:48.35
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 11/30/24 12:39:48.354
  I1130 12:39:48.355034 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:39:49.652505 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:39:54.602535 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8919" for this suite. @ 11/30/24 12:39:54.61
• [6.284 seconds]
------------------------------
SS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 11/30/24 12:39:54.619
  I1130 12:39:54.619120 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename csiinlinevolumes @ 11/30/24 12:39:54.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:54.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:54.64
  STEP: creating @ 11/30/24 12:39:54.643
  STEP: getting @ 11/30/24 12:39:54.663
  STEP: listing in namespace @ 11/30/24 12:39:54.667
  STEP: patching @ 11/30/24 12:39:54.671
  STEP: deleting @ 11/30/24 12:39:54.679
  I1130 12:39:54.696483 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4239" for this suite. @ 11/30/24 12:39:54.7
• [0.090 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1858
  STEP: Creating a kubernetes client @ 11/30/24 12:39:54.709
  I1130 12:39:54.709801 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 12:39:54.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:54.732
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:54.736
  STEP: Starting the proxy @ 11/30/24 12:39:54.74
  I1130 12:39:54.740683 19 util.go:585] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8738 proxy --unix-socket=/tmp/kubectl-proxy-unix3124216788/test'
  STEP: retrieving proxy /api/ output @ 11/30/24 12:39:54.771
  I1130 12:39:54.772431 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8738" for this suite. @ 11/30/24 12:39:54.782
• [0.082 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
  STEP: Creating a kubernetes client @ 11/30/24 12:39:54.791
  I1130 12:39:54.791885 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 12:39:54.792
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:54.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:54.812
  STEP: creating the pod @ 11/30/24 12:39:54.815
  I1130 12:39:54.815768 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8102 create -f -'
  I1130 12:39:54.910167 19 builder.go:146] stderr: ""
  I1130 12:39:54.910204 19 builder.go:147] stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 11/30/24 12:39:56.92
  I1130 12:39:56.920852 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8102 label pods pause testing-label=testing-label-value'
  I1130 12:39:56.973952 19 builder.go:146] stderr: ""
  I1130 12:39:56.973998 19 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 11/30/24 12:39:56.974
  I1130 12:39:56.974100 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8102 get pod pause -L testing-label'
  I1130 12:39:57.019961 19 builder.go:146] stderr: ""
  I1130 12:39:57.020015 19 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 11/30/24 12:39:57.02
  I1130 12:39:57.020090 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8102 label pods pause testing-label-'
  I1130 12:39:57.072068 19 builder.go:146] stderr: ""
  I1130 12:39:57.072106 19 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 11/30/24 12:39:57.072
  I1130 12:39:57.072183 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8102 get pod pause -L testing-label'
  I1130 12:39:57.120693 19 builder.go:146] stderr: ""
  I1130 12:39:57.120738 19 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 11/30/24 12:39:57.12
  I1130 12:39:57.120878 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8102 delete --grace-period=0 --force -f -'
  I1130 12:39:57.176737 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 12:39:57.176847 19 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I1130 12:39:57.176889 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8102 get rc,svc -l name=pause --no-headers'
  I1130 12:39:57.225640 19 builder.go:146] stderr: "No resources found in kubectl-8102 namespace.\n"
  I1130 12:39:57.225679 19 builder.go:147] stdout: ""
  I1130 12:39:57.225784 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8102 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I1130 12:39:57.271698 19 builder.go:146] stderr: ""
  I1130 12:39:57.271740 19 builder.go:147] stdout: ""
  I1130 12:39:57.271862 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8102" for this suite. @ 11/30/24 12:39:57.276
• [2.495 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:218
  STEP: Creating a kubernetes client @ 11/30/24 12:39:57.287
  I1130 12:39:57.287296 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:39:57.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:39:57.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:39:57.306
  STEP: Setting up server cert @ 11/30/24 12:39:57.331
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:39:57.424
  STEP: Deploying the webhook pod @ 11/30/24 12:39:57.436
  STEP: Wait for the deployment to be ready @ 11/30/24 12:39:57.451
  I1130 12:39:57.467440 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 11/30/24 12:39:59.481
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:39:59.492
  I1130 12:40:00.494114 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I1130 12:40:00.503920 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 11/30/24 12:40:01.015
  STEP: Creating a custom resource that should be denied by the webhook @ 11/30/24 12:40:01.031
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 11/30/24 12:40:03.049
  STEP: Updating the custom resource with disallowed data should be denied @ 11/30/24 12:40:03.057
  STEP: Deleting the custom resource should be denied @ 11/30/24 12:40:03.068
  STEP: Remove the offending key and value from the custom resource data @ 11/30/24 12:40:03.077
  STEP: Deleting the updated custom resource should be successful @ 11/30/24 12:40:03.088
  I1130 12:40:03.671732 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5974" for this suite. @ 11/30/24 12:40:03.675
  STEP: Destroying namespace "webhook-markers-71" for this suite. @ 11/30/24 12:40:03.685
• [6.406 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2179
  STEP: Creating a kubernetes client @ 11/30/24 12:40:03.693
  I1130 12:40:03.693327 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:40:03.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:40:03.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:40:03.714
  STEP: creating service in namespace services-3554 @ 11/30/24 12:40:03.717
  STEP: creating service affinity-clusterip-transition in namespace services-3554 @ 11/30/24 12:40:03.717
  STEP: creating replication controller affinity-clusterip-transition in namespace services-3554 @ 11/30/24 12:40:03.728
  I1130 12:40:03.737891      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3554, replica count: 3
  I1130 12:40:06.789444      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 12:40:06.798226 19 resource.go:361] Creating new exec pod
  I1130 12:40:09.813936 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3554 exec execpod-affinity4rm42 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I1130 12:40:09.907262 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  I1130 12:40:09.907308 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:40:09.907504 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3554 exec execpod-affinity4rm42 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
  I1130 12:40:09.994872 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n"
  I1130 12:40:09.994915 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:40:10.005828 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3554 exec execpod-affinity4rm42 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.45:80/ ; done'
  I1130 12:40:10.152244 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n"
  I1130 12:40:10.152355 19 builder.go:147] stdout: "\naffinity-clusterip-transition-4vsdb\naffinity-clusterip-transition-p78sq\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-4vsdb\naffinity-clusterip-transition-4vsdb\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-p78sq\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-4vsdb\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-4vsdb\naffinity-clusterip-transition-4vsdb\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g"
  I1130 12:40:10.152382 19 service.go:242] Received response from host: affinity-clusterip-transition-4vsdb
  I1130 12:40:10.152391 19 service.go:242] Received response from host: affinity-clusterip-transition-p78sq
  I1130 12:40:10.152396 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.152402 19 service.go:242] Received response from host: affinity-clusterip-transition-4vsdb
  I1130 12:40:10.152408 19 service.go:242] Received response from host: affinity-clusterip-transition-4vsdb
  I1130 12:40:10.152413 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.152418 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.152424 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.152433 19 service.go:242] Received response from host: affinity-clusterip-transition-p78sq
  I1130 12:40:10.152474 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.152480 19 service.go:242] Received response from host: affinity-clusterip-transition-4vsdb
  I1130 12:40:10.152486 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.152493 19 service.go:242] Received response from host: affinity-clusterip-transition-4vsdb
  I1130 12:40:10.152500 19 service.go:242] Received response from host: affinity-clusterip-transition-4vsdb
  I1130 12:40:10.152506 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.152511 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.164455 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3554 exec execpod-affinity4rm42 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.45:80/ ; done'
  I1130 12:40:10.303059 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.45:80/\n"
  I1130 12:40:10.303109 19 builder.go:147] stdout: "\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g\naffinity-clusterip-transition-7wz4g"
  I1130 12:40:10.303120 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303127 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303131 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303135 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303140 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303144 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303148 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303151 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303155 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303159 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303163 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303170 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303177 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303185 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303189 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303194 19 service.go:242] Received response from host: affinity-clusterip-transition-7wz4g
  I1130 12:40:10.303260 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3554, will wait for the garbage collector to delete the pods @ 11/30/24 12:40:10.319
  I1130 12:40:10.382779 19 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 7.779868ms
  I1130 12:40:10.483523 19 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 100.73176ms
  I1130 12:40:13.806084 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3554" for this suite. @ 11/30/24 12:40:13.81
• [10.124 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 11/30/24 12:40:13.816
  I1130 12:40:13.816996 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename daemonsets @ 11/30/24 12:40:13.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:40:13.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:40:13.837
  I1130 12:40:13.860224 19 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 11/30/24 12:40:13.867
  I1130 12:40:13.871770 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:40:13.871795 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 11/30/24 12:40:13.871
  I1130 12:40:13.893439 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:40:13.893483 19 fixtures.go:130] Node ip-172-31-94-166 is running 0 daemon pod, expected 1
  I1130 12:40:14.893897 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1130 12:40:14.893932 19 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 11/30/24 12:40:14.897
  I1130 12:40:14.916670 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1130 12:40:14.916701 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  I1130 12:40:15.916855 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:40:15.916889 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 11/30/24 12:40:15.916
  I1130 12:40:15.931424 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:40:15.931454 19 fixtures.go:130] Node ip-172-31-94-166 is running 0 daemon pod, expected 1
  I1130 12:40:16.930942 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1130 12:40:16.930978 19 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 11/30/24 12:40:16.939
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8810, will wait for the garbage collector to delete the pods @ 11/30/24 12:40:16.939
  I1130 12:40:17.003899 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 10.483776ms
  I1130 12:40:17.104815 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.909113ms
  I1130 12:40:18.810202 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:40:18.810242 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1130 12:40:18.813776 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16859"},"items":null}

  I1130 12:40:18.818417 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16859"},"items":null}

  I1130 12:40:18.841886 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8810" for this suite. @ 11/30/24 12:40:18.846
• [5.036 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 11/30/24 12:40:18.853
  I1130 12:40:18.853518 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename prestop @ 11/30/24 12:40:18.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:40:18.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:40:18.874
  STEP: Creating server pod server in namespace prestop-5687 @ 11/30/24 12:40:18.877
  STEP: Waiting for pods to come up. @ 11/30/24 12:40:18.886
  STEP: Creating tester pod tester in namespace prestop-5687 @ 11/30/24 12:40:20.899
  STEP: Deleting pre-stop pod @ 11/30/24 12:40:22.917
  I1130 12:40:27.935004 19 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 11/30/24 12:40:27.935
  I1130 12:40:27.950799 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-5687" for this suite. @ 11/30/24 12:40:27.955
• [9.108 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:331
  STEP: Creating a kubernetes client @ 11/30/24 12:40:27.962
  I1130 12:40:27.962058 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename dns @ 11/30/24 12:40:27.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:40:27.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:40:27.983
  STEP: Creating a test externalName service @ 11/30/24 12:40:27.989
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9958.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9958.svc.cluster.local; sleep 1; done
   @ 11/30/24 12:40:27.997
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9958.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9958.svc.cluster.local; sleep 1; done
   @ 11/30/24 12:40:27.998
  STEP: creating a pod to probe DNS @ 11/30/24 12:40:27.998
  STEP: submitting the pod to kubernetes @ 11/30/24 12:40:27.998
  STEP: retrieving the pod @ 11/30/24 12:40:34.029
  STEP: looking for the results for each expected name from probers @ 11/30/24 12:40:34.032
  I1130 12:40:34.043193 19 dns_common.go:552] DNS probes using dns-test-7935d110-a47d-4560-8638-d763626ef96f succeeded

  STEP: changing the externalName to bar.example.com @ 11/30/24 12:40:34.043
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9958.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9958.svc.cluster.local; sleep 1; done
   @ 11/30/24 12:40:34.052
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9958.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9958.svc.cluster.local; sleep 1; done
   @ 11/30/24 12:40:34.052
  STEP: creating a second pod to probe DNS @ 11/30/24 12:40:34.052
  STEP: submitting the pod to kubernetes @ 11/30/24 12:40:34.052
  STEP: retrieving the pod @ 11/30/24 12:40:36.072
  STEP: looking for the results for each expected name from probers @ 11/30/24 12:40:36.077
  I1130 12:40:36.084178 19 dns_common.go:482] File wheezy_udp@dns-test-service-3.dns-9958.svc.cluster.local from pod  dns-9958/dns-test-f7c3a263-99e3-4868-bbfc-39884facf913 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I1130 12:40:36.089342 19 dns_common.go:482] File jessie_udp@dns-test-service-3.dns-9958.svc.cluster.local from pod  dns-9958/dns-test-f7c3a263-99e3-4868-bbfc-39884facf913 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  I1130 12:40:36.089386 19 dns_common.go:489] Lookups using dns-9958/dns-test-f7c3a263-99e3-4868-bbfc-39884facf913 failed for: [wheezy_udp@dns-test-service-3.dns-9958.svc.cluster.local jessie_udp@dns-test-service-3.dns-9958.svc.cluster.local]

  I1130 12:40:36.097318 19 dns_common.go:495] Pod client logs for webserver: 
  I1130 12:40:36.105103 19 dns_common.go:495] Pod client logs for querier: 
  I1130 12:40:36.112053 19 dns_common.go:495] Pod client logs for jessie-querier: 
  I1130 12:40:41.091812 19 dns_common.go:552] DNS probes using dns-test-f7c3a263-99e3-4868-bbfc-39884facf913 succeeded

  STEP: changing the service to type=ClusterIP @ 11/30/24 12:40:41.091
  W1130 12:40:41.108601      19 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9958.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9958.svc.cluster.local; sleep 1; done
   @ 11/30/24 12:40:41.108
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9958.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9958.svc.cluster.local; sleep 1; done
   @ 11/30/24 12:40:41.108
  STEP: creating a third pod to probe DNS @ 11/30/24 12:40:41.109
  STEP: submitting the pod to kubernetes @ 11/30/24 12:40:41.113
  STEP: retrieving the pod @ 11/30/24 12:40:43.129
  STEP: looking for the results for each expected name from probers @ 11/30/24 12:40:43.133
  I1130 12:40:43.145000 19 dns_common.go:552] DNS probes using dns-test-ed0107e1-a4c3-45d6-a5e2-9d236ee82ed2 succeeded

  STEP: deleting the pod @ 11/30/24 12:40:43.145
  STEP: deleting the pod @ 11/30/24 12:40:43.16
  STEP: deleting the pod @ 11/30/24 12:40:43.18
  STEP: deleting the test externalName service @ 11/30/24 12:40:43.196
  I1130 12:40:43.211712 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9958" for this suite. @ 11/30/24 12:40:43.216
• [15.263 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:104
  STEP: Creating a kubernetes client @ 11/30/24 12:40:43.225
  I1130 12:40:43.225958 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:40:43.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:40:43.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:40:43.248
  STEP: Counting existing ResourceQuota @ 11/30/24 12:40:43.251
  STEP: Creating a ResourceQuota @ 11/30/24 12:40:48.256
  STEP: Ensuring resource quota status is calculated @ 11/30/24 12:40:48.263
  STEP: Creating a Service @ 11/30/24 12:40:50.269
  STEP: Creating a NodePort Service @ 11/30/24 12:40:50.288
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 11/30/24 12:40:50.314
  STEP: Ensuring resource quota status captures service creation @ 11/30/24 12:40:50.337
  STEP: Deleting Services @ 11/30/24 12:40:52.343
  STEP: Ensuring resource quota status released usage @ 11/30/24 12:40:52.387
  I1130 12:40:54.393529 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3675" for this suite. @ 11/30/24 12:40:54.397
• [11.179 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 11/30/24 12:40:54.405
  I1130 12:40:54.405102 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename runtimeclass @ 11/30/24 12:40:54.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:40:54.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:40:54.428
  I1130 12:40:54.438429 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2176" for this suite. @ 11/30/24 12:40:54.442
• [0.047 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 11/30/24 12:40:54.452
  I1130 12:40:54.452054 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 12:40:54.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:40:54.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:40:54.478
  I1130 12:40:54.481406 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: creating the pod @ 11/30/24 12:40:54.481
  STEP: submitting the pod to kubernetes @ 11/30/24 12:40:54.481
  I1130 12:40:56.525594 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4456" for this suite. @ 11/30/24 12:40:56.53
• [2.087 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 11/30/24 12:40:56.539
  I1130 12:40:56.539674 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:40:56.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:40:56.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:40:56.56
  STEP: Creating a pod to test downward api env vars @ 11/30/24 12:40:56.563
  STEP: Saw pod success @ 11/30/24 12:41:00.588
  I1130 12:41:00.592517 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod downward-api-49ea2281-f342-48a5-93cc-2c78a6a602a1 container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 12:41:00.599
  I1130 12:41:00.619725 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8333" for this suite. @ 11/30/24 12:41:00.625
• [4.093 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:760
  STEP: Creating a kubernetes client @ 11/30/24 12:41:00.632
  I1130 12:41:00.632385 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:41:00.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:00.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:00.653
  STEP: creating service endpoint-test2 in namespace services-8369 @ 11/30/24 12:41:00.656
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8369 to expose endpoints map[] @ 11/30/24 12:41:00.666
  I1130 12:41:00.670715 19 service.go:4267] Failed go get Endpoints object: endpoints "endpoint-test2" not found
  I1130 12:41:01.680317 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-8369 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-8369 @ 11/30/24 12:41:01.68
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8369 to expose endpoints map[pod1:[80]] @ 11/30/24 12:41:03.704
  I1130 12:41:03.718044 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-8369 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 11/30/24 12:41:03.718
  I1130 12:41:03.718128 19 resource.go:361] Creating new exec pod
  I1130 12:41:06.736400 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8369 exec execpod8jr5x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I1130 12:41:06.829519 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I1130 12:41:06.829570 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:41:06.829646 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8369 exec execpod8jr5x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.182 80'
  I1130 12:41:06.918884 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.182 80\nConnection to 10.152.183.182 80 port [tcp/http] succeeded!\n"
  I1130 12:41:06.918933 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-8369 @ 11/30/24 12:41:06.918
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8369 to expose endpoints map[pod1:[80] pod2:[80]] @ 11/30/24 12:41:08.941
  I1130 12:41:08.958665 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-8369 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 11/30/24 12:41:08.958
  I1130 12:41:09.959095 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8369 exec execpod8jr5x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I1130 12:41:10.042266 19 builder.go:146] stderr: "+ + ncecho -v hostName -t\n -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I1130 12:41:10.042308 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:41:10.042425 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8369 exec execpod8jr5x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.182 80'
  I1130 12:41:10.125837 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.182 80\nConnection to 10.152.183.182 80 port [tcp/http] succeeded!\n"
  I1130 12:41:10.125893 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-8369 @ 11/30/24 12:41:10.125
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8369 to expose endpoints map[pod2:[80]] @ 11/30/24 12:41:10.144
  I1130 12:41:10.158636 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-8369 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 11/30/24 12:41:10.158
  I1130 12:41:11.159657 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8369 exec execpod8jr5x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I1130 12:41:11.243036 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I1130 12:41:11.243102 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 12:41:11.243215 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8369 exec execpod8jr5x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.182 80'
  I1130 12:41:11.325868 19 builder.go:146] stderr: "+ + echonc -v hostName -t -w 2\n 10.152.183.182 80\nConnection to 10.152.183.182 80 port [tcp/http] succeeded!\n"
  I1130 12:41:11.325914 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-8369 @ 11/30/24 12:41:11.325
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8369 to expose endpoints map[] @ 11/30/24 12:41:11.347
  I1130 12:41:11.359430 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-8369 exposes endpoints map[]
  I1130 12:41:11.377293 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8369" for this suite. @ 11/30/24 12:41:11.381
• [10.758 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 11/30/24 12:41:11.39
  I1130 12:41:11.390963 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 12:41:11.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:11.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:11.413
  I1130 12:41:11.417971 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 11/30/24 12:41:12.704
  I1130 12:41:12.704986 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-4386 --namespace=crd-publish-openapi-4386 create -f -'
  I1130 12:41:14.782967 19 builder.go:146] stderr: ""
  I1130 12:41:14.783007 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2791-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I1130 12:41:14.783075 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-4386 --namespace=crd-publish-openapi-4386 delete e2e-test-crd-publish-openapi-2791-crds test-cr'
  I1130 12:41:14.837560 19 builder.go:146] stderr: ""
  I1130 12:41:14.837627 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2791-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I1130 12:41:14.837690 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-4386 --namespace=crd-publish-openapi-4386 apply -f -'
  I1130 12:41:14.894908 19 builder.go:146] stderr: ""
  I1130 12:41:14.894944 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2791-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I1130 12:41:14.895004 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-4386 --namespace=crd-publish-openapi-4386 delete e2e-test-crd-publish-openapi-2791-crds test-cr'
  I1130 12:41:14.946927 19 builder.go:146] stderr: ""
  I1130 12:41:14.946981 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2791-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 11/30/24 12:41:14.946
  I1130 12:41:14.947084 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-4386 explain e2e-test-crd-publish-openapi-2791-crds'
  I1130 12:41:14.989256 19 builder.go:146] stderr: ""
  I1130 12:41:14.989310 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-2791-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I1130 12:41:16.225666 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4386" for this suite. @ 11/30/24 12:41:16.233
• [4.850 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 11/30/24 12:41:16.24
  I1130 12:41:16.240751 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename var-expansion @ 11/30/24 12:41:16.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:16.26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:16.263
  STEP: Creating a pod to test substitution in container's args @ 11/30/24 12:41:16.266
  STEP: Saw pod success @ 11/30/24 12:41:18.287
  I1130 12:41:18.292139 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod var-expansion-9419c216-8290-44ae-a26d-6bdb74c8185f container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 12:41:18.301
  I1130 12:41:18.320720 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8566" for this suite. @ 11/30/24 12:41:18.324
• [2.094 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 11/30/24 12:41:18.335
  I1130 12:41:18.335126 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:41:18.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:18.354
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:18.357
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:41:18.36
  STEP: Saw pod success @ 11/30/24 12:41:20.381
  I1130 12:41:20.385167 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-fa17b860-0cb1-4165-9e94-802e67e36859 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:41:20.394
  I1130 12:41:20.416537 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7321" for this suite. @ 11/30/24 12:41:20.421
• [2.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 11/30/24 12:41:20.428
  I1130 12:41:20.428927 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename csi-storageclass @ 11/30/24 12:41:20.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:20.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:20.451
  STEP: Creating a StorageClass @ 11/30/24 12:41:20.454
  STEP: Get StorageClass "e2e-8bbh9" @ 11/30/24 12:41:20.459
  STEP: Patching the StorageClass "e2e-8bbh9" @ 11/30/24 12:41:20.463
  STEP: Delete StorageClass "e2e-8bbh9" @ 11/30/24 12:41:20.47
  STEP: Confirm deletion of StorageClass "e2e-8bbh9" @ 11/30/24 12:41:20.477
  STEP: Create a replacement StorageClass @ 11/30/24 12:41:20.481
  STEP: Updating StorageClass "e2e-v2-wnfnp" @ 11/30/24 12:41:20.486
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-wnfnp=updated" @ 11/30/24 12:41:20.495
  STEP: Deleting StorageClass "e2e-v2-wnfnp" via DeleteCollection @ 11/30/24 12:41:20.498
  STEP: Confirm deletion of StorageClass "e2e-v2-wnfnp" @ 11/30/24 12:41:20.508
  I1130 12:41:20.512602 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-4630" for this suite. @ 11/30/24 12:41:20.516
• [0.096 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1365
  STEP: Creating a kubernetes client @ 11/30/24 12:41:20.525
  I1130 12:41:20.525308 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 12:41:20.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:20.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:20.549
  STEP: validating cluster-info @ 11/30/24 12:41:20.552
  I1130 12:41:20.552668 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-5340 cluster-info'
  I1130 12:41:20.597972 19 builder.go:146] stderr: ""
  I1130 12:41:20.598013 19 builder.go:147] stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I1130 12:41:20.598118 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5340" for this suite. @ 11/30/24 12:41:20.602
• [0.084 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:337
  STEP: Creating a kubernetes client @ 11/30/24 12:41:20.609
  I1130 12:41:20.609753 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename security-context @ 11/30/24 12:41:20.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:20.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:20.635
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 11/30/24 12:41:20.641
  STEP: Saw pod success @ 11/30/24 12:41:24.667
  I1130 12:41:24.671566 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod security-context-79015b0a-cd0e-43ef-be36-14a1424f57f9 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:41:24.684
  I1130 12:41:24.707019 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-5018" for this suite. @ 11/30/24 12:41:24.71
• [4.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 11/30/24 12:41:24.718
  I1130 12:41:24.718195 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replication-controller @ 11/30/24 12:41:24.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:24.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:24.738
  STEP: Given a ReplicationController is created @ 11/30/24 12:41:24.741
  STEP: When the matched label of one of its pods change @ 11/30/24 12:41:24.746
  I1130 12:41:24.750155 19 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  I1130 12:41:29.756822 19 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 11/30/24 12:41:29.768
  I1130 12:41:30.777817 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4685" for this suite. @ 11/30/24 12:41:30.782
• [6.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 11/30/24 12:41:30.792
  I1130 12:41:30.792550 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename apf @ 11/30/24 12:41:30.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:30.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:30.816
  STEP: getting /apis @ 11/30/24 12:41:30.819
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 11/30/24 12:41:30.823
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 11/30/24 12:41:30.824
  STEP: creating @ 11/30/24 12:41:30.826
  STEP: getting @ 11/30/24 12:41:30.847
  STEP: listing @ 11/30/24 12:41:30.852
  STEP: watching @ 11/30/24 12:41:30.856
  I1130 12:41:30.856904 19 flowcontrol.go:394] starting watch
  STEP: patching @ 11/30/24 12:41:30.858
  STEP: updating @ 11/30/24 12:41:30.863
  I1130 12:41:30.873547 19 flowcontrol.go:422] waiting for watch events with expected annotations
  STEP: getting /status @ 11/30/24 12:41:30.873
  STEP: patching /status @ 11/30/24 12:41:30.877
  STEP: updating /status @ 11/30/24 12:41:30.884
  STEP: deleting @ 11/30/24 12:41:30.917
  STEP: deleting a collection @ 11/30/24 12:41:30.932
  I1130 12:41:30.957142 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-9594" for this suite. @ 11/30/24 12:41:30.961
• [0.178 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1066
  STEP: Creating a kubernetes client @ 11/30/24 12:41:30.97
  I1130 12:41:30.970641 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:41:30.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:41:30.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:41:30.991
  STEP: Creating resourceQuota "e2e-rq-status-6cgrc" @ 11/30/24 12:41:30.997
  I1130 12:41:31.008448 19 resource_quota.go:1102] Resource quota "e2e-rq-status-6cgrc" reports spec: hard cpu limit of 500m
  I1130 12:41:31.008486 19 resource_quota.go:1104] Resource quota "e2e-rq-status-6cgrc" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-6cgrc" /status @ 11/30/24 12:41:31.008
  STEP: Confirm /status for "e2e-rq-status-6cgrc" resourceQuota via watch @ 11/30/24 12:41:31.018
  I1130 12:41:31.021087 19 resource_quota.go:1131] observed resourceQuota "e2e-rq-status-6cgrc" in namespace "resourcequota-2436" with hard status: v1.ResourceList(nil)
  I1130 12:41:31.021148 19 resource_quota.go:1134] Found resourceQuota "e2e-rq-status-6cgrc" in namespace "resourcequota-2436" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I1130 12:41:31.021161 19 resource_quota.go:1141] ResourceQuota "e2e-rq-status-6cgrc" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 11/30/24 12:41:31.024
  I1130 12:41:31.032426 19 resource_quota.go:1152] Resource quota "e2e-rq-status-6cgrc" reports spec: hard cpu limit of 1
  I1130 12:41:31.032446 19 resource_quota.go:1153] Resource quota "e2e-rq-status-6cgrc" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-6cgrc" /status @ 11/30/24 12:41:31.032
  STEP: Confirm /status for "e2e-rq-status-6cgrc" resourceQuota via watch @ 11/30/24 12:41:31.041
  I1130 12:41:31.043438 19 resource_quota.go:1175] observed resourceQuota "e2e-rq-status-6cgrc" in namespace "resourcequota-2436" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I1130 12:41:31.043478 19 resource_quota.go:1178] Found resourceQuota "e2e-rq-status-6cgrc" in namespace "resourcequota-2436" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I1130 12:41:31.043491 19 resource_quota.go:1185] ResourceQuota "e2e-rq-status-6cgrc" /status was patched
  STEP: Get "e2e-rq-status-6cgrc" /status @ 11/30/24 12:41:31.043
  I1130 12:41:31.047532 19 resource_quota.go:1196] Resourcequota "e2e-rq-status-6cgrc" reports status: hard cpu of 1
  I1130 12:41:31.047560 19 resource_quota.go:1198] Resourcequota "e2e-rq-status-6cgrc" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-6cgrc" /status before checking Spec is unchanged @ 11/30/24 12:41:31.051
  I1130 12:41:31.057304 19 resource_quota.go:1218] Resourcequota "e2e-rq-status-6cgrc" reports status: hard cpu of 2
  I1130 12:41:31.057336 19 resource_quota.go:1220] Resourcequota "e2e-rq-status-6cgrc" reports status: hard memory of 2Gi
  I1130 12:41:31.058902 19 resource_quota.go:1232] Found resourceQuota "e2e-rq-status-6cgrc" in namespace "resourcequota-2436" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I1130 12:41:31.062613 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9668), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e96e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9728), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:41:36.068753 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9908), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9938), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e99b0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:41:41.064914 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044deae0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044deb28), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044deb88), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:41:46.065806 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ded50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dedb0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dedf8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:41:51.065205 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9ba8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9bd8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9c38), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:41:56.068193 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044deff0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df038), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df080), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:01.063706 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df218), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df260), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df2c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:06.067346 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df458), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df4a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df500), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:11.068606 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9ea8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9f08), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0043e9f50), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:16.068446 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046121b0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046121e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612210), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:21.068473 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612378), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046123a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046123f0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:26.064691 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612528), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612558), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046125a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:31.068211 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046126f0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612720), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612768), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:36.068827 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df800), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df878), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044df8a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:41.064821 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dfa58), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dfaa0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dfad0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:46.067475 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dfc80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dfcc8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dfd28), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:51.065289 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dfea8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dff20), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044dff50), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:42:56.068199 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a168), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a1c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a1f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:01.063897 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a3a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a408), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a450), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:06.067712 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a5e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a618), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a678), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:11.063897 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612ac8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612af8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612b58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:16.067811 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a858), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a8b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a918), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:21.064196 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612090), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046120d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612150), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:26.067189 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a0c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a168), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:31.064805 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a300), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a348), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a3a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:36.067921 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a540), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a570), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a5e8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:41.063769 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a768), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a7c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459a828), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:46.065119 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046123c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612408), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612438), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:51.068311 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459aa08), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459aa80), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459aac8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:43:56.067434 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459ac78), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459aca8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459acd8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:01.065127 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459ae88), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459aee8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459af48), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:06.065145 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b0c8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b140), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b188), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:11.066717 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b338), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b368), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b3e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:16.068258 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046126d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612708), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612750), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:21.064243 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612888), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046128b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612900), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:26.064401 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b5a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b620), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b650), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:31.065417 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b800), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b848), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459b8a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:36.065537 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459ba40), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459baa0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459bae8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:41.067781 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612bd0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612c00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612c30), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:46.065330 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612db0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612de0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612e28), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:51.068481 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612f90), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004612ff0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004613050), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:44:56.065225 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046131d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004613248), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004613320), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:45:01.068433 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459bdb8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459be30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00459be78), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:45:06.067807 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046134a0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004613500), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004613530), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:45:11.067167 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-6cgrc" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-6cgrc", GenerateName:"", Namespace:"resourcequota-2436", SelfLink:"", UID:"d3fefcdc-9088-40b4-a85d-07301d62a00d", ResourceVersion:"17661", Generation:0, CreationTimestamp:time.Date(2024, time.November, 30, 12, 41, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-6cgrc"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046136e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004613758), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.November, 30, 12, 41, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0046137b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  I1130 12:45:16.068287 19 resource_quota.go:1260] ResourceQuota "e2e-rq-status-6cgrc" Spec was unchanged and /status reset
  I1130 12:45:16.068442 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2436" for this suite. @ 11/30/24 12:45:16.073
• [225.113 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 11/30/24 12:45:16.083
  I1130 12:45:16.083566 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename daemonsets @ 11/30/24 12:45:16.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:16.103
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:16.106
  STEP: Creating a simple DaemonSet "daemon-set" @ 11/30/24 12:45:16.131
  STEP: Check that daemon pods launch on every node of the cluster. @ 11/30/24 12:45:16.136
  I1130 12:45:16.139875 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:16.139914 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:16.144594 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:45:16.144617 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  I1130 12:45:17.144326 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:17.144407 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:17.149891 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:45:17.149935 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  I1130 12:45:18.143319 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:18.143363 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:18.148048 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 12:45:18.148074 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 11/30/24 12:45:18.152
  I1130 12:45:18.168766 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:18.168808 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:18.175064 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1130 12:45:18.175088 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  I1130 12:45:19.170826 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:19.170878 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:19.175151 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1130 12:45:19.175167 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  I1130 12:45:20.171393 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:20.171465 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 12:45:20.175840 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 12:45:20.175860 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 11/30/24 12:45:20.175
  STEP: Deleting DaemonSet "daemon-set" @ 11/30/24 12:45:20.183
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2153, will wait for the garbage collector to delete the pods @ 11/30/24 12:45:20.183
  I1130 12:45:20.247653 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 9.850341ms
  I1130 12:45:20.348798 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.132517ms
  I1130 12:45:21.453820 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 12:45:21.453857 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1130 12:45:21.457310 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18252"},"items":null}

  I1130 12:45:21.460682 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18252"},"items":null}

  I1130 12:45:21.475257 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2153" for this suite. @ 11/30/24 12:45:21.479
• [5.403 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 11/30/24 12:45:21.486
  I1130 12:45:21.486817 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename apf @ 11/30/24 12:45:21.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:21.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:21.509
  STEP: getting /apis @ 11/30/24 12:45:21.512
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 11/30/24 12:45:21.515
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 11/30/24 12:45:21.517
  STEP: creating @ 11/30/24 12:45:21.518
  STEP: getting @ 11/30/24 12:45:21.535
  STEP: listing @ 11/30/24 12:45:21.539
  STEP: watching @ 11/30/24 12:45:21.542
  I1130 12:45:21.542963 19 flowcontrol.go:620] starting watch
  STEP: patching @ 11/30/24 12:45:21.544
  STEP: updating @ 11/30/24 12:45:21.55
  I1130 12:45:21.558724 19 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 11/30/24 12:45:21.558
  STEP: patching /status @ 11/30/24 12:45:21.562
  STEP: updating /status @ 11/30/24 12:45:21.569
  STEP: deleting @ 11/30/24 12:45:21.578
  STEP: deleting a collection @ 11/30/24 12:45:21.593
  I1130 12:45:21.616161 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-1826" for this suite. @ 11/30/24 12:45:21.62
• [0.143 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 11/30/24 12:45:21.629
  I1130 12:45:21.629829 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 12:45:21.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:21.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:21.652
  STEP: Create a pod @ 11/30/24 12:45:21.655
  STEP: patching /status @ 11/30/24 12:45:23.672
  I1130 12:45:23.681872 19 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I1130 12:45:23.681994 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2954" for this suite. @ 11/30/24 12:45:23.686
• [2.065 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:288
  STEP: Creating a kubernetes client @ 11/30/24 12:45:23.694
  I1130 12:45:23.694573 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename dns @ 11/30/24 12:45:23.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:23.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:23.721
  STEP: Creating a test headless service @ 11/30/24 12:45:23.724
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7458.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7458.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7458.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7458.svc.cluster.local;sleep 1; done
   @ 11/30/24 12:45:23.731
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7458.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7458.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7458.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7458.svc.cluster.local;sleep 1; done
   @ 11/30/24 12:45:23.731
  STEP: creating a pod to probe DNS @ 11/30/24 12:45:23.731
  STEP: submitting the pod to kubernetes @ 11/30/24 12:45:23.731
  STEP: retrieving the pod @ 11/30/24 12:45:25.761
  STEP: looking for the results for each expected name from probers @ 11/30/24 12:45:25.764
  I1130 12:45:25.772229 19 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local from pod dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa: the server could not find the requested resource (get pods dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa)
  I1130 12:45:25.777795 19 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local from pod dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa: the server could not find the requested resource (get pods dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa)
  I1130 12:45:25.782523 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-7458.svc.cluster.local from pod dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa: the server could not find the requested resource (get pods dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa)
  I1130 12:45:25.787793 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-7458.svc.cluster.local from pod dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa: the server could not find the requested resource (get pods dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa)
  I1130 12:45:25.792903 19 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local from pod dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa: the server could not find the requested resource (get pods dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa)
  I1130 12:45:25.797533 19 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local from pod dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa: the server could not find the requested resource (get pods dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa)
  I1130 12:45:25.802531 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-7458.svc.cluster.local from pod dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa: the server could not find the requested resource (get pods dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa)
  I1130 12:45:25.807782 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-7458.svc.cluster.local from pod dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa: the server could not find the requested resource (get pods dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa)
  I1130 12:45:25.807812 19 dns_common.go:489] Lookups using dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7458.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7458.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7458.svc.cluster.local jessie_udp@dns-test-service-2.dns-7458.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7458.svc.cluster.local]

  I1130 12:45:25.824966 19 dns_common.go:495] Pod client logs for webserver: 
  I1130 12:45:25.834093 19 dns_common.go:495] Pod client logs for querier: 
  I1130 12:45:25.842560 19 dns_common.go:495] Pod client logs for jessie-querier: 
  I1130 12:45:30.811402 19 dns_common.go:527] DNS probes using dns-7458/dns-test-0757ed95-a4f1-40b9-a74b-800dd3a089fa succeeded

  STEP: deleting the pod @ 11/30/24 12:45:30.811
  STEP: deleting the test headless service @ 11/30/24 12:45:30.832
  I1130 12:45:30.844616 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7458" for this suite. @ 11/30/24 12:45:30.848
• [7.163 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 11/30/24 12:45:30.857
  I1130 12:45:30.857970 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:45:30.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:30.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:30.884
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:45:30.888
  STEP: Saw pod success @ 11/30/24 12:45:34.916
  I1130 12:45:34.919947 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-c11abcd9-b2f9-4cae-9b7a-8f927970c770 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:45:34.929
  I1130 12:45:34.948133 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7577" for this suite. @ 11/30/24 12:45:34.952
• [4.101 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:119
  STEP: Creating a kubernetes client @ 11/30/24 12:45:34.958
  I1130 12:45:34.958693 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename dns @ 11/30/24 12:45:34.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:34.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:34.979
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9148.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9148.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 11/30/24 12:45:34.982
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9148.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9148.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 11/30/24 12:45:34.982
  STEP: creating a pod to probe /etc/hosts @ 11/30/24 12:45:34.982
  STEP: submitting the pod to kubernetes @ 11/30/24 12:45:34.982
  STEP: retrieving the pod @ 11/30/24 12:45:37.006
  STEP: looking for the results for each expected name from probers @ 11/30/24 12:45:37.011
  I1130 12:45:37.031512 19 dns_common.go:527] DNS probes using dns-9148/dns-test-521e3212-8e34-468a-b0f5-9dcaec786522 succeeded

  STEP: deleting the pod @ 11/30/24 12:45:37.031
  I1130 12:45:37.046738 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9148" for this suite. @ 11/30/24 12:45:37.051
• [2.100 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 11/30/24 12:45:37.058
  I1130 12:45:37.058482 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename deployment @ 11/30/24 12:45:37.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:37.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:37.081
  STEP: creating a Deployment @ 11/30/24 12:45:37.088
  STEP: waiting for Deployment to be created @ 11/30/24 12:45:37.094
  STEP: waiting for all Replicas to be Ready @ 11/30/24 12:45:37.096
  I1130 12:45:37.097355 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1130 12:45:37.097389 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1130 12:45:37.107875 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1130 12:45:37.107915 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1130 12:45:37.123502 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1130 12:45:37.123535 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1130 12:45:37.161274 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1130 12:45:37.161325 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1130 12:45:38.339696 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I1130 12:45:38.339729 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I1130 12:45:38.454897 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 11/30/24 12:45:38.454
  I1130 12:45:38.465475 19 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 11/30/24 12:45:38.465
  I1130 12:45:38.467184 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0
  I1130 12:45:38.467204 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0
  I1130 12:45:38.467213 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0
  I1130 12:45:38.467219 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0
  I1130 12:45:38.467238 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0
  I1130 12:45:38.467244 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0
  I1130 12:45:38.467316 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0
  I1130 12:45:38.467323 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 0
  I1130 12:45:38.467330 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:38.467335 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:38.467343 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:38.467349 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:38.467396 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:38.467403 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:38.478939 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:38.478981 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:38.501841 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:38.501873 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:38.510072 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:38.510104 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:38.516954 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:38.516975 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:39.479423 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:39.479459 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:39.503116 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  STEP: listing Deployments @ 11/30/24 12:45:39.503
  I1130 12:45:39.507945 19 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 11/30/24 12:45:39.507
  I1130 12:45:39.519679 19 deployment.go:360] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 11/30/24 12:45:39.519
  I1130 12:45:39.526951 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:39.536730 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:39.552743 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:39.572394 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:39.585735 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:40.348319 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:40.486304 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:40.524853 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:40.536208 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I1130 12:45:41.358363 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 11/30/24 12:45:41.377
  STEP: fetching the DeploymentStatus @ 11/30/24 12:45:41.388
  I1130 12:45:41.393753 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:41.393782 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:41.393790 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:41.393901 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:41.393908 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 1
  I1130 12:45:41.393915 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:41.393998 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 3
  I1130 12:45:41.394005 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:41.394014 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 2
  I1130 12:45:41.394066 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-2315 with ReadyReplicas 3
  STEP: deleting the Deployment @ 11/30/24 12:45:41.394
  I1130 12:45:41.405262 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405291 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405300 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405391 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405399 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405407 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405478 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405485 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405494 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405540 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405551 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405675 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.405684 19 deployment.go:475] observed event type MODIFIED
  I1130 12:45:41.409240 19 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I1130 12:45:41.418281 19 deployment.go:657] ReplicaSet "test-deployment-6c86c7f765":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-6c86c7f765",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2315",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5c71b6f0-3f5b-462e-bff7-fe3edb2601f1",
      ResourceVersion: (string) (len=5) "18664",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567539,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "c9051112-6e82-4be6-8e63-90a590f1a0ec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 63 39 30 35  31 31 31 32 2d 36 65 38  |":\"c9051112-6e8|
              00000130  32 2d 34 62 65 36 2d 38  65 36 33 2d 39 30 61 35  |2-4be6-8e63-90a5|
              00000140  39 30 66 31 61 30 65 63  5c 22 7d 22 3a 7b 7d 7d  |90f1a0ec\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I1130 12:45:41.424769 19 deployment.go:669] pod: "test-deployment-6c86c7f765-qjft4":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6c86c7f765-qjft4",
      GenerateName: (string) (len=27) "test-deployment-6c86c7f765-",
      Namespace: (string) (len=15) "deployment-2315",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9631a0b3-3c5c-4930-89a2-dd1bcbcf413c",
      ResourceVersion: (string) (len=5) "18627",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567539,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6c86c7f765",
          UID: (types.UID) (len=36) "5c71b6f0-3f5b-462e-bff7-fe3edb2601f1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  35 63 37 31 62 36 66 30  |uid\":\"5c71b6f0|
              000000a0  2d 33 66 35 62 2d 34 36  32 65 2d 62 66 66 37 2d  |-3f5b-462e-bff7-|
              000000b0  66 65 33 65 64 62 32 36  30 31 66 31 5c 22 7d 22  |fe3edb2601f1\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 32 31 36 5c 22 7d  |2.168.244.216\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-98q8b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-98q8b",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.216",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.216"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567539,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567540,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b53b39b87d2a6487c6c35970de850af2f102f84ec6387b2c2fda5db3522297f8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-98q8b",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I1130 12:45:41.428335 19 deployment.go:669] pod: "test-deployment-6c86c7f765-tk744":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6c86c7f765-tk744",
      GenerateName: (string) (len=27) "test-deployment-6c86c7f765-",
      Namespace: (string) (len=15) "deployment-2315",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b2da6635-33e8-4ccf-819e-dd3148e71809",
      ResourceVersion: (string) (len=5) "18663",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567540,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6c86c7f765",
          UID: (types.UID) (len=36) "5c71b6f0-3f5b-462e-bff7-fe3edb2601f1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  35 63 37 31 62 36 66 30  |uid\":\"5c71b6f0|
              000000a0  2d 33 66 35 62 2d 34 36  32 65 2d 62 66 66 37 2d  |-3f5b-462e-bff7-|
              000000b0  66 65 33 65 64 62 32 36  30 31 66 31 5c 22 7d 22  |fe3edb2601f1\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 36 32  2e 32 37 5c 22 7d 22 3a  |2.168.62.27\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6rfs8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6rfs8",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-4-119",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.4.119",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.4.119"
        }
      },
      PodIP: (string) (len=13) "192.168.62.27",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.62.27"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567540,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567541,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://7d1e246ee2a6a71e5a756848c55060331a72a918d2e898de1a2ca2661993fff5",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-6rfs8",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I1130 12:45:41.430469 19 deployment.go:657] ReplicaSet "test-deployment-77bdf6fb4b":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-77bdf6fb4b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2315",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ea067294-77ee-4b3c-a201-b23dc334438a",
      ResourceVersion: (string) (len=5) "18564",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567537,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "77bdf6fb4b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "c9051112-6e82-4be6-8e63-90a590f1a0ec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 63 39 30 35  31 31 31 32 2d 36 65 38  |":\"c9051112-6e8|
              00000130  32 2d 34 62 65 36 2d 38  65 36 33 2d 39 30 61 35  |2-4be6-8e63-90a5|
              00000140  39 30 66 31 61 30 65 63  5c 22 7d 22 3a 7b 7d 7d  |90f1a0ec\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "77bdf6fb4b",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "77bdf6fb4b",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I1130 12:45:41.435907 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2315" for this suite. @ 11/30/24 12:45:41.44
• [4.393 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 11/30/24 12:45:41.452
  I1130 12:45:41.452318 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replicaset @ 11/30/24 12:45:41.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:41.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:41.481
  STEP: Create a ReplicaSet @ 11/30/24 12:45:41.487
  STEP: Verify that the required pods have come up @ 11/30/24 12:45:41.501
  I1130 12:45:41.509633 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 3
  I1130 12:45:46.513943 19 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 11/30/24 12:45:46.513
  I1130 12:45:46.517659 19 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 11/30/24 12:45:46.517
  STEP: DeleteCollection of the ReplicaSets @ 11/30/24 12:45:46.522
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 11/30/24 12:45:46.532
  I1130 12:45:46.536475 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2380" for this suite. @ 11/30/24 12:45:46.539
• [5.100 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 11/30/24 12:45:46.552
  I1130 12:45:46.552349 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:45:46.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:46.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:46.581
  STEP: Creating a pod to test downward api env vars @ 11/30/24 12:45:46.584
  STEP: Saw pod success @ 11/30/24 12:45:50.606
  I1130 12:45:50.611206 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downward-api-de8eff1c-ab93-43b8-96f9-789206803192 container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 12:45:50.62
  I1130 12:45:50.638536 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4928" for this suite. @ 11/30/24 12:45:50.643
• [4.099 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 11/30/24 12:45:50.651
  I1130 12:45:50.651930 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:45:50.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:50.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:50.678
  STEP: Creating projection with secret that has name projected-secret-test-map-b75d436f-08f7-4b49-a4d0-286210e0298e @ 11/30/24 12:45:50.682
  STEP: Creating a pod to test consume secrets @ 11/30/24 12:45:50.688
  STEP: Saw pod success @ 11/30/24 12:45:52.71
  I1130 12:45:52.714809 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-secrets-b2670fdc-a349-40d5-9ec9-3abf98adce39 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:45:52.722
  I1130 12:45:52.738504 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6241" for this suite. @ 11/30/24 12:45:52.742
• [2.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:409
  STEP: Creating a kubernetes client @ 11/30/24 12:45:52.75
  I1130 12:45:52.750013 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename dns @ 11/30/24 12:45:52.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:52.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:52.772
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 11/30/24 12:45:52.775
  I1130 12:45:52.783670 19 dns.go:421] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3974  fd410e66-374d-4e34-8e27-9c4a4e60d06b 18931 0 2024-11-30 12:45:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-11-30 12:45:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zmtgl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,Image:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.52,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zmtgl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,SupplementalGroupsPolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 11/30/24 12:45:54.792
  I1130 12:45:54.792740 19 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3974 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 12:45:54.792758 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:45:54.793198 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 12:45:54.793235 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-3974/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 11/30/24 12:45:54.85
  I1130 12:45:54.850721 19 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3974 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 12:45:54.850757 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:45:54.851214 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 12:45:54.851257 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-3974/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I1130 12:45:54.904555 19 dns.go:423] Deleting pod test-dns-nameservers...
  I1130 12:45:54.922544 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3974" for this suite. @ 11/30/24 12:45:54.93
• [2.188 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 11/30/24 12:45:54.938
  I1130 12:45:54.938596 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename gc @ 11/30/24 12:45:54.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:54.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:54.969
  STEP: create the deployment @ 11/30/24 12:45:54.972
  W1130 12:45:54.980313      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 11/30/24 12:45:54.98
  STEP: delete the deployment @ 11/30/24 12:45:55.487
  STEP: wait for all rs to be garbage collected @ 11/30/24 12:45:55.494
  STEP: expected 0 rs, got 1 rs @ 11/30/24 12:45:55.502
  STEP: expected 0 pods, got 2 pods @ 11/30/24 12:45:55.506
  STEP: Gathering metrics @ 11/30/24 12:45:56.009
  W1130 12:45:56.015688      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1130 12:45:56.015730 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1130 12:45:56.015891 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6254" for this suite. @ 11/30/24 12:45:56.02
• [1.091 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 11/30/24 12:45:56.029
  I1130 12:45:56.029306 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 12:45:56.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:45:56.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:45:56.054
  STEP: Creating secret with name secret-test-236a549c-1e66-46ad-bcf1-73a1f2cee206 @ 11/30/24 12:45:56.058
  STEP: Creating a pod to test consume secrets @ 11/30/24 12:45:56.064
  STEP: Saw pod success @ 11/30/24 12:46:00.094
  I1130 12:46:00.098045 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-secrets-1e570ecc-400c-4dc8-b507-3978d7093454 container secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:46:00.105
  I1130 12:46:00.124802 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5197" for this suite. @ 11/30/24 12:46:00.13
• [4.109 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 11/30/24 12:46:00.138
  I1130 12:46:00.138770 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename deployment @ 11/30/24 12:46:00.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:00.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:00.163
  I1130 12:46:00.166140 19 deployment.go:1645] Creating simple deployment test-new-deployment
  I1130 12:46:00.180757 19 deployment.go:222] deployment "test-new-deployment" doesn't have the required revision set
  STEP: getting scale subresource @ 11/30/24 12:46:02.197
  STEP: updating a scale subresource @ 11/30/24 12:46:02.201
  STEP: verifying the deployment Spec.Replicas was modified @ 11/30/24 12:46:02.209
  STEP: Patch a scale subresource @ 11/30/24 12:46:02.213
  I1130 12:46:02.237662 19 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2957",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cb8d2ecb-1678-469b-ae1a-f6638480a615",
      ResourceVersion: (string) (len=5) "19118",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567560,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567560,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567561,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567561,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567561,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567561,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567560,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-64bcfc6446\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1130 12:46:02.241997 19 deployment.go:39] New ReplicaSet "test-new-deployment-64bcfc6446" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-64bcfc6446",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2957",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6a95a5c8-0cab-4779-b8e8-6b8faa813f42",
      ResourceVersion: (string) (len=5) "19124",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567560,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "cb8d2ecb-1678-469b-ae1a-f6638480a615",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 62 38 64 32 65  63 62 2d 31 36 37 38 2d  |\"cb8d2ecb-1678-|
              00000120  34 36 39 62 2d 61 65 31  61 2d 66 36 36 33 38 34  |469b-ae1a-f66384|
              00000130  38 30 61 36 31 35 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |80a615\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:46:02.246044 19 deployment.go:67] Pod "test-new-deployment-64bcfc6446-h5gnh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-64bcfc6446-h5gnh",
      GenerateName: (string) (len=31) "test-new-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2957",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "87afd528-fe4c-41c7-8864-f363daab7764",
      ResourceVersion: (string) (len=5) "19123",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567562,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "6a95a5c8-0cab-4779-b8e8-6b8faa813f42",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  39 35 61 35 63 38 2d 30  |d\":\"6a95a5c8-0|
              00000090  63 61 62 2d 34 37 37 39  2d 62 38 65 38 2d 36 62  |cab-4779-b8e8-6b|
              000000a0  38 66 61 61 38 31 33 66  34 32 5c 22 7d 22 3a 7b  |8faa813f42\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k9fwv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k9fwv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-4-119",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567562,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:46:02.247139 19 deployment.go:67] Pod "test-new-deployment-64bcfc6446-hd2j9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-64bcfc6446-hd2j9",
      GenerateName: (string) (len=31) "test-new-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2957",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "25053a92-e550-4c4c-851d-bbf0d76fddf1",
      ResourceVersion: (string) (len=5) "19113",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567560,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "6a95a5c8-0cab-4779-b8e8-6b8faa813f42",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567560,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 61  39 35 61 35 63 38 2d 30  |d\":\"6a95a5c8-0|
              00000090  63 61 62 2d 34 37 37 39  2d 62 38 65 38 2d 36 62  |cab-4779-b8e8-6b|
              000000a0  38 66 61 61 38 31 33 66  34 32 5c 22 7d 22 3a 7b  |8faa813f42\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567561,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 32 31 35 5c 22 7d  |2.168.244.215\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-f2zwq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-f2zwq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567561,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567560,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567561,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567561,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567560,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.215",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.215"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567560,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567560,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0adf043fcb7c5dc8abacb5b05e60f0b094ac2f65f9d2e3471d418e3952faaaac",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-f2zwq",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:46:02.248574 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2957" for this suite. @ 11/30/24 12:46:02.253
• [2.126 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 11/30/24 12:46:02.264
  I1130 12:46:02.264716 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replication-controller @ 11/30/24 12:46:02.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:02.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:02.292
  STEP: creating a ReplicationController @ 11/30/24 12:46:02.298
  STEP: waiting for RC to be added @ 11/30/24 12:46:02.306
  STEP: waiting for available Replicas @ 11/30/24 12:46:02.306
  STEP: patching ReplicationController @ 11/30/24 12:46:03.549
  STEP: waiting for RC to be modified @ 11/30/24 12:46:03.558
  STEP: patching ReplicationController status @ 11/30/24 12:46:03.558
  STEP: waiting for RC to be modified @ 11/30/24 12:46:03.564
  STEP: waiting for available Replicas @ 11/30/24 12:46:03.565
  STEP: fetching ReplicationController status @ 11/30/24 12:46:03.572
  STEP: patching ReplicationController scale @ 11/30/24 12:46:03.576
  STEP: waiting for RC to be modified @ 11/30/24 12:46:03.583
  STEP: waiting for ReplicationController's scale to be the max amount @ 11/30/24 12:46:03.583
  STEP: fetching ReplicationController; ensuring that it's patched @ 11/30/24 12:46:04.387
  STEP: updating ReplicationController status @ 11/30/24 12:46:04.391
  STEP: waiting for RC to be modified @ 11/30/24 12:46:04.399
  STEP: listing all ReplicationControllers @ 11/30/24 12:46:04.399
  STEP: checking that ReplicationController has expected values @ 11/30/24 12:46:04.406
  STEP: deleting ReplicationControllers by collection @ 11/30/24 12:46:04.406
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 11/30/24 12:46:04.415
  I1130 12:46:04.464880 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E1130 12:46:04.464969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-9656" for this suite. @ 11/30/24 12:46:04.469
• [2.213 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:111
  STEP: Creating a kubernetes client @ 11/30/24 12:46:04.477
  I1130 12:46:04.477791 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename disruption @ 11/30/24 12:46:04.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:04.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:04.502
  STEP: creating the pdb @ 11/30/24 12:46:04.505
  STEP: Waiting for the pdb to be processed @ 11/30/24 12:46:04.511
  E1130 12:46:05.465633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:06.466131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 11/30/24 12:46:06.517
  STEP: Waiting for the pdb to be processed @ 11/30/24 12:46:06.527
  E1130 12:46:07.466280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:08.466478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 11/30/24 12:46:08.534
  STEP: Waiting for the pdb to be processed @ 11/30/24 12:46:08.543
  E1130 12:46:09.466665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:10.467531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 11/30/24 12:46:10.554
  I1130 12:46:10.559222 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6686" for this suite. @ 11/30/24 12:46:10.565
• [6.096 seconds]
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 11/30/24 12:46:10.573
  I1130 12:46:10.573834 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir-wrapper @ 11/30/24 12:46:10.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:10.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:10.596
  STEP: Creating 50 configmaps @ 11/30/24 12:46:10.602
  STEP: Creating RC which spawns configmap-volume pods @ 11/30/24 12:46:10.892
  I1130 12:46:10.993532 19 resource.go:87] Pod name wrapped-volume-race-ee994151-e8d3-4ca4-bc3e-550416234891: Found 3 pods out of 5
  E1130 12:46:11.468226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:12.468408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:13.468542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:14.468652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:15.468765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:46:16.002209 19 resource.go:87] Pod name wrapped-volume-race-ee994151-e8d3-4ca4-bc3e-550416234891: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 11/30/24 12:46:16.002
  STEP: Creating RC which spawns configmap-volume pods @ 11/30/24 12:46:16.028
  I1130 12:46:16.043396 19 resource.go:87] Pod name wrapped-volume-race-30c3fbb8-f66b-4a04-8548-f303ad4c7b9e: Found 0 pods out of 5
  E1130 12:46:16.468867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:17.469594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:18.469673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:19.469739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:20.469883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:46:21.052861 19 resource.go:87] Pod name wrapped-volume-race-30c3fbb8-f66b-4a04-8548-f303ad4c7b9e: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 11/30/24 12:46:21.052
  STEP: Creating RC which spawns configmap-volume pods @ 11/30/24 12:46:21.077
  I1130 12:46:21.092009 19 resource.go:87] Pod name wrapped-volume-race-e7d39f37-107f-42f0-82a1-61609bc06d84: Found 0 pods out of 5
  E1130 12:46:21.470729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:22.470874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:23.470956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:24.471033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:25.471613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:46:26.106303 19 resource.go:87] Pod name wrapped-volume-race-e7d39f37-107f-42f0-82a1-61609bc06d84: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 11/30/24 12:46:26.106
  STEP: deleting ReplicationController wrapped-volume-race-e7d39f37-107f-42f0-82a1-61609bc06d84 in namespace emptydir-wrapper-8967, will wait for the garbage collector to delete the pods @ 11/30/24 12:46:26.127
  I1130 12:46:26.192018 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-e7d39f37-107f-42f0-82a1-61609bc06d84 took: 8.999462ms
  I1130 12:46:26.294450 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-e7d39f37-107f-42f0-82a1-61609bc06d84 pods took: 102.42544ms
  E1130 12:46:26.472138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:27.472973      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-30c3fbb8-f66b-4a04-8548-f303ad4c7b9e in namespace emptydir-wrapper-8967, will wait for the garbage collector to delete the pods @ 11/30/24 12:46:27.694
  I1130 12:46:27.759653 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-30c3fbb8-f66b-4a04-8548-f303ad4c7b9e took: 9.08561ms
  I1130 12:46:27.859958 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-30c3fbb8-f66b-4a04-8548-f303ad4c7b9e pods took: 100.298769ms
  E1130 12:46:28.473585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-ee994151-e8d3-4ca4-bc3e-550416234891 in namespace emptydir-wrapper-8967, will wait for the garbage collector to delete the pods @ 11/30/24 12:46:28.761
  I1130 12:46:28.825143 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-ee994151-e8d3-4ca4-bc3e-550416234891 took: 8.581475ms
  I1130 12:46:28.925818 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-ee994151-e8d3-4ca4-bc3e-550416234891 pods took: 100.667019ms
  E1130 12:46:29.473760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 11/30/24 12:46:29.726
  I1130 12:46:30.108539 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-8967" for this suite. @ 11/30/24 12:46:30.113
• [19.546 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 11/30/24 12:46:30.119
  I1130 12:46:30.119992 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:46:30.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:30.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:30.143
  STEP: Creating configMap with name projected-configmap-test-volume-map-3f7e953f-42eb-4196-9d29-847ae28f6eec @ 11/30/24 12:46:30.147
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:46:30.152
  E1130 12:46:30.474835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:31.475754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:32.475872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:33.475991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:46:34.174
  I1130 12:46:34.179578 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-configmaps-a1526023-c964-456f-a3fe-103bdb5f5343 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:46:34.188
  I1130 12:46:34.205692 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6502" for this suite. @ 11/30/24 12:46:34.209
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 11/30/24 12:46:34.218
  I1130 12:46:34.218316 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 11/30/24 12:46:34.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:34.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:34.24
  STEP: create the container to handle the HTTPGet hook request. @ 11/30/24 12:46:34.248
  E1130 12:46:34.476988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:35.477174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 11/30/24 12:46:36.271
  E1130 12:46:36.478143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:37.479107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 11/30/24 12:46:38.294
  E1130 12:46:38.479537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:39.479632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 11/30/24 12:46:40.313
  I1130 12:46:40.322442 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-3433" for this suite. @ 11/30/24 12:46:40.327
• [6.117 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 11/30/24 12:46:40.335
  I1130 12:46:40.335264 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 12:46:40.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:40.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:40.359
  STEP: creating the pod @ 11/30/24 12:46:40.362
  STEP: submitting the pod to kubernetes @ 11/30/24 12:46:40.362
  STEP: verifying QOS class is set on the pod @ 11/30/24 12:46:40.372
  I1130 12:46:40.375588 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1441" for this suite. @ 11/30/24 12:46:40.381
• [0.054 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 11/30/24 12:46:40.389
  I1130 12:46:40.389525 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-runtime @ 11/30/24 12:46:40.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:40.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:40.41
  STEP: create the container @ 11/30/24 12:46:40.414
  W1130 12:46:40.421257      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 11/30/24 12:46:40.421
  E1130 12:46:40.480528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:41.480746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:42.481215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 11/30/24 12:46:43.443
  STEP: the container should be terminated @ 11/30/24 12:46:43.447
  STEP: the termination message should be set @ 11/30/24 12:46:43.448
  I1130 12:46:43.448033 19 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 11/30/24 12:46:43.448
  I1130 12:46:43.467882 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7634" for this suite. @ 11/30/24 12:46:43.472
  E1130 12:46:43.481180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [3.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 11/30/24 12:46:43.481
  I1130 12:46:43.481600 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:46:43.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:43.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:43.502
  STEP: Creating projection with secret that has name projected-secret-test-0f28c66d-5af7-4874-ab7b-49c4f00a06bd @ 11/30/24 12:46:43.505
  STEP: Creating a pod to test consume secrets @ 11/30/24 12:46:43.511
  E1130 12:46:44.481342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:45.481545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:46.482212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:47.482549      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:46:47.537
  I1130 12:46:47.542516 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-secrets-4bdf2b5c-4328-4b29-b1b2-ecf8dc651993 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:46:47.55
  I1130 12:46:47.580039 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-446" for this suite. @ 11/30/24 12:46:47.584
• [4.112 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:472
  STEP: Creating a kubernetes client @ 11/30/24 12:46:47.594
  I1130 12:46:47.594269 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename field-validation @ 11/30/24 12:46:47.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:47.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:47.615
  I1130 12:46:47.618123 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 12:46:48.483143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:49.483356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W1130 12:46:50.155403      19 warnings.go:70] unknown field "alpha"
  W1130 12:46:50.155422      19 warnings.go:70] unknown field "beta"
  W1130 12:46:50.155425      19 warnings.go:70] unknown field "delta"
  W1130 12:46:50.155428      19 warnings.go:70] unknown field "epsilon"
  W1130 12:46:50.155435      19 warnings.go:70] unknown field "gamma"
  E1130 12:46:50.483447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:46:50.715136 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6605" for this suite. @ 11/30/24 12:46:50.718
• [3.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 11/30/24 12:46:50.725
  I1130 12:46:50.725778 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 12:46:50.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:50.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:50.749
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 11/30/24 12:46:50.752
  E1130 12:46:51.483991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:52.484322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:53.484633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:54.484835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:46:54.774
  I1130 12:46:54.779091 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-969aae1a-e200-4910-9926-06728ed7e78e container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:46:54.788
  I1130 12:46:54.818660 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5476" for this suite. @ 11/30/24 12:46:54.828
• [4.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:247
  STEP: Creating a kubernetes client @ 11/30/24 12:46:54.844
  I1130 12:46:54.844945 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:46:54.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:54.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:54.876
  STEP: Setting up server cert @ 11/30/24 12:46:54.916
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:46:55.084
  STEP: Deploying the webhook pod @ 11/30/24 12:46:55.096
  STEP: Wait for the deployment to be ready @ 11/30/24 12:46:55.112
  I1130 12:46:55.126037 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 12:46:55.485606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:56.486050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 12:46:57.139
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:46:57.151
  E1130 12:46:57.486990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:46:58.151283 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 11/30/24 12:46:58.159
  STEP: create a configmap that should be updated by the webhook @ 11/30/24 12:46:58.175
  I1130 12:46:58.236317 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5928" for this suite. @ 11/30/24 12:46:58.239
  STEP: Destroying namespace "webhook-markers-9421" for this suite. @ 11/30/24 12:46:58.246
• [3.409 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 11/30/24 12:46:58.254
  I1130 12:46:58.254357 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename runtimeclass @ 11/30/24 12:46:58.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:58.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:58.276
  STEP: Deleting RuntimeClass runtimeclass-4094-delete-me @ 11/30/24 12:46:58.283
  STEP: Waiting for the RuntimeClass to disappear @ 11/30/24 12:46:58.29
  I1130 12:46:58.301619 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4094" for this suite. @ 11/30/24 12:46:58.305
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 11/30/24 12:46:58.313
  I1130 12:46:58.313918 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sysctl @ 11/30/24 12:46:58.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:46:58.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:46:58.336
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 11/30/24 12:46:58.339
  STEP: Watching for error events or started pod @ 11/30/24 12:46:58.349
  E1130 12:46:58.487119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:46:59.487274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 11/30/24 12:47:00.354
  E1130 12:47:00.487742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:01.488330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 11/30/24 12:47:02.368
  STEP: Getting logs from the pod @ 11/30/24 12:47:02.368
  STEP: Checking that the sysctl is actually updated @ 11/30/24 12:47:02.377
  I1130 12:47:02.377875 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-3384" for this suite. @ 11/30/24 12:47:02.382
• [4.075 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:331
  STEP: Creating a kubernetes client @ 11/30/24 12:47:02.389
  I1130 12:47:02.389196 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:47:02.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:47:02.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:47:02.412
  E1130 12:47:02.489275      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:03.489349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:04.489816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:05.490425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:06.491457      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:07.492027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:08.492687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:09.493410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:10.494128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:11.494500      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:12.494931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:13.495975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:14.496146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:15.496433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:16.497211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:17.497349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:18.498348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 11/30/24 12:47:19.42
  E1130 12:47:19.498551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:20.499627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:21.499924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:22.500479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:23.501526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 11/30/24 12:47:24.425
  STEP: Ensuring resource quota status is calculated @ 11/30/24 12:47:24.431
  E1130 12:47:24.502403      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:25.502612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 11/30/24 12:47:26.437
  STEP: Ensuring resource quota status captures configMap creation @ 11/30/24 12:47:26.449
  E1130 12:47:26.502849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:27.503002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 11/30/24 12:47:28.455
  STEP: Ensuring resource quota status released usage @ 11/30/24 12:47:28.463
  E1130 12:47:28.503785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:29.503893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:47:30.468920 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2098" for this suite. @ 11/30/24 12:47:30.473
• [28.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1473
  STEP: Creating a kubernetes client @ 11/30/24 12:47:30.483
  I1130 12:47:30.483113 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:47:30.483
  E1130 12:47:30.504216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:47:30.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:47:30.507
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2145 @ 11/30/24 12:47:30.51
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 11/30/24 12:47:30.522
  STEP: creating service externalsvc in namespace services-2145 @ 11/30/24 12:47:30.522
  STEP: creating replication controller externalsvc in namespace services-2145 @ 11/30/24 12:47:30.534
  I1130 12:47:30.543727      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2145, replica count: 2
  E1130 12:47:31.505194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:32.505334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:33.505575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:47:33.594884      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 11/30/24 12:47:33.6
  I1130 12:47:33.615765 19 resource.go:361] Creating new exec pod
  E1130 12:47:34.506608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:35.506809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:47:35.640225 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2145 exec execpodtvljp -- /bin/sh -x -c nslookup clusterip-service.services-2145.svc.cluster.local'
  I1130 12:47:35.735823 19 builder.go:146] stderr: "+ nslookup clusterip-service.services-2145.svc.cluster.local\n"
  I1130 12:47:35.735873 19 builder.go:147] stdout: "Server:\t\t10.152.183.50\nAddress:\t10.152.183.50#53\n\nclusterip-service.services-2145.svc.cluster.local\tcanonical name = externalsvc.services-2145.svc.cluster.local.\nName:\texternalsvc.services-2145.svc.cluster.local\nAddress: 10.152.183.77\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-2145, will wait for the garbage collector to delete the pods @ 11/30/24 12:47:35.736
  I1130 12:47:35.798401 19 resources.go:139] Deleting ReplicationController externalsvc took: 7.931493ms
  I1130 12:47:35.899046 19 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.637951ms
  E1130 12:47:36.507577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:37.507814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:38.508052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:47:38.819207 19 service.go:1482] Cleaning up the ClusterIP to ExternalName test service
  I1130 12:47:38.830516 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2145" for this suite. @ 11/30/24 12:47:38.834
• [8.360 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 11/30/24 12:47:38.843
  I1130 12:47:38.843658 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:47:38.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:47:38.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:47:38.866
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:47:38.869
  E1130 12:47:39.508232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:40.508611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:41.508916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:42.509038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:47:42.894
  I1130 12:47:42.897718 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-c1825214-88d1-4979-8b82-170b8422cb9e container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:47:42.906
  I1130 12:47:42.926732 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9084" for this suite. @ 11/30/24 12:47:42.931
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:127
  STEP: Creating a kubernetes client @ 11/30/24 12:47:42.94
  I1130 12:47:42.940399 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-preemption @ 11/30/24 12:47:42.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:47:42.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:47:42.966
  I1130 12:47:42.984056 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1130 12:47:43.509310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:44.509511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:45.509621      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:46.510111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:47.510617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:48.511573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:49.511724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:50.511809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:51.512739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:52.512800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:53.513598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:54.513667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:55.513810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:56.514088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:57.514545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:58.514768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:47:59.514859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:00.515064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:01.515977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:02.516191      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:03.516666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:04.516855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:05.517223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:06.517695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:07.518362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:08.518510      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:09.519287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:10.519453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:11.520643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:12.521578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:13.522161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:14.522566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:15.522624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:16.523210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:17.523301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:18.523571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:19.523689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:20.523815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:21.524177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:22.524423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:23.524551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:24.524765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:25.524850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:26.525416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:27.525559      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:28.526474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:29.527347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:30.527645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:31.528009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:32.528092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:33.528569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:34.528926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:35.529482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:36.530076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:37.530494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:38.530600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:39.531063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:40.531334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:41.532015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:42.532111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:48:42.989946 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 11/30/24 12:48:42.994
  I1130 12:48:43.013001 19 preemption.go:175] Created pod: pod0-0-sched-preemption-low-priority
  I1130 12:48:43.021713 19 preemption.go:175] Created pod: pod0-1-sched-preemption-medium-priority
  I1130 12:48:43.038339 19 preemption.go:175] Created pod: pod1-0-sched-preemption-medium-priority
  I1130 12:48:43.045740 19 preemption.go:175] Created pod: pod1-1-sched-preemption-medium-priority
  I1130 12:48:43.058785 19 preemption.go:175] Created pod: pod2-0-sched-preemption-medium-priority
  I1130 12:48:43.067505 19 preemption.go:175] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 11/30/24 12:48:43.067
  E1130 12:48:43.532466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:44.532534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 11/30/24 12:48:45.099
  E1130 12:48:45.533138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:46.533664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:47.534586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:48.534789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:48:49.205734 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-143" for this suite. @ 11/30/24 12:48:49.21
• [66.276 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 11/30/24 12:48:49.216
  I1130 12:48:49.216999 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 12:48:49.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:48:49.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:48:49.296
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 11/30/24 12:48:49.299
  E1130 12:48:49.535547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:50.536039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:51.536905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:52.537010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:48:53.329
  I1130 12:48:53.334247 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-5f0a3208-f8c9-43af-a725-7189dd5be102 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:48:53.342
  I1130 12:48:53.363892 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7736" for this suite. @ 11/30/24 12:48:53.367
• [4.158 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:940
  STEP: Creating a kubernetes client @ 11/30/24 12:48:53.376
  I1130 12:48:53.376214 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 12:48:53.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:48:53.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:48:53.4
  STEP: Creating a ResourceQuota @ 11/30/24 12:48:53.403
  STEP: Getting a ResourceQuota @ 11/30/24 12:48:53.407
  STEP: Updating a ResourceQuota @ 11/30/24 12:48:53.412
  STEP: Verifying a ResourceQuota was modified @ 11/30/24 12:48:53.418
  STEP: Deleting a ResourceQuota @ 11/30/24 12:48:53.421
  STEP: Verifying the deleted ResourceQuota @ 11/30/24 12:48:53.428
  I1130 12:48:53.433285 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7796" for this suite. @ 11/30/24 12:48:53.437
• [0.070 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 11/30/24 12:48:53.446
  I1130 12:48:53.446310 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename containers @ 11/30/24 12:48:53.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:48:53.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:48:53.467
  STEP: Creating a pod to test override all @ 11/30/24 12:48:53.471
  E1130 12:48:53.537104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:54.537987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:55.538851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:56.539100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:48:57.493
  I1130 12:48:57.497640 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod client-containers-eb74a616-61bb-407b-9821-84541958ae86 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:48:57.505
  I1130 12:48:57.524586 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4925" for this suite. @ 11/30/24 12:48:57.528
• [4.089 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1260
  STEP: Creating a kubernetes client @ 11/30/24 12:48:57.535
  I1130 12:48:57.535448 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:48:57.536
  E1130 12:48:57.539355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:48:57.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:48:57.559
  STEP: creating service nodeport-test with type=NodePort in namespace services-3050 @ 11/30/24 12:48:57.562
  STEP: creating replication controller nodeport-test in namespace services-3050 @ 11/30/24 12:48:57.58
  I1130 12:48:57.589081      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-3050, replica count: 2
  E1130 12:48:58.539547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:48:59.539644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:00.540607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:00.640887      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 12:49:00.641092 19 resource.go:361] Creating new exec pod
  E1130 12:49:01.540984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:02.541091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:03.541605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:03.667925 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3050 exec execpodxftjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I1130 12:49:03.750024 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I1130 12:49:03.750062 19 builder.go:147] stdout: ""
  E1130 12:49:04.542594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:04.668915 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3050 exec execpodxftjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I1130 12:49:04.753812 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I1130 12:49:04.753859 19 builder.go:147] stdout: ""
  E1130 12:49:05.542858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:05.668263 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3050 exec execpodxftjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I1130 12:49:05.766021 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I1130 12:49:05.766060 19 builder.go:147] stdout: "nodeport-test-qgmlp"
  I1130 12:49:05.766138 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3050 exec execpodxftjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.247 80'
  I1130 12:49:05.848061 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.247 80\nConnection to 10.152.183.247 80 port [tcp/http] succeeded!\n"
  I1130 12:49:05.848101 19 builder.go:147] stdout: "nodeport-test-qgmlp"
  I1130 12:49:05.848183 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3050 exec execpodxftjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.94.166 30886'
  I1130 12:49:05.936440 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.94.166 30886\nConnection to 172.31.94.166 30886 port [tcp/*] succeeded!\n"
  I1130 12:49:05.936492 19 builder.go:147] stdout: "nodeport-test-k79tc"
  I1130 12:49:05.936567 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3050 exec execpodxftjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.64.147 30886'
  I1130 12:49:06.016770 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.64.147 30886\nConnection to 172.31.64.147 30886 port [tcp/*] succeeded!\n"
  I1130 12:49:06.016814 19 builder.go:147] stdout: ""
  E1130 12:49:06.543581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:06.937211 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-3050 exec execpodxftjn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.64.147 30886'
  I1130 12:49:07.019544 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.64.147 30886\nConnection to 172.31.64.147 30886 port [tcp/*] succeeded!\n"
  I1130 12:49:07.019588 19 builder.go:147] stdout: "nodeport-test-k79tc"
  I1130 12:49:07.019744 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3050" for this suite. @ 11/30/24 12:49:07.025
• [9.497 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 11/30/24 12:49:07.033
  I1130 12:49:07.033044 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:49:07.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:07.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:07.06
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:49:07.064
  E1130 12:49:07.543704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:08.544752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:49:09.082
  I1130 12:49:09.086898 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod downwardapi-volume-63c670ff-2345-4e7d-aa16-841a86cc2378 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:49:09.104
  I1130 12:49:09.126774 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2747" for this suite. @ 11/30/24 12:49:09.13
• [2.105 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 11/30/24 12:49:09.137
  I1130 12:49:09.137809 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replicaset @ 11/30/24 12:49:09.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:09.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:09.164
  I1130 12:49:09.167411 19 replica_set.go:191] Creating ReplicaSet my-hostname-basic-b93e71be-0f5c-4213-9c47-06c6999ed7f8
  I1130 12:49:09.176126 19 resource.go:87] Pod name my-hostname-basic-b93e71be-0f5c-4213-9c47-06c6999ed7f8: Found 0 pods out of 1
  E1130 12:49:09.545696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:10.545811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:11.546152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:12.546533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:13.546693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:14.180919 19 resource.go:87] Pod name my-hostname-basic-b93e71be-0f5c-4213-9c47-06c6999ed7f8: Found 1 pods out of 1
  I1130 12:49:14.180961 19 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-b93e71be-0f5c-4213-9c47-06c6999ed7f8" is running
  I1130 12:49:14.184646 19 replica_set.go:220] Pod "my-hostname-basic-b93e71be-0f5c-4213-9c47-06c6999ed7f8-qjlvb" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:49:09 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:49:09 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:49:09 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:49:09 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:49:09 +0000 UTC Reason: Message:}])
  I1130 12:49:14.184740 19 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 11/30/24 12:49:14.184
  I1130 12:49:14.199137 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8717" for this suite. @ 11/30/24 12:49:14.205
• [5.076 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 11/30/24 12:49:14.213
  I1130 12:49:14.213916 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename containers @ 11/30/24 12:49:14.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:14.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:14.248
  E1130 12:49:14.547229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:15.547389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:16.278391 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4458" for this suite. @ 11/30/24 12:49:16.282
• [2.076 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 11/30/24 12:49:16.29
  I1130 12:49:16.290498 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename gc @ 11/30/24 12:49:16.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:16.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:16.313
  STEP: create the deployment @ 11/30/24 12:49:16.316
  W1130 12:49:16.324679      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 11/30/24 12:49:16.324
  E1130 12:49:16.548195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 11/30/24 12:49:16.834
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 11/30/24 12:49:16.845
  STEP: Gathering metrics @ 11/30/24 12:49:17.367
  W1130 12:49:17.373732      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1130 12:49:17.373763 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1130 12:49:17.373923 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8583" for this suite. @ 11/30/24 12:49:17.378
• [1.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:139
  STEP: Creating a kubernetes client @ 11/30/24 12:49:17.386
  I1130 12:49:17.386024 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename dns @ 11/30/24 12:49:17.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:17.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:17.415
  STEP: Creating a test headless service @ 11/30/24 12:49:17.418
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2634.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2634.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2634.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2634.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2634.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2634.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2634.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2634.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2634.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2634.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 104.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.104_udp@PTR;check="$$(dig +tcp +noall +answer +search 104.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.104_tcp@PTR;sleep 1; done
   @ 11/30/24 12:49:17.435
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2634.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2634.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2634.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2634.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2634.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2634.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2634.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2634.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2634.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2634.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 104.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.104_udp@PTR;check="$$(dig +tcp +noall +answer +search 104.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.104_tcp@PTR;sleep 1; done
   @ 11/30/24 12:49:17.435
  STEP: creating a pod to probe DNS @ 11/30/24 12:49:17.435
  STEP: submitting the pod to kubernetes @ 11/30/24 12:49:17.435
  E1130 12:49:17.548689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:18.548834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 11/30/24 12:49:19.456
  STEP: looking for the results for each expected name from probers @ 11/30/24 12:49:19.46
  I1130 12:49:19.466783 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-2634.svc.cluster.local from pod dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9: the server could not find the requested resource (get pods dns-test-de9819e6-6941-420d-993d-a40fc93bcde9)
  I1130 12:49:19.471570 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-2634.svc.cluster.local from pod dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9: the server could not find the requested resource (get pods dns-test-de9819e6-6941-420d-993d-a40fc93bcde9)
  I1130 12:49:19.475517 19 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local from pod dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9: the server could not find the requested resource (get pods dns-test-de9819e6-6941-420d-993d-a40fc93bcde9)
  I1130 12:49:19.480424 19 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local from pod dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9: the server could not find the requested resource (get pods dns-test-de9819e6-6941-420d-993d-a40fc93bcde9)
  I1130 12:49:19.502344 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-2634.svc.cluster.local from pod dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9: the server could not find the requested resource (get pods dns-test-de9819e6-6941-420d-993d-a40fc93bcde9)
  I1130 12:49:19.507727 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-2634.svc.cluster.local from pod dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9: the server could not find the requested resource (get pods dns-test-de9819e6-6941-420d-993d-a40fc93bcde9)
  I1130 12:49:19.512819 19 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local from pod dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9: the server could not find the requested resource (get pods dns-test-de9819e6-6941-420d-993d-a40fc93bcde9)
  I1130 12:49:19.517009 19 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local from pod dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9: the server could not find the requested resource (get pods dns-test-de9819e6-6941-420d-993d-a40fc93bcde9)
  I1130 12:49:19.536071 19 dns_common.go:489] Lookups using dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9 failed for: [wheezy_udp@dns-test-service.dns-2634.svc.cluster.local wheezy_tcp@dns-test-service.dns-2634.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local jessie_udp@dns-test-service.dns-2634.svc.cluster.local jessie_tcp@dns-test-service.dns-2634.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2634.svc.cluster.local]

  I1130 12:49:19.543426 19 dns_common.go:495] Pod client logs for webserver: 
  E1130 12:49:19.548840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:19.549362 19 dns_common.go:495] Pod client logs for querier: 
  I1130 12:49:19.556716 19 dns_common.go:495] Pod client logs for jessie-querier: 
  E1130 12:49:20.549504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:21.549633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:22.549758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:23.549846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:24.539693 19 dns_common.go:527] DNS probes using dns-2634/dns-test-de9819e6-6941-420d-993d-a40fc93bcde9 succeeded

  STEP: deleting the pod @ 11/30/24 12:49:24.539
  E1130 12:49:24.550903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the test service @ 11/30/24 12:49:24.553
  STEP: deleting the test headless service @ 11/30/24 12:49:24.575
  I1130 12:49:24.590486 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2634" for this suite. @ 11/30/24 12:49:24.595
• [7.216 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 11/30/24 12:49:24.602
  I1130 12:49:24.602611 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:49:24.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:24.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:24.624
  STEP: Creating projection with secret that has name projected-secret-test-fca8821d-ca0d-4571-a6a3-808af27152ce @ 11/30/24 12:49:24.627
  STEP: Creating a pod to test consume secrets @ 11/30/24 12:49:24.633
  E1130 12:49:25.551013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:26.551182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:27.551856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:28.552022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:49:28.655
  I1130 12:49:28.659897 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-secrets-a18b8fa3-dcad-4457-ab94-d270dc17931a container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:49:28.667
  I1130 12:49:28.689133 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4404" for this suite. @ 11/30/24 12:49:28.693
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 11/30/24 12:49:28.7
  I1130 12:49:28.701007 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename events @ 11/30/24 12:49:28.701
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:28.721
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:28.728
  STEP: creating a test event @ 11/30/24 12:49:28.736
  STEP: listing events in all namespaces @ 11/30/24 12:49:28.747
  STEP: listing events in test namespace @ 11/30/24 12:49:28.762
  STEP: listing events with field selection filtering on source @ 11/30/24 12:49:28.767
  STEP: listing events with field selection filtering on reportingController @ 11/30/24 12:49:28.771
  STEP: getting the test event @ 11/30/24 12:49:28.774
  STEP: patching the test event @ 11/30/24 12:49:28.778
  STEP: getting the test event @ 11/30/24 12:49:28.788
  STEP: updating the test event @ 11/30/24 12:49:28.791
  STEP: getting the test event @ 11/30/24 12:49:28.798
  STEP: deleting the test event @ 11/30/24 12:49:28.801
  STEP: listing events in all namespaces @ 11/30/24 12:49:28.811
  STEP: listing events in test namespace @ 11/30/24 12:49:28.825
  I1130 12:49:28.828939 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2630" for this suite. @ 11/30/24 12:49:28.834
• [0.141 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:302
  STEP: Creating a kubernetes client @ 11/30/24 12:49:28.842
  I1130 12:49:28.842587 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename security-context @ 11/30/24 12:49:28.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:28.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:28.865
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 11/30/24 12:49:28.868
  E1130 12:49:29.552269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:30.552351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:31.553210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:32.553483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:49:32.895
  I1130 12:49:32.899307 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod security-context-d32817a5-c7e5-4172-8b48-ee57492dd020 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:49:32.907
  I1130 12:49:32.926522 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-1921" for this suite. @ 11/30/24 12:49:32.93
• [4.094 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:298
  STEP: Creating a kubernetes client @ 11/30/24 12:49:32.937
  I1130 12:49:32.937327 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:49:32.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:32.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:32.962
  STEP: Setting up server cert @ 11/30/24 12:49:32.992
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:49:33.404
  STEP: Deploying the webhook pod @ 11/30/24 12:49:33.416
  STEP: Wait for the deployment to be ready @ 11/30/24 12:49:33.428
  I1130 12:49:33.437810 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 12:49:33.554362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:34.554643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 12:49:35.452
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:49:35.465
  E1130 12:49:35.555038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:36.466034 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 11/30/24 12:49:36.476
  STEP: Creating a custom resource definition that should be denied by the webhook @ 11/30/24 12:49:36.492
  I1130 12:49:36.492603 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 12:49:36.547666 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2144" for this suite. @ 11/30/24 12:49:36.552
  E1130 12:49:36.555920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-markers-9498" for this suite. @ 11/30/24 12:49:36.56
• [3.634 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 11/30/24 12:49:36.571
  I1130 12:49:36.571536 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 12:49:36.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:36.59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:36.593
  I1130 12:49:36.640931 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7843" for this suite. @ 11/30/24 12:49:36.644
• [0.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 11/30/24 12:49:36.652
  I1130 12:49:36.652816 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename deployment @ 11/30/24 12:49:36.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:36.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:36.673
  I1130 12:49:36.677055 19 deployment.go:1196] Creating deployment "webserver-deployment"
  I1130 12:49:36.682100 19 deployment.go:1200] Waiting for observed generation 1
  E1130 12:49:37.556612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:38.556821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:38.689850 19 deployment.go:1205] Waiting for all required pods to come up
  I1130 12:49:38.695047 19 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 11/30/24 12:49:38.695
  I1130 12:49:38.699631 19 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I1130 12:49:38.704591 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:10, UpdatedReplicas:10, ReadyReplicas:9, AvailableReplicas:9, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 49, 38, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 49, 38, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 49, 38, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 49, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"webserver-deployment-64bcfc6446\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1130 12:49:39.557505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:40.557679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:40.715211 19 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I1130 12:49:40.725523 19 deployment.go:313] Updating deployment webserver-deployment
  I1130 12:49:40.725557 19 deployment.go:1224] Waiting for observed generation 2
  E1130 12:49:41.558222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:42.558455      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:42.734265 19 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I1130 12:49:42.737634 19 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I1130 12:49:42.741245 19 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I1130 12:49:42.751784 19 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I1130 12:49:42.751811 19 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I1130 12:49:42.755428 19 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I1130 12:49:42.761560 19 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I1130 12:49:42.761584 19 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I1130 12:49:42.770872 19 deployment.go:313] Updating deployment webserver-deployment
  I1130 12:49:42.770898 19 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I1130 12:49:42.777744 19 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I1130 12:49:42.781089 19 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  I1130 12:49:42.790173 19 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3a037758-adec-4834-baa6-feae2d949254",
      ResourceVersion: (string) (len=5) "21839",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-786f49d774\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1130 12:49:42.798553 19 deployment.go:39] New ReplicaSet "webserver-deployment-786f49d774" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-786f49d774",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a8fc4546-ad32-407a-bb15-8fb5696d2bc6",
      ResourceVersion: (string) (len=5) "21842",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "3a037758-adec-4834-baa6-feae2d949254",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 61 30 33 37 37  35 38 2d 61 64 65 63 2d  |\"3a037758-adec-|
              00000120  34 38 33 34 2d 62 61 61  36 2d 66 65 61 65 32 64  |4834-baa6-feae2d|
              00000130  39 34 39 32 35 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |949254\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:49:42.799106 19 deployment.go:44] All old ReplicaSets of Deployment "webserver-deployment":
  I1130 12:49:42.799342 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-64bcfc6446",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
      ResourceVersion: (string) (len=5) "21840",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "3a037758-adec-4834-baa6-feae2d949254",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 61 30 33 37 37  35 38 2d 61 64 65 63 2d  |\"3a037758-adec-|
              00000120  34 38 33 34 2d 62 61 61  36 2d 66 65 61 65 32 64  |4834-baa6-feae2d|
              00000130  39 34 39 32 35 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |949254\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:49:42.811262 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-4s5n7" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-4s5n7",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ad21da89-c7a6-4f41-8491-d38e426f9af1",
      ResourceVersion: (string) (len=5) "21846",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567782,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lgx9b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lgx9b",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-4-119",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.812109 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-87nt4" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-87nt4",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "94c02fc0-d7f6-4c1a-9c1f-cd7fc9eafb49",
      ResourceVersion: (string) (len=5) "21697",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 38 31  2e 31 38 38 5c 22 7d 22  |2.168.81.188\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jcdk6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jcdk6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-94-166",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.94.166",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.94.166"
        }
      },
      PodIP: (string) (len=14) "192.168.81.188",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.81.188"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567778,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b6cddb1db81d25ab1f0d0f526e61db7e5907220a6e7f77a0ce4149e19e91c257",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jcdk6",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.814661 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-f9q7x" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-f9q7x",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "765d57fb-41e3-476a-9d7c-97305cd497e3",
      ResourceVersion: (string) (len=5) "21851",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567782,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-d59f2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-d59f2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.815664 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-gtdjr" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-gtdjr",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2d65f9b1-8256-4143-80e0-f55cd1d5975b",
      ResourceVersion: (string) (len=5) "21660",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 32 33 30 5c 22 7d  |2.168.244.230\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t2n2g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t2n2g",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.230",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.230"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567777,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://5abbebbc9a7ad150578eaa8456d2a482b4f5af1e5a11804ba97bc6e0106b066f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-t2n2g",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.818016 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-j7z4p" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-j7z4p",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0013aa51-5f2b-495a-bdc2-7d7f543a6ef6",
      ResourceVersion: (string) (len=5) "21700",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 38 31  2e 31 39 30 5c 22 7d 22  |2.168.81.190\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dhlp9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dhlp9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-94-166",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.94.166",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.94.166"
        }
      },
      PodIP: (string) (len=14) "192.168.81.190",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.81.190"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567778,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://abeb2f82e43bfde14cdbff51f29f29c8b8f13113c4a7bd7d1ce3075227dad455",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-dhlp9",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.820254 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-jshs8" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-jshs8",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e816a083-5913-4b95-8f10-9c80bccbc404",
      ResourceVersion: (string) (len=5) "21703",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 38 31  2e 31 38 39 5c 22 7d 22  |2.168.81.189\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-v864g",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-v864g",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-94-166",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.94.166",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.94.166"
        }
      },
      PodIP: (string) (len=14) "192.168.81.189",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.81.189"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567778,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0fdb656a3b05f988aca715c9b2eaebda304037d9199e294b7e215e6d4937e0db",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-v864g",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.821649 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-lbtkg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-lbtkg",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e2130274-752c-44b5-9209-1909a186cad5",
      ResourceVersion: (string) (len=5) "21656",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 32 32 39 5c 22 7d  |2.168.244.229\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9khwv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9khwv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.229",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.229"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567777,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://e165b14b420914b5a0aa6cfb99b38bf842e5f5a4ab47844219e94da30a8003d3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-9khwv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.822907 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-lnl5l" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-lnl5l",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3b73779e-66e7-41f1-84f2-5c53843487dd",
      ResourceVersion: (string) (len=5) "21650",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 36 32  2e 33 33 5c 22 7d 22 3a  |2.168.62.33\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xswww",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xswww",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-4-119",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.4.119",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.4.119"
        }
      },
      PodIP: (string) (len=13) "192.168.62.33",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.62.33"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567777,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://bc78348908b6eb41b0ae805994842be75f04f10e9c71d841d18991ecbebe74a6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-xswww",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.824561 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-mvd2b" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-mvd2b",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "671e0228-b74b-4dc0-a1f8-e6cd3e94ea23",
      ResourceVersion: (string) (len=5) "21665",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567778,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 32 33 33 5c 22 7d  |2.168.244.233\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-khxlk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-khxlk",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.233",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.233"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567777,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://af2b63b70145349923ab0cb0df2168a23fffe812b88e89d107df22bafa5be6ac",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-khxlk",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.825824 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-n85xl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-n85xl",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9e039fe3-f24a-42fa-a2a2-2a2ffa9c7bb8",
      ResourceVersion: (string) (len=5) "21647",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 36 32  2e 34 36 5c 22 7d 22 3a  |2.168.62.46\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-52gzj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-52gzj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-4-119",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567777,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567776,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.4.119",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.4.119"
        }
      },
      PodIP: (string) (len=13) "192.168.62.46",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.62.46"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567776,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868567777,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://30b4efdf32831f8a39ebc67391c6199098cc2c26a4e97a08319501a4a97f680b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-52gzj",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.826947 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-rg22p" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-rg22p",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "34ad7e8d-8388-41cc-af94-aaa6f8419c78",
      ResourceVersion: (string) (len=5) "21853",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567782,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vjmvz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vjmvz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.827711 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-rkwgv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-rkwgv",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "04b48a1b-d62b-48a6-a8a1-efeca72f5af4",
      ResourceVersion: (string) (len=5) "21852",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567782,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "e6140b70-783c-45db-b93c-98187416a237",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 36  31 34 30 62 37 30 2d 37  |d\":\"e6140b70-7|
              00000090  38 33 63 2d 34 35 64 62  2d 62 39 33 63 2d 39 38  |83c-45db-b93c-98|
              000000a0  31 38 37 34 31 36 61 32  33 37 5c 22 7d 22 3a 7b  |187416a237\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lfnxj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lfnxj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-4-119",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.829177 19 deployment.go:67] Pod "webserver-deployment-786f49d774-2zjrs" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-2zjrs",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c764b2ba-e2fc-40f6-9d0e-870ef0916c7a",
      ResourceVersion: (string) (len=5) "21835",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "a8fc4546-ad32-407a-bb15-8fb5696d2bc6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 38  66 63 34 35 34 36 2d 61  |d\":\"a8fc4546-a|
              00000090  64 33 32 2d 34 30 37 61  2d 62 62 31 35 2d 38 66  |d32-407a-bb15-8f|
              000000a0  62 35 36 39 36 64 32 62  63 36 5c 22 7d 22 3a 7b  |b5696d2bc6\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 34 34 2e 32  33 34 5c 22 7d 22 3a 7b  |68.244.234\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mlcr2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mlcr2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567781,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.234",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.234"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-mlcr2",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.831452 19 deployment.go:67] Pod "webserver-deployment-786f49d774-6hr5b" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-6hr5b",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "becf55db-045b-462b-bd34-4f30bc8301a3",
      ResourceVersion: (string) (len=5) "21830",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "a8fc4546-ad32-407a-bb15-8fb5696d2bc6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 38  66 63 34 35 34 36 2d 61  |d\":\"a8fc4546-a|
              00000090  64 33 32 2d 34 30 37 61  2d 62 62 31 35 2d 38 66  |d32-407a-bb15-8f|
              000000a0  62 35 36 39 36 64 32 62  63 36 5c 22 7d 22 3a 7b  |b5696d2bc6\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567781,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=707) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 36 32 2e 33 34  5c 22 7d 22 3a 7b 22 2e  |68.62.34\"}":{".|
              000002a0  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              000002b0  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              000002c0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vg5vf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vg5vf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-4-119",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567781,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.4.119",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.4.119"
        }
      },
      PodIP: (string) (len=13) "192.168.62.34",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.62.34"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-vg5vf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.832715 19 deployment.go:67] Pod "webserver-deployment-786f49d774-fxb45" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-fxb45",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "98ce7766-ad9c-48c2-8fd9-a3a85c94ffc5",
      ResourceVersion: (string) (len=5) "21803",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "a8fc4546-ad32-407a-bb15-8fb5696d2bc6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 38  66 63 34 35 34 36 2d 61  |d\":\"a8fc4546-a|
              00000090  64 33 32 2d 34 30 37 61  2d 62 62 31 35 2d 38 66  |d32-407a-bb15-8f|
              000000a0  62 35 36 39 36 64 32 62  63 36 5c 22 7d 22 3a 7b  |b5696d2bc6\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567781,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 38 31 2e 31 39  31 5c 22 7d 22 3a 7b 22  |68.81.191\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8km8j",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8km8j",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-94-166",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567781,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.94.166",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.94.166"
        }
      },
      PodIP: (string) (len=14) "192.168.81.191",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.81.191"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-8km8j",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.835331 19 deployment.go:67] Pod "webserver-deployment-786f49d774-glm6q" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-glm6q",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6f83f33d-458c-44e2-9f2d-90aae7849a48",
      ResourceVersion: (string) (len=5) "21832",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "a8fc4546-ad32-407a-bb15-8fb5696d2bc6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 38  66 63 34 35 34 36 2d 61  |d\":\"a8fc4546-a|
              00000090  64 33 32 2d 34 30 37 61  2d 62 62 31 35 2d 38 66  |d32-407a-bb15-8f|
              000000a0  62 35 36 39 36 64 32 62  63 36 5c 22 7d 22 3a 7b  |b5696d2bc6\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 34 34 2e 32  33 32 5c 22 7d 22 3a 7b  |68.244.232\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jhhm9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jhhm9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567781,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.232",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.232"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jhhm9",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.836617 19 deployment.go:67] Pod "webserver-deployment-786f49d774-tlc47" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-tlc47",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a21eb8b2-8959-4575-ab2d-2ee0b08f2f5f",
      ResourceVersion: (string) (len=5) "21849",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567782,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "a8fc4546-ad32-407a-bb15-8fb5696d2bc6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567782,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 38  66 63 34 35 34 36 2d 61  |d\":\"a8fc4546-a|
              00000090  64 33 32 2d 34 30 37 61  2d 62 62 31 35 2d 38 66  |d32-407a-bb15-8f|
              000000a0  62 35 36 39 36 64 32 62  63 36 5c 22 7d 22 3a 7b  |b5696d2bc6\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xxpdm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xxpdm",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.837634 19 deployment.go:67] Pod "webserver-deployment-786f49d774-zb679" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-zb679",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-2183",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7c03a778-d45e-4398-a7fb-1705a0fce7fe",
      ResourceVersion: (string) (len=5) "21827",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "a8fc4546-ad32-407a-bb15-8fb5696d2bc6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 38  66 63 34 35 34 36 2d 61  |d\":\"a8fc4546-a|
              00000090  64 33 32 2d 34 30 37 61  2d 62 62 31 35 2d 38 66  |d32-407a-bb15-8f|
              000000a0  62 35 36 39 36 64 32 62  63 36 5c 22 7d 22 3a 7b  |b5696d2bc6\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567781,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=707) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 36 32 2e 35 38  5c 22 7d 22 3a 7b 22 2e  |68.62.58\"}":{".|
              000002a0  22 3a 7b 7d 2c 22 66 3a  69 70 22 3a 7b 7d 7d 7d  |":{},"f:ip":{}}}|
              000002b0  2c 22 66 3a 73 74 61 72  74 54 69 6d 65 22 3a 7b  |,"f:startTime":{|
              000002c0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dz7gd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dz7gd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-4-119",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567781,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868567780,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.4.119",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.4.119"
        }
      },
      PodIP: (string) (len=13) "192.168.62.58",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.62.58"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868567780,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-dz7gd",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:49:42.842128 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2183" for this suite. @ 11/30/24 12:49:42.85
• [6.218 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 11/30/24 12:49:42.871
  I1130 12:49:42.871031 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename init-container @ 11/30/24 12:49:42.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:42.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:42.928
  STEP: creating the pod @ 11/30/24 12:49:42.931
  I1130 12:49:42.931345 19 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E1130 12:49:43.558620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:44.558715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:45.559537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:46.016127 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5206" for this suite. @ 11/30/24 12:49:46.02
• [3.158 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1435
  STEP: Creating a kubernetes client @ 11/30/24 12:49:46.029
  I1130 12:49:46.029018 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:49:46.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:46.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:46.054
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-8566 @ 11/30/24 12:49:46.057
  STEP: changing the ExternalName service to type=NodePort @ 11/30/24 12:49:46.064
  STEP: creating replication controller externalname-service in namespace services-8566 @ 11/30/24 12:49:46.082
  I1130 12:49:46.090886      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8566, replica count: 2
  E1130 12:49:46.559839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:47.560606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:48.561105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:49.143919      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 12:49:49.144634 19 resource.go:361] Creating new exec pod
  E1130 12:49:49.561456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:50.561530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:51.561838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:49:52.173366 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8566 exec execpodp66l2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I1130 12:49:52.262032 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I1130 12:49:52.262081 19 builder.go:147] stdout: "externalname-service-wvzfs"
  I1130 12:49:52.262152 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8566 exec execpodp66l2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
  I1130 12:49:52.345326 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n"
  I1130 12:49:52.345390 19 builder.go:147] stdout: "externalname-service-wvzfs"
  I1130 12:49:52.345470 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8566 exec execpodp66l2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.64.147 30357'
  I1130 12:49:52.436739 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.64.147 30357\nConnection to 172.31.64.147 30357 port [tcp/*] succeeded!\n"
  I1130 12:49:52.436792 19 builder.go:147] stdout: "externalname-service-wvzfs"
  I1130 12:49:52.436864 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-8566 exec execpodp66l2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.94.166 30357'
  I1130 12:49:52.525209 19 builder.go:146] stderr: "+ + nc -v -t -w 2 172.31.94.166 30357\necho hostName\nConnection to 172.31.94.166 30357 port [tcp/*] succeeded!\n"
  I1130 12:49:52.525253 19 builder.go:147] stdout: "externalname-service-j2lmz"
  I1130 12:49:52.525331 19 service.go:1444] Cleaning up the ExternalName to NodePort test service
  I1130 12:49:52.549570 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8566" for this suite. @ 11/30/24 12:49:52.553
  E1130 12:49:52.562630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [6.534 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 11/30/24 12:49:52.563
  I1130 12:49:52.563086 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename var-expansion @ 11/30/24 12:49:52.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:52.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:52.585
  STEP: Creating a pod to test substitution in container's command @ 11/30/24 12:49:52.588
  E1130 12:49:53.562900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:54.563040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:55.564019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:56.564440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:49:56.612
  I1130 12:49:56.616909 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod var-expansion-a0d73bea-b948-4356-903d-85615485554b container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 12:49:56.625
  I1130 12:49:56.645451 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5767" for this suite. @ 11/30/24 12:49:56.65
• [4.094 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:878
  STEP: Creating a kubernetes client @ 11/30/24 12:49:56.657
  I1130 12:49:56.657319 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename job @ 11/30/24 12:49:56.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:49:56.676
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:49:56.678
  STEP: Creating a job @ 11/30/24 12:49:56.681
  STEP: Ensuring active pods == parallelism @ 11/30/24 12:49:56.688
  E1130 12:49:57.564706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:49:58.565580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete a job @ 11/30/24 12:49:58.693
  STEP: deleting Job.batch foo in namespace job-1434, will wait for the garbage collector to delete the pods @ 11/30/24 12:49:58.693
  I1130 12:49:58.756917 19 resources.go:139] Deleting Job.batch foo took: 8.213938ms
  I1130 12:49:58.857514 19 resources.go:163] Terminating Job.batch foo pods took: 100.585662ms
  E1130 12:49:59.566287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 11/30/24 12:50:00.257
  I1130 12:50:00.263064 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1434" for this suite. @ 11/30/24 12:50:00.267
• [3.617 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 11/30/24 12:50:00.274
  I1130 12:50:00.274796 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 12:50:00.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:50:00.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:50:00.297
  STEP: Creating the pod @ 11/30/24 12:50:00.3
  E1130 12:50:00.566579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:01.567128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:02.567907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:50:02.847698 19 pod_client.go:173] Successfully updated pod "annotationupdate985a5197-8137-4982-a247-5d469e0e2915"
  E1130 12:50:03.568323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:04.568557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:05.569303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:06.569603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:50:06.876857 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1847" for this suite. @ 11/30/24 12:50:06.881
• [6.616 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 11/30/24 12:50:06.891
  I1130 12:50:06.891212 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 12:50:06.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:50:06.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:50:06.914
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 11/30/24 12:50:06.919
  E1130 12:50:07.570465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:08.570653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:09.571714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:10.571820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:50:10.949
  I1130 12:50:10.954043 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-507488e5-d864-4b32-bacb-cdee4490f17a container test-container: <nil>
  STEP: delete the pod @ 11/30/24 12:50:10.962
  I1130 12:50:10.982791 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3123" for this suite. @ 11/30/24 12:50:10.987
• [4.104 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 11/30/24 12:50:10.995
  I1130 12:50:10.995325 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename subpath @ 11/30/24 12:50:10.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:50:11.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:50:11.016
  STEP: Setting up data @ 11/30/24 12:50:11.019
  STEP: Creating pod pod-subpath-test-configmap-r8cm @ 11/30/24 12:50:11.028
  STEP: Creating a pod to test atomic-volume-subpath @ 11/30/24 12:50:11.028
  E1130 12:50:11.572543      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:12.572649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:13.572763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:14.572942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:15.573604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:16.573878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:17.574093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:18.574308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:19.574540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:20.574776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:21.575846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:22.576185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:23.576314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:24.576547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:25.576688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:26.577186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:27.577773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:28.577972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:29.578936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:30.579024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:31.579116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:32.579230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:33.579303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:34.579423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:50:35.108
  I1130 12:50:35.113018 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-subpath-test-configmap-r8cm container test-container-subpath-configmap-r8cm: <nil>
  STEP: delete the pod @ 11/30/24 12:50:35.128
  STEP: Deleting pod pod-subpath-test-configmap-r8cm @ 11/30/24 12:50:35.15
  I1130 12:50:35.150834 19 delete.go:62] Deleting pod "pod-subpath-test-configmap-r8cm" in namespace "subpath-2885"
  I1130 12:50:35.155522 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2885" for this suite. @ 11/30/24 12:50:35.159
• [24.171 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1034
  STEP: Creating a kubernetes client @ 11/30/24 12:50:35.166
  I1130 12:50:35.166550 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename statefulset @ 11/30/24 12:50:35.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:50:35.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:50:35.188
  STEP: Creating service test in namespace statefulset-7506 @ 11/30/24 12:50:35.194
  STEP: Creating statefulset ss in namespace statefulset-7506 @ 11/30/24 12:50:35.207
  I1130 12:50:35.218570 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E1130 12:50:35.580123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:36.581052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:37.581151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:38.581294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:39.581569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:40.581683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:41.582144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:42.582431      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:43.582502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:44.583576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:50:45.220510 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 11/30/24 12:50:45.228
  STEP: Getting /status @ 11/30/24 12:50:45.235
  I1130 12:50:45.240204 19 statefulset.go:1070] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 11/30/24 12:50:45.24
  I1130 12:50:45.250348 19 statefulset.go:1090] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 11/30/24 12:50:45.25
  I1130 12:50:45.252052 19 statefulset.go:1118] Observed &StatefulSet event: ADDED
  I1130 12:50:45.252081 19 statefulset.go:1111] Found Statefulset ss in namespace statefulset-7506 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1130 12:50:45.252091 19 statefulset.go:1122] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 11/30/24 12:50:45.252
  I1130 12:50:45.252116 19 statefulset.go:1126] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I1130 12:50:45.260509 19 statefulset.go:1130] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 11/30/24 12:50:45.26
  I1130 12:50:45.262193 19 statefulset.go:1155] Observed &StatefulSet event: ADDED
  I1130 12:50:45.262246 19 statefulset.go:138] Deleting all statefulset in ns statefulset-7506
  I1130 12:50:45.265592 19 rest.go:150] Scaling statefulset ss to 0
  E1130 12:50:45.584335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:46.585196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:47.585442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:48.585659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:49.586598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:50.586709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:51.587527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:52.587646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:53.587852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:54.588789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:50:55.282876 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1130 12:50:55.286872 19 rest.go:88] Deleting statefulset ss
  I1130 12:50:55.302384 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7506" for this suite. @ 11/30/24 12:50:55.307
• [20.148 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 11/30/24 12:50:55.314
  I1130 12:50:55.314799 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename proxy @ 11/30/24 12:50:55.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:50:55.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:50:55.339
  I1130 12:50:55.342518 19 proxy.go:293] Creating pod...
  E1130 12:50:55.589593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:50:56.589874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:50:57.359969 19 proxy.go:317] Creating service...
  I1130 12:50:57.372230 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/pods/agnhost/proxy/some/path/with/DELETE
  I1130 12:50:57.378761 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I1130 12:50:57.378797 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/pods/agnhost/proxy/some/path/with/GET
  I1130 12:50:57.383415 19 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I1130 12:50:57.383448 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/pods/agnhost/proxy/some/path/with/HEAD
  I1130 12:50:57.387727 19 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I1130 12:50:57.387760 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/pods/agnhost/proxy/some/path/with/OPTIONS
  I1130 12:50:57.393165 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I1130 12:50:57.393192 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/pods/agnhost/proxy/some/path/with/PATCH
  I1130 12:50:57.398089 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I1130 12:50:57.398117 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/pods/agnhost/proxy/some/path/with/POST
  I1130 12:50:57.402404 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I1130 12:50:57.402425 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/pods/agnhost/proxy/some/path/with/PUT
  I1130 12:50:57.407261 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I1130 12:50:57.407287 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/services/test-service/proxy/some/path/with/DELETE
  I1130 12:50:57.413972 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I1130 12:50:57.413998 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/services/test-service/proxy/some/path/with/GET
  I1130 12:50:57.423138 19 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I1130 12:50:57.423169 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/services/test-service/proxy/some/path/with/HEAD
  I1130 12:50:57.430631 19 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I1130 12:50:57.430660 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/services/test-service/proxy/some/path/with/OPTIONS
  I1130 12:50:57.437959 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I1130 12:50:57.437986 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/services/test-service/proxy/some/path/with/PATCH
  I1130 12:50:57.444694 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I1130 12:50:57.444728 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/services/test-service/proxy/some/path/with/POST
  I1130 12:50:57.453133 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I1130 12:50:57.453170 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9917/services/test-service/proxy/some/path/with/PUT
  I1130 12:50:57.459828 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I1130 12:50:57.459955 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-9917" for this suite. @ 11/30/24 12:50:57.463
• [2.156 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1530
  STEP: Creating a kubernetes client @ 11/30/24 12:50:57.471
  I1130 12:50:57.471173 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 12:50:57.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:50:57.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:50:57.493
  STEP: creating Agnhost RC @ 11/30/24 12:50:57.496
  I1130 12:50:57.496582 19 kubectl.go:1537] namespace kubectl-9972
  I1130 12:50:57.496634 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-9972 create -f -'
  I1130 12:50:57.583862 19 builder.go:146] stderr: ""
  I1130 12:50:57.583902 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 11/30/24 12:50:57.583
  E1130 12:50:57.589973      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:50:58.589893 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1130 12:50:58.589928 19 framework.go:733] Found 1 / 1
  I1130 12:50:58.589946 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  E1130 12:50:58.590084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:50:58.594889 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1130 12:50:58.594916 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I1130 12:50:58.594925 19 kubectl.go:1544] wait on agnhost-primary startup in kubectl-9972 
  I1130 12:50:58.594974 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-9972 logs agnhost-primary-g7gdm agnhost-primary'
  I1130 12:50:58.655864 19 builder.go:146] stderr: ""
  I1130 12:50:58.655906 19 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 11/30/24 12:50:58.655
  I1130 12:50:58.655992 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-9972 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I1130 12:50:58.727535 19 builder.go:146] stderr: ""
  I1130 12:50:58.727607 19 builder.go:147] stdout: "service/rm2 exposed\n"
  I1130 12:50:58.737571 19 utils.go:1203] Service rm2 in namespace kubectl-9972 found.
  E1130 12:50:59.590308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:00.590378      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: exposing service @ 11/30/24 12:51:00.747
  I1130 12:51:00.747889 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-9972 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I1130 12:51:00.808379 19 builder.go:146] stderr: ""
  I1130 12:51:00.808441 19 builder.go:147] stdout: "service/rm3 exposed\n"
  I1130 12:51:00.813434 19 utils.go:1203] Service rm3 in namespace kubectl-9972 found.
  E1130 12:51:01.590521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:02.591611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:02.823408 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9972" for this suite. @ 11/30/24 12:51:02.827
• [5.365 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 11/30/24 12:51:02.836
  I1130 12:51:02.836307 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replication-controller @ 11/30/24 12:51:02.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:02.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:02.858
  STEP: Creating replication controller my-hostname-basic-8782c10b-3f85-4afd-9786-6fa34c397912 @ 11/30/24 12:51:02.861
  I1130 12:51:02.871668 19 resource.go:87] Pod name my-hostname-basic-8782c10b-3f85-4afd-9786-6fa34c397912: Found 0 pods out of 1
  E1130 12:51:03.591668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:04.591895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:05.592113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:06.592465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:07.592702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:07.878228 19 resource.go:87] Pod name my-hostname-basic-8782c10b-3f85-4afd-9786-6fa34c397912: Found 1 pods out of 1
  I1130 12:51:07.878264 19 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-8782c10b-3f85-4afd-9786-6fa34c397912" are running
  I1130 12:51:07.884937 19 rc.go:523] Pod "my-hostname-basic-8782c10b-3f85-4afd-9786-6fa34c397912-q89gx" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:51:04 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:51:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:51:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:51:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-11-30 12:51:02 +0000 UTC Reason: Message:}])
  I1130 12:51:07.884973 19 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 11/30/24 12:51:07.884
  I1130 12:51:07.900269 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7110" for this suite. @ 11/30/24 12:51:07.905
• [5.078 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 11/30/24 12:51:07.914
  I1130 12:51:07.914085 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename lease-test @ 11/30/24 12:51:07.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:07.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:07.944
  I1130 12:51:08.009632 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-3443" for this suite. @ 11/30/24 12:51:08.014
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 11/30/24 12:51:08.02
  I1130 12:51:08.020719 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename proxy @ 11/30/24 12:51:08.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:08.044
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:08.046
  I1130 12:51:08.049925 19 proxy.go:387] Creating pod...
  E1130 12:51:08.593648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:09.594062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:10.069803 19 proxy.go:411] Creating service...
  I1130 12:51:10.082470 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/pods/agnhost/proxy?method=DELETE
  I1130 12:51:10.092168 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I1130 12:51:10.092210 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/pods/agnhost/proxy?method=OPTIONS
  I1130 12:51:10.096484 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I1130 12:51:10.096520 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/pods/agnhost/proxy?method=PATCH
  I1130 12:51:10.101059 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I1130 12:51:10.101088 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/pods/agnhost/proxy?method=POST
  I1130 12:51:10.105611 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I1130 12:51:10.105636 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/pods/agnhost/proxy?method=PUT
  I1130 12:51:10.109877 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I1130 12:51:10.109914 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/services/e2e-proxy-test-service/proxy?method=DELETE
  I1130 12:51:10.116877 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I1130 12:51:10.116908 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I1130 12:51:10.124805 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I1130 12:51:10.124840 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/services/e2e-proxy-test-service/proxy?method=PATCH
  I1130 12:51:10.129882 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I1130 12:51:10.129915 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/services/e2e-proxy-test-service/proxy?method=POST
  I1130 12:51:10.136607 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I1130 12:51:10.136639 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/services/e2e-proxy-test-service/proxy?method=PUT
  I1130 12:51:10.143783 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I1130 12:51:10.143816 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/pods/agnhost/proxy?method=GET
  I1130 12:51:10.147657 19 proxy.go:487] http.Client request:GET StatusCode:301
  I1130 12:51:10.147700 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/services/e2e-proxy-test-service/proxy?method=GET
  I1130 12:51:10.153959 19 proxy.go:487] http.Client request:GET StatusCode:301
  I1130 12:51:10.153986 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/pods/agnhost/proxy?method=HEAD
  I1130 12:51:10.157820 19 proxy.go:487] http.Client request:HEAD StatusCode:301
  I1130 12:51:10.157858 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-2702/services/e2e-proxy-test-service/proxy?method=HEAD
  I1130 12:51:10.162944 19 proxy.go:487] http.Client request:HEAD StatusCode:301
  I1130 12:51:10.163086 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2702" for this suite. @ 11/30/24 12:51:10.167
• [2.157 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 11/30/24 12:51:10.177
  I1130 12:51:10.177583 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename subpath @ 11/30/24 12:51:10.178
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:10.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:10.2
  STEP: Setting up data @ 11/30/24 12:51:10.204
  STEP: Creating pod pod-subpath-test-secret-2pjv @ 11/30/24 12:51:10.214
  STEP: Creating a pod to test atomic-volume-subpath @ 11/30/24 12:51:10.214
  E1130 12:51:10.594164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:11.595006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:12.596024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:13.596596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:14.596723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:15.596939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:16.597212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:17.597294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:18.598395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:19.599092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:20.599175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:21.599597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:22.600499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:23.600554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:24.601410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:25.601525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:26.602362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:27.602591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:28.602801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:29.603021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:30.603711      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:31.604193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:32.604818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:33.605221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:51:34.293
  I1130 12:51:34.298202 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-subpath-test-secret-2pjv container test-container-subpath-secret-2pjv: <nil>
  STEP: delete the pod @ 11/30/24 12:51:34.305
  STEP: Deleting pod pod-subpath-test-secret-2pjv @ 11/30/24 12:51:34.324
  I1130 12:51:34.324732 19 delete.go:62] Deleting pod "pod-subpath-test-secret-2pjv" in namespace "subpath-8948"
  I1130 12:51:34.328576 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8948" for this suite. @ 11/30/24 12:51:34.332
• [24.163 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 11/30/24 12:51:34.34
  I1130 12:51:34.340629 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename proxy @ 11/30/24 12:51:34.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:34.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:34.365
  STEP: starting an echo server on multiple ports @ 11/30/24 12:51:34.38
  STEP: creating replication controller proxy-service-zjg5f in namespace proxy-624 @ 11/30/24 12:51:34.38
  I1130 12:51:34.389803      19 runners.go:193] Created replication controller with name: proxy-service-zjg5f, namespace: proxy-624, replica count: 1
  E1130 12:51:34.606113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:35.440968      19 runners.go:193] proxy-service-zjg5f Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 12:51:35.446870 19 proxy.go:230] setup took 1.078935742s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 11/30/24 12:51:35.446
  I1130 12:51:35.453883 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.639165ms)
  I1130 12:51:35.453883 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 6.904463ms)
  I1130 12:51:35.454080 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 6.638924ms)
  I1130 12:51:35.454103 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.927589ms)
  I1130 12:51:35.456382 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 9.027346ms)
  I1130 12:51:35.456403 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 8.981812ms)
  I1130 12:51:35.456544 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 9.052872ms)
  I1130 12:51:35.458459 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 11.000996ms)
  I1130 12:51:35.458532 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 11.25184ms)
  I1130 12:51:35.458981 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 11.853057ms)
  I1130 12:51:35.458997 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 11.78741ms)
  I1130 12:51:35.459413 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 12.149119ms)
  I1130 12:51:35.459768 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 12.367018ms)
  I1130 12:51:35.459777 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 12.409817ms)
  I1130 12:51:35.459792 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 12.711807ms)
  I1130 12:51:35.460051 19 proxy.go:558] (0) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 12.571674ms)
  I1130 12:51:35.464906 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 4.72175ms)
  I1130 12:51:35.465835 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.746019ms)
  I1130 12:51:35.466002 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 5.803534ms)
  I1130 12:51:35.466343 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 6.201401ms)
  I1130 12:51:35.466399 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 6.130113ms)
  I1130 12:51:35.466420 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 6.189645ms)
  I1130 12:51:35.466597 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 6.306182ms)
  I1130 12:51:35.466689 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.332413ms)
  I1130 12:51:35.466798 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.548803ms)
  I1130 12:51:35.466806 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 6.46812ms)
  I1130 12:51:35.466895 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.477744ms)
  I1130 12:51:35.467394 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 7.229648ms)
  I1130 12:51:35.467791 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 7.713611ms)
  I1130 12:51:35.468068 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.854266ms)
  I1130 12:51:35.468218 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 7.818963ms)
  I1130 12:51:35.468328 19 proxy.go:558] (1) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 8.020765ms)
  I1130 12:51:35.473787 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 5.421903ms)
  I1130 12:51:35.473804 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 5.119186ms)
  I1130 12:51:35.473784 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 5.42284ms)
  I1130 12:51:35.474411 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.874991ms)
  I1130 12:51:35.474927 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 6.413579ms)
  I1130 12:51:35.475123 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.530068ms)
  I1130 12:51:35.475335 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 6.778088ms)
  I1130 12:51:35.475444 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.712025ms)
  I1130 12:51:35.475598 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 7.138784ms)
  I1130 12:51:35.475675 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.957971ms)
  I1130 12:51:35.475967 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 7.316906ms)
  I1130 12:51:35.476502 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.801469ms)
  I1130 12:51:35.476503 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 7.83456ms)
  I1130 12:51:35.476625 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 7.992495ms)
  I1130 12:51:35.476743 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 8.166131ms)
  I1130 12:51:35.478020 19 proxy.go:558] (2) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 9.403212ms)
  I1130 12:51:35.482650 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 4.549326ms)
  I1130 12:51:35.482760 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.543194ms)
  I1130 12:51:35.482779 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 4.737403ms)
  I1130 12:51:35.483058 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 4.761581ms)
  I1130 12:51:35.483259 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.109056ms)
  I1130 12:51:35.483464 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 5.346698ms)
  I1130 12:51:35.483640 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.508273ms)
  I1130 12:51:35.483655 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 5.414235ms)
  I1130 12:51:35.484516 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 6.450651ms)
  I1130 12:51:35.484587 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.271704ms)
  I1130 12:51:35.484855 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 6.687285ms)
  I1130 12:51:35.485473 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 7.196408ms)
  I1130 12:51:35.485641 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.301432ms)
  I1130 12:51:35.485818 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 7.63438ms)
  I1130 12:51:35.485951 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.693545ms)
  I1130 12:51:35.486312 19 proxy.go:558] (3) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 8.113051ms)
  I1130 12:51:35.490119 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 3.707738ms)
  I1130 12:51:35.490934 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.457491ms)
  I1130 12:51:35.491033 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 4.60647ms)
  I1130 12:51:35.491794 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.198889ms)
  I1130 12:51:35.491869 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.321078ms)
  I1130 12:51:35.492109 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.545249ms)
  I1130 12:51:35.492185 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.694282ms)
  I1130 12:51:35.492266 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 5.918214ms)
  I1130 12:51:35.492433 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 5.853942ms)
  I1130 12:51:35.492759 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 6.244455ms)
  I1130 12:51:35.493318 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 6.857962ms)
  I1130 12:51:35.493413 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 6.96789ms)
  I1130 12:51:35.493545 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 6.904471ms)
  I1130 12:51:35.494276 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.744462ms)
  I1130 12:51:35.494490 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 7.832619ms)
  I1130 12:51:35.494680 19 proxy.go:558] (4) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 8.059565ms)
  I1130 12:51:35.499414 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.596738ms)
  I1130 12:51:35.499435 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.604202ms)
  I1130 12:51:35.500025 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.173662ms)
  I1130 12:51:35.500273 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 5.281919ms)
  I1130 12:51:35.500292 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 5.505204ms)
  I1130 12:51:35.500307 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 5.367115ms)
  I1130 12:51:35.501064 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 6.057228ms)
  I1130 12:51:35.501291 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 6.370033ms)
  I1130 12:51:35.501774 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 6.90772ms)
  I1130 12:51:35.502027 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.311535ms)
  I1130 12:51:35.502116 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 7.089011ms)
  I1130 12:51:35.502205 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 7.45808ms)
  I1130 12:51:35.502205 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 7.230718ms)
  I1130 12:51:35.502460 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.504483ms)
  I1130 12:51:35.503048 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 8.15042ms)
  I1130 12:51:35.503330 19 proxy.go:558] (5) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 8.448604ms)
  I1130 12:51:35.507674 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 4.260981ms)
  I1130 12:51:35.507962 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.581594ms)
  I1130 12:51:35.508612 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.094852ms)
  I1130 12:51:35.508661 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.212728ms)
  I1130 12:51:35.508942 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 5.510143ms)
  I1130 12:51:35.508965 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 5.433099ms)
  I1130 12:51:35.509620 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 6.153816ms)
  I1130 12:51:35.509842 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 6.217754ms)
  I1130 12:51:35.510492 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 7.126197ms)
  I1130 12:51:35.510620 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 6.9763ms)
  I1130 12:51:35.510948 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.345381ms)
  I1130 12:51:35.511444 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.896441ms)
  I1130 12:51:35.511456 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 7.955909ms)
  I1130 12:51:35.511586 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 8.10252ms)
  I1130 12:51:35.511882 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 8.316719ms)
  I1130 12:51:35.512126 19 proxy.go:558] (6) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 8.535547ms)
  I1130 12:51:35.516116 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 3.96045ms)
  I1130 12:51:35.516502 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 4.193964ms)
  I1130 12:51:35.516885 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 4.619235ms)
  I1130 12:51:35.516978 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 4.741921ms)
  I1130 12:51:35.517201 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.867139ms)
  I1130 12:51:35.517214 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 4.767479ms)
  I1130 12:51:35.517319 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 4.90944ms)
  I1130 12:51:35.517581 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.230524ms)
  I1130 12:51:35.517818 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 5.318013ms)
  I1130 12:51:35.517780 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 5.413364ms)
  I1130 12:51:35.519152 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 6.848179ms)
  I1130 12:51:35.519268 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 6.805124ms)
  I1130 12:51:35.519389 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 6.870759ms)
  I1130 12:51:35.519748 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 7.332227ms)
  I1130 12:51:35.519755 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 7.272143ms)
  I1130 12:51:35.520064 19 proxy.go:558] (7) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 7.633635ms)
  I1130 12:51:35.524956 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.674567ms)
  I1130 12:51:35.525254 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 5.164951ms)
  I1130 12:51:35.525731 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 5.571849ms)
  I1130 12:51:35.525799 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.394316ms)
  I1130 12:51:35.526362 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 6.138058ms)
  I1130 12:51:35.526576 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.185256ms)
  I1130 12:51:35.526701 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.403133ms)
  I1130 12:51:35.526856 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 6.545853ms)
  I1130 12:51:35.526930 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 6.508308ms)
  I1130 12:51:35.527082 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 6.842105ms)
  I1130 12:51:35.527154 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 6.749046ms)
  I1130 12:51:35.527723 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.395919ms)
  I1130 12:51:35.527785 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 7.44419ms)
  I1130 12:51:35.527863 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.688852ms)
  I1130 12:51:35.527956 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 7.841435ms)
  I1130 12:51:35.528982 19 proxy.go:558] (8) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 8.628072ms)
  I1130 12:51:35.533719 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 4.487283ms)
  I1130 12:51:35.533963 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.701009ms)
  I1130 12:51:35.534754 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 5.558359ms)
  I1130 12:51:35.535254 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 6.241729ms)
  I1130 12:51:35.535328 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 6.175397ms)
  I1130 12:51:35.535732 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 6.672886ms)
  I1130 12:51:35.535998 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.667186ms)
  I1130 12:51:35.536149 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 6.971078ms)
  I1130 12:51:35.536549 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 7.232473ms)
  I1130 12:51:35.536555 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 7.345471ms)
  I1130 12:51:35.536627 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 7.497548ms)
  I1130 12:51:35.537335 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 8.249528ms)
  I1130 12:51:35.537491 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 8.203642ms)
  I1130 12:51:35.537549 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 8.305442ms)
  I1130 12:51:35.537624 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 8.271107ms)
  I1130 12:51:35.538269 19 proxy.go:558] (9) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 8.968094ms)
  I1130 12:51:35.542985 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 4.678316ms)
  I1130 12:51:35.543150 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 4.659935ms)
  I1130 12:51:35.544074 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.51038ms)
  I1130 12:51:35.544108 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 5.528694ms)
  I1130 12:51:35.544178 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 5.738946ms)
  I1130 12:51:35.545101 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.474663ms)
  I1130 12:51:35.545144 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.616807ms)
  I1130 12:51:35.545296 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 6.883567ms)
  I1130 12:51:35.545722 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 7.330835ms)
  I1130 12:51:35.545734 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 7.432804ms)
  I1130 12:51:35.545779 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 7.275373ms)
  I1130 12:51:35.546092 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 7.547514ms)
  I1130 12:51:35.546192 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.72405ms)
  I1130 12:51:35.546426 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 8.071787ms)
  I1130 12:51:35.546662 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 8.004931ms)
  I1130 12:51:35.547996 19 proxy.go:558] (10) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 9.397769ms)
  I1130 12:51:35.552797 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 4.718104ms)
  I1130 12:51:35.552967 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 4.83171ms)
  I1130 12:51:35.553147 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 5.049782ms)
  I1130 12:51:35.553419 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.12391ms)
  I1130 12:51:35.553585 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 5.365551ms)
  I1130 12:51:35.554120 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.967915ms)
  I1130 12:51:35.554302 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.134528ms)
  I1130 12:51:35.554689 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 6.642403ms)
  I1130 12:51:35.554775 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.572681ms)
  I1130 12:51:35.555512 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 7.328684ms)
  I1130 12:51:35.555604 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.486438ms)
  I1130 12:51:35.555620 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 7.384822ms)
  I1130 12:51:35.557128 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 9.105505ms)
  I1130 12:51:35.557269 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 8.989176ms)
  I1130 12:51:35.557356 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 9.045101ms)
  I1130 12:51:35.557389 19 proxy.go:558] (11) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 9.131707ms)
  I1130 12:51:35.562235 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 4.825872ms)
  I1130 12:51:35.562233 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 4.800588ms)
  I1130 12:51:35.563127 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.475432ms)
  I1130 12:51:35.563193 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 5.616056ms)
  I1130 12:51:35.564026 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 6.394676ms)
  I1130 12:51:35.564540 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 7.003063ms)
  I1130 12:51:35.564794 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 7.285983ms)
  I1130 12:51:35.564931 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 7.324006ms)
  I1130 12:51:35.565015 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 7.324614ms)
  I1130 12:51:35.565038 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 7.43799ms)
  I1130 12:51:35.565528 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.854461ms)
  I1130 12:51:35.565713 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 8.209513ms)
  I1130 12:51:35.566056 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 8.583361ms)
  I1130 12:51:35.566056 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 8.500416ms)
  I1130 12:51:35.566866 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 9.140081ms)
  I1130 12:51:35.567002 19 proxy.go:558] (12) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 9.294458ms)
  I1130 12:51:35.571447 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.167183ms)
  I1130 12:51:35.572223 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 4.990485ms)
  I1130 12:51:35.572949 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.828859ms)
  I1130 12:51:35.573173 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.879172ms)
  I1130 12:51:35.573175 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.855603ms)
  I1130 12:51:35.573203 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 6.009515ms)
  I1130 12:51:35.573694 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 6.667742ms)
  I1130 12:51:35.573740 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.604668ms)
  I1130 12:51:35.574439 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 7.291351ms)
  I1130 12:51:35.574524 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 7.473463ms)
  I1130 12:51:35.574540 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 7.213665ms)
  I1130 12:51:35.574574 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 7.474226ms)
  I1130 12:51:35.574716 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.546098ms)
  I1130 12:51:35.574810 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.597335ms)
  I1130 12:51:35.574836 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 7.583415ms)
  I1130 12:51:35.575354 19 proxy.go:558] (13) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 7.997743ms)
  I1130 12:51:35.580997 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.521424ms)
  I1130 12:51:35.580997 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.502651ms)
  I1130 12:51:35.581017 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.426465ms)
  I1130 12:51:35.581249 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 5.700247ms)
  I1130 12:51:35.581255 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.637842ms)
  I1130 12:51:35.581567 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 6.049256ms)
  I1130 12:51:35.581602 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 5.9947ms)
  I1130 12:51:35.581626 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 6.000161ms)
  I1130 12:51:35.581811 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 6.178647ms)
  I1130 12:51:35.582643 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 7.247215ms)
  I1130 12:51:35.582944 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.538184ms)
  I1130 12:51:35.582944 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 7.492733ms)
  I1130 12:51:35.582984 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 7.409141ms)
  I1130 12:51:35.583147 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.619462ms)
  I1130 12:51:35.583926 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 8.275277ms)
  I1130 12:51:35.584038 19 proxy.go:558] (14) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 8.437351ms)
  I1130 12:51:35.590503 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.22818ms)
  I1130 12:51:35.590518 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.452815ms)
  I1130 12:51:35.591249 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 7.046756ms)
  I1130 12:51:35.591249 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.851918ms)
  I1130 12:51:35.592064 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 7.703572ms)
  I1130 12:51:35.592279 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 8.026ms)
  I1130 12:51:35.592296 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 8.056036ms)
  I1130 12:51:35.592362 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 7.946851ms)
  I1130 12:51:35.592979 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 8.672918ms)
  I1130 12:51:35.593088 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 8.765128ms)
  I1130 12:51:35.593142 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 9.053711ms)
  I1130 12:51:35.593276 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 8.987027ms)
  I1130 12:51:35.593505 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 9.359426ms)
  I1130 12:51:35.593838 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 9.664992ms)
  I1130 12:51:35.593938 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 9.700629ms)
  I1130 12:51:35.594441 19 proxy.go:558] (15) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 10.098291ms)
  I1130 12:51:35.598536 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 4.065395ms)
  I1130 12:51:35.599014 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 4.36805ms)
  I1130 12:51:35.599699 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.172941ms)
  I1130 12:51:35.599943 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 5.314292ms)
  I1130 12:51:35.600328 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.608878ms)
  I1130 12:51:35.600737 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 6.002295ms)
  I1130 12:51:35.600770 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 5.970079ms)
  I1130 12:51:35.601008 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 6.346124ms)
  I1130 12:51:35.601396 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 6.841583ms)
  I1130 12:51:35.601396 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 6.630554ms)
  I1130 12:51:35.601548 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 6.938798ms)
  I1130 12:51:35.601640 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 6.958196ms)
  I1130 12:51:35.602763 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 8.188428ms)
  I1130 12:51:35.602778 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.994715ms)
  I1130 12:51:35.603284 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 8.585663ms)
  I1130 12:51:35.603406 19 proxy.go:558] (16) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 8.656465ms)
  E1130 12:51:35.606586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:35.607629 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 4.197057ms)
  I1130 12:51:35.608347 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 4.592014ms)
  I1130 12:51:35.609135 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 5.525977ms)
  I1130 12:51:35.609172 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 5.666189ms)
  I1130 12:51:35.609297 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.659452ms)
  I1130 12:51:35.609769 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 5.962239ms)
  I1130 12:51:35.610968 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 7.349629ms)
  I1130 12:51:35.610985 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 7.307414ms)
  I1130 12:51:35.610971 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 7.391386ms)
  I1130 12:51:35.611199 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 7.375206ms)
  I1130 12:51:35.611199 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 7.428221ms)
  I1130 12:51:35.611219 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 7.484078ms)
  I1130 12:51:35.611411 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 7.690085ms)
  I1130 12:51:35.611698 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 7.998898ms)
  I1130 12:51:35.612517 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 8.973555ms)
  I1130 12:51:35.612636 19 proxy.go:558] (17) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 8.847107ms)
  I1130 12:51:35.617736 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.993406ms)
  I1130 12:51:35.617804 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.045853ms)
  I1130 12:51:35.618041 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 5.15452ms)
  I1130 12:51:35.618065 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.113748ms)
  I1130 12:51:35.618429 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 5.753991ms)
  I1130 12:51:35.618526 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 5.556146ms)
  I1130 12:51:35.618689 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 5.769645ms)
  I1130 12:51:35.618806 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 5.904209ms)
  I1130 12:51:35.619387 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 6.728783ms)
  I1130 12:51:35.620236 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 7.4013ms)
  I1130 12:51:35.620543 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 7.734479ms)
  I1130 12:51:35.620699 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 7.697315ms)
  I1130 12:51:35.620710 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 7.84351ms)
  I1130 12:51:35.620820 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 7.88478ms)
  I1130 12:51:35.621987 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 9.196004ms)
  I1130 12:51:35.622152 19 proxy.go:558] (18) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 9.167658ms)
  I1130 12:51:35.626861 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 4.542458ms)
  I1130 12:51:35.627091 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:443/proxy/tlsrewriteme... (200; 4.739243ms)
  I1130 12:51:35.627565 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">test</... (200; 5.130577ms)
  I1130 12:51:35.627569 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw/proxy/rewriteme">test</a> (200; 5.048411ms)
  I1130 12:51:35.627586 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.253794ms)
  I1130 12:51:35.628053 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:162/proxy/: bar (200; 5.567786ms)
  I1130 12:51:35.628801 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:460/proxy/: tls baz (200; 6.624793ms)
  I1130 12:51:35.629055 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/https:proxy-service-zjg5f-z7kmw:462/proxy/: tls qux (200; 6.607911ms)
  I1130 12:51:35.629055 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:160/proxy/: foo (200; 6.552733ms)
  I1130 12:51:35.629071 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-624/pods/http:proxy-service-zjg5f-z7kmw:1080/proxy/rewriteme">t... (200; 6.654972ms)
  I1130 12:51:35.629600 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname2/proxy/: bar (200; 7.234218ms)
  I1130 12:51:35.629836 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname2/proxy/: tls qux (200; 7.540326ms)
  I1130 12:51:35.629937 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/services/proxy-service-zjg5f:portname1/proxy/: foo (200; 7.664117ms)
  I1130 12:51:35.630326 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname1/proxy/: foo (200; 7.863773ms)
  I1130 12:51:35.630733 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/services/https:proxy-service-zjg5f:tlsportname1/proxy/: tls baz (200; 8.507617ms)
  I1130 12:51:35.633099 19 proxy.go:558] (19) /api/v1/namespaces/proxy-624/services/http:proxy-service-zjg5f:portname2/proxy/: bar (200; 10.697032ms)
  STEP: deleting ReplicationController proxy-service-zjg5f in namespace proxy-624, will wait for the garbage collector to delete the pods @ 11/30/24 12:51:35.633
  I1130 12:51:35.697187 19 resources.go:139] Deleting ReplicationController proxy-service-zjg5f took: 8.710736ms
  I1130 12:51:35.797403 19 resources.go:163] Terminating ReplicationController proxy-service-zjg5f pods took: 100.191131ms
  E1130 12:51:36.607003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:37.607187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:38.397992 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-624" for this suite. @ 11/30/24 12:51:38.403
• [4.072 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1391
  STEP: Creating a kubernetes client @ 11/30/24 12:51:38.412
  I1130 12:51:38.412758 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 12:51:38.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:38.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:38.436
  I1130 12:51:38.439821 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-719 create -f -'
  I1130 12:51:38.523001 19 builder.go:146] stderr: ""
  I1130 12:51:38.523039 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I1130 12:51:38.523085 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-719 create -f -'
  E1130 12:51:38.607527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:38.618823 19 builder.go:146] stderr: ""
  I1130 12:51:38.618863 19 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 11/30/24 12:51:38.618
  E1130 12:51:39.607926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:39.625074 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1130 12:51:39.625120 19 framework.go:733] Found 1 / 1
  I1130 12:51:39.625140 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I1130 12:51:39.629730 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1130 12:51:39.629756 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I1130 12:51:39.629809 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-719 describe pod agnhost-primary-sqjp5'
  I1130 12:51:39.689214 19 builder.go:146] stderr: ""
  I1130 12:51:39.689275 19 builder.go:147] stdout: "Name:             agnhost-primary-sqjp5\nNamespace:        kubectl-719\nPriority:         0\nService Account:  default\nNode:             ip-172-31-64-147/172.31.64.147\nStart Time:       Sat, 30 Nov 2024 12:51:38 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.244.249\nIPs:\n  IP:           192.168.244.249\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://1738ac5d46f0914e9976301208a2a6b1fae8d4d428ce989c18ec81efdba4dbe3\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.52\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 30 Nov 2024 12:51:39 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-cffhl (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-cffhl:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-719/agnhost-primary-sqjp5 to ip-172-31-64-147\n  Normal  Pulled     0s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.52\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
  I1130 12:51:39.689352 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-719 describe rc agnhost-primary'
  I1130 12:51:39.749967 19 builder.go:146] stderr: ""
  I1130 12:51:39.750015 19 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-719\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.52\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-sqjp5\n"
  I1130 12:51:39.750090 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-719 describe service agnhost-primary'
  I1130 12:51:39.805257 19 builder.go:146] stderr: ""
  I1130 12:51:39.805299 19 builder.go:147] stdout: "Name:                     agnhost-primary\nNamespace:                kubectl-719\nLabels:                   app=agnhost\n                          role=primary\nAnnotations:              <none>\nSelector:                 app=agnhost,role=primary\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.152.183.150\nIPs:                      10.152.183.150\nPort:                     <unset>  6379/TCP\nTargetPort:               agnhost-server/TCP\nEndpoints:                192.168.244.249:6379\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n"
  I1130 12:51:39.809825 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-719 describe node ip-172-31-37-252'
  I1130 12:51:39.913566 19 builder.go:146] stderr: ""
  I1130 12:51:39.913868 19 builder.go:147] stdout: "Name:               ip-172-31-37-252\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-control-plane\n                    juju-charm=kubernetes-control-plane\n                    juju.io/cloud=ec2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-37-252\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 30 Nov 2024 11:51:11 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-37-252\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 30 Nov 2024 12:51:37 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 30 Nov 2024 12:08:45 +0000   Sat, 30 Nov 2024 12:08:45 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 30 Nov 2024 12:49:42 +0000   Sat, 30 Nov 2024 11:51:11 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 30 Nov 2024 12:49:42 +0000   Sat, 30 Nov 2024 11:51:11 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 30 Nov 2024 12:49:42 +0000   Sat, 30 Nov 2024 11:51:11 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 30 Nov 2024 12:49:42 +0000   Sat, 30 Nov 2024 11:52:10 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.31.37.252\n  Hostname:    ip-172-31-37-252\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7967648Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7865248Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2415ac89aba1286e998d577221446a\n  System UUID:                ec2415ac-89ab-a128-6e99-8d577221446a\n  Boot ID:                    617fdd44-e35c-41cd-ac25-ddbfde62d75e\n  Kernel Version:             6.8.0-1019-aws\n  OS Image:                   Ubuntu 22.04.5 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.31.3\n  Kube-Proxy Version:         v1.31.3\nNon-terminated Pods:          (2 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-4jq26                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         43m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-nh7wp    0 (0%)        0 (0%)      0 (0%)           0 (0%)         38m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age   From             Message\n  ----     ------                   ----  ----             -------\n  Normal   Starting                 49m   kube-proxy       \n  Normal   Starting                 58m   kube-proxy       \n  Normal   Starting                 55m   kube-proxy       \n  Normal   Starting                 47m   kube-proxy       \n  Normal   Starting                 46m   kube-proxy       \n  Normal   Starting                 57m   kube-proxy       \n  Normal   Starting                 45m   kube-proxy       \n  Normal   Starting                 47m   kube-proxy       \n  Normal   Starting                 44m   kube-proxy       \n  Normal   Starting                 59m   kube-proxy       \n  Normal   Starting                 48m   kube-proxy       \n  Normal   Starting                 52m   kube-proxy       \n  Normal   Starting                 51m   kube-proxy       \n  Normal   Starting                 50m   kube-proxy       \n  Normal   Starting                 53m   kube-proxy       \n  Normal   Starting                 39m   kube-proxy       \n  Normal   Starting                 52m   kube-proxy       \n  Normal   Starting                 56m   kube-proxy       \n  Normal   Starting                 38m   kube-proxy       \n  Normal   Starting                 40m   kube-proxy       \n  Normal   Starting                 41m   kube-proxy       \n  Normal   Starting                 42m   kube-proxy       \n  Normal   Starting                 42m   kube-proxy       \n  Normal   Starting                 54m   kube-proxy       \n  Normal   Starting                 57m   kube-proxy       \n  Normal   Starting                 43m   kube-proxy       \n  Normal   RegisteredNode           60m   node-controller  Node ip-172-31-37-252 event: Registered Node ip-172-31-37-252 in Controller\n  Normal   Starting                 59m   kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     59m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    59m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  59m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  59m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      59m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeReady                59m   kubelet          Node ip-172-31-37-252 status is now: NodeReady\n  Normal   RegisteredNode           59m   node-controller  Node ip-172-31-37-252 event: Registered Node ip-172-31-37-252 in Controller\n  Normal   NodeHasSufficientPID     58m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   Starting                 58m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      58m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  58m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  58m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    58m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     57m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   Starting                 57m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      57m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  57m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  57m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    57m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  57m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   Starting                 57m   kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    57m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     57m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  57m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      57m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  56m   kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 56m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      56m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasNoDiskPressure    56m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  56m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     56m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientPID     55m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    55m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  55m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  55m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      55m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 55m   kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    54m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 54m   kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     54m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  54m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  54m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      54m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  53m   kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 53m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      53m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasNoDiskPressure    53m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  53m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     53m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   Starting                 53m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      53m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  53m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  52m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     52m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    52m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 52m   kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     52m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      52m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  52m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  52m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    52m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   RegisteredNode           51m   node-controller  Node ip-172-31-37-252 event: Registered Node ip-172-31-37-252 in Controller\n  Warning  InvalidDiskCapacity      51m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientPID     51m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    51m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  51m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  51m   kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 51m   kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     50m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    50m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  50m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  50m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      50m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 50m   kubelet          Starting kubelet.\n  Normal   Starting                 49m   kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    49m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Warning  InvalidDiskCapacity      49m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  49m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  49m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     49m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   RegisteredNode           49m   node-controller  Node ip-172-31-37-252 event: Registered Node ip-172-31-37-252 in Controller\n  Normal   RegisteredNode           48m   node-controller  Node ip-172-31-37-252 event: Registered Node ip-172-31-37-252 in Controller\n  Normal   NodeHasNoDiskPressure    48m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Warning  InvalidDiskCapacity      48m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  48m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     48m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  48m   kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 48m   kubelet          Starting kubelet.\n  Normal   Starting                 47m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      47m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  47m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  47m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    47m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     47m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   RegisteredNode           47m   node-controller  Node ip-172-31-37-252 event: Registered Node ip-172-31-37-252 in Controller\n  Normal   NodeHasNoDiskPressure    47m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     47m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  47m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  47m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      47m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 47m   kubelet          Starting kubelet.\n  Normal   RegisteredNode           46m   node-controller  Node ip-172-31-37-252 event: Registered Node ip-172-31-37-252 in Controller\n  Normal   RegisteredNode           46m   node-controller  Node ip-172-31-37-252 event: Registered Node ip-172-31-37-252 in Controller\n  Normal   NodeAllocatableEnforced  46m   kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 46m   kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     46m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    46m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  46m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  45m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     45m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    45m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  45m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   Starting                 45m   kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    44m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     44m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   Starting                 44m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      44m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  44m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  44m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasNoDiskPressure    43m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Warning  InvalidDiskCapacity      43m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientPID     43m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   Starting                 43m   kubelet          Starting kubelet.\n  Normal   NodeHasSufficientMemory  43m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  43m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasNoDiskPressure    42m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 42m   kubelet          Starting kubelet.\n  Normal   NodeHasSufficientPID     42m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  42m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  42m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      42m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 42m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      42m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  42m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasNoDiskPressure    42m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     42m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  42m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  41m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  41m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    41m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     41m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      41m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 41m   kubelet          Starting kubelet.\n  Normal   Starting                 40m   kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    40m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     40m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  40m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Warning  InvalidDiskCapacity      40m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  40m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     39m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  39m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    39m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeAllocatableEnforced  39m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      39m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 39m   kubelet          Starting kubelet.\n  Normal   Starting                 38m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      38m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  38m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  38m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    38m   kubelet          Node ip-172-31-37-252 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     38m   kubelet          Node ip-172-31-37-252 status is now: NodeHasSufficientPID\n"
  I1130 12:51:39.913989 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-719 describe namespace kubectl-719'
  I1130 12:51:39.972001 19 builder.go:146] stderr: ""
  I1130 12:51:39.972044 19 builder.go:147] stdout: "Name:         kubectl-719\nLabels:       e2e-framework=kubectl\n              e2e-run=d87efc80-85e9-45de-a155-d58a801812e9\n              kubernetes.io/metadata.name=kubectl-719\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I1130 12:51:39.972156 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-719" for this suite. @ 11/30/24 12:51:39.976
• [1.574 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 11/30/24 12:51:39.987
  I1130 12:51:39.987193 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename ingressclass @ 11/30/24 12:51:39.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:40.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:40.011
  STEP: getting /apis @ 11/30/24 12:51:40.015
  STEP: getting /apis/networking.k8s.io @ 11/30/24 12:51:40.018
  STEP: getting /apis/networking.k8s.iov1 @ 11/30/24 12:51:40.019
  STEP: creating @ 11/30/24 12:51:40.02
  STEP: getting @ 11/30/24 12:51:40.038
  STEP: listing @ 11/30/24 12:51:40.042
  STEP: watching @ 11/30/24 12:51:40.046
  I1130 12:51:40.046570 19 ingressclass.go:348] starting watch
  STEP: patching @ 11/30/24 12:51:40.047
  STEP: updating @ 11/30/24 12:51:40.053
  I1130 12:51:40.061016 19 ingressclass.go:364] waiting for watch events with expected annotations
  I1130 12:51:40.061050 19 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 11/30/24 12:51:40.061
  STEP: deleting a collection @ 11/30/24 12:51:40.075
  I1130 12:51:40.094024 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-6161" for this suite. @ 11/30/24 12:51:40.098
• [0.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:139
  STEP: Creating a kubernetes client @ 11/30/24 12:51:40.108
  I1130 12:51:40.108214 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-webhook @ 11/30/24 12:51:40.108
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:40.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:40.13
  STEP: Setting up server cert @ 11/30/24 12:51:40.133
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 11/30/24 12:51:40.339
  STEP: Deploying the custom resource conversion webhook pod @ 11/30/24 12:51:40.348
  STEP: Wait for the deployment to be ready @ 11/30/24 12:51:40.363
  I1130 12:51:40.373309 19 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E1130 12:51:40.608870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:41.609162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 12:51:42.387
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:51:42.401
  E1130 12:51:42.609691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:43.401423 19 util.go:420] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I1130 12:51:43.411157 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 12:51:43.610283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:44.610443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:45.610777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 11/30/24 12:51:45.974
  STEP: v2 custom resource should be converted @ 11/30/24 12:51:45.979
  I1130 12:51:46.542101 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-592" for this suite. @ 11/30/24 12:51:46.546
• [6.446 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 11/30/24 12:51:46.554
  I1130 12:51:46.554514 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 12:51:46.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:51:46.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:51:46.577
  STEP: Creating pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205 @ 11/30/24 12:51:46.58
  E1130 12:51:46.610851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:47.610979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 11/30/24 12:51:48.597
  I1130 12:51:48.601841 19 container_probe.go:1749] Initial restart count of pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b is 0
  I1130 12:51:48.606504 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:51:48.611668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:49.612605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:50.612563 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:51:50.612688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:51.612813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:52.613008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:52.618118 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:51:53.614075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:54.614302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:54.623959 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:51:55.614437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:56.615486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:56.629583 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:51:57.615790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:51:58.615989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:51:58.635590 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:51:59.616128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:00.616864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:00.640978 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:01.617134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:02.617400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:02.646829 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:03.617525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:04.617539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:04.653337 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:05.617821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:06.618409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:06.659586 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:07.618556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:08.618657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:08.665673 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  I1130 12:52:08.665714 19 container_probe.go:1763] Restart count of pod container-probe-1205/liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b is now 1 (20.063847131s elapsed)
  E1130 12:52:09.619657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:10.620592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:10.672166 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:11.621459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:12.621541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:12.677456 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:13.621641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:14.621845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:14.683679 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:15.622118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:16.622467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:16.689839 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:17.622664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:18.622906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:18.696195 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:19.623131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:20.623426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:20.701469 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:21.623631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:22.623808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:22.707981 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:23.623938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:24.624150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:24.713857 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:25.624858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:26.625267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:26.719086 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:27.625417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:28.625580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:28.726612 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  I1130 12:52:28.727520 19 container_probe.go:1763] Restart count of pod container-probe-1205/liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b is now 2 (40.125651834s elapsed)
  E1130 12:52:29.625931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:30.626046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:30.732992 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:31.627133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:32.627392      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:32.739653 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:33.627809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:34.628132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:34.746209 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:35.628868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:36.628963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:36.752251 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:37.629076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:38.629704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:38.758950 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:39.629841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:40.629904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:40.763820 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:41.630757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:42.630869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:42.769707 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:43.631548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:44.632611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:44.775098 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:45.632915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:46.633008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:46.780094 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:47.633328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:48.633509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:48.786664 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  I1130 12:52:48.786703 19 container_probe.go:1763] Restart count of pod container-probe-1205/liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b is now 3 (1m0.184835368s elapsed)
  E1130 12:52:49.633672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:50.633829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:50.793051 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:51.634450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:52.634518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:52.798413 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:53.635265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:54.635349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:54.804281 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:55.635673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:56.636038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:56.808844 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:57.636538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:52:58.636781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:52:58.814450 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:52:59.636992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:00.637106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:00.820969 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:01.638039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:02.638925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:02.825970 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:03.639854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:04.640615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:04.832660 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:05.641591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:06.642028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:06.839131 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:07.643269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:08.643529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:08.843703 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  I1130 12:53:08.843741 19 container_probe.go:1763] Restart count of pod container-probe-1205/liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b is now 4 (1m20.241874286s elapsed)
  E1130 12:53:09.643642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:10.643962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:10.849595 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:11.645019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:12.645132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:12.855266 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:13.645279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:14.645503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:14.861662 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:15.645662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:16.645739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:16.867600 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:17.646481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:18.646717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:18.873279 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:19.646954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:20.647138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:20.878546 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:21.647657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:22.647817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:22.883827 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:23.648557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:24.648696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:24.888661 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:25.648834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:26.649164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:26.894778 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:27.649532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:28.650597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:28.899846 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:29.651607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:30.652592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:30.905595 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:31.653171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:32.653495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:32.911548 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:33.653748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:34.653951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:34.917251 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:35.653959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:36.654580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:36.923486 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:37.654829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:38.655056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:38.929025 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:39.656019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:40.656219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:40.935739 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:41.656892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:42.657007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:42.941870 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:43.657801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:44.658049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:44.947412 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:45.658167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:46.658523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:46.953855 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:47.659093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:48.659278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:48.959946 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:49.660080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:50.660574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:50.965482 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:51.661173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:52.661572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:52.970870 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:53.661701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:54.662570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:54.976910 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:55.662745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:56.663590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:56.981787 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:57.664646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:53:58.664885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:53:58.987816 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:53:59.665557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:00.665919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:00.993862 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:01.666958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:02.667061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:03.000244 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:03.668059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:04.668159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:05.005159 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:05.668263      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:06.668581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:07.011036 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:07.668684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:08.669078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:09.017272 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:09.669892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:10.669989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:11.022952 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:11.670881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:12.670985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:13.027798 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:13.671080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:14.671188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:15.033255 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:15.671561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:16.672025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:17.038440 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:17.672145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:18.672389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:19.044621 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  E1130 12:54:19.672462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:20.672657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:54:21.050600 19 container_probe.go:1759] Get pod liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b in namespace container-probe-1205
  I1130 12:54:21.050640 19 container_probe.go:1763] Restart count of pod container-probe-1205/liveness-cb9ec12a-4799-4de3-ae30-fd9ce9880c3b is now 5 (2m32.448772646s elapsed)
  STEP: deleting the pod @ 11/30/24 12:54:21.05
  I1130 12:54:21.064654 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1205" for this suite. @ 11/30/24 12:54:21.072
• [154.525 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 11/30/24 12:54:21.079
  I1130 12:54:21.079325 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename namespaces @ 11/30/24 12:54:21.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:54:21.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:54:21.101
  STEP: Read namespace status @ 11/30/24 12:54:21.105
  I1130 12:54:21.109074 19 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 11/30/24 12:54:21.109
  I1130 12:54:21.114727 19 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 11/30/24 12:54:21.114
  I1130 12:54:21.124803 19 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I1130 12:54:21.124893 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9185" for this suite. @ 11/30/24 12:54:21.128
• [0.057 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 11/30/24 12:54:21.135
  I1130 12:54:21.135985 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-watch @ 11/30/24 12:54:21.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:54:21.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:54:21.155
  I1130 12:54:21.158193 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 12:54:21.672657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:22.673121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:23.673353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 11/30/24 12:54:23.7
  I1130 12:54:23.708402 19 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-11-30T12:54:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-11-30T12:54:23Z]] name:name1 resourceVersion:23639 uid:22a891fb-151f-46a1-ac8f-2bed516b062b] num:map[num1:9223372036854775807 num2:1000000]]}
  E1130 12:54:24.673601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:25.673868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:26.674587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:27.674703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:28.674851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:29.675132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:30.675227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:31.675339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:32.676393      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:33.676734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 11/30/24 12:54:33.709
  I1130 12:54:33.716757 19 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-11-30T12:54:33Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-11-30T12:54:33Z]] name:name2 resourceVersion:23677 uid:4f7f9a59-8826-4c11-a357-21c5228eadb0] num:map[num1:9223372036854775807 num2:1000000]]}
  E1130 12:54:34.676846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:35.677107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:36.677580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:37.677842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:38.678109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:39.678219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:40.678281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:41.678397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:42.678540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:43.678639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 11/30/24 12:54:43.716
  I1130 12:54:43.723944 19 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-11-30T12:54:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-11-30T12:54:43Z]] name:name1 resourceVersion:23699 uid:22a891fb-151f-46a1-ac8f-2bed516b062b] num:map[num1:9223372036854775807 num2:1000000]]}
  E1130 12:54:44.678667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:45.678971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:46.679892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:47.680602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:48.681579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:49.682607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:50.682878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:51.683335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:52.683894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:53.684108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 11/30/24 12:54:53.724
  I1130 12:54:53.733037 19 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-11-30T12:54:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-11-30T12:54:53Z]] name:name2 resourceVersion:23721 uid:4f7f9a59-8826-4c11-a357-21c5228eadb0] num:map[num1:9223372036854775807 num2:1000000]]}
  E1130 12:54:54.684527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:55.684746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:56.685493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:57.685832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:58.686075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:54:59.686409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:00.687442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:01.688454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:02.688641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:03.688740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 11/30/24 12:55:03.734
  I1130 12:55:03.742848 19 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-11-30T12:54:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-11-30T12:54:43Z]] name:name1 resourceVersion:23743 uid:22a891fb-151f-46a1-ac8f-2bed516b062b] num:map[num1:9223372036854775807 num2:1000000]]}
  E1130 12:55:04.689174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:05.689242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:06.689911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:07.690598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:08.690733      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:09.690958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:10.691592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:11.692120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:12.692222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:13.692594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 11/30/24 12:55:13.743
  I1130 12:55:13.753914 19 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-11-30T12:54:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-11-30T12:54:53Z]] name:name2 resourceVersion:23763 uid:4f7f9a59-8826-4c11-a357-21c5228eadb0] num:map[num1:9223372036854775807 num2:1000000]]}
  E1130 12:55:14.692856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:15.693583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:16.694073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:17.694244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:18.694392      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:19.694525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:20.694769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:21.695497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:22.695816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:23.696021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:24.271201 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-1983" for this suite. @ 11/30/24 12:55:24.276
• [63.147 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:643
  STEP: Creating a kubernetes client @ 11/30/24 12:55:24.283
  I1130 12:55:24.283419 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 12:55:24.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:55:24.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:55:24.303
  STEP: Setting up server cert @ 11/30/24 12:55:24.329
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 12:55:24.443
  STEP: Deploying the webhook pod @ 11/30/24 12:55:24.454
  STEP: Wait for the deployment to be ready @ 11/30/24 12:55:24.467
  I1130 12:55:24.474169 19 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1130 12:55:24.696613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:25.696784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 12:55:26.489
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:55:26.5
  E1130 12:55:26.697206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:27.500814 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 11/30/24 12:55:27.577
  STEP: Creating a configMap that should be mutated @ 11/30/24 12:55:27.59
  STEP: Deleting the collection of validation webhooks @ 11/30/24 12:55:27.618
  STEP: Creating a configMap that should not be mutated @ 11/30/24 12:55:27.675
  E1130 12:55:27.698111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:27.731550 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6731" for this suite. @ 11/30/24 12:55:27.736
  STEP: Destroying namespace "webhook-markers-978" for this suite. @ 11/30/24 12:55:27.743
• [3.467 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1148
  STEP: Creating a kubernetes client @ 11/30/24 12:55:27.75
  I1130 12:55:27.750927 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename job @ 11/30/24 12:55:27.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:55:27.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:55:27.771
  STEP: Creating a suspended job @ 11/30/24 12:55:27.778
  STEP: Patching the Job @ 11/30/24 12:55:27.785
  STEP: Watching for Job to be patched @ 11/30/24 12:55:27.8
  I1130 12:55:27.802433 19 job.go:1330] Event ADDED observed for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g] and annotations: map[]
  I1130 12:55:27.802481 19 job.go:1330] Event MODIFIED observed for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g] and annotations: map[]
  I1130 12:55:27.802494 19 job.go:1333] Event MODIFIED found for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched] and annotations: map[]
  STEP: Updating the job @ 11/30/24 12:55:27.802
  STEP: Watching for Job to be updated @ 11/30/24 12:55:27.812
  I1130 12:55:27.814708 19 job.go:1333] Event MODIFIED found for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched] and annotations: map[updated:true]
  I1130 12:55:27.814752 19 job.go:1226] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 11/30/24 12:55:27.814
  I1130 12:55:27.818782 19 job.go:1233] Job: e2e-sws7g as labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched]
  STEP: Waiting for job to complete @ 11/30/24 12:55:27.818
  E1130 12:55:28.698534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:29.698664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:30.698861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:31.699236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:32.699540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:33.699841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:34.700590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:35.701572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:36.702016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:37.702248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 11/30/24 12:55:37.83
  STEP: Watching for Job to be deleted @ 11/30/24 12:55:37.841
  I1130 12:55:37.842898 19 job.go:1330] Event MODIFIED observed for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched] and annotations: map[updated:true]
  I1130 12:55:37.842980 19 job.go:1330] Event MODIFIED observed for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched] and annotations: map[updated:true]
  I1130 12:55:37.842996 19 job.go:1330] Event MODIFIED observed for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched] and annotations: map[updated:true]
  I1130 12:55:37.843009 19 job.go:1330] Event MODIFIED observed for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched] and annotations: map[updated:true]
  I1130 12:55:37.843127 19 job.go:1330] Event MODIFIED observed for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched] and annotations: map[updated:true]
  I1130 12:55:37.843142 19 job.go:1333] Event DELETED found for Job e2e-sws7g in namespace job-2498 with labels: map[e2e-job-label:e2e-sws7g e2e-sws7g:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 11/30/24 12:55:37.843
  I1130 12:55:37.846662 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2498" for this suite. @ 11/30/24 12:55:37.85
• [10.112 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:174
  STEP: Creating a kubernetes client @ 11/30/24 12:55:37.863
  I1130 12:55:37.863333 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-webhook @ 11/30/24 12:55:37.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:55:37.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:55:37.887
  STEP: Setting up server cert @ 11/30/24 12:55:37.89
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 11/30/24 12:55:38.135
  STEP: Deploying the custom resource conversion webhook pod @ 11/30/24 12:55:38.142
  STEP: Wait for the deployment to be ready @ 11/30/24 12:55:38.153
  I1130 12:55:38.164975 19 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E1130 12:55:38.702613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:39.702750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 12:55:40.178
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 12:55:40.19
  E1130 12:55:40.703600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:41.191308 19 util.go:420] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I1130 12:55:41.201281 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 12:55:41.704635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:42.704702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:43.705767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 11/30/24 12:55:43.759
  STEP: Create a v2 custom resource @ 11/30/24 12:55:43.778
  STEP: List CRs in v1 @ 11/30/24 12:55:43.805
  STEP: List CRs in v2 @ 11/30/24 12:55:43.81
  I1130 12:55:44.376577 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-1759" for this suite. @ 11/30/24 12:55:44.382
• [6.528 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 11/30/24 12:55:44.391
  I1130 12:55:44.391173 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename deployment @ 11/30/24 12:55:44.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:55:44.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:55:44.41
  I1130 12:55:44.423614 19 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E1130 12:55:44.706066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:45.706256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:46.706593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:47.706694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:48.707588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:49.427835 19 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 11/30/24 12:55:49.427
  I1130 12:55:49.427913 19 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E1130 12:55:49.708306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:50.708357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:51.433340 19 deployment.go:921] Creating deployment "test-rollover-deployment"
  I1130 12:55:51.445609 19 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E1130 12:55:51.708482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:52.708590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:53.456207 19 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I1130 12:55:53.464751 19 deployment.go:943] Ensure that both replica sets have 1 created replica
  I1130 12:55:53.473866 19 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I1130 12:55:53.485638 19 deployment.go:313] Updating deployment test-rollover-deployment
  I1130 12:55:53.485681 19 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E1130 12:55:53.709575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:54.709906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:55.497899 19 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I1130 12:55:55.505701 19 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I1130 12:55:55.514021 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1130 12:55:55.514067 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1130 12:55:55.710223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:56.711148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:57.523681 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1130 12:55:57.523750 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1130 12:55:57.711220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:55:58.711311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:55:59.523394 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1130 12:55:59.523443 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1130 12:55:59.711532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:00.711679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:56:01.524928 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1130 12:56:01.524993 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1130 12:56:01.712150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:02.712354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:56:03.523899 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1130 12:56:03.523958 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.November, 30, 12, 55, 54, 0, time.Local), LastTransitionTime:time.Date(2024, time.November, 30, 12, 55, 51, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1130 12:56:03.712445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:04.712663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:56:05.523895 19 deployment.go:94] 
  I1130 12:56:05.523946 19 deployment.go:974] Ensure that both old replica sets have no replicas
  I1130 12:56:05.536445 19 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2781",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "be63d4a3-f214-450e-8dcb-f2300b79ec23",
      ResourceVersion: (string) (len=5) "24265",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868568151,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568151,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568151,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568151,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5f974d7468\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1130 12:56:05.541444 19 deployment.go:39] New ReplicaSet "test-rollover-deployment-5f974d7468" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5f974d7468",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2781",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "11ad9e16-a4f2-462a-95ff-590f41fe0dcd",
      ResourceVersion: (string) (len=5) "24255",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868568153,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "be63d4a3-f214-450e-8dcb-f2300b79ec23",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 65 36 33 64 34  61 33 2d 66 32 31 34 2d  |\"be63d4a3-f214-|
              00000120  34 35 30 65 2d 38 64 63  62 2d 66 32 33 30 30 62  |450e-8dcb-f2300b|
              00000130  37 39 65 63 32 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |79ec23\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:56:05.541947 19 deployment.go:44] All old ReplicaSets of Deployment "test-rollover-deployment":
  I1130 12:56:05.542149 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2781",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "88173929-be82-40ec-a715-160f14dd8235",
      ResourceVersion: (string) (len=5) "24264",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868568144,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "be63d4a3-f214-450e-8dcb-f2300b79ec23",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568144,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  62 65 36 33 64 34 61 33  2d 66 32 31 34 2d 34 35  |be63d4a3-f214-45|
              000000c0  30 65 2d 38 64 63 62 2d  66 32 33 30 30 62 37 39  |0e-8dcb-f2300b79|
              000000d0  65 63 32 33 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |ec23\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568164,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:56:05.542808 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-55f4dbffff",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2781",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f886b826-3bd4-4da0-9a9c-f625917a9ae5",
      ResourceVersion: (string) (len=5) "24220",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868568151,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff",
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "be63d4a3-f214-450e-8dcb-f2300b79ec23",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 62 65 36 33 64 34  61 33 2d 66 32 31 34 2d  |\"be63d4a3-f214-|
              00000120  34 35 30 65 2d 38 64 63  62 2d 66 32 33 30 30 62  |450e-8dcb-f2300b|
              00000130  37 39 65 63 32 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |79ec23\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 12:56:05.548567 19 deployment.go:67] Pod "test-rollover-deployment-5f974d7468-h85mq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5f974d7468-h85mq",
      GenerateName: (string) (len=36) "test-rollover-deployment-5f974d7468-",
      Namespace: (string) (len=15) "deployment-2781",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ff30adaa-bfbe-4539-a143-77a0173bb007",
      ResourceVersion: (string) (len=5) "24233",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868568153,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5f974d7468",
          UID: (types.UID) (len=36) "11ad9e16-a4f2-462a-95ff-590f41fe0dcd",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 31  61 64 39 65 31 36 2d 61  |d\":\"11ad9e16-a|
              00000090  34 66 32 2d 34 36 32 61  2d 39 35 66 66 2d 35 39  |4f2-462a-95ff-59|
              000000a0  30 66 34 31 66 65 30 64  63 64 5c 22 7d 22 3a 7b  |0f41fe0dcd\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568154,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 31 39 37 5c 22 7d  |2.168.244.197\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7xnjf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7xnjf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568154,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568154,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568154,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868568153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.197",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.197"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868568153,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868568154,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6",
          ContainerID: (string) (len=77) "containerd://1c969fe60b7e32e9b098fe09ae2fa14664a72ff3a511910997d4ff3726b79bdd",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-7xnjf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 12:56:05.549736 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2781" for this suite. @ 11/30/24 12:56:05.554
• [21.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 11/30/24 12:56:05.563
  I1130 12:56:05.563186 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:56:05.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:56:05.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:56:05.586
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 12:56:05.589
  E1130 12:56:05.712791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:06.713147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:07.713589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:08.714407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:56:09.611
  I1130 12:56:09.615033 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod downwardapi-volume-5fa718f5-8a35-4850-85b3-693c9aae4ed7 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 12:56:09.634
  I1130 12:56:09.654205 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2829" for this suite. @ 11/30/24 12:56:09.659
• [4.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:878
  STEP: Creating a kubernetes client @ 11/30/24 12:56:09.669
  I1130 12:56:09.669087 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 12:56:09.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:56:09.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:56:09.689
  STEP: validating api versions @ 11/30/24 12:56:09.692
  I1130 12:56:09.692437 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1247 api-versions'
  E1130 12:56:09.715310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:56:09.735633 19 builder.go:146] stderr: ""
  I1130 12:56:09.735673 19 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I1130 12:56:09.735801 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1247" for this suite. @ 11/30/24 12:56:09.74
• [0.080 seconds]
------------------------------
SS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 11/30/24 12:56:09.749
  I1130 12:56:09.749017 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename cronjob @ 11/30/24 12:56:09.749
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:56:09.767
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:56:09.77
  STEP: Creating a cronjob @ 11/30/24 12:56:09.773
  STEP: Ensuring more than one job is running at a time @ 11/30/24 12:56:09.778
  E1130 12:56:10.715614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:11.716229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:12.716508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:13.716706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:14.716825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:15.717037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:16.717209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:17.717421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:18.717959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:19.718322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:20.718437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:21.719262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:22.719530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:23.720575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:24.720697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:25.720792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:26.721039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:27.721135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:28.721557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:29.721661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:30.721874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:31.722389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:32.722603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:33.722775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:34.722902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:35.723048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:36.723982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:37.724196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:38.724561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:39.724853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:40.725021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:41.725305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:42.725560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:43.725688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:44.725877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:45.725959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:46.726485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:47.726702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:48.727613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:49.727956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:50.728062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:51.728245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:52.728349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:53.728516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:54.728548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:55.729600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:56.730297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:57.730417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:58.732557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:56:59.732672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:00.732886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:01.733450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:02.733722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:03.733871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:04.733969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:05.734089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:06.735176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:07.735392      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:08.737339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:09.737516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:10.737706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:11.738293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:12.738760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:13.738860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:14.738954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:15.739160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:16.739231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:17.739624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:18.739797      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:19.739907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:20.740540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:21.740923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:22.741020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:23.741117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:24.741822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:25.741967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:26.742202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:27.742498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:28.742540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:29.742763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:30.743040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:31.743299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:32.743521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:33.743959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:34.744773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:35.745024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:36.746022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:37.746620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:38.746712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:39.746967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:40.747120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:41.747270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:42.748152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:43.748223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:44.748505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:45.748835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:46.749176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:47.749276      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:48.749900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:49.749998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:50.750527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:51.750818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:52.751541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:53.751565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:54.751651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:55.751758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:56.752201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:57.752447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:58.752991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:57:59.753100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:00.753438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:01.754433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 11/30/24 12:58:01.784
  STEP: Removing cronjob @ 11/30/24 12:58:01.788
  I1130 12:58:01.795877 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7132" for this suite. @ 11/30/24 12:58:01.8
• [112.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 11/30/24 12:58:01.81
  I1130 12:58:01.810185 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:58:01.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:58:01.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:58:01.837
  STEP: Creating secret with name projected-secret-test-5af6d2da-ceb9-40ac-85f5-3bd5587af21e @ 11/30/24 12:58:01.84
  STEP: Creating a pod to test consume secrets @ 11/30/24 12:58:01.845
  E1130 12:58:02.754686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:03.755596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:04.755792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:05.755923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:58:05.871
  I1130 12:58:05.876325 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-secrets-5838ddea-edeb-45f9-8bea-52320e9bd9ff container secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:58:05.9
  I1130 12:58:05.920147 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1588" for this suite. @ 11/30/24 12:58:05.924
• [4.122 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 11/30/24 12:58:05.932
  I1130 12:58:05.932512 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename aggregateddiscovery @ 11/30/24 12:58:05.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:58:05.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:58:05.953
  I1130 12:58:05.959950 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-8992" for this suite. @ 11/30/24 12:58:05.965
• [0.042 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 11/30/24 12:58:05.974
  I1130 12:58:05.974550 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:58:05.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:58:05.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:58:05.995
  STEP: Creating configMap with name projected-configmap-test-volume-6c867a1c-d1d0-49b9-924c-dba706935b31 @ 11/30/24 12:58:05.998
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:58:06.004
  E1130 12:58:06.756205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:07.756508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:08.756613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:09.756691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:58:10.032
  I1130 12:58:10.036197 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-configmaps-986ba27b-7555-4165-b2ee-7ef2fb171001 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 12:58:10.045
  I1130 12:58:10.068356 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9315" for this suite. @ 11/30/24 12:58:10.072
• [4.106 seconds]
------------------------------
S
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3184
  STEP: Creating a kubernetes client @ 11/30/24 12:58:10.08
  I1130 12:58:10.080298 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 12:58:10.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:58:10.099
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:58:10.102
  STEP: fetching services @ 11/30/24 12:58:10.105
  I1130 12:58:10.108696 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5887" for this suite. @ 11/30/24 12:58:10.112
• [0.041 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 11/30/24 12:58:10.121
  I1130 12:58:10.121425 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 12:58:10.121
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:58:10.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:58:10.141
  STEP: Creating configMap with name projected-configmap-test-volume-map-ed44b1a4-41f6-4a64-b818-ca4f0d7c7b17 @ 11/30/24 12:58:10.144
  STEP: Creating a pod to test consume configMaps @ 11/30/24 12:58:10.149
  E1130 12:58:10.756840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:11.757123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 12:58:12.168
  I1130 12:58:12.172556 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-configmaps-a65510fc-4a12-4473-b4a3-8cb2c7ecad04 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 12:58:12.18
  I1130 12:58:12.199251 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9965" for this suite. @ 11/30/24 12:58:12.202
• [2.090 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:754
  STEP: Creating a kubernetes client @ 11/30/24 12:58:12.211
  I1130 12:58:12.211906 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename statefulset @ 11/30/24 12:58:12.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:58:12.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:58:12.229
  STEP: Creating service test in namespace statefulset-5429 @ 11/30/24 12:58:12.232
  STEP: Creating stateful set ss in namespace statefulset-5429 @ 11/30/24 12:58:12.239
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5429 @ 11/30/24 12:58:12.246
  I1130 12:58:12.250717 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E1130 12:58:12.757263      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:13.757643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:14.757851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:15.758023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:16.758147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:17.758237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:18.758343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:19.758513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:20.758996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:21.759285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:22.253124 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 11/30/24 12:58:22.253
  I1130 12:58:22.257606 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5429 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 12:58:22.358250 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 12:58:22.358287 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 12:58:22.358297 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 12:58:22.362839 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1130 12:58:22.760278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:23.761188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:24.761864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:25.761945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:26.762119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:27.762222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:28.762316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:29.762515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:30.762705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:31.763158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:32.362686 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I1130 12:58:32.362762 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I1130 12:58:32.384338 19 resource.go:168] POD   NODE              PHASE    GRACE  CONDITIONS
  I1130 12:58:32.384420 19 resource.go:175] ss-0  ip-172-31-64-147  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:13 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:12 +0000 UTC  }]
  I1130 12:58:32.384428 19 resource.go:178] 
  I1130 12:58:32.384434 19 statefulset.go:2413] StatefulSet ss has not reached scale 3, at 1
  E1130 12:58:32.763615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:33.391184 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 8.994041172s
  E1130 12:58:33.764517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:34.396017 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 7.98829822s
  E1130 12:58:34.765485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:35.401657 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 6.983248219s
  E1130 12:58:35.766237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:36.407820 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 5.977051817s
  E1130 12:58:36.766339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:37.413612 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 4.971385979s
  E1130 12:58:37.767064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:38.420287 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 3.965060754s
  E1130 12:58:38.767063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:39.425728 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 2.959016765s
  E1130 12:58:39.767197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:40.430815 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 1.953559633s
  E1130 12:58:40.768204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:41.437128 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 948.060132ms
  E1130 12:58:41.769038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5429 @ 11/30/24 12:58:42.437
  I1130 12:58:42.443525 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5429 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1130 12:58:42.527738 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1130 12:58:42.527788 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 12:58:42.527801 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 12:58:42.527908 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5429 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1130 12:58:42.618889 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I1130 12:58:42.618929 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 12:58:42.618939 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 12:58:42.618993 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5429 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1130 12:58:42.710946 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I1130 12:58:42.710983 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 12:58:42.710993 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 12:58:42.716063 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I1130 12:58:42.716092 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I1130 12:58:42.716099 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 11/30/24 12:58:42.716
  I1130 12:58:42.719999 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5429 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E1130 12:58:42.769359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:42.804066 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 12:58:42.804104 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 12:58:42.804113 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 12:58:42.804161 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5429 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 12:58:42.888298 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 12:58:42.888338 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 12:58:42.888347 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 12:58:42.888415 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5429 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 12:58:42.978156 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 12:58:42.978195 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 12:58:42.978206 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 12:58:42.978215 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I1130 12:58:42.983324 19 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E1130 12:58:43.770042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:44.770114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:45.770214      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:46.770324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:47.770513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:48.770613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:49.770714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:50.770800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:51.771138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:58:52.771609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:52.988720 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I1130 12:58:52.988752 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I1130 12:58:52.988758 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I1130 12:58:53.004673 19 resource.go:168] POD   NODE              PHASE    GRACE  CONDITIONS
  I1130 12:58:53.004728 19 resource.go:175] ss-0  ip-172-31-64-147  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:13 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:12 +0000 UTC  }]
  I1130 12:58:53.004745 19 resource.go:175] ss-1  ip-172-31-94-166  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:33 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:32 +0000 UTC  }]
  I1130 12:58:53.004760 19 resource.go:175] ss-2  ip-172-31-4-119   Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:33 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:43 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:32 +0000 UTC  }]
  I1130 12:58:53.004766 19 resource.go:178] 
  I1130 12:58:53.004773 19 statefulset.go:2413] StatefulSet ss has not reached scale 0, at 3
  E1130 12:58:53.772122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:54.010287 19 resource.go:168] POD   NODE              PHASE      GRACE  CONDITIONS
  I1130 12:58:54.010338 19 resource.go:175] ss-0  ip-172-31-64-147  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:53 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:12 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:43 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:43 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 12:58:12 +0000 UTC  }]
  I1130 12:58:54.010344 19 resource.go:178] 
  I1130 12:58:54.010351 19 statefulset.go:2413] StatefulSet ss has not reached scale 0, at 1
  E1130 12:58:54.772605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:55.016357 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 7.98927473s
  E1130 12:58:55.773658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:56.022733 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 6.98307127s
  E1130 12:58:56.773927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:57.028855 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 5.976852233s
  E1130 12:58:57.774006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:58.033894 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 4.970852872s
  E1130 12:58:58.774085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:58:59.039793 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 3.965761764s
  E1130 12:58:59.774255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:59:00.045749 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 2.959776131s
  E1130 12:59:00.774646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:59:01.050818 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 1.954330105s
  E1130 12:59:01.775112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 12:59:02.057001 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 948.784992ms
  E1130 12:59:02.775350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5429 @ 11/30/24 12:59:03.058
  I1130 12:59:03.063023 19 rest.go:150] Scaling statefulset ss to 0
  I1130 12:59:03.072023 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1130 12:59:03.075587 19 statefulset.go:138] Deleting all statefulset in ns statefulset-5429
  I1130 12:59:03.079664 19 rest.go:150] Scaling statefulset ss to 0
  I1130 12:59:03.087580 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1130 12:59:03.090860 19 rest.go:88] Deleting statefulset ss
  I1130 12:59:03.105191 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5429" for this suite. @ 11/30/24 12:59:03.109
• [50.905 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:329
  STEP: Creating a kubernetes client @ 11/30/24 12:59:03.117
  I1130 12:59:03.117230 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-preemption @ 11/30/24 12:59:03.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 12:59:03.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 12:59:03.194
  I1130 12:59:03.214217 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1130 12:59:03.775600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:04.775819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:05.776795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:06.777261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:07.777507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:08.777617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:09.777712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:10.777895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:11.778020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:12.778588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:13.779202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:14.779544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:15.779890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:16.780141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:17.780531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:18.780591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:19.780716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:20.780785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:21.780918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:22.780981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:23.781609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:24.782571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:25.783709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:26.784127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:27.784355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:28.784516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:29.784909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:30.785104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:31.786040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:32.786187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:33.786450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:34.786647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:35.787581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:36.788412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:37.788523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:38.789383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:39.789502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:40.789595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:41.790489      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:42.791580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:43.792573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:44.793573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:45.793670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:46.794686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:47.794717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:48.794910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:49.795743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:50.795936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:51.795961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:52.796739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:53.796776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:54.796971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:55.797249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:56.797414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:57.797469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:58.797509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 12:59:59.798268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:00.798492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:01.798997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:02.799602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:03.220909 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Select a node to run the lower and higher priority pods @ 11/30/24 13:00:03.225
  STEP: Create a low priority pod that consumes 1/1 of node resources @ 11/30/24 13:00:03.234
  I1130 13:00:03.249132 19 preemption.go:367] Created pod: victim-pod
  STEP: Wait for the victim pod to be scheduled @ 11/30/24 13:00:03.249
  E1130 13:00:03.800005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:04.800101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create a high priority pod to trigger preemption of the lower priority pod @ 11/30/24 13:00:05.262
  I1130 13:00:05.270189 19 preemption.go:385] Created pod: preemptor-pod
  STEP: Waiting for the victim pod to be terminating @ 11/30/24 13:00:05.27
  E1130 13:00:05.800166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:06.800258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying the pod has the pod disruption condition @ 11/30/24 13:00:07.279
  I1130 13:00:07.283086 19 pod_client.go:378] Removing pod's "victim-pod" finalizer: "example.com/test-finalizer"
  I1130 13:00:07.798076 19 pod_client.go:173] Successfully updated pod "victim-pod"
  E1130 13:00:07.801195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:07.839360 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-9845" for this suite. @ 11/30/24 13:00:07.843
• [64.734 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:644
  STEP: Creating a kubernetes client @ 11/30/24 13:00:07.851
  I1130 13:00:07.851644 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename statefulset @ 11/30/24 13:00:07.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:00:07.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:00:07.874
  STEP: Creating service test in namespace statefulset-5669 @ 11/30/24 13:00:07.877
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 11/30/24 13:00:07.882
  STEP: Creating stateful set ss in namespace statefulset-5669 @ 11/30/24 13:00:07.889
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5669 @ 11/30/24 13:00:07.895
  I1130 13:00:07.899515 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E1130 13:00:08.801614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:09.801703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:10.802056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:11.802134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:12.802325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:13.802585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:14.802818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:15.802948      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:16.803292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:17.803514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:17.900794 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 11/30/24 13:00:17.9
  I1130 13:00:17.905404 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5669 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 13:00:17.992805 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 13:00:17.992844 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 13:00:17.992853 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 13:00:17.998415 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1130 13:00:18.804414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:19.804550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:20.804766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:21.805000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:22.805230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:23.805464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:24.805674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:25.806046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:26.806324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:27.806567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:27.998770 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I1130 13:00:27.998812 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I1130 13:00:28.017621 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 9.99999981s
  E1130 13:00:28.806824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:29.023957 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 8.995345606s
  E1130 13:00:29.807880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:30.028675 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 7.989332509s
  E1130 13:00:30.808548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:31.035647 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 6.983804866s
  E1130 13:00:31.808581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:32.041626 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 5.97760505s
  E1130 13:00:32.808714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:33.047521 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 4.971389099s
  E1130 13:00:33.809198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:34.053975 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 3.964895288s
  E1130 13:00:34.809754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:35.060125 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 2.958939994s
  E1130 13:00:35.810607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:36.066111 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 1.952499954s
  E1130 13:00:36.811256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:37.071646 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 946.69656ms
  E1130 13:00:37.811401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5669 @ 11/30/24 13:00:38.071
  I1130 13:00:38.077332 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5669 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1130 13:00:38.160911 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1130 13:00:38.160951 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 13:00:38.160961 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 13:00:38.165667 19 wait.go:40] Found 1 stateful pods, waiting for 3
  E1130 13:00:38.812437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:39.813274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:40.813524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:41.814527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:42.815571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:43.815662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:44.816576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:45.816802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:46.817152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:47.817446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:48.167628 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I1130 13:00:48.167662 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I1130 13:00:48.167669 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 11/30/24 13:00:48.167
  STEP: Scale down will halt with unhealthy stateful pod @ 11/30/24 13:00:48.167
  I1130 13:00:48.175549 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5669 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 13:00:48.265758 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 13:00:48.265801 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 13:00:48.265810 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 13:00:48.265861 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5669 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 13:00:48.356403 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 13:00:48.356446 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 13:00:48.356454 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 13:00:48.356498 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5669 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1130 13:00:48.441292 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1130 13:00:48.441332 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1130 13:00:48.441342 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1130 13:00:48.441351 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I1130 13:00:48.445957 19 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E1130 13:00:48.817600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:49.817623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:50.817855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:51.818143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:52.818416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:53.818599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:54.818645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:55.819586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:56.819706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:00:57.819768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:58.451246 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I1130 13:00:58.451271 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I1130 13:00:58.451279 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I1130 13:00:58.469714 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 9.99999968s
  E1130 13:00:58.820041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:00:59.475314 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 8.992827718s
  E1130 13:00:59.820595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:00.481517 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 7.986911771s
  E1130 13:01:00.820698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:01.487747 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 6.981353281s
  E1130 13:01:01.821157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:02.492523 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 5.975228895s
  E1130 13:01:02.821744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:03.497623 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 4.970552562s
  E1130 13:01:03.822149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:04.504022 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 3.964834184s
  E1130 13:01:04.822391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:05.509970 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 2.959101138s
  E1130 13:01:05.822592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:06.517699 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 1.952679088s
  E1130 13:01:06.823054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:07.523538 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 945.482881ms
  E1130 13:01:07.823609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5669 @ 11/30/24 13:01:08.524
  I1130 13:01:08.529682 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5669 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1130 13:01:08.612061 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1130 13:01:08.612100 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 13:01:08.612110 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 13:01:08.612160 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5669 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1130 13:01:08.702834 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1130 13:01:08.702883 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 13:01:08.702900 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 13:01:08.702946 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=statefulset-5669 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1130 13:01:08.824609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:08.839747 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1130 13:01:08.839793 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1130 13:01:08.839802 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1130 13:01:08.839812 19 rest.go:150] Scaling statefulset ss to 0
  E1130 13:01:09.825611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:10.826182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:11.826825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:12.827003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:13.827389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:14.827584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:15.827804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:16.828334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:17.828543      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:18.828626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 11/30/24 13:01:18.85
  I1130 13:01:18.850208 19 statefulset.go:138] Deleting all statefulset in ns statefulset-5669
  I1130 13:01:18.854442 19 rest.go:150] Scaling statefulset ss to 0
  I1130 13:01:18.862181 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1130 13:01:18.865314 19 rest.go:88] Deleting statefulset ss
  I1130 13:01:18.880615 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5669" for this suite. @ 11/30/24 13:01:18.885
• [71.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:406
  STEP: Creating a kubernetes client @ 11/30/24 13:01:18.894
  I1130 13:01:18.894653 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename validating-admission-policy @ 11/30/24 13:01:18.895
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:18.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:18.923
  STEP: getting /apis @ 11/30/24 13:01:18.931
  STEP: getting /apis/admissionregistration.k8s.io @ 11/30/24 13:01:18.934
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 11/30/24 13:01:18.935
  STEP: creating @ 11/30/24 13:01:18.936
  STEP: getting @ 11/30/24 13:01:18.954
  STEP: listing @ 11/30/24 13:01:18.958
  STEP: watching @ 11/30/24 13:01:18.961
  I1130 13:01:18.961579 19 validatingadmissionpolicy.go:523] starting watch
  STEP: patching @ 11/30/24 13:01:18.963
  STEP: updating @ 11/30/24 13:01:18.969
  I1130 13:01:18.977484 19 validatingadmissionpolicy.go:552] waiting for watch events with expected annotations
  STEP: getting /status @ 11/30/24 13:01:18.977
  STEP: patching /status @ 11/30/24 13:01:18.981
  STEP: updating /status @ 11/30/24 13:01:18.988
  STEP: deleting @ 11/30/24 13:01:19.023
  STEP: deleting a collection @ 11/30/24 13:01:19.039
  I1130 13:01:19.063830 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-305" for this suite. @ 11/30/24 13:01:19.068
• [0.182 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 11/30/24 13:01:19.076
  I1130 13:01:19.076414 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename security-context-test @ 11/30/24 13:01:19.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:19.098
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:19.101
  E1130 13:01:19.829585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:20.829698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:21.829796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:22.830597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:23.140596 19 security_context.go:538] Got logs for pod "busybox-privileged-false-b3676ba7-a65d-4155-bbf8-dfce53669bb0": "ip: RTNETLINK answers: Operation not permitted\n"
  I1130 13:01:23.140721 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5561" for this suite. @ 11/30/24 13:01:23.145
• [4.077 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3209
  STEP: Creating a kubernetes client @ 11/30/24 13:01:23.153
  I1130 13:01:23.153663 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 13:01:23.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:23.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:23.175
  STEP: creating an Endpoint @ 11/30/24 13:01:23.182
  STEP: waiting for available Endpoint @ 11/30/24 13:01:23.187
  STEP: listing all Endpoints @ 11/30/24 13:01:23.188
  STEP: updating the Endpoint @ 11/30/24 13:01:23.192
  STEP: fetching the Endpoint @ 11/30/24 13:01:23.199
  STEP: patching the Endpoint @ 11/30/24 13:01:23.203
  STEP: fetching the Endpoint @ 11/30/24 13:01:23.21
  STEP: deleting the Endpoint by Collection @ 11/30/24 13:01:23.214
  STEP: waiting for Endpoint deletion @ 11/30/24 13:01:23.223
  STEP: fetching the Endpoint @ 11/30/24 13:01:23.224
  I1130 13:01:23.229618 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2740" for this suite. @ 11/30/24 13:01:23.234
• [0.088 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:144
  STEP: Creating a kubernetes client @ 11/30/24 13:01:23.241
  I1130 13:01:23.241578 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename disruption @ 11/30/24 13:01:23.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:23.26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:23.264
  STEP: Waiting for the pdb to be processed @ 11/30/24 13:01:23.273
  E1130 13:01:23.831551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:24.831773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 11/30/24 13:01:25.301
  I1130 13:01:25.307251 19 disruption.go:691] running pods: 0 < 3
  E1130 13:01:25.832030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:26.832587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:27.312275 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3646" for this suite. @ 11/30/24 13:01:27.316
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:79
  STEP: Creating a kubernetes client @ 11/30/24 13:01:27.326
  I1130 13:01:27.326398 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 13:01:27.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:27.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:27.348
  STEP: Counting existing ResourceQuota @ 11/30/24 13:01:27.351
  E1130 13:01:27.832913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:28.833887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:29.834233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:30.834299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:31.834636      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 11/30/24 13:01:32.357
  STEP: Ensuring resource quota status is calculated @ 11/30/24 13:01:32.367
  E1130 13:01:32.834949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:33.835158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:34.372752 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-342" for this suite. @ 11/30/24 13:01:34.377
• [7.059 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:62
  STEP: Creating a kubernetes client @ 11/30/24 13:01:34.386
  I1130 13:01:34.386041 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename field-validation @ 11/30/24 13:01:34.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:34.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:34.418
  STEP: apply creating a deployment @ 11/30/24 13:01:34.421
  I1130 13:01:34.440108 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1393" for this suite. @ 11/30/24 13:01:34.444
• [0.066 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 11/30/24 13:01:34.452
  I1130 13:01:34.452268 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 13:01:34.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:34.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:34.474
  STEP: Creating configMap with name configmap-test-upd-5a17398f-6c13-48d8-a262-3fe2767607ca @ 11/30/24 13:01:34.481
  STEP: Creating the pod @ 11/30/24 13:01:34.486
  E1130 13:01:34.835658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:35.835873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 11/30/24 13:01:36.511
  STEP: Waiting for pod with binary data @ 11/30/24 13:01:36.52
  I1130 13:01:36.529011 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7797" for this suite. @ 11/30/24 13:01:36.533
• [2.091 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 11/30/24 13:01:36.542
  I1130 13:01:36.542910 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 13:01:36.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:36.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:36.566
  STEP: Creating secret with name s-test-opt-del-7a37f8f0-033f-4974-b379-5bcbcb1e6714 @ 11/30/24 13:01:36.573
  STEP: Creating secret with name s-test-opt-upd-0c7ef077-dbd8-4fe2-9b70-c011e26bd96e @ 11/30/24 13:01:36.578
  STEP: Creating the pod @ 11/30/24 13:01:36.583
  E1130 13:01:36.836643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:37.836937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-7a37f8f0-033f-4974-b379-5bcbcb1e6714 @ 11/30/24 13:01:38.641
  STEP: Updating secret s-test-opt-upd-0c7ef077-dbd8-4fe2-9b70-c011e26bd96e @ 11/30/24 13:01:38.649
  STEP: Creating secret with name s-test-opt-create-4534a7b0-6570-4cd1-8528-30fa0920d902 @ 11/30/24 13:01:38.656
  STEP: waiting to observe update in volume @ 11/30/24 13:01:38.662
  E1130 13:01:38.837889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:39.838124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:40.838730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:41.838847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:42.705105 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2000" for this suite. @ 11/30/24 13:01:42.71
• [6.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 11/30/24 13:01:42.719
  I1130 13:01:42.719047 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:01:42.719
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:42.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:42.741
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 13:01:42.743
  E1130 13:01:42.839156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:43.839256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:01:44.761
  I1130 13:01:44.766669 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-5967bd26-1140-4199-b999-430c08bcdd82 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 13:01:44.775
  I1130 13:01:44.795538 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4862" for this suite. @ 11/30/24 13:01:44.799
• [2.089 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 11/30/24 13:01:44.808
  I1130 13:01:44.808504 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 13:01:44.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:44.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:44.832
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 11/30/24 13:01:44.835
  E1130 13:01:44.840020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:45.840194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:46.840418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:47.840529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:48.840625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:01:48.86
  I1130 13:01:48.864134 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-2cc13d80-ebc5-4a11-ba98-b59da75d65e0 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 13:01:48.872
  I1130 13:01:48.893759 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1047" for this suite. @ 11/30/24 13:01:48.897
• [4.097 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 11/30/24 13:01:48.905
  I1130 13:01:48.905974 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename gc @ 11/30/24 13:01:48.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:48.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:48.927
  I1130 13:01:48.963037 19 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ff7f6771-967b-49ff-9805-29548e861922", Controller:(*bool)(0xc0013bd396), BlockOwnerDeletion:(*bool)(0xc0013bd397)}}
  I1130 13:01:48.970879 19 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"c0d4dfa6-ed4e-4d32-b004-905f3fa3a731", Controller:(*bool)(0xc002f4286e), BlockOwnerDeletion:(*bool)(0xc002f4286f)}}
  I1130 13:01:48.978193 19 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ecade027-6817-48a4-b2dd-cfaa7a62e765", Controller:(*bool)(0xc0013bd5e6), BlockOwnerDeletion:(*bool)(0xc0013bd5e7)}}
  E1130 13:01:49.840743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:50.840836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:51.840904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:52.841012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:53.841131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:01:53.988591 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2974" for this suite. @ 11/30/24 13:01:53.992
• [5.092 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:335
  STEP: Creating a kubernetes client @ 11/30/24 13:01:53.998
  I1130 13:01:53.998259 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename statefulset @ 11/30/24 13:01:53.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:01:54.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:01:54.022
  STEP: Creating service test in namespace statefulset-5053 @ 11/30/24 13:01:54.025
  STEP: Creating a new StatefulSet @ 11/30/24 13:01:54.032
  I1130 13:01:54.045231 19 wait.go:40] Found 0 stateful pods, waiting for 3
  E1130 13:01:54.841607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:55.841696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:56.841809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:57.841888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:58.841998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:01:59.842151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:00.842391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:01.842532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:02.842643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:03.842735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:02:04.044712 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I1130 13:02:04.044740 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I1130 13:02:04.044747 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 11/30/24 13:02:04.057
  I1130 13:02:04.066565 19 statefulset.go:2507] Updating stateful set ss2
  STEP: Creating a new revision @ 11/30/24 13:02:04.066
  E1130 13:02:04.842849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:05.843081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:06.843221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:07.843299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:08.843523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:09.843845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:10.843986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:11.844329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:12.844511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:13.844777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 11/30/24 13:02:14.076
  STEP: Performing a canary update @ 11/30/24 13:02:14.076
  I1130 13:02:14.089568 19 statefulset.go:2507] Updating stateful set ss2
  I1130 13:02:14.098340 19 wait.go:74] Waiting for Pod statefulset-5053/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1130 13:02:14.845154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:15.845365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:16.845457      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:17.845599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:18.845812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:19.846043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:20.846159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:21.846423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:22.846546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:23.846719      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 11/30/24 13:02:24.099
  I1130 13:02:24.138183 19 wait.go:40] Found 1 stateful pods, waiting for 3
  E1130 13:02:24.846934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:25.847097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:26.847413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:27.847617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:28.847788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:29.848018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:30.848236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:31.848543      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:32.848684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:33.849662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:02:34.140717 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I1130 13:02:34.140751 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I1130 13:02:34.140760 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 11/30/24 13:02:34.148
  I1130 13:02:34.160872 19 statefulset.go:2507] Updating stateful set ss2
  I1130 13:02:34.180795 19 wait.go:74] Waiting for Pod statefulset-5053/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1130 13:02:34.850521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:35.850636      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:36.850729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:37.851603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:38.852576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:39.853639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:40.853738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:41.854065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:42.854429      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:43.854556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:02:44.181736 19 statefulset.go:2507] Updating stateful set ss2
  I1130 13:02:44.192598 19 wait.go:56] Waiting for StatefulSet statefulset-5053/ss2 to complete update
  I1130 13:02:44.192642 19 wait.go:63] Waiting for Pod statefulset-5053/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1130 13:02:44.855537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:45.855856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:46.855969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:47.856146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:48.856227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:49.856482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:50.856711      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:51.857047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:52.857269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:53.857513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:02:54.192584 19 statefulset.go:138] Deleting all statefulset in ns statefulset-5053
  I1130 13:02:54.196887 19 rest.go:150] Scaling statefulset ss2 to 0
  E1130 13:02:54.857793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:55.858048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:56.858159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:57.858248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:58.858346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:02:59.858559      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:00.858685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:01.859495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:02.859551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:03.860568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:03:04.214834 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1130 13:03:04.219624 19 rest.go:88] Deleting statefulset ss2
  I1130 13:03:04.234496 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5053" for this suite. @ 11/30/24 13:03:04.242
• [70.252 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 11/30/24 13:03:04.25
  I1130 13:03:04.250332 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 13:03:04.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:03:04.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:03:04.271
  STEP: Creating configMap with name configmap-test-volume-map-67b971eb-65b4-4647-bdfa-622120b1da81 @ 11/30/24 13:03:04.274
  STEP: Creating a pod to test consume configMaps @ 11/30/24 13:03:04.278
  E1130 13:03:04.861560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:05.861656      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:06.861950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:07.862595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:03:08.303
  I1130 13:03:08.308320 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-configmaps-f6acfd6d-019f-486a-a514-759c29011ace container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 13:03:08.32
  I1130 13:03:08.344572 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-529" for this suite. @ 11/30/24 13:03:08.348
• [4.106 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 11/30/24 13:03:08.355
  I1130 13:03:08.355981 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replicaset @ 11/30/24 13:03:08.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:03:08.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:03:08.378
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 11/30/24 13:03:08.382
  E1130 13:03:08.862801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:09.863050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 11/30/24 13:03:10.406
  STEP: Then the orphan pod is adopted @ 11/30/24 13:03:10.411
  E1130 13:03:10.863622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 11/30/24 13:03:11.42
  I1130 13:03:11.425813 19 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 11/30/24 13:03:11.436
  E1130 13:03:11.864361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:03:12.445889 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6822" for this suite. @ 11/30/24 13:03:12.45
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 11/30/24 13:03:12.459
  I1130 13:03:12.459196 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename var-expansion @ 11/30/24 13:03:12.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:03:12.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:03:12.484
  STEP: creating the pod with failed condition @ 11/30/24 13:03:12.487
  E1130 13:03:12.864514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:13.864733      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:14.864833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:15.865043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:16.865211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:17.865320      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:18.865497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:19.865582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:20.865748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:21.866096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:22.866308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:23.866439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:24.867038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:25.867297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:26.867840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:27.868606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:28.869473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:29.869561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:30.870313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:31.871315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:32.872049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:33.872385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:34.872602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:35.873593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:36.874646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:37.874887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:38.875505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:39.875621      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:40.876428      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:41.876522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:42.877254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:43.877458      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:44.877538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:45.878691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:46.879591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:47.880569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:48.881148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:49.881251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:50.881569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:51.882224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:52.882288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:53.882518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:54.883260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:55.883402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:56.883638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:57.883847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:58.884108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:03:59.884439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:00.885555      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:01.886586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:02.887594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:03.887750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:04.888726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:05.888841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:06.888939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:07.889035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:08.889686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:09.889790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:10.890396      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:11.890466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:12.891239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:13.891343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:14.891512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:15.891696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:16.891819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:17.892290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:18.893014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:19.893228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:20.893321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:21.893613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:22.894296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:23.894460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:24.895385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:25.895665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:26.896687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:27.896889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:28.896962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:29.897114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:30.897269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:31.898327      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:32.899139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:33.899235      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:34.899498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:35.899599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:36.900290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:37.900416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:38.900504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:39.900601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:40.901034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:41.901081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:42.901142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:43.901238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:44.901554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:45.901663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:46.901814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:47.901995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:48.902608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:49.903127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:50.903192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:51.903524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:52.904384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:53.904699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:54.905447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:55.905557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:56.905683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:57.905980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:58.906354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:04:59.906560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:00.906738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:01.907070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:02.907474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:03.907800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:04.908241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:05.909305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:06.909997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:07.910089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:08.910563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:09.910677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:10.911714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:11.911837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating the pod @ 11/30/24 13:05:12.496
  E1130 13:05:12.912586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:05:13.011871 19 pod_client.go:173] Successfully updated pod "var-expansion-ccbbab4a-9fe2-44a2-9815-16ea9d3a35d6"
  STEP: waiting for pod running @ 11/30/24 13:05:13.011
  E1130 13:05:13.912828      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:14.913051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 11/30/24 13:05:15.022
  I1130 13:05:15.022218 19 delete.go:62] Deleting pod "var-expansion-ccbbab4a-9fe2-44a2-9815-16ea9d3a35d6" in namespace "var-expansion-5174"
  I1130 13:05:15.031770 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-ccbbab4a-9fe2-44a2-9815-16ea9d3a35d6" to be fully deleted
  E1130 13:05:15.913225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:16.913527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:17.913608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:18.913762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:19.913881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:20.914088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:21.915038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:22.915265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:23.915479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:24.915711      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:25.915820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:26.916352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:27.916468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:28.916531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:29.916795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:30.917013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:31.917421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:32.917642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:33.917958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:34.917885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:35.917944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:36.918592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:37.918871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:38.919595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:39.919692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:40.919797      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:41.920575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:42.921080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:43.921496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:44.921609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:45.922561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:46.923103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:05:47.126158 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5174" for this suite. @ 11/30/24 13:05:47.13
• [154.680 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 11/30/24 13:05:47.138
  I1130 13:05:47.138925 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename svcaccounts @ 11/30/24 13:05:47.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:05:47.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:05:47.161
  I1130 13:05:47.167673 19 service_accounts.go:754] Got root ca configmap in namespace "svcaccounts-9592"
  I1130 13:05:47.175194 19 service_accounts.go:757] Deleted root ca configmap in namespace "svcaccounts-9592"
  STEP: waiting for a new root ca configmap created @ 11/30/24 13:05:47.676
  I1130 13:05:47.680678 19 service_accounts.go:771] Recreated root ca configmap in namespace "svcaccounts-9592"
  I1130 13:05:47.687189 19 service_accounts.go:782] Updated root ca configmap in namespace "svcaccounts-9592"
  E1130 13:05:47.923596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting for the root ca configmap reconciled @ 11/30/24 13:05:48.188
  I1130 13:05:48.193054 19 service_accounts.go:800] Reconciled root ca configmap in namespace "svcaccounts-9592"
  I1130 13:05:48.193170 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9592" for this suite. @ 11/30/24 13:05:48.197
• [1.066 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 11/30/24 13:05:48.205
  I1130 13:05:48.205473 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename custom-resource-definition @ 11/30/24 13:05:48.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:05:48.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:05:48.227
  I1130 13:05:48.230847 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:05:48.924139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:49.924922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:50.925695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:51.926239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:52.926471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:53.926475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:05:54.452782 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5568" for this suite. @ 11/30/24 13:05:54.458
• [6.261 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3393
  STEP: Creating a kubernetes client @ 11/30/24 13:05:54.466
  I1130 13:05:54.466448 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 13:05:54.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:05:54.484
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:05:54.487
  STEP: creating a Service @ 11/30/24 13:05:54.493
  STEP: watching for the Service to be added @ 11/30/24 13:05:54.509
  I1130 13:05:54.511284 19 service.go:3445] Found Service test-service-gwbdc in namespace services-8636 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 31095}]
  I1130 13:05:54.511314 19 service.go:3452] Service test-service-gwbdc created
  STEP: Getting /status @ 11/30/24 13:05:54.511
  I1130 13:05:54.516650 19 service.go:3463] Service test-service-gwbdc has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 11/30/24 13:05:54.516
  STEP: watching for the Service to be patched @ 11/30/24 13:05:54.522
  I1130 13:05:54.524276 19 service.go:3486] observed Service test-service-gwbdc in namespace services-8636 with annotations: map[] & LoadBalancer: {[]}
  I1130 13:05:54.524327 19 service.go:3489] Found Service test-service-gwbdc in namespace services-8636 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc000fa1200 []}]}
  I1130 13:05:54.524345 19 service.go:3496] Service test-service-gwbdc has service status patched
  STEP: updating the ServiceStatus @ 11/30/24 13:05:54.524
  I1130 13:05:54.536994 19 service.go:3516] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 11/30/24 13:05:54.537
  I1130 13:05:54.538517 19 service.go:3527] Observed Service test-service-gwbdc in namespace services-8636 with annotations: map[] & Conditions: []
  I1130 13:05:54.538590 19 service.go:3538] Observed Service test-service-gwbdc in namespace services-8636 with annotations: map[patchedstatus:true] & Conditions: []
  I1130 13:05:54.538619 19 service.go:3534] Found Service test-service-gwbdc in namespace services-8636 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I1130 13:05:54.538628 19 service.go:3545] Service test-service-gwbdc has service status updated
  STEP: patching the service @ 11/30/24 13:05:54.538
  STEP: watching for the Service to be patched @ 11/30/24 13:05:54.549
  I1130 13:05:54.551062 19 service.go:3568] observed Service test-service-gwbdc in namespace services-8636 with labels: map[test-service-static:true]
  I1130 13:05:54.551083 19 service.go:3568] observed Service test-service-gwbdc in namespace services-8636 with labels: map[test-service-static:true]
  I1130 13:05:54.551092 19 service.go:3568] observed Service test-service-gwbdc in namespace services-8636 with labels: map[test-service-static:true]
  I1130 13:05:54.551112 19 service.go:3571] Found Service test-service-gwbdc in namespace services-8636 with labels: map[test-service:patched test-service-static:true]
  I1130 13:05:54.551119 19 service.go:3578] Service test-service-gwbdc patched
  STEP: deleting the service @ 11/30/24 13:05:54.551
  STEP: watching for the Service to be deleted @ 11/30/24 13:05:54.568
  I1130 13:05:54.570522 19 service.go:3602] Observed event: ADDED
  I1130 13:05:54.570551 19 service.go:3602] Observed event: MODIFIED
  I1130 13:05:54.570561 19 service.go:3602] Observed event: MODIFIED
  I1130 13:05:54.570666 19 service.go:3602] Observed event: MODIFIED
  I1130 13:05:54.570691 19 service.go:3598] Found Service test-service-gwbdc in namespace services-8636 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I1130 13:05:54.570698 19 service.go:3607] Service test-service-gwbdc deleted
  I1130 13:05:54.570791 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8636" for this suite. @ 11/30/24 13:05:54.575
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 11/30/24 13:05:54.583
  I1130 13:05:54.583490 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 13:05:54.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:05:54.601
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:05:54.604
  STEP: creating secret secrets-9149/secret-test-86fffab5-5315-4412-a258-eaab26af1297 @ 11/30/24 13:05:54.606
  STEP: Creating a pod to test consume secrets @ 11/30/24 13:05:54.613
  E1130 13:05:54.926739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:55.926958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:56.927636      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:57.927718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:05:58.639
  I1130 13:05:58.642903 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-configmaps-a2813fee-dde2-4b7d-9dd8-6760ad93ac1a container env-test: <nil>
  STEP: delete the pod @ 11/30/24 13:05:58.656
  I1130 13:05:58.675607 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9149" for this suite. @ 11/30/24 13:05:58.68
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 11/30/24 13:05:58.688
  I1130 13:05:58.688338 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:05:58.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:05:58.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:05:58.717
  STEP: Creating configMap with name projected-configmap-test-volume-map-9adf5266-7e21-4588-867a-28cceae00db2 @ 11/30/24 13:05:58.729
  STEP: Creating a pod to test consume configMaps @ 11/30/24 13:05:58.735
  E1130 13:05:58.928408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:05:59.928552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:00.929264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:01.930091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:06:02.764
  I1130 13:06:02.768679 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-configmaps-97e9472b-c9e0-4ea9-a121-da1c277bf59b container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 13:06:02.776
  I1130 13:06:02.795911 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3656" for this suite. @ 11/30/24 13:06:02.799
• [4.119 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:90
  STEP: Creating a kubernetes client @ 11/30/24 13:06:02.807
  I1130 13:06:02.807747 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename disruption @ 11/30/24 13:06:02.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:02.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:02.829
  STEP: Creating a kubernetes client @ 11/30/24 13:06:02.832
  I1130 13:06:02.832314 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename disruption-2 @ 11/30/24 13:06:02.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:02.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:02.856
  STEP: Waiting for the pdb to be processed @ 11/30/24 13:06:02.863
  E1130 13:06:02.930807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:03.931074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 11/30/24 13:06:04.873
  E1130 13:06:04.931687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:05.931895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 11/30/24 13:06:06.886
  STEP: listing a collection of PDBs across all namespaces @ 11/30/24 13:06:06.893
  STEP: listing a collection of PDBs in namespace disruption-2728 @ 11/30/24 13:06:06.897
  STEP: deleting a collection of PDBs @ 11/30/24 13:06:06.901
  STEP: Waiting for the PDB collection to be deleted @ 11/30/24 13:06:06.917
  I1130 13:06:06.921992 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-7845" for this suite. @ 11/30/24 13:06:06.926
  E1130 13:06:06.932529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:06.933758 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2728" for this suite. @ 11/30/24 13:06:06.937
• [4.139 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 11/30/24 13:06:06.947
  I1130 13:06:06.947281 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename init-container @ 11/30/24 13:06:06.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:06.965
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:06.968
  STEP: creating the pod @ 11/30/24 13:06:06.971
  I1130 13:06:06.971700 19 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E1130 13:06:07.932834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:08.933220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:09.933456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:09.988481 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-858" for this suite. @ 11/30/24 13:06:09.992
• [3.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 11/30/24 13:06:10
  I1130 13:06:10.000786 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename runtimeclass @ 11/30/24 13:06:10.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:10.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:10.021
  E1130 13:06:10.933646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:11.933993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:12.057411 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3206" for this suite. @ 11/30/24 13:06:12.061
• [2.068 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 11/30/24 13:06:12.068
  I1130 13:06:12.068737 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename containers @ 11/30/24 13:06:12.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:12.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:12.094
  STEP: Creating a pod to test override arguments @ 11/30/24 13:06:12.097
  E1130 13:06:12.934244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:13.934344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:14.934525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:15.935609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:06:16.126
  I1130 13:06:16.129846 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod client-containers-f75e07d4-093d-42d1-8c17-ebb73427d957 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 13:06:16.142
  I1130 13:06:16.159981 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5007" for this suite. @ 11/30/24 13:06:16.163
• [4.103 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 11/30/24 13:06:16.172
  I1130 13:06:16.172052 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename var-expansion @ 11/30/24 13:06:16.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:16.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:16.217
  STEP: Creating a pod to test env composition @ 11/30/24 13:06:16.221
  E1130 13:06:16.936697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:17.936911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:06:18.238
  I1130 13:06:18.242736 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod var-expansion-ea9bce89-48af-4e2e-9213-c9d40e4a5c90 container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 13:06:18.25
  I1130 13:06:18.269424 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5698" for this suite. @ 11/30/24 13:06:18.274
• [2.111 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 11/30/24 13:06:18.283
  I1130 13:06:18.283478 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 13:06:18.284
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:18.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:18.304
  I1130 13:06:18.307319 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:06:18.937008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 11/30/24 13:06:19.594
  I1130 13:06:19.594959 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-9066 --namespace=crd-publish-openapi-9066 create -f -'
  E1130 13:06:19.937818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:20.938775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:21.671238 19 builder.go:146] stderr: ""
  I1130 13:06:21.671291 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9197-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I1130 13:06:21.671341 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-9066 --namespace=crd-publish-openapi-9066 delete e2e-test-crd-publish-openapi-9197-crds test-cr'
  I1130 13:06:21.722767 19 builder.go:146] stderr: ""
  I1130 13:06:21.722806 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9197-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I1130 13:06:21.722868 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-9066 --namespace=crd-publish-openapi-9066 apply -f -'
  I1130 13:06:21.783899 19 builder.go:146] stderr: ""
  I1130 13:06:21.783940 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9197-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I1130 13:06:21.783987 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-9066 --namespace=crd-publish-openapi-9066 delete e2e-test-crd-publish-openapi-9197-crds test-cr'
  I1130 13:06:21.835136 19 builder.go:146] stderr: ""
  I1130 13:06:21.835178 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9197-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 11/30/24 13:06:21.835
  I1130 13:06:21.835257 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-9066 explain e2e-test-crd-publish-openapi-9197-crds'
  I1130 13:06:21.877840 19 builder.go:146] stderr: ""
  I1130 13:06:21.877903 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-9197-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E1130 13:06:21.939841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:22.940822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:23.098954 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9066" for this suite. @ 11/30/24 13:06:23.106
• [4.833 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 11/30/24 13:06:23.116
  I1130 13:06:23.116480 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename svcaccounts @ 11/30/24 13:06:23.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:23.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:23.138
  STEP: Creating ServiceAccount "e2e-sa-pjdqr"  @ 11/30/24 13:06:23.14
  I1130 13:06:23.145459 19 service_accounts.go:825] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-pjdqr"  @ 11/30/24 13:06:23.145
  I1130 13:06:23.152912 19 service_accounts.go:839] AutomountServiceAccountToken: true
  I1130 13:06:23.153012 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1196" for this suite. @ 11/30/24 13:06:23.156
• [0.047 seconds]
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 11/30/24 13:06:23.163
  I1130 13:06:23.163699 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 13:06:23.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:23.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:23.186
  STEP: Creating a pod to test downward api env vars @ 11/30/24 13:06:23.19
  E1130 13:06:23.940964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:24.941596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:06:25.212
  I1130 13:06:25.217745 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downward-api-d1d38d93-2686-4e59-9649-d48f910c768e container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 13:06:25.229
  I1130 13:06:25.246707 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-403" for this suite. @ 11/30/24 13:06:25.25
• [2.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:207
  STEP: Creating a kubernetes client @ 11/30/24 13:06:25.259
  I1130 13:06:25.259198 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:06:25.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:25.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:25.274
  STEP: Setting up server cert @ 11/30/24 13:06:25.305
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:06:25.649
  STEP: Deploying the webhook pod @ 11/30/24 13:06:25.659
  STEP: Wait for the deployment to be ready @ 11/30/24 13:06:25.672
  I1130 13:06:25.687056 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:06:25.942392      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:26.942517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:06:27.7
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:06:27.713
  E1130 13:06:27.943074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:28.714552 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 11/30/24 13:06:28.725
  STEP: create a pod @ 11/30/24 13:06:28.745
  E1130 13:06:28.943692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:29.943791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 11/30/24 13:06:30.765
  I1130 13:06:30.765725 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=webhook-8549 attach --namespace=webhook-8549 to-be-attached-pod -i -c=container1'
  I1130 13:06:30.833090 19 builder.go:135] rc: 1
  I1130 13:06:30.890816 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8549" for this suite. @ 11/30/24 13:06:30.895
  STEP: Destroying namespace "webhook-markers-4460" for this suite. @ 11/30/24 13:06:30.907
• [5.655 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 11/30/24 13:06:30.914
  I1130 13:06:30.914339 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 13:06:30.914
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:30.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:30.932
  STEP: Creating Pod @ 11/30/24 13:06:30.935
  E1130 13:06:30.944485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:31.945485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:32.945840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 11/30/24 13:06:32.954
  I1130 13:06:32.955020 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-4625 PodName:pod-sharedvolume-690d353c-9930-4c6b-ac33-1f55ab62a45c ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:06:32.955038 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:06:32.955484 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:06:32.955526 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-4625/pods/pod-sharedvolume-690d353c-9930-4c6b-ac33-1f55ab62a45c/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  I1130 13:06:32.997319 19 exec_util.go:111] Exec stderr: ""
  I1130 13:06:32.997471 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4625" for this suite. @ 11/30/24 13:06:33.001
• [2.094 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:350
  STEP: Creating a kubernetes client @ 11/30/24 13:06:33.008
  I1130 13:06:33.008884 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 13:06:33.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:33.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:33.027
  STEP: creating a replication controller @ 11/30/24 13:06:33.031
  I1130 13:06:33.031163 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 create -f -'
  I1130 13:06:33.111271 19 builder.go:146] stderr: ""
  I1130 13:06:33.111308 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 11/30/24 13:06:33.111
  I1130 13:06:33.111434 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1130 13:06:33.155894 19 builder.go:146] stderr: ""
  I1130 13:06:33.155929 19 builder.go:147] stdout: "update-demo-nautilus-4ss94 update-demo-nautilus-vj6ql "
  I1130 13:06:33.155987 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ss94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:06:33.201615 19 builder.go:146] stderr: ""
  I1130 13:06:33.201651 19 builder.go:147] stdout: ""
  I1130 13:06:33.201661 19 kubectl.go:2502] update-demo-nautilus-4ss94 is created but not running
  E1130 13:06:33.946085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:34.946140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:35.946195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:36.947033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:37.947228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:38.202540 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1130 13:06:38.262306 19 builder.go:146] stderr: ""
  I1130 13:06:38.262359 19 builder.go:147] stdout: "update-demo-nautilus-4ss94 update-demo-nautilus-vj6ql "
  I1130 13:06:38.262419 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ss94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:06:38.322864 19 builder.go:146] stderr: ""
  I1130 13:06:38.322904 19 builder.go:147] stdout: "true"
  I1130 13:06:38.322947 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ss94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1130 13:06:38.370278 19 builder.go:146] stderr: ""
  I1130 13:06:38.370317 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1130 13:06:38.370328 19 kubectl.go:2393] validating pod update-demo-nautilus-4ss94
  I1130 13:06:38.377223 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1130 13:06:38.377292 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1130 13:06:38.377304 19 kubectl.go:2520] update-demo-nautilus-4ss94 is verified up and running
  I1130 13:06:38.377347 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-vj6ql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:06:38.426949 19 builder.go:146] stderr: ""
  I1130 13:06:38.427001 19 builder.go:147] stdout: "true"
  I1130 13:06:38.427046 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-vj6ql -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1130 13:06:38.492719 19 builder.go:146] stderr: ""
  I1130 13:06:38.492777 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1130 13:06:38.492789 19 kubectl.go:2393] validating pod update-demo-nautilus-vj6ql
  I1130 13:06:38.499803 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1130 13:06:38.499869 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1130 13:06:38.499882 19 kubectl.go:2520] update-demo-nautilus-vj6ql is verified up and running
  STEP: scaling down the replication controller @ 11/30/24 13:06:38.499
  I1130 13:06:38.500869 19 kubectl.go:319] scanned /root for discovery docs: <nil>
  I1130 13:06:38.501066 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E1130 13:06:38.947592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:39.613293 19 builder.go:146] stderr: ""
  I1130 13:06:39.613330 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 11/30/24 13:06:39.613
  I1130 13:06:39.613439 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1130 13:06:39.660573 19 builder.go:146] stderr: ""
  I1130 13:06:39.660611 19 builder.go:147] stdout: "update-demo-nautilus-4ss94 "
  I1130 13:06:39.660662 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ss94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:06:39.703195 19 builder.go:146] stderr: ""
  I1130 13:06:39.703237 19 builder.go:147] stdout: "true"
  I1130 13:06:39.703313 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ss94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1130 13:06:39.746651 19 builder.go:146] stderr: ""
  I1130 13:06:39.746688 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1130 13:06:39.746701 19 kubectl.go:2393] validating pod update-demo-nautilus-4ss94
  I1130 13:06:39.752962 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1130 13:06:39.753018 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1130 13:06:39.753032 19 kubectl.go:2520] update-demo-nautilus-4ss94 is verified up and running
  STEP: scaling up the replication controller @ 11/30/24 13:06:39.753
  I1130 13:06:39.753768 19 kubectl.go:319] scanned /root for discovery docs: <nil>
  I1130 13:06:39.753805 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E1130 13:06:39.948279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:40.814055 19 builder.go:146] stderr: ""
  I1130 13:06:40.814091 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 11/30/24 13:06:40.814
  I1130 13:06:40.814176 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1130 13:06:40.858231 19 builder.go:146] stderr: ""
  I1130 13:06:40.858267 19 builder.go:147] stdout: "update-demo-nautilus-4ghcr update-demo-nautilus-4ss94 "
  I1130 13:06:40.858315 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ghcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:06:40.902868 19 builder.go:146] stderr: ""
  I1130 13:06:40.902906 19 builder.go:147] stdout: ""
  I1130 13:06:40.902922 19 kubectl.go:2502] update-demo-nautilus-4ghcr is created but not running
  E1130 13:06:40.948959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:41.949237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:42.949382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:43.949534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:44.950277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:45.903273 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E1130 13:06:45.951169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:45.951146 19 builder.go:146] stderr: ""
  I1130 13:06:45.951204 19 builder.go:147] stdout: "update-demo-nautilus-4ghcr update-demo-nautilus-4ss94 "
  I1130 13:06:45.951247 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ghcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:06:45.995894 19 builder.go:146] stderr: ""
  I1130 13:06:45.995930 19 builder.go:147] stdout: "true"
  I1130 13:06:45.995974 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ghcr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1130 13:06:46.042788 19 builder.go:146] stderr: ""
  I1130 13:06:46.042834 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1130 13:06:46.042846 19 kubectl.go:2393] validating pod update-demo-nautilus-4ghcr
  I1130 13:06:46.050445 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1130 13:06:46.050498 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1130 13:06:46.050515 19 kubectl.go:2520] update-demo-nautilus-4ghcr is verified up and running
  I1130 13:06:46.050563 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ss94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:06:46.097902 19 builder.go:146] stderr: ""
  I1130 13:06:46.097937 19 builder.go:147] stdout: "true"
  I1130 13:06:46.097989 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods update-demo-nautilus-4ss94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1130 13:06:46.142705 19 builder.go:146] stderr: ""
  I1130 13:06:46.142742 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1130 13:06:46.142757 19 kubectl.go:2393] validating pod update-demo-nautilus-4ss94
  I1130 13:06:46.147879 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1130 13:06:46.147940 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1130 13:06:46.147951 19 kubectl.go:2520] update-demo-nautilus-4ss94 is verified up and running
  STEP: using delete to clean up resources @ 11/30/24 13:06:46.147
  I1130 13:06:46.148047 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 delete --grace-period=0 --force -f -'
  I1130 13:06:46.199133 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 13:06:46.199169 19 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I1130 13:06:46.199213 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get rc,svc -l name=update-demo --no-headers'
  I1130 13:06:46.264568 19 builder.go:146] stderr: "No resources found in kubectl-4535 namespace.\n"
  I1130 13:06:46.264618 19 builder.go:147] stdout: ""
  I1130 13:06:46.264668 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-4535 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I1130 13:06:46.334058 19 builder.go:146] stderr: ""
  I1130 13:06:46.334127 19 builder.go:147] stdout: ""
  I1130 13:06:46.334312 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4535" for this suite. @ 11/30/24 13:06:46.345
• [13.348 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:107
  STEP: Creating a kubernetes client @ 11/30/24 13:06:46.356
  I1130 13:06:46.356670 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename job @ 11/30/24 13:06:46.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:46.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:46.382
  STEP: Looking for a node to schedule job pod @ 11/30/24 13:06:46.385
  STEP: Creating a job @ 11/30/24 13:06:46.389
  STEP: Ensuring job fails @ 11/30/24 13:06:46.394
  E1130 13:06:46.951282      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:47.951598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:48.952423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:49.953159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:50.954074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:51.954220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:06:52.406595 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7492" for this suite. @ 11/30/24 13:06:52.41
• [6.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 11/30/24 13:06:52.418
  I1130 13:06:52.418959 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename namespaces @ 11/30/24 13:06:52.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:52.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:52.439
  STEP: Creating a test namespace @ 11/30/24 13:06:52.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:52.459
  STEP: Creating a service in the namespace @ 11/30/24 13:06:52.465
  STEP: Deleting the namespace @ 11/30/24 13:06:52.475
  STEP: Waiting for the namespace to be removed. @ 11/30/24 13:06:52.485
  E1130 13:06:52.955157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:53.955254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:54.955344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:55.955474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:56.956309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:57.956420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 11/30/24 13:06:58.49
  STEP: Verifying there is no service in the namespace @ 11/30/24 13:06:58.513
  I1130 13:06:58.517326 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6713" for this suite. @ 11/30/24 13:06:58.521
  STEP: Destroying namespace "nsdeletetest-6353" for this suite. @ 11/30/24 13:06:58.532
  I1130 13:06:58.536658 19 framework.go:370] Namespace nsdeletetest-6353 was already deleted
  STEP: Destroying namespace "nsdeletetest-9110" for this suite. @ 11/30/24 13:06:58.536
• [6.125 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 11/30/24 13:06:58.543
  I1130 13:06:58.543637 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 13:06:58.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:06:58.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:06:58.566
  STEP: Creating configMap with name configmap-test-volume-571ab651-9f86-43a5-b3d6-1455b795be84 @ 11/30/24 13:06:58.569
  STEP: Creating a pod to test consume configMaps @ 11/30/24 13:06:58.574
  E1130 13:06:58.956867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:06:59.956978      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:00.957145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:01.957255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:07:02.599
  I1130 13:07:02.604600 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-configmaps-ab7981d6-9641-443a-84ec-804a2b63da73 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 13:07:02.612
  I1130 13:07:02.631212 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3344" for this suite. @ 11/30/24 13:07:02.635
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 11/30/24 13:07:02.643
  I1130 13:07:02.643027 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replication-controller @ 11/30/24 13:07:02.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:02.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:02.662
  I1130 13:07:02.666364 19 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 11/30/24 13:07:02.676
  STEP: Checking rc "condition-test" has the desired failure condition set @ 11/30/24 13:07:02.683
  E1130 13:07:02.957403      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 11/30/24 13:07:03.691
  I1130 13:07:03.708808 19 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 11/30/24 13:07:03.708
  E1130 13:07:03.958348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:04.719682 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7170" for this suite. @ 11/30/24 13:07:04.724
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 11/30/24 13:07:04.731
  I1130 13:07:04.731813 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 11/30/24 13:07:04.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:04.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:04.751
  STEP: creating a target pod @ 11/30/24 13:07:04.755
  E1130 13:07:04.958432      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:05.958638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 11/30/24 13:07:06.776
  E1130 13:07:06.959526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:07.959756      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 11/30/24 13:07:08.793
  I1130 13:07:08.793814 19 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-577 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:07:08.793833 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:07:08.794276 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:07:08.794319 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-577/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I1130 13:07:08.843196 19 exec_util.go:111] Exec stderr: ""
  I1130 13:07:08.850482 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-577" for this suite. @ 11/30/24 13:07:08.854
• [4.130 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 11/30/24 13:07:08.862
  I1130 13:07:08.862333 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename gc @ 11/30/24 13:07:08.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:08.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:08.882
  STEP: create the rc @ 11/30/24 13:07:08.891
  W1130 13:07:08.899063      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1130 13:07:08.960285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:09.960808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:10.960804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:11.968281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:12.969291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:13.969128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 11/30/24 13:07:14.904
  STEP: wait for the rc to be deleted @ 11/30/24 13:07:14.912
  E1130 13:07:14.970750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:15.924541 19 garbage_collector.go:670] 80 pods remaining
  I1130 13:07:15.924568 19 garbage_collector.go:677] 80 pods has nil DeletionTimestamp
  I1130 13:07:15.924574 19 garbage_collector.go:678] 
  E1130 13:07:15.971043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:16.924349 19 garbage_collector.go:670] 71 pods remaining
  I1130 13:07:16.926166 19 garbage_collector.go:677] 71 pods has nil DeletionTimestamp
  I1130 13:07:16.926451 19 garbage_collector.go:678] 
  E1130 13:07:16.972555      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:17.931075 19 garbage_collector.go:670] 60 pods remaining
  I1130 13:07:17.931120 19 garbage_collector.go:677] 60 pods has nil DeletionTimestamp
  I1130 13:07:17.931128 19 garbage_collector.go:678] 
  E1130 13:07:17.972930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:18.933303 19 garbage_collector.go:670] 40 pods remaining
  I1130 13:07:18.933360 19 garbage_collector.go:677] 40 pods has nil DeletionTimestamp
  I1130 13:07:18.933379 19 garbage_collector.go:678] 
  E1130 13:07:18.973900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:19.922434 19 garbage_collector.go:670] 31 pods remaining
  I1130 13:07:19.922482 19 garbage_collector.go:677] 31 pods has nil DeletionTimestamp
  I1130 13:07:19.922488 19 garbage_collector.go:678] 
  E1130 13:07:19.976153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:20.920608 19 garbage_collector.go:670] 20 pods remaining
  I1130 13:07:20.920639 19 garbage_collector.go:677] 20 pods has nil DeletionTimestamp
  I1130 13:07:20.920645 19 garbage_collector.go:678] 
  E1130 13:07:20.976525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 11/30/24 13:07:21.921
  W1130 13:07:21.926224      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1130 13:07:21.926257 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1130 13:07:21.926414 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8405" for this suite. @ 11/30/24 13:07:21.93
• [13.077 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 11/30/24 13:07:21.939
  I1130 13:07:21.939126 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename csistoragecapacity @ 11/30/24 13:07:21.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:21.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:21.958
  STEP: getting /apis @ 11/30/24 13:07:21.961
  STEP: getting /apis/storage.k8s.io @ 11/30/24 13:07:21.964
  STEP: getting /apis/storage.k8s.io/v1 @ 11/30/24 13:07:21.965
  STEP: creating @ 11/30/24 13:07:21.967
  E1130 13:07:21.977047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: watching @ 11/30/24 13:07:21.983
  I1130 13:07:21.983905 19 csistoragecapacity.go:143] starting watch
  STEP: getting @ 11/30/24 13:07:21.993
  STEP: listing in namespace @ 11/30/24 13:07:21.998
  STEP: listing across namespaces @ 11/30/24 13:07:22.001
  STEP: patching @ 11/30/24 13:07:22.004
  STEP: updating @ 11/30/24 13:07:22.011
  I1130 13:07:22.015559 19 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I1130 13:07:22.015626 19 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 11/30/24 13:07:22.015
  STEP: deleting a collection @ 11/30/24 13:07:22.031
  I1130 13:07:22.046313 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-2936" for this suite. @ 11/30/24 13:07:22.05
• [0.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 11/30/24 13:07:22.058
  I1130 13:07:22.058686 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename svcaccounts @ 11/30/24 13:07:22.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:22.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:22.076
  STEP: Creating a pod to test service account token:  @ 11/30/24 13:07:22.08
  E1130 13:07:22.977254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:23.977545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:24.977798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:25.977863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:07:26.1
  I1130 13:07:26.104362 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod test-pod-ce1ff41f-3ead-4514-89e0-670cd324601e container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 13:07:26.112
  I1130 13:07:26.131464 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8853" for this suite. @ 11/30/24 13:07:26.134
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 11/30/24 13:07:26.142
  I1130 13:07:26.142336 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename svc-latency @ 11/30/24 13:07:26.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:26.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:26.167
  I1130 13:07:26.170618 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-7302 @ 11/30/24 13:07:26.171
  I1130 13:07:26.178209      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7302, replica count: 1
  E1130 13:07:26.978089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:27.229503      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E1130 13:07:27.979004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:28.230425      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 13:07:28.346362 19 service_latency.go:356] Created: latency-svc-c9q82
  I1130 13:07:28.352132 19 service_latency.go:363] Got endpoints: latency-svc-c9q82 [20.634536ms]
  I1130 13:07:28.367067 19 service_latency.go:356] Created: latency-svc-tr6xj
  I1130 13:07:28.371966 19 service_latency.go:363] Got endpoints: latency-svc-tr6xj [19.682674ms]
  I1130 13:07:28.380503 19 service_latency.go:356] Created: latency-svc-p7w7m
  I1130 13:07:28.381889 19 service_latency.go:356] Created: latency-svc-4n7v2
  I1130 13:07:28.389699 19 service_latency.go:363] Got endpoints: latency-svc-p7w7m [37.019308ms]
  I1130 13:07:28.389712 19 service_latency.go:363] Got endpoints: latency-svc-4n7v2 [37.088926ms]
  I1130 13:07:28.392354 19 service_latency.go:356] Created: latency-svc-2kqbd
  I1130 13:07:28.399656 19 service_latency.go:363] Got endpoints: latency-svc-2kqbd [47.088438ms]
  I1130 13:07:28.404304 19 service_latency.go:356] Created: latency-svc-td9mw
  I1130 13:07:28.409742 19 service_latency.go:363] Got endpoints: latency-svc-td9mw [57.245502ms]
  I1130 13:07:28.410526 19 service_latency.go:356] Created: latency-svc-htxj8
  I1130 13:07:28.421322 19 service_latency.go:356] Created: latency-svc-88t77
  I1130 13:07:28.421335 19 service_latency.go:363] Got endpoints: latency-svc-htxj8 [68.607238ms]
  I1130 13:07:28.427879 19 service_latency.go:363] Got endpoints: latency-svc-88t77 [75.082064ms]
  I1130 13:07:28.432820 19 service_latency.go:356] Created: latency-svc-clp2n
  I1130 13:07:28.438050 19 service_latency.go:356] Created: latency-svc-v2x56
  I1130 13:07:28.438512 19 service_latency.go:363] Got endpoints: latency-svc-clp2n [85.693944ms]
  I1130 13:07:28.448704 19 service_latency.go:356] Created: latency-svc-jf42z
  I1130 13:07:28.448699 19 service_latency.go:363] Got endpoints: latency-svc-v2x56 [95.957694ms]
  I1130 13:07:28.457117 19 service_latency.go:363] Got endpoints: latency-svc-jf42z [104.261058ms]
  I1130 13:07:28.460542 19 service_latency.go:356] Created: latency-svc-64r2z
  I1130 13:07:28.467695 19 service_latency.go:363] Got endpoints: latency-svc-64r2z [114.798743ms]
  I1130 13:07:28.468595 19 service_latency.go:356] Created: latency-svc-jlkcd
  I1130 13:07:28.474131 19 service_latency.go:363] Got endpoints: latency-svc-jlkcd [121.1693ms]
  I1130 13:07:28.478525 19 service_latency.go:356] Created: latency-svc-7hd24
  I1130 13:07:28.485395 19 service_latency.go:363] Got endpoints: latency-svc-7hd24 [132.463912ms]
  I1130 13:07:28.489172 19 service_latency.go:356] Created: latency-svc-b95k4
  I1130 13:07:28.494989 19 service_latency.go:363] Got endpoints: latency-svc-b95k4 [142.080113ms]
  I1130 13:07:28.497120 19 service_latency.go:356] Created: latency-svc-bq7rz
  I1130 13:07:28.503781 19 service_latency.go:363] Got endpoints: latency-svc-bq7rz [150.934654ms]
  I1130 13:07:28.508411 19 service_latency.go:356] Created: latency-svc-dszcp
  I1130 13:07:28.513551 19 service_latency.go:363] Got endpoints: latency-svc-dszcp [141.551352ms]
  I1130 13:07:28.523836 19 service_latency.go:356] Created: latency-svc-nfg54
  I1130 13:07:28.528217 19 service_latency.go:363] Got endpoints: latency-svc-nfg54 [138.473288ms]
  I1130 13:07:28.533199 19 service_latency.go:356] Created: latency-svc-28ngs
  I1130 13:07:28.537387 19 service_latency.go:363] Got endpoints: latency-svc-28ngs [147.537698ms]
  I1130 13:07:28.540725 19 service_latency.go:356] Created: latency-svc-5v66c
  I1130 13:07:28.548273 19 service_latency.go:363] Got endpoints: latency-svc-5v66c [148.576984ms]
  I1130 13:07:28.552292 19 service_latency.go:356] Created: latency-svc-9nglr
  I1130 13:07:28.558710 19 service_latency.go:363] Got endpoints: latency-svc-9nglr [148.929731ms]
  I1130 13:07:28.562326 19 service_latency.go:356] Created: latency-svc-zfcds
  I1130 13:07:28.569166 19 service_latency.go:363] Got endpoints: latency-svc-zfcds [147.808325ms]
  I1130 13:07:28.571638 19 service_latency.go:356] Created: latency-svc-nrjxf
  I1130 13:07:28.575563 19 service_latency.go:363] Got endpoints: latency-svc-nrjxf [147.655388ms]
  I1130 13:07:28.581362 19 service_latency.go:356] Created: latency-svc-whhvh
  I1130 13:07:28.587189 19 service_latency.go:363] Got endpoints: latency-svc-whhvh [148.658086ms]
  I1130 13:07:28.592159 19 service_latency.go:356] Created: latency-svc-ntqhs
  I1130 13:07:28.597215 19 service_latency.go:363] Got endpoints: latency-svc-ntqhs [148.47283ms]
  I1130 13:07:28.601581 19 service_latency.go:356] Created: latency-svc-55vsb
  I1130 13:07:28.605978 19 service_latency.go:363] Got endpoints: latency-svc-55vsb [148.830773ms]
  I1130 13:07:28.615912 19 service_latency.go:356] Created: latency-svc-zt5rv
  I1130 13:07:28.620355 19 service_latency.go:363] Got endpoints: latency-svc-zt5rv [152.629748ms]
  I1130 13:07:28.625250 19 service_latency.go:356] Created: latency-svc-9j4qd
  I1130 13:07:28.633264 19 service_latency.go:356] Created: latency-svc-dv5jt
  I1130 13:07:28.633344 19 service_latency.go:363] Got endpoints: latency-svc-9j4qd [159.182336ms]
  I1130 13:07:28.637984 19 service_latency.go:363] Got endpoints: latency-svc-dv5jt [152.559107ms]
  I1130 13:07:28.645729 19 service_latency.go:356] Created: latency-svc-5lvm6
  I1130 13:07:28.651465 19 service_latency.go:363] Got endpoints: latency-svc-5lvm6 [156.442658ms]
  I1130 13:07:28.651962 19 service_latency.go:356] Created: latency-svc-vqfqs
  I1130 13:07:28.657588 19 service_latency.go:363] Got endpoints: latency-svc-vqfqs [153.779033ms]
  I1130 13:07:28.660070 19 service_latency.go:356] Created: latency-svc-dvvmp
  I1130 13:07:28.663827 19 service_latency.go:363] Got endpoints: latency-svc-dvvmp [150.244495ms]
  I1130 13:07:28.670298 19 service_latency.go:356] Created: latency-svc-l9d8l
  I1130 13:07:28.676846 19 service_latency.go:363] Got endpoints: latency-svc-l9d8l [148.589587ms]
  I1130 13:07:28.683680 19 service_latency.go:356] Created: latency-svc-kk557
  I1130 13:07:28.686687 19 service_latency.go:356] Created: latency-svc-zrtgk
  I1130 13:07:28.691350 19 service_latency.go:363] Got endpoints: latency-svc-kk557 [153.929511ms]
  I1130 13:07:28.695037 19 service_latency.go:363] Got endpoints: latency-svc-zrtgk [146.730162ms]
  I1130 13:07:28.699909 19 service_latency.go:356] Created: latency-svc-jgn7c
  I1130 13:07:28.704295 19 service_latency.go:363] Got endpoints: latency-svc-jgn7c [145.557713ms]
  I1130 13:07:28.708920 19 service_latency.go:356] Created: latency-svc-2cljk
  I1130 13:07:28.716950 19 service_latency.go:363] Got endpoints: latency-svc-2cljk [147.745905ms]
  I1130 13:07:28.720687 19 service_latency.go:356] Created: latency-svc-g5kr5
  I1130 13:07:28.724079 19 service_latency.go:356] Created: latency-svc-4xjwn
  I1130 13:07:28.729941 19 service_latency.go:356] Created: latency-svc-j6bq4
  I1130 13:07:28.736287 19 service_latency.go:356] Created: latency-svc-4wzx9
  I1130 13:07:28.743529 19 service_latency.go:356] Created: latency-svc-wht8j
  I1130 13:07:28.750143 19 service_latency.go:356] Created: latency-svc-vjrrm
  I1130 13:07:28.752301 19 service_latency.go:363] Got endpoints: latency-svc-g5kr5 [176.705651ms]
  I1130 13:07:28.756909 19 service_latency.go:356] Created: latency-svc-j582j
  I1130 13:07:28.766971 19 service_latency.go:356] Created: latency-svc-pskxv
  I1130 13:07:28.771117 19 service_latency.go:356] Created: latency-svc-ndvqt
  I1130 13:07:28.777842 19 service_latency.go:356] Created: latency-svc-8v9mb
  I1130 13:07:28.784514 19 service_latency.go:356] Created: latency-svc-j6fw5
  I1130 13:07:28.789676 19 service_latency.go:356] Created: latency-svc-gz7bn
  I1130 13:07:28.796736 19 service_latency.go:356] Created: latency-svc-jbxz6
  I1130 13:07:28.803695 19 service_latency.go:363] Got endpoints: latency-svc-4xjwn [216.480813ms]
  I1130 13:07:28.807796 19 service_latency.go:356] Created: latency-svc-l6xcx
  I1130 13:07:28.814764 19 service_latency.go:356] Created: latency-svc-2qkms
  I1130 13:07:28.820478 19 service_latency.go:356] Created: latency-svc-flh5f
  I1130 13:07:28.829228 19 service_latency.go:356] Created: latency-svc-467g5
  I1130 13:07:28.852433 19 service_latency.go:363] Got endpoints: latency-svc-j6bq4 [255.186953ms]
  I1130 13:07:28.863558 19 service_latency.go:356] Created: latency-svc-htzcj
  I1130 13:07:28.902558 19 service_latency.go:363] Got endpoints: latency-svc-4wzx9 [296.527998ms]
  I1130 13:07:28.918027 19 service_latency.go:356] Created: latency-svc-7k9v8
  I1130 13:07:28.960625 19 service_latency.go:363] Got endpoints: latency-svc-wht8j [340.205219ms]
  I1130 13:07:28.977630 19 service_latency.go:356] Created: latency-svc-w247r
  E1130 13:07:28.979672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:29.008421 19 service_latency.go:363] Got endpoints: latency-svc-vjrrm [374.980725ms]
  I1130 13:07:29.025517 19 service_latency.go:356] Created: latency-svc-m6g6p
  I1130 13:07:29.053905 19 service_latency.go:363] Got endpoints: latency-svc-j582j [415.880715ms]
  I1130 13:07:29.066115 19 service_latency.go:356] Created: latency-svc-62rl8
  I1130 13:07:29.101423 19 service_latency.go:363] Got endpoints: latency-svc-pskxv [449.9237ms]
  I1130 13:07:29.114431 19 service_latency.go:356] Created: latency-svc-l4f48
  I1130 13:07:29.157578 19 service_latency.go:363] Got endpoints: latency-svc-ndvqt [499.95089ms]
  I1130 13:07:29.174418 19 service_latency.go:356] Created: latency-svc-tgtbf
  I1130 13:07:29.206669 19 service_latency.go:363] Got endpoints: latency-svc-8v9mb [542.807767ms]
  I1130 13:07:29.219989 19 service_latency.go:356] Created: latency-svc-tqlrt
  I1130 13:07:29.253630 19 service_latency.go:363] Got endpoints: latency-svc-j6fw5 [576.728612ms]
  I1130 13:07:29.266698 19 service_latency.go:356] Created: latency-svc-dlhkj
  I1130 13:07:29.301326 19 service_latency.go:363] Got endpoints: latency-svc-gz7bn [609.929875ms]
  I1130 13:07:29.313246 19 service_latency.go:356] Created: latency-svc-4qzpb
  I1130 13:07:29.352562 19 service_latency.go:363] Got endpoints: latency-svc-jbxz6 [657.492595ms]
  I1130 13:07:29.365448 19 service_latency.go:356] Created: latency-svc-bqvk5
  I1130 13:07:29.403343 19 service_latency.go:363] Got endpoints: latency-svc-l6xcx [699.016327ms]
  I1130 13:07:29.416715 19 service_latency.go:356] Created: latency-svc-gfc4v
  I1130 13:07:29.453755 19 service_latency.go:363] Got endpoints: latency-svc-2qkms [734.968342ms]
  I1130 13:07:29.465069 19 service_latency.go:356] Created: latency-svc-8c5bc
  I1130 13:07:29.503566 19 service_latency.go:363] Got endpoints: latency-svc-flh5f [751.145154ms]
  I1130 13:07:29.514438 19 service_latency.go:356] Created: latency-svc-ktzmq
  I1130 13:07:29.551595 19 service_latency.go:363] Got endpoints: latency-svc-467g5 [747.866319ms]
  I1130 13:07:29.564638 19 service_latency.go:356] Created: latency-svc-4g7kz
  I1130 13:07:29.602111 19 service_latency.go:363] Got endpoints: latency-svc-htzcj [749.627909ms]
  I1130 13:07:29.615493 19 service_latency.go:356] Created: latency-svc-hqlsm
  I1130 13:07:29.650910 19 service_latency.go:363] Got endpoints: latency-svc-7k9v8 [748.265839ms]
  I1130 13:07:29.661430 19 service_latency.go:356] Created: latency-svc-t85br
  I1130 13:07:29.700840 19 service_latency.go:363] Got endpoints: latency-svc-w247r [740.159539ms]
  I1130 13:07:29.713951 19 service_latency.go:356] Created: latency-svc-gb7t5
  I1130 13:07:29.753500 19 service_latency.go:363] Got endpoints: latency-svc-m6g6p [745.024911ms]
  I1130 13:07:29.764167 19 service_latency.go:356] Created: latency-svc-xtbmn
  I1130 13:07:29.802295 19 service_latency.go:363] Got endpoints: latency-svc-62rl8 [748.338406ms]
  I1130 13:07:29.813797 19 service_latency.go:356] Created: latency-svc-d5zp2
  I1130 13:07:29.850978 19 service_latency.go:363] Got endpoints: latency-svc-l4f48 [749.500454ms]
  I1130 13:07:29.865403 19 service_latency.go:356] Created: latency-svc-6fm2t
  I1130 13:07:29.905335 19 service_latency.go:363] Got endpoints: latency-svc-tgtbf [747.706288ms]
  I1130 13:07:29.919982 19 service_latency.go:356] Created: latency-svc-lktwr
  I1130 13:07:29.952651 19 service_latency.go:363] Got endpoints: latency-svc-tqlrt [745.927562ms]
  I1130 13:07:29.969552 19 service_latency.go:356] Created: latency-svc-kfpgt
  E1130 13:07:29.980655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:30.006361 19 service_latency.go:363] Got endpoints: latency-svc-dlhkj [752.526941ms]
  I1130 13:07:30.023406 19 service_latency.go:356] Created: latency-svc-ngbsg
  I1130 13:07:30.053065 19 service_latency.go:363] Got endpoints: latency-svc-4qzpb [751.674174ms]
  I1130 13:07:30.063635 19 service_latency.go:356] Created: latency-svc-5tx2k
  I1130 13:07:30.101877 19 service_latency.go:363] Got endpoints: latency-svc-bqvk5 [749.15463ms]
  I1130 13:07:30.142742 19 service_latency.go:356] Created: latency-svc-8sdrq
  I1130 13:07:30.152362 19 service_latency.go:363] Got endpoints: latency-svc-gfc4v [748.942933ms]
  I1130 13:07:30.164723 19 service_latency.go:356] Created: latency-svc-mqf6p
  I1130 13:07:30.201754 19 service_latency.go:363] Got endpoints: latency-svc-8c5bc [747.94153ms]
  I1130 13:07:30.213397 19 service_latency.go:356] Created: latency-svc-cr4s6
  I1130 13:07:30.254211 19 service_latency.go:363] Got endpoints: latency-svc-ktzmq [750.569989ms]
  I1130 13:07:30.264857 19 service_latency.go:356] Created: latency-svc-mvvcl
  I1130 13:07:30.300262 19 service_latency.go:363] Got endpoints: latency-svc-4g7kz [748.607485ms]
  I1130 13:07:30.313409 19 service_latency.go:356] Created: latency-svc-4m8mb
  I1130 13:07:30.352928 19 service_latency.go:363] Got endpoints: latency-svc-hqlsm [750.76867ms]
  I1130 13:07:30.365279 19 service_latency.go:356] Created: latency-svc-lclnt
  I1130 13:07:30.401898 19 service_latency.go:363] Got endpoints: latency-svc-t85br [750.93541ms]
  I1130 13:07:30.413642 19 service_latency.go:356] Created: latency-svc-fbl58
  I1130 13:07:30.450483 19 service_latency.go:363] Got endpoints: latency-svc-gb7t5 [749.584029ms]
  I1130 13:07:30.463103 19 service_latency.go:356] Created: latency-svc-p76dv
  I1130 13:07:30.502625 19 service_latency.go:363] Got endpoints: latency-svc-xtbmn [749.074849ms]
  I1130 13:07:30.514818 19 service_latency.go:356] Created: latency-svc-pgw8r
  I1130 13:07:30.551833 19 service_latency.go:363] Got endpoints: latency-svc-d5zp2 [749.487544ms]
  I1130 13:07:30.562441 19 service_latency.go:356] Created: latency-svc-hrltx
  I1130 13:07:30.600833 19 service_latency.go:363] Got endpoints: latency-svc-6fm2t [749.764471ms]
  I1130 13:07:30.614203 19 service_latency.go:356] Created: latency-svc-xqvcz
  I1130 13:07:30.653401 19 service_latency.go:363] Got endpoints: latency-svc-lktwr [747.981613ms]
  I1130 13:07:30.663898 19 service_latency.go:356] Created: latency-svc-2pjls
  I1130 13:07:30.701861 19 service_latency.go:363] Got endpoints: latency-svc-kfpgt [749.157709ms]
  I1130 13:07:30.713100 19 service_latency.go:356] Created: latency-svc-5zjc6
  I1130 13:07:30.751037 19 service_latency.go:363] Got endpoints: latency-svc-ngbsg [744.610935ms]
  I1130 13:07:30.764082 19 service_latency.go:356] Created: latency-svc-l9sdk
  I1130 13:07:30.804513 19 service_latency.go:363] Got endpoints: latency-svc-5tx2k [751.356636ms]
  I1130 13:07:30.823915 19 service_latency.go:356] Created: latency-svc-khsfk
  I1130 13:07:30.852093 19 service_latency.go:363] Got endpoints: latency-svc-8sdrq [750.158152ms]
  I1130 13:07:30.867294 19 service_latency.go:356] Created: latency-svc-zq5cm
  I1130 13:07:30.902668 19 service_latency.go:363] Got endpoints: latency-svc-mqf6p [750.236257ms]
  I1130 13:07:30.915132 19 service_latency.go:356] Created: latency-svc-wm77t
  I1130 13:07:30.957157 19 service_latency.go:363] Got endpoints: latency-svc-cr4s6 [755.342258ms]
  I1130 13:07:30.968849 19 service_latency.go:356] Created: latency-svc-zgkc5
  E1130 13:07:30.980960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:31.001154 19 service_latency.go:363] Got endpoints: latency-svc-mvvcl [746.899373ms]
  I1130 13:07:31.016244 19 service_latency.go:356] Created: latency-svc-86x8d
  I1130 13:07:31.053627 19 service_latency.go:363] Got endpoints: latency-svc-4m8mb [753.313017ms]
  I1130 13:07:31.066489 19 service_latency.go:356] Created: latency-svc-56jqc
  I1130 13:07:31.119125 19 service_latency.go:363] Got endpoints: latency-svc-lclnt [766.130105ms]
  I1130 13:07:31.130986 19 service_latency.go:356] Created: latency-svc-fn2sl
  I1130 13:07:31.154140 19 service_latency.go:363] Got endpoints: latency-svc-fbl58 [752.193953ms]
  I1130 13:07:31.164863 19 service_latency.go:356] Created: latency-svc-2zh52
  I1130 13:07:31.205732 19 service_latency.go:363] Got endpoints: latency-svc-p76dv [755.203557ms]
  I1130 13:07:31.217753 19 service_latency.go:356] Created: latency-svc-mp5f2
  I1130 13:07:31.250945 19 service_latency.go:363] Got endpoints: latency-svc-pgw8r [748.264661ms]
  I1130 13:07:31.263939 19 service_latency.go:356] Created: latency-svc-ntwdr
  I1130 13:07:31.301005 19 service_latency.go:363] Got endpoints: latency-svc-hrltx [749.122627ms]
  I1130 13:07:31.314442 19 service_latency.go:356] Created: latency-svc-vc2cw
  I1130 13:07:31.351106 19 service_latency.go:363] Got endpoints: latency-svc-xqvcz [750.216097ms]
  I1130 13:07:31.366972 19 service_latency.go:356] Created: latency-svc-rl88l
  I1130 13:07:31.402878 19 service_latency.go:363] Got endpoints: latency-svc-2pjls [749.425195ms]
  I1130 13:07:31.411690 19 service_latency.go:356] Created: latency-svc-6mb6k
  I1130 13:07:31.450928 19 service_latency.go:363] Got endpoints: latency-svc-5zjc6 [749.00988ms]
  I1130 13:07:31.464113 19 service_latency.go:356] Created: latency-svc-zlmnz
  I1130 13:07:31.501449 19 service_latency.go:363] Got endpoints: latency-svc-l9sdk [750.360781ms]
  I1130 13:07:31.513930 19 service_latency.go:356] Created: latency-svc-l4hf2
  I1130 13:07:31.551116 19 service_latency.go:363] Got endpoints: latency-svc-khsfk [746.524014ms]
  I1130 13:07:31.565153 19 service_latency.go:356] Created: latency-svc-kx646
  I1130 13:07:31.602473 19 service_latency.go:363] Got endpoints: latency-svc-zq5cm [750.289428ms]
  I1130 13:07:31.616158 19 service_latency.go:356] Created: latency-svc-kgrlg
  I1130 13:07:31.654558 19 service_latency.go:363] Got endpoints: latency-svc-wm77t [751.827068ms]
  I1130 13:07:31.666285 19 service_latency.go:356] Created: latency-svc-nhvwj
  I1130 13:07:31.702868 19 service_latency.go:363] Got endpoints: latency-svc-zgkc5 [745.652961ms]
  I1130 13:07:31.714164 19 service_latency.go:356] Created: latency-svc-lfbrb
  I1130 13:07:31.753820 19 service_latency.go:363] Got endpoints: latency-svc-86x8d [752.596626ms]
  I1130 13:07:31.766035 19 service_latency.go:356] Created: latency-svc-g8k2l
  I1130 13:07:31.802120 19 service_latency.go:363] Got endpoints: latency-svc-56jqc [748.446581ms]
  I1130 13:07:31.815302 19 service_latency.go:356] Created: latency-svc-ffhsw
  I1130 13:07:31.850162 19 service_latency.go:363] Got endpoints: latency-svc-fn2sl [730.986937ms]
  I1130 13:07:31.859954 19 service_latency.go:356] Created: latency-svc-8pl5z
  I1130 13:07:31.902860 19 service_latency.go:363] Got endpoints: latency-svc-2zh52 [748.669786ms]
  I1130 13:07:31.914301 19 service_latency.go:356] Created: latency-svc-k6tcs
  I1130 13:07:31.954088 19 service_latency.go:363] Got endpoints: latency-svc-mp5f2 [748.302359ms]
  I1130 13:07:31.966252 19 service_latency.go:356] Created: latency-svc-mjtx7
  E1130 13:07:31.981350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:32.001779 19 service_latency.go:363] Got endpoints: latency-svc-ntwdr [750.776912ms]
  I1130 13:07:32.013631 19 service_latency.go:356] Created: latency-svc-lrm7k
  I1130 13:07:32.052771 19 service_latency.go:363] Got endpoints: latency-svc-vc2cw [751.705086ms]
  I1130 13:07:32.065040 19 service_latency.go:356] Created: latency-svc-j99qx
  I1130 13:07:32.102081 19 service_latency.go:363] Got endpoints: latency-svc-rl88l [750.908249ms]
  I1130 13:07:32.114787 19 service_latency.go:356] Created: latency-svc-4h772
  I1130 13:07:32.156419 19 service_latency.go:363] Got endpoints: latency-svc-6mb6k [753.476887ms]
  I1130 13:07:32.167132 19 service_latency.go:356] Created: latency-svc-csxbx
  I1130 13:07:32.201632 19 service_latency.go:363] Got endpoints: latency-svc-zlmnz [750.626694ms]
  I1130 13:07:32.214780 19 service_latency.go:356] Created: latency-svc-5n2sk
  I1130 13:07:32.251863 19 service_latency.go:363] Got endpoints: latency-svc-l4hf2 [750.354287ms]
  I1130 13:07:32.264871 19 service_latency.go:356] Created: latency-svc-2nnw4
  I1130 13:07:32.300267 19 service_latency.go:363] Got endpoints: latency-svc-kx646 [749.109064ms]
  I1130 13:07:32.310457 19 service_latency.go:356] Created: latency-svc-tbmg8
  I1130 13:07:32.355041 19 service_latency.go:363] Got endpoints: latency-svc-kgrlg [752.519629ms]
  I1130 13:07:32.368512 19 service_latency.go:356] Created: latency-svc-9jx7n
  I1130 13:07:32.402584 19 service_latency.go:363] Got endpoints: latency-svc-nhvwj [747.945281ms]
  I1130 13:07:32.414978 19 service_latency.go:356] Created: latency-svc-2xm9k
  I1130 13:07:32.450951 19 service_latency.go:363] Got endpoints: latency-svc-lfbrb [748.025618ms]
  I1130 13:07:32.463407 19 service_latency.go:356] Created: latency-svc-825nw
  I1130 13:07:32.502047 19 service_latency.go:363] Got endpoints: latency-svc-g8k2l [748.17057ms]
  I1130 13:07:32.513567 19 service_latency.go:356] Created: latency-svc-h5nlj
  I1130 13:07:32.554245 19 service_latency.go:363] Got endpoints: latency-svc-ffhsw [752.046617ms]
  I1130 13:07:32.564410 19 service_latency.go:356] Created: latency-svc-zrzxm
  I1130 13:07:32.604529 19 service_latency.go:363] Got endpoints: latency-svc-8pl5z [754.312102ms]
  I1130 13:07:32.615297 19 service_latency.go:356] Created: latency-svc-jtjrh
  I1130 13:07:32.652518 19 service_latency.go:363] Got endpoints: latency-svc-k6tcs [749.607486ms]
  I1130 13:07:32.664676 19 service_latency.go:356] Created: latency-svc-22nk4
  I1130 13:07:32.701089 19 service_latency.go:363] Got endpoints: latency-svc-mjtx7 [746.942611ms]
  I1130 13:07:32.714608 19 service_latency.go:356] Created: latency-svc-r95qc
  I1130 13:07:32.752504 19 service_latency.go:363] Got endpoints: latency-svc-lrm7k [750.678129ms]
  I1130 13:07:32.763139 19 service_latency.go:356] Created: latency-svc-zj6bh
  I1130 13:07:32.803264 19 service_latency.go:363] Got endpoints: latency-svc-j99qx [750.445013ms]
  I1130 13:07:32.815406 19 service_latency.go:356] Created: latency-svc-7qr4f
  I1130 13:07:32.851739 19 service_latency.go:363] Got endpoints: latency-svc-4h772 [749.602967ms]
  I1130 13:07:32.903253 19 service_latency.go:363] Got endpoints: latency-svc-csxbx [746.636091ms]
  I1130 13:07:32.936558 19 service_latency.go:356] Created: latency-svc-5bc67
  I1130 13:07:32.944794 19 service_latency.go:356] Created: latency-svc-22gdt
  I1130 13:07:32.951352 19 service_latency.go:363] Got endpoints: latency-svc-5n2sk [749.679128ms]
  I1130 13:07:32.963042 19 service_latency.go:356] Created: latency-svc-r2qkm
  E1130 13:07:32.982163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:33.003628 19 service_latency.go:363] Got endpoints: latency-svc-2nnw4 [751.705935ms]
  I1130 13:07:33.014819 19 service_latency.go:356] Created: latency-svc-6cv28
  I1130 13:07:33.050119 19 service_latency.go:363] Got endpoints: latency-svc-tbmg8 [749.800842ms]
  I1130 13:07:33.058702 19 service_latency.go:356] Created: latency-svc-2xs2c
  I1130 13:07:33.100742 19 service_latency.go:363] Got endpoints: latency-svc-9jx7n [745.64516ms]
  I1130 13:07:33.114073 19 service_latency.go:356] Created: latency-svc-4562n
  I1130 13:07:33.151498 19 service_latency.go:363] Got endpoints: latency-svc-2xm9k [748.86189ms]
  I1130 13:07:33.162903 19 service_latency.go:356] Created: latency-svc-96tqz
  I1130 13:07:33.203398 19 service_latency.go:363] Got endpoints: latency-svc-825nw [752.393008ms]
  I1130 13:07:33.213600 19 service_latency.go:356] Created: latency-svc-zbq6t
  I1130 13:07:33.252841 19 service_latency.go:363] Got endpoints: latency-svc-h5nlj [750.740537ms]
  I1130 13:07:33.263760 19 service_latency.go:356] Created: latency-svc-smf62
  I1130 13:07:33.300864 19 service_latency.go:363] Got endpoints: latency-svc-zrzxm [746.571031ms]
  I1130 13:07:33.313913 19 service_latency.go:356] Created: latency-svc-zshsl
  I1130 13:07:33.350709 19 service_latency.go:363] Got endpoints: latency-svc-jtjrh [746.108053ms]
  I1130 13:07:33.361310 19 service_latency.go:356] Created: latency-svc-hzz5l
  I1130 13:07:33.401761 19 service_latency.go:363] Got endpoints: latency-svc-22nk4 [749.197614ms]
  I1130 13:07:33.413172 19 service_latency.go:356] Created: latency-svc-kvshr
  I1130 13:07:33.453651 19 service_latency.go:363] Got endpoints: latency-svc-r95qc [752.50736ms]
  I1130 13:07:33.464951 19 service_latency.go:356] Created: latency-svc-8t68z
  I1130 13:07:33.501759 19 service_latency.go:363] Got endpoints: latency-svc-zj6bh [749.197145ms]
  I1130 13:07:33.512320 19 service_latency.go:356] Created: latency-svc-92fr9
  I1130 13:07:33.550759 19 service_latency.go:363] Got endpoints: latency-svc-7qr4f [747.442779ms]
  I1130 13:07:33.563345 19 service_latency.go:356] Created: latency-svc-jxkdh
  I1130 13:07:33.601419 19 service_latency.go:363] Got endpoints: latency-svc-5bc67 [749.553312ms]
  I1130 13:07:33.613345 19 service_latency.go:356] Created: latency-svc-swc7f
  I1130 13:07:33.649715 19 service_latency.go:363] Got endpoints: latency-svc-22gdt [746.408356ms]
  I1130 13:07:33.660695 19 service_latency.go:356] Created: latency-svc-fg9q2
  I1130 13:07:33.702501 19 service_latency.go:363] Got endpoints: latency-svc-r2qkm [751.084535ms]
  I1130 13:07:33.713655 19 service_latency.go:356] Created: latency-svc-56gld
  I1130 13:07:33.754316 19 service_latency.go:363] Got endpoints: latency-svc-6cv28 [750.625166ms]
  I1130 13:07:33.766204 19 service_latency.go:356] Created: latency-svc-44hrd
  I1130 13:07:33.801005 19 service_latency.go:363] Got endpoints: latency-svc-2xs2c [750.83373ms]
  I1130 13:07:33.812784 19 service_latency.go:356] Created: latency-svc-hf9wx
  I1130 13:07:33.851771 19 service_latency.go:363] Got endpoints: latency-svc-4562n [750.977329ms]
  I1130 13:07:33.865473 19 service_latency.go:356] Created: latency-svc-v6f47
  I1130 13:07:33.902260 19 service_latency.go:363] Got endpoints: latency-svc-96tqz [750.320971ms]
  I1130 13:07:33.913454 19 service_latency.go:356] Created: latency-svc-sm54f
  I1130 13:07:33.953412 19 service_latency.go:363] Got endpoints: latency-svc-zbq6t [749.959846ms]
  I1130 13:07:33.962843 19 service_latency.go:356] Created: latency-svc-2zqgp
  E1130 13:07:33.982965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:34.003093 19 service_latency.go:363] Got endpoints: latency-svc-smf62 [750.200842ms]
  I1130 13:07:34.014068 19 service_latency.go:356] Created: latency-svc-tssnt
  I1130 13:07:34.052274 19 service_latency.go:363] Got endpoints: latency-svc-zshsl [751.327384ms]
  I1130 13:07:34.066108 19 service_latency.go:356] Created: latency-svc-8q4bf
  I1130 13:07:34.101406 19 service_latency.go:363] Got endpoints: latency-svc-hzz5l [750.155455ms]
  I1130 13:07:34.112515 19 service_latency.go:356] Created: latency-svc-zvwmg
  I1130 13:07:34.153930 19 service_latency.go:363] Got endpoints: latency-svc-kvshr [752.116153ms]
  I1130 13:07:34.164527 19 service_latency.go:356] Created: latency-svc-rlxqn
  I1130 13:07:34.203724 19 service_latency.go:363] Got endpoints: latency-svc-8t68z [750.0237ms]
  I1130 13:07:34.215434 19 service_latency.go:356] Created: latency-svc-7p77f
  I1130 13:07:34.252612 19 service_latency.go:363] Got endpoints: latency-svc-92fr9 [750.79159ms]
  I1130 13:07:34.263093 19 service_latency.go:356] Created: latency-svc-5chb4
  I1130 13:07:34.301041 19 service_latency.go:363] Got endpoints: latency-svc-jxkdh [750.213774ms]
  I1130 13:07:34.314624 19 service_latency.go:356] Created: latency-svc-2x8f5
  I1130 13:07:34.352770 19 service_latency.go:363] Got endpoints: latency-svc-swc7f [751.075078ms]
  I1130 13:07:34.365530 19 service_latency.go:356] Created: latency-svc-wdbvz
  I1130 13:07:34.401136 19 service_latency.go:363] Got endpoints: latency-svc-fg9q2 [751.371499ms]
  I1130 13:07:34.411555 19 service_latency.go:356] Created: latency-svc-hhp5k
  I1130 13:07:34.453745 19 service_latency.go:363] Got endpoints: latency-svc-56gld [751.181513ms]
  I1130 13:07:34.464633 19 service_latency.go:356] Created: latency-svc-kj65z
  I1130 13:07:34.503750 19 service_latency.go:363] Got endpoints: latency-svc-44hrd [749.381436ms]
  I1130 13:07:34.515902 19 service_latency.go:356] Created: latency-svc-gs7kb
  I1130 13:07:34.551110 19 service_latency.go:363] Got endpoints: latency-svc-hf9wx [749.976301ms]
  I1130 13:07:34.563037 19 service_latency.go:356] Created: latency-svc-qwgqn
  I1130 13:07:34.600977 19 service_latency.go:363] Got endpoints: latency-svc-v6f47 [749.159069ms]
  I1130 13:07:34.614312 19 service_latency.go:356] Created: latency-svc-p8b97
  I1130 13:07:34.653510 19 service_latency.go:363] Got endpoints: latency-svc-sm54f [751.209216ms]
  I1130 13:07:34.664228 19 service_latency.go:356] Created: latency-svc-gx4qt
  I1130 13:07:34.703945 19 service_latency.go:363] Got endpoints: latency-svc-2zqgp [750.263761ms]
  I1130 13:07:34.716047 19 service_latency.go:356] Created: latency-svc-bqxpr
  I1130 13:07:34.751566 19 service_latency.go:363] Got endpoints: latency-svc-tssnt [748.414192ms]
  I1130 13:07:34.763289 19 service_latency.go:356] Created: latency-svc-x5fxq
  I1130 13:07:34.801021 19 service_latency.go:363] Got endpoints: latency-svc-8q4bf [748.685203ms]
  I1130 13:07:34.812109 19 service_latency.go:356] Created: latency-svc-m55np
  I1130 13:07:34.852518 19 service_latency.go:363] Got endpoints: latency-svc-zvwmg [751.061925ms]
  I1130 13:07:34.861924 19 service_latency.go:356] Created: latency-svc-zjj97
  I1130 13:07:34.902821 19 service_latency.go:363] Got endpoints: latency-svc-rlxqn [748.834575ms]
  I1130 13:07:34.914563 19 service_latency.go:356] Created: latency-svc-9wt5b
  I1130 13:07:34.950960 19 service_latency.go:363] Got endpoints: latency-svc-7p77f [747.185896ms]
  I1130 13:07:34.964785 19 service_latency.go:356] Created: latency-svc-j47v5
  E1130 13:07:34.983122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:35.000872 19 service_latency.go:363] Got endpoints: latency-svc-5chb4 [748.211424ms]
  I1130 13:07:35.010417 19 service_latency.go:356] Created: latency-svc-vjj7d
  I1130 13:07:35.053688 19 service_latency.go:363] Got endpoints: latency-svc-2x8f5 [752.582547ms]
  I1130 13:07:35.064050 19 service_latency.go:356] Created: latency-svc-rw4gc
  I1130 13:07:35.103205 19 service_latency.go:363] Got endpoints: latency-svc-wdbvz [750.291679ms]
  I1130 13:07:35.113771 19 service_latency.go:356] Created: latency-svc-6cqns
  I1130 13:07:35.153511 19 service_latency.go:363] Got endpoints: latency-svc-hhp5k [752.315572ms]
  I1130 13:07:35.162045 19 service_latency.go:356] Created: latency-svc-nhd5h
  I1130 13:07:35.200645 19 service_latency.go:363] Got endpoints: latency-svc-kj65z [746.844076ms]
  I1130 13:07:35.213200 19 service_latency.go:356] Created: latency-svc-jxpb2
  I1130 13:07:35.251651 19 service_latency.go:363] Got endpoints: latency-svc-gs7kb [747.848632ms]
  I1130 13:07:35.265548 19 service_latency.go:356] Created: latency-svc-k28ft
  I1130 13:07:35.302276 19 service_latency.go:363] Got endpoints: latency-svc-qwgqn [751.109584ms]
  I1130 13:07:35.312257 19 service_latency.go:356] Created: latency-svc-xf2jf
  I1130 13:07:35.353326 19 service_latency.go:363] Got endpoints: latency-svc-p8b97 [751.794715ms]
  I1130 13:07:35.366752 19 service_latency.go:356] Created: latency-svc-dp8fx
  I1130 13:07:35.401577 19 service_latency.go:363] Got endpoints: latency-svc-gx4qt [748.016396ms]
  I1130 13:07:35.413288 19 service_latency.go:356] Created: latency-svc-4mw4d
  I1130 13:07:35.449572 19 service_latency.go:363] Got endpoints: latency-svc-bqxpr [745.55296ms]
  I1130 13:07:35.459098 19 service_latency.go:356] Created: latency-svc-42b9g
  I1130 13:07:35.503608 19 service_latency.go:363] Got endpoints: latency-svc-x5fxq [751.992024ms]
  I1130 13:07:35.512566 19 service_latency.go:356] Created: latency-svc-zbv5n
  I1130 13:07:35.552300 19 service_latency.go:363] Got endpoints: latency-svc-m55np [751.22387ms]
  I1130 13:07:35.563451 19 service_latency.go:356] Created: latency-svc-5wl2f
  I1130 13:07:35.601538 19 service_latency.go:363] Got endpoints: latency-svc-zjj97 [748.96704ms]
  I1130 13:07:35.615093 19 service_latency.go:356] Created: latency-svc-vbdf7
  I1130 13:07:35.652937 19 service_latency.go:363] Got endpoints: latency-svc-9wt5b [750.056879ms]
  I1130 13:07:35.662888 19 service_latency.go:356] Created: latency-svc-zklnb
  I1130 13:07:35.700823 19 service_latency.go:363] Got endpoints: latency-svc-j47v5 [749.804158ms]
  I1130 13:07:35.714179 19 service_latency.go:356] Created: latency-svc-s24vj
  I1130 13:07:35.751617 19 service_latency.go:363] Got endpoints: latency-svc-vjj7d [750.68196ms]
  I1130 13:07:35.764618 19 service_latency.go:356] Created: latency-svc-psncw
  I1130 13:07:35.801425 19 service_latency.go:363] Got endpoints: latency-svc-rw4gc [747.69532ms]
  I1130 13:07:35.810768 19 service_latency.go:356] Created: latency-svc-k277r
  I1130 13:07:35.853503 19 service_latency.go:363] Got endpoints: latency-svc-6cqns [750.244283ms]
  I1130 13:07:35.865519 19 service_latency.go:356] Created: latency-svc-vpk4q
  I1130 13:07:35.904097 19 service_latency.go:363] Got endpoints: latency-svc-nhd5h [750.504961ms]
  I1130 13:07:35.913751 19 service_latency.go:356] Created: latency-svc-xbz88
  I1130 13:07:35.953226 19 service_latency.go:363] Got endpoints: latency-svc-jxpb2 [752.530122ms]
  I1130 13:07:35.966028 19 service_latency.go:356] Created: latency-svc-jbltc
  E1130 13:07:35.983262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:36.001220 19 service_latency.go:363] Got endpoints: latency-svc-k28ft [749.377591ms]
  I1130 13:07:36.016691 19 service_latency.go:356] Created: latency-svc-z2474
  I1130 13:07:36.051548 19 service_latency.go:363] Got endpoints: latency-svc-xf2jf [749.216544ms]
  I1130 13:07:36.062963 19 service_latency.go:356] Created: latency-svc-r5dgv
  I1130 13:07:36.104855 19 service_latency.go:363] Got endpoints: latency-svc-dp8fx [751.371267ms]
  I1130 13:07:36.114551 19 service_latency.go:356] Created: latency-svc-2f2vv
  I1130 13:07:36.152524 19 service_latency.go:363] Got endpoints: latency-svc-4mw4d [750.875042ms]
  I1130 13:07:36.163538 19 service_latency.go:356] Created: latency-svc-xj7qp
  I1130 13:07:36.202436 19 service_latency.go:363] Got endpoints: latency-svc-42b9g [752.720195ms]
  I1130 13:07:36.252015 19 service_latency.go:363] Got endpoints: latency-svc-zbv5n [748.323568ms]
  I1130 13:07:36.305428 19 service_latency.go:363] Got endpoints: latency-svc-5wl2f [753.025045ms]
  I1130 13:07:36.352303 19 service_latency.go:363] Got endpoints: latency-svc-vbdf7 [750.713218ms]
  I1130 13:07:36.404243 19 service_latency.go:363] Got endpoints: latency-svc-zklnb [751.2467ms]
  I1130 13:07:36.451631 19 service_latency.go:363] Got endpoints: latency-svc-s24vj [750.753002ms]
  I1130 13:07:36.504637 19 service_latency.go:363] Got endpoints: latency-svc-psncw [752.969448ms]
  I1130 13:07:36.552016 19 service_latency.go:363] Got endpoints: latency-svc-k277r [750.544574ms]
  I1130 13:07:36.603824 19 service_latency.go:363] Got endpoints: latency-svc-vpk4q [750.28175ms]
  I1130 13:07:36.651835 19 service_latency.go:363] Got endpoints: latency-svc-xbz88 [747.687515ms]
  I1130 13:07:36.704708 19 service_latency.go:363] Got endpoints: latency-svc-jbltc [751.426555ms]
  I1130 13:07:36.753991 19 service_latency.go:363] Got endpoints: latency-svc-z2474 [752.722826ms]
  I1130 13:07:36.804725 19 service_latency.go:363] Got endpoints: latency-svc-r5dgv [753.126093ms]
  I1130 13:07:36.850905 19 service_latency.go:363] Got endpoints: latency-svc-2f2vv [745.979238ms]
  I1130 13:07:36.904698 19 service_latency.go:363] Got endpoints: latency-svc-xj7qp [752.11627ms]
  I1130 13:07:36.904800 19 service_latency.go:114] Latencies: [19.682674ms 37.019308ms 37.088926ms 47.088438ms 57.245502ms 68.607238ms 75.082064ms 85.693944ms 95.957694ms 104.261058ms 114.798743ms 121.1693ms 132.463912ms 138.473288ms 141.551352ms 142.080113ms 145.557713ms 146.730162ms 147.537698ms 147.655388ms 147.745905ms 147.808325ms 148.47283ms 148.576984ms 148.589587ms 148.658086ms 148.830773ms 148.929731ms 150.244495ms 150.934654ms 152.559107ms 152.629748ms 153.779033ms 153.929511ms 156.442658ms 159.182336ms 176.705651ms 216.480813ms 255.186953ms 296.527998ms 340.205219ms 374.980725ms 415.880715ms 449.9237ms 499.95089ms 542.807767ms 576.728612ms 609.929875ms 657.492595ms 699.016327ms 730.986937ms 734.968342ms 740.159539ms 744.610935ms 745.024911ms 745.55296ms 745.64516ms 745.652961ms 745.927562ms 745.979238ms 746.108053ms 746.408356ms 746.524014ms 746.571031ms 746.636091ms 746.844076ms 746.899373ms 746.942611ms 747.185896ms 747.442779ms 747.687515ms 747.69532ms 747.706288ms 747.848632ms 747.866319ms 747.94153ms 747.945281ms 747.981613ms 748.016396ms 748.025618ms 748.17057ms 748.211424ms 748.264661ms 748.265839ms 748.302359ms 748.323568ms 748.338406ms 748.414192ms 748.446581ms 748.607485ms 748.669786ms 748.685203ms 748.834575ms 748.86189ms 748.942933ms 748.96704ms 749.00988ms 749.074849ms 749.109064ms 749.122627ms 749.15463ms 749.157709ms 749.159069ms 749.197145ms 749.197614ms 749.216544ms 749.377591ms 749.381436ms 749.425195ms 749.487544ms 749.500454ms 749.553312ms 749.584029ms 749.602967ms 749.607486ms 749.627909ms 749.679128ms 749.764471ms 749.800842ms 749.804158ms 749.959846ms 749.976301ms 750.0237ms 750.056879ms 750.155455ms 750.158152ms 750.200842ms 750.213774ms 750.216097ms 750.236257ms 750.244283ms 750.263761ms 750.28175ms 750.289428ms 750.291679ms 750.320971ms 750.354287ms 750.360781ms 750.445013ms 750.504961ms 750.544574ms 750.569989ms 750.625166ms 750.626694ms 750.678129ms 750.68196ms 750.713218ms 750.740537ms 750.753002ms 750.76867ms 750.776912ms 750.79159ms 750.83373ms 750.875042ms 750.908249ms 750.93541ms 750.977329ms 751.061925ms 751.075078ms 751.084535ms 751.109584ms 751.145154ms 751.181513ms 751.209216ms 751.22387ms 751.2467ms 751.327384ms 751.356636ms 751.371267ms 751.371499ms 751.426555ms 751.674174ms 751.705086ms 751.705935ms 751.794715ms 751.827068ms 751.992024ms 752.046617ms 752.116153ms 752.11627ms 752.193953ms 752.315572ms 752.393008ms 752.50736ms 752.519629ms 752.526941ms 752.530122ms 752.582547ms 752.596626ms 752.720195ms 752.722826ms 752.969448ms 753.025045ms 753.126093ms 753.313017ms 753.476887ms 754.312102ms 755.203557ms 755.342258ms 766.130105ms]
  I1130 13:07:36.904814 19 service_latency.go:118] 50 %ile: 749.15463ms
  I1130 13:07:36.904822 19 service_latency.go:119] 90 %ile: 752.193953ms
  I1130 13:07:36.904828 19 service_latency.go:120] 99 %ile: 755.342258ms
  I1130 13:07:36.904833 19 service_latency.go:121] Total sample count: 200
  I1130 13:07:36.904937 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-7302" for this suite. @ 11/30/24 13:07:36.91
• [10.776 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:116
  STEP: Creating a kubernetes client @ 11/30/24 13:07:36.918
  I1130 13:07:36.918840 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:07:36.919
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:36.936
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:36.939
  STEP: Setting up server cert @ 11/30/24 13:07:36.966
  E1130 13:07:36.983485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:07:37.254
  STEP: Deploying the webhook pod @ 11/30/24 13:07:37.263
  STEP: Wait for the deployment to be ready @ 11/30/24 13:07:37.275
  I1130 13:07:37.283439 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:07:37.983593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:38.983999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:07:39.297
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:07:39.307
  E1130 13:07:39.984657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:40.308553 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 11/30/24 13:07:40.316
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 11/30/24 13:07:40.318
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 11/30/24 13:07:40.318
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 11/30/24 13:07:40.318
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 11/30/24 13:07:40.319
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 11/30/24 13:07:40.319
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 11/30/24 13:07:40.32
  I1130 13:07:40.371322 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6319" for this suite. @ 11/30/24 13:07:40.381
  STEP: Destroying namespace "webhook-markers-755" for this suite. @ 11/30/24 13:07:40.389
• [3.480 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 11/30/24 13:07:40.399
  I1130 13:07:40.399619 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 13:07:40.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:40.416
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:40.419
  E1130 13:07:40.984893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:41.985206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:42.985540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:43.985645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:44.985734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:45.985843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:07:46.483
  I1130 13:07:46.486925 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod client-envvars-a2de0f04-6a47-428e-befd-f158ad300c93 container env3cont: <nil>
  STEP: delete the pod @ 11/30/24 13:07:46.494
  I1130 13:07:46.513209 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5350" for this suite. @ 11/30/24 13:07:46.517
• [6.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 11/30/24 13:07:46.525
  I1130 13:07:46.525605 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 13:07:46.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:46.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:46.545
  STEP: Creating secret with name secret-test-5013fabb-0c6a-4fc4-a29a-cdf3a0594c89 @ 11/30/24 13:07:46.548
  STEP: Creating a pod to test consume secrets @ 11/30/24 13:07:46.554
  E1130 13:07:46.986224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:47.986336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:48.986530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:49.986773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:07:50.579
  I1130 13:07:50.583559 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-secrets-3ff7b382-f29f-47c4-86f8-6643eec5ef4d container secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 13:07:50.603
  I1130 13:07:50.622224 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1086" for this suite. @ 11/30/24 13:07:50.626
• [4.110 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:393
  STEP: Creating a kubernetes client @ 11/30/24 13:07:50.635
  I1130 13:07:50.635698 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 13:07:50.636
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:50.653
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:50.656
  STEP: creating all guestbook components @ 11/30/24 13:07:50.658
  I1130 13:07:50.658900 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I1130 13:07:50.659012 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 create -f -'
  I1130 13:07:50.755029 19 builder.go:146] stderr: ""
  I1130 13:07:50.755094 19 builder.go:147] stdout: "service/agnhost-replica created\n"
  I1130 13:07:50.755273 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I1130 13:07:50.755342 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 create -f -'
  I1130 13:07:50.851681 19 builder.go:146] stderr: ""
  I1130 13:07:50.851722 19 builder.go:147] stdout: "service/agnhost-primary created\n"
  I1130 13:07:50.851766 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I1130 13:07:50.851832 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 create -f -'
  I1130 13:07:50.941723 19 builder.go:146] stderr: ""
  I1130 13:07:50.941762 19 builder.go:147] stdout: "service/frontend created\n"
  I1130 13:07:50.941829 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I1130 13:07:50.941908 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 create -f -'
  E1130 13:07:50.988363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:51.015845 19 builder.go:146] stderr: ""
  I1130 13:07:51.015883 19 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I1130 13:07:51.015948 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I1130 13:07:51.016054 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 create -f -'
  I1130 13:07:51.086301 19 builder.go:146] stderr: ""
  I1130 13:07:51.086340 19 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I1130 13:07:51.086465 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I1130 13:07:51.086545 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 create -f -'
  I1130 13:07:51.152553 19 builder.go:146] stderr: ""
  I1130 13:07:51.152603 19 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 11/30/24 13:07:51.152
  I1130 13:07:51.152643 19 kubectl.go:2272] Waiting for all frontend pods to be Running.
  E1130 13:07:51.988858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:52.988968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:53.989089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:54.989174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:55.989267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:07:56.203934 19 kubectl.go:2276] Waiting for frontend to serve content.
  I1130 13:07:56.216818 19 kubectl.go:2281] Trying to add a new entry to the guestbook.
  I1130 13:07:56.229519 19 kubectl.go:2286] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 11/30/24 13:07:56.239
  I1130 13:07:56.239155 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 delete --grace-period=0 --force -f -'
  I1130 13:07:56.304453 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 13:07:56.304493 19 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 11/30/24 13:07:56.304
  I1130 13:07:56.304648 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 delete --grace-period=0 --force -f -'
  I1130 13:07:56.368349 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 13:07:56.368562 19 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 11/30/24 13:07:56.368
  I1130 13:07:56.368771 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 delete --grace-period=0 --force -f -'
  I1130 13:07:56.429851 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 13:07:56.429888 19 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 11/30/24 13:07:56.429
  I1130 13:07:56.430020 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 delete --grace-period=0 --force -f -'
  I1130 13:07:56.480850 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 13:07:56.480888 19 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 11/30/24 13:07:56.48
  I1130 13:07:56.481016 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 delete --grace-period=0 --force -f -'
  I1130 13:07:56.599936 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 13:07:56.599982 19 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 11/30/24 13:07:56.6
  I1130 13:07:56.600108 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-1816 delete --grace-period=0 --force -f -'
  I1130 13:07:56.690180 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 13:07:56.690514 19 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I1130 13:07:56.690663 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1816" for this suite. @ 11/30/24 13:07:56.697
• [6.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:626
  STEP: Creating a kubernetes client @ 11/30/24 13:07:56.71
  I1130 13:07:56.710539 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-preemption @ 11/30/24 13:07:56.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:07:56.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:07:56.729
  I1130 13:07:56.748619 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1130 13:07:56.989858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:57.989956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:58.990525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:07:59.990592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:00.991605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:01.991690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:02.992414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:03.992634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:04.993254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:05.993477      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:06.993571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:07.993747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:08.994651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:09.994832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:10.995766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:11.995883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:12.995989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:13.996081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:14.996214      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:15.996523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:16.997440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:17.997627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:18.998139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:19.998332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:20.998519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:21.999034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:22.999593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:24.000562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:25.001734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:26.002560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:27.003486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:28.003593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:29.004614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:30.004843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:31.004887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:32.005269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:33.005980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:34.006287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:35.006935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:36.007581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:37.007685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:38.007870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:39.008856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:40.008955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:41.009680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:42.010588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:43.011211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:44.011675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:45.012283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:46.012400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:47.013509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:48.013713      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:49.014004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:50.014816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:51.015598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:52.016072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:53.016220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:54.016474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:55.016503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:56.017584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:08:56.754680 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 11/30/24 13:08:56.758
  I1130 13:08:56.758826 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-preemption-path @ 11/30/24 13:08:56.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:08:56.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:08:56.781
  STEP: Finding an available node @ 11/30/24 13:08:56.785
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 11/30/24 13:08:56.785
  E1130 13:08:57.018611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:08:58.018794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 11/30/24 13:08:58.807
  I1130 13:08:58.822598 19 preemption.go:585] found a healthy node: ip-172-31-64-147
  E1130 13:08:59.019182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:00.019238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:01.020054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:02.020132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:03.020471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:04.021295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:04.892487 19 preemption.go:708] pods created so far: [1 1 1]
  I1130 13:09:04.892516 19 preemption.go:709] length of pods created so far: 3
  E1130 13:09:05.021465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:06.021919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:06.904581 19 preemption.go:726] pods created so far: [2 2 1]
  E1130 13:09:07.022854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:08.023760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:09.024334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:10.024547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:11.024771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:12.024824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:13.025035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:13.984019 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-6044" for this suite. @ 11/30/24 13:09:13.988
  I1130 13:09:13.995397 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1079" for this suite. @ 11/30/24 13:09:13.998
• [77.295 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1791
  STEP: Creating a kubernetes client @ 11/30/24 13:09:14.005
  I1130 13:09:14.005473 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 13:09:14.006
  E1130 13:09:14.025580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:09:14.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:09:14.033
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 11/30/24 13:09:14.038
  I1130 13:09:14.038959 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-9951 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I1130 13:09:14.097919 19 builder.go:146] stderr: ""
  I1130 13:09:14.097955 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 11/30/24 13:09:14.097
  E1130 13:09:15.026451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:16.026534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:17.026637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:18.026708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:19.026955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 11/30/24 13:09:19.149
  I1130 13:09:19.149357 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-9951 get pod e2e-test-httpd-pod -o json'
  I1130 13:09:19.194868 19 builder.go:146] stderr: ""
  I1130 13:09:19.195136 19 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-11-30T13:09:14Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9951\",\n        \"resourceVersion\": \"33128\",\n        \"uid\": \"e9ed2e22-72ae-4497-97fc-535e94447d8d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-rzdvh\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-4-119\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-rzdvh\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-11-30T13:09:14Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-11-30T13:09:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-11-30T13:09:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-11-30T13:09:14Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-11-30T13:09:14Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://e5c876a9ba3fdf1baf18361de94b64222cbd55419e8948282f436135283c8abb\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-11-30T13:09:14Z\"\n                    }\n                },\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-rzdvh\",\n                        \"readOnly\": true,\n                        \"recursiveReadOnly\": \"Disabled\"\n                    }\n                ]\n            }\n        ],\n        \"hostIP\": \"172.31.4.119\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.31.4.119\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.62.34\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.62.34\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-11-30T13:09:14Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 11/30/24 13:09:19.195
  I1130 13:09:19.195239 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-9951 replace -f -'
  I1130 13:09:19.280795 19 builder.go:146] stderr: ""
  I1130 13:09:19.281088 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 11/30/24 13:09:19.281
  I1130 13:09:19.287639 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-9951 delete pods e2e-test-httpd-pod'
  E1130 13:09:20.027581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:20.854086 19 builder.go:146] stderr: ""
  I1130 13:09:20.854123 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I1130 13:09:20.854322 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9951" for this suite. @ 11/30/24 13:09:20.858
• [6.861 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 11/30/24 13:09:20.866
  I1130 13:09:20.866844 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename daemonsets @ 11/30/24 13:09:20.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:09:20.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:09:20.889
  STEP: Creating simple DaemonSet "daemon-set" @ 11/30/24 13:09:20.912
  STEP: Check that daemon pods launch on every node of the cluster. @ 11/30/24 13:09:20.92
  I1130 13:09:20.923480 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:20.923532 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:20.926884 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 13:09:20.926906 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  E1130 13:09:21.028219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:21.925243 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:21.925292 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:21.929121 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1130 13:09:21.929139 19 fixtures.go:130] Node ip-172-31-94-166 is running 0 daemon pod, expected 1
  E1130 13:09:22.028427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:22.925789 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:22.925838 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:22.929713 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 13:09:22.929733 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 11/30/24 13:09:22.934
  I1130 13:09:22.951891 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:22.951934 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:22.955463 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1130 13:09:22.955485 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  E1130 13:09:23.028600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:23.952580 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:23.952637 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:09:23.956237 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 13:09:23.956258 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 11/30/24 13:09:23.96
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2429, will wait for the garbage collector to delete the pods @ 11/30/24 13:09:23.96
  I1130 13:09:24.023696 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.405665ms
  E1130 13:09:24.028863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:24.124018 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.317493ms
  E1130 13:09:25.029611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:25.928209 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 13:09:25.928249 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1130 13:09:25.931437 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33331"},"items":null}

  I1130 13:09:25.934403 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33331"},"items":null}

  I1130 13:09:25.948040 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2429" for this suite. @ 11/30/24 13:09:25.951
• [5.091 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 11/30/24 13:09:25.957
  I1130 13:09:25.957716 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename endpointslice @ 11/30/24 13:09:25.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:09:25.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:09:25.975
  E1130 13:09:26.029869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:27.030739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:28.030863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 11/30/24 13:09:28.055
  STEP: referencing matching pods with named port @ 11/30/24 13:09:28.064
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 11/30/24 13:09:28.071
  STEP: recreating EndpointSlices after they've been deleted @ 11/30/24 13:09:28.079
  I1130 13:09:28.099243 19 endpointslice.go:938] EndpointSlice for Service endpointslice-2865/example-named-port not found
  E1130 13:09:29.031317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:30.031530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:09:30.104770 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2865" for this suite. @ 11/30/24 13:09:30.109
• [4.160 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 11/30/24 13:09:30.118
  I1130 13:09:30.118319 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 13:09:30.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:09:30.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:09:30.147
  E1130 13:09:31.031697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:32.032588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:33.032724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:34.032780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:35.033534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:36.033703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:37.034526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:38.034744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:39.034889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:40.034982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:41.035143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:42.035839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:43.035914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:44.036043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:45.036138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:46.036248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:47.036592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:48.036706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:49.036813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:50.036892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:51.037006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:52.037279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:53.037616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:54.037748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:55.037803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:56.038074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:57.038165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:58.038394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:09:59.038602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:00.038727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:01.038814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:02.039275      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:03.040023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:04.040125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:05.040534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:06.040646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:07.041594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:08.041977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:09.042203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:10.042331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:11.042539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:12.042808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:13.043799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:14.044783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:15.045347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:16.045527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:17.046525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:18.046782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:19.046870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:20.047009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:21.047124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:22.047181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:23.047236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:24.047409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:25.047641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:26.047742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:27.047843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:28.048744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:29.049807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:30.050581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:10:30.166824 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9999" for this suite. @ 11/30/24 13:10:30.17
• [60.077 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 11/30/24 13:10:30.194
  I1130 13:10:30.194737 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename init-container @ 11/30/24 13:10:30.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:30.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:30.214
  STEP: creating the pod @ 11/30/24 13:10:30.217
  I1130 13:10:30.217439 19 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E1130 13:10:31.050716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:32.051606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:33.052404      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:34.052669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:10:34.998077 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9530" for this suite. @ 11/30/24 13:10:35.003
• [4.817 seconds]
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 11/30/24 13:10:35.011
  I1130 13:10:35.011579 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 11/30/24 13:10:35.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:35.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:35.028
  STEP: Setting up the test @ 11/30/24 13:10:35.034
  STEP: Creating hostNetwork=false pod @ 11/30/24 13:10:35.034
  E1130 13:10:35.052796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:36.053809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:37.053886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 11/30/24 13:10:37.058
  E1130 13:10:38.054576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:39.055579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Running the test @ 11/30/24 13:10:39.077
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 11/30/24 13:10:39.077
  I1130 13:10:39.077887 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.077905 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.078404 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.078453 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I1130 13:10:39.120242 19 exec_util.go:111] Exec stderr: ""
  I1130 13:10:39.120299 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.120308 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.120822 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.120872 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I1130 13:10:39.161698 19 exec_util.go:111] Exec stderr: ""
  I1130 13:10:39.161748 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.161758 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.162187 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.162234 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I1130 13:10:39.202005 19 exec_util.go:111] Exec stderr: ""
  I1130 13:10:39.202062 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.202072 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.202518 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.202612 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I1130 13:10:39.240171 19 exec_util.go:111] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 11/30/24 13:10:39.24
  I1130 13:10:39.240261 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.240270 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.240794 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.240843 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I1130 13:10:39.281151 19 exec_util.go:111] Exec stderr: ""
  I1130 13:10:39.281206 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.281216 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.281740 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.281808 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I1130 13:10:39.318698 19 exec_util.go:111] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 11/30/24 13:10:39.318
  I1130 13:10:39.318787 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.318797 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.319318 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.319398 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I1130 13:10:39.356432 19 exec_util.go:111] Exec stderr: ""
  I1130 13:10:39.356480 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.356489 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.356908 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.356963 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I1130 13:10:39.393610 19 exec_util.go:111] Exec stderr: ""
  I1130 13:10:39.393702 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.393711 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.394106 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.394153 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I1130 13:10:39.432635 19 exec_util.go:111] Exec stderr: ""
  I1130 13:10:39.432692 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-204 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:10:39.432701 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:10:39.433179 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:10:39.433248 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-204/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I1130 13:10:39.474197 19 exec_util.go:111] Exec stderr: ""
  I1130 13:10:39.474341 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-204" for this suite. @ 11/30/24 13:10:39.479
• [4.476 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 11/30/24 13:10:39.487
  I1130 13:10:39.487829 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 13:10:39.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:39.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:39.508
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 11/30/24 13:10:39.512
  E1130 13:10:40.056536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:41.056676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:42.056816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:43.057048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:10:43.54
  I1130 13:10:43.544173 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-01af2fce-2103-41cd-a9fa-1c81d5214003 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 13:10:43.564
  I1130 13:10:43.580879 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8248" for this suite. @ 11/30/24 13:10:43.585
• [4.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 11/30/24 13:10:43.594
  I1130 13:10:43.594326 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 13:10:43.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:43.61
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:43.614
  STEP: Creating configMap with name configmap-test-volume-3609d29d-e18f-4c20-b673-8a5735c791a0 @ 11/30/24 13:10:43.618
  STEP: Creating a pod to test consume configMaps @ 11/30/24 13:10:43.623
  E1130 13:10:44.057262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:45.057769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:46.057904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:47.058587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:10:47.651
  I1130 13:10:47.655640 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-configmaps-f14be0d9-7c40-487c-b3e3-64796d903c1f container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 13:10:47.663
  I1130 13:10:47.683745 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2295" for this suite. @ 11/30/24 13:10:47.687
• [4.101 seconds]
------------------------------
SSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 11/30/24 13:10:47.695
  I1130 13:10:47.695147 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename podtemplate @ 11/30/24 13:10:47.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:47.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:47.716
  I1130 13:10:47.757387 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-6242" for this suite. @ 11/30/24 13:10:47.761
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:270
  STEP: Creating a kubernetes client @ 11/30/24 13:10:47.768
  I1130 13:10:47.768116 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:10:47.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:47.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:47.787
  STEP: Setting up server cert @ 11/30/24 13:10:47.811
  E1130 13:10:48.058717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:10:48.067
  STEP: Deploying the webhook pod @ 11/30/24 13:10:48.077
  STEP: Wait for the deployment to be ready @ 11/30/24 13:10:48.092
  I1130 13:10:48.111631 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:10:49.059538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:50.059634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:10:50.124
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:10:50.134
  E1130 13:10:51.059989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:10:51.135222 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 11/30/24 13:10:51.143
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 11/30/24 13:10:51.158
  STEP: Creating a dummy validating-webhook-configuration object @ 11/30/24 13:10:51.172
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 11/30/24 13:10:51.183
  STEP: Creating a dummy mutating-webhook-configuration object @ 11/30/24 13:10:51.19
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 11/30/24 13:10:51.199
  I1130 13:10:51.266539 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4214" for this suite. @ 11/30/24 13:10:51.27
  STEP: Destroying namespace "webhook-markers-6234" for this suite. @ 11/30/24 13:10:51.276
• [3.515 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 11/30/24 13:10:51.283
  I1130 13:10:51.283395 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 13:10:51.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:51.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:51.302
  STEP: creating pod @ 11/30/24 13:10:51.304
  E1130 13:10:52.060081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:53.060184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:10:53.359420 19 pods.go:83] Pod pod-hostip-a11ad275-f7b6-4ed1-82ce-ebdb8f9ecb92 has hostIP: 172.31.64.147
  I1130 13:10:53.359536 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4033" for this suite. @ 11/30/24 13:10:53.364
• [2.087 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 11/30/24 13:10:53.37
  I1130 13:10:53.370821 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:10:53.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:53.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:53.391
  STEP: Creating configMap with name cm-test-opt-del-a5b0b1ea-6b19-4786-9ecb-0a47ccf0e84b @ 11/30/24 13:10:53.398
  STEP: Creating configMap with name cm-test-opt-upd-e812096b-b0d1-46e7-8b4d-641f9fd55c71 @ 11/30/24 13:10:53.403
  STEP: Creating the pod @ 11/30/24 13:10:53.408
  E1130 13:10:54.060311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:55.060533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-a5b0b1ea-6b19-4786-9ecb-0a47ccf0e84b @ 11/30/24 13:10:55.457
  STEP: Updating configmap cm-test-opt-upd-e812096b-b0d1-46e7-8b4d-641f9fd55c71 @ 11/30/24 13:10:55.463
  STEP: Creating configMap with name cm-test-opt-create-0dbc6fed-e879-46fd-96cf-902ac5f3d6f7 @ 11/30/24 13:10:55.468
  STEP: waiting to observe update in volume @ 11/30/24 13:10:55.472
  E1130 13:10:56.060616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:57.060892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:58.061570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:10:59.062187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:10:59.511809 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5251" for this suite. @ 11/30/24 13:10:59.515
• [6.152 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 11/30/24 13:10:59.523
  I1130 13:10:59.523812 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 13:10:59.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:10:59.537
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:10:59.54
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 11/30/24 13:10:59.544
  I1130 13:10:59.544618 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:11:00.062769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:01.062996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:02.063199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:03.063438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:04.064355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 11/30/24 13:11:04.575
  I1130 13:11:04.575488 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:11:05.064592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:05.814620 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:11:06.064725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:07.065449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:08.065802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:09.066186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:10.066339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:10.818985 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7035" for this suite. @ 11/30/24 13:11:10.827
• [11.312 seconds]
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1396
  STEP: Creating a kubernetes client @ 11/30/24 13:11:10.835
  I1130 13:11:10.835842 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 13:11:10.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:10.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:10.853
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1446 @ 11/30/24 13:11:10.857
  STEP: changing the ExternalName service to type=ClusterIP @ 11/30/24 13:11:10.863
  STEP: creating replication controller externalname-service in namespace services-1446 @ 11/30/24 13:11:10.876
  I1130 13:11:10.890569      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1446, replica count: 2
  E1130 13:11:11.067277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:12.067607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:13.068081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:13.941081      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 13:11:13.941120 19 resource.go:361] Creating new exec pod
  E1130 13:11:14.069069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:15.069156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:16.070180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:16.960483 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-1446 exec execpodnxfl9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I1130 13:11:17.043278 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I1130 13:11:17.043320 19 builder.go:147] stdout: "externalname-service-mppkc"
  I1130 13:11:17.043426 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-1446 exec execpodnxfl9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.110 80'
  E1130 13:11:17.070830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:17.125224 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.110 80\nConnection to 10.152.183.110 80 port [tcp/http] succeeded!\n"
  I1130 13:11:17.125266 19 builder.go:147] stdout: "externalname-service-mppkc"
  I1130 13:11:17.125344 19 service.go:1405] Cleaning up the ExternalName to ClusterIP test service
  I1130 13:11:17.146203 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1446" for this suite. @ 11/30/24 13:11:17.15
• [6.322 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 11/30/24 13:11:17.158
  I1130 13:11:17.158170 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename runtimeclass @ 11/30/24 13:11:17.159
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:17.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:17.179
  I1130 13:11:17.212198 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8459" for this suite. @ 11/30/24 13:11:17.215
• [0.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 11/30/24 13:11:17.224
  I1130 13:11:17.224586 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 13:11:17.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:17.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:17.244
  STEP: Creating secret with name secret-test-50dccd77-dce5-4509-8f3f-9672aed264e6 @ 11/30/24 13:11:17.247
  STEP: Creating a pod to test consume secrets @ 11/30/24 13:11:17.253
  E1130 13:11:18.070932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:19.071032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:11:19.273
  I1130 13:11:19.277613 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-secrets-e0a9e0c8-03b8-4276-b749-5db3076ad508 container secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 13:11:19.285
  I1130 13:11:19.303556 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3976" for this suite. @ 11/30/24 13:11:19.308
• [2.093 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 11/30/24 13:11:19.318
  I1130 13:11:19.318834 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename chunking @ 11/30/24 13:11:19.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:19.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:19.341
  STEP: creating a large number of resources @ 11/30/24 13:11:19.345
  E1130 13:11:20.071747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:21.072030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:22.073020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:23.073383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:24.074302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:25.074420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:26.075331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:27.075918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:28.076129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:29.076721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:30.076865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:31.076852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:32.077512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:33.078037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:34.078819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:35.079606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:36.079879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 11/30/24 13:11:37.026
  I1130 13:11:37.075248 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  E1130 13:11:37.080261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:37.125340 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I1130 13:11:37.174983 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I1130 13:11:37.226346 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I1130 13:11:37.275484 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I1130 13:11:37.324901 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I1130 13:11:37.375422 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I1130 13:11:37.425568 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I1130 13:11:37.474391 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I1130 13:11:37.524272 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I1130 13:11:37.575868 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I1130 13:11:37.624944 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I1130 13:11:37.674972 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I1130 13:11:37.725298 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I1130 13:11:37.774180 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I1130 13:11:37.825310 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I1130 13:11:37.874911 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I1130 13:11:37.925420 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I1130 13:11:37.974711 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I1130 13:11:38.025400 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I1130 13:11:38.075015 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  E1130 13:11:38.081023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:38.124978 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I1130 13:11:38.175631 19 chunking.go:98] Retrieved 17/17 results with rv 34745 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDUsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I1130 13:11:38.224806 19 chunking.go:98] Retrieved 9/17 results with rv 34745 and continue 
  I1130 13:11:38.275093 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I1130 13:11:38.326069 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I1130 13:11:38.374476 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I1130 13:11:38.424446 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I1130 13:11:38.474958 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I1130 13:11:38.525424 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I1130 13:11:38.574321 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I1130 13:11:38.624893 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I1130 13:11:38.675260 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I1130 13:11:38.725074 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I1130 13:11:38.775695 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I1130 13:11:38.824990 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I1130 13:11:38.875567 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  I1130 13:11:38.925357 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I1130 13:11:38.974716 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I1130 13:11:39.025017 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I1130 13:11:39.075894 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  E1130 13:11:39.081953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:39.125741 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I1130 13:11:39.175899 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I1130 13:11:39.225892 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I1130 13:11:39.275012 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I1130 13:11:39.325300 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I1130 13:11:39.375019 19 chunking.go:98] Retrieved 17/17 results with rv 34746 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDYsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I1130 13:11:39.425055 19 chunking.go:98] Retrieved 9/17 results with rv 34746 and continue 
  I1130 13:11:39.475038 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  I1130 13:11:39.525907 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  I1130 13:11:39.574591 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  I1130 13:11:39.624613 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  I1130 13:11:39.675341 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  I1130 13:11:39.724443 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  I1130 13:11:39.774392 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  I1130 13:11:39.825018 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  I1130 13:11:39.875420 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  I1130 13:11:39.924355 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  I1130 13:11:39.974932 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  I1130 13:11:40.024868 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  I1130 13:11:40.074598 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  E1130 13:11:40.082697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:40.125453 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  I1130 13:11:40.174759 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  I1130 13:11:40.224689 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  I1130 13:11:40.275872 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  I1130 13:11:40.324221 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  I1130 13:11:40.375032 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  I1130 13:11:40.425436 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  I1130 13:11:40.474434 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  I1130 13:11:40.523814 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  I1130 13:11:40.575642 19 chunking.go:98] Retrieved 17/17 results with rv 34748 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ3NDgsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  I1130 13:11:40.624732 19 chunking.go:98] Retrieved 9/17 results with rv 34748 and continue 
  STEP: retrieving those results all at once @ 11/30/24 13:11:40.624
  I1130 13:11:40.681944 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-2049" for this suite. @ 11/30/24 13:11:40.724
• [21.463 seconds]
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 11/30/24 13:11:40.781
  I1130 13:11:40.781561 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pod-network-test @ 11/30/24 13:11:40.782
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:40.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:40.799
  STEP: Performing setup for networking test in namespace pod-network-test-7581 @ 11/30/24 13:11:40.803
  STEP: creating a selector @ 11/30/24 13:11:40.803
  STEP: Creating the service pods in kubernetes @ 11/30/24 13:11:40.803
  I1130 13:11:40.803056 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1130 13:11:41.083613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:42.083707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:43.084108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:44.084658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:45.085228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:46.085325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:47.086189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:48.086285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:49.087072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:50.087037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:51.087537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:52.087832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 11/30/24 13:11:52.895
  E1130 13:11:53.088243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:54.088461      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:11:54.931710 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I1130 13:11:54.931748 19 utils.go:496] Going to poll 192.168.62.47 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I1130 13:11:54.935885 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.62.47:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7581 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:11:54.935908 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:11:54.936324 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:11:54.936389 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7581/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.62.47%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I1130 13:11:54.984878 19 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I1130 13:11:54.984928 19 utils.go:496] Going to poll 192.168.244.209 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I1130 13:11:54.989520 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.244.209:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7581 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:11:54.989545 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:11:54.989980 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:11:54.990034 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7581/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.244.209%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I1130 13:11:55.037313 19 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I1130 13:11:55.037364 19 utils.go:496] Going to poll 192.168.81.163 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I1130 13:11:55.041865 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.81.163:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7581 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:11:55.041888 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:11:55.042286 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:11:55.042328 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7581/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.81.163%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I1130 13:11:55.085288 19 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I1130 13:11:55.085427 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E1130 13:11:55.088441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "pod-network-test-7581" for this suite. @ 11/30/24 13:11:55.09
• [14.316 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 11/30/24 13:11:55.097
  I1130 13:11:55.097836 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename svcaccounts @ 11/30/24 13:11:55.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:55.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:55.119
  STEP: creating a ServiceAccount @ 11/30/24 13:11:55.122
  STEP: watching for the ServiceAccount to be added @ 11/30/24 13:11:55.13
  STEP: patching the ServiceAccount @ 11/30/24 13:11:55.132
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 11/30/24 13:11:55.138
  STEP: deleting the ServiceAccount @ 11/30/24 13:11:55.142
  I1130 13:11:55.157677 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6147" for this suite. @ 11/30/24 13:11:55.161
• [0.072 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 11/30/24 13:11:55.169
  I1130 13:11:55.169688 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 13:11:55.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:55.185
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:55.189
  STEP: Creating configMap that has name configmap-test-emptyKey-4c399785-c0c5-4f50-96ee-82ed76e626e4 @ 11/30/24 13:11:55.193
  I1130 13:11:55.195415 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3777" for this suite. @ 11/30/24 13:11:55.199
• [0.038 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 11/30/24 13:11:55.207
  I1130 13:11:55.207709 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename podtemplate @ 11/30/24 13:11:55.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:55.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:55.227
  STEP: Create a pod template @ 11/30/24 13:11:55.231
  STEP: Replace a pod template @ 11/30/24 13:11:55.237
  I1130 13:11:55.246662 19 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I1130 13:11:55.246796 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9124" for this suite. @ 11/30/24 13:11:55.251
• [0.049 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 11/30/24 13:11:55.257
  I1130 13:11:55.257078 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pod-network-test @ 11/30/24 13:11:55.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:11:55.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:11:55.279
  STEP: Performing setup for networking test in namespace pod-network-test-2248 @ 11/30/24 13:11:55.283
  STEP: creating a selector @ 11/30/24 13:11:55.283
  STEP: Creating the service pods in kubernetes @ 11/30/24 13:11:55.283
  I1130 13:11:55.283190 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1130 13:11:56.088702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:57.088799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:58.089520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:11:59.089547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:00.089646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:01.089735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:02.089865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:03.090584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:04.090684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:05.091603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:06.091759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:07.092333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 11/30/24 13:12:07.384
  E1130 13:12:08.092544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:09.092700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:12:09.409184 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I1130 13:12:09.409215 19 networking.go:42] Breadth first check of 192.168.62.44 on host 172.31.4.119...
  I1130 13:12:09.412853 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.244.201:9080/dial?request=hostname&protocol=udp&host=192.168.62.44&port=8081&tries=1'] Namespace:pod-network-test-2248 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:12:09.412875 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:12:09.413318 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:12:09.413384 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2248/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.244.201%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.62.44%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1130 13:12:09.462939 19 utils.go:356] Waiting for responses: map[]
  I1130 13:12:09.462969 19 utils.go:360] reached 192.168.62.44 after 0/1 tries
  I1130 13:12:09.462978 19 networking.go:42] Breadth first check of 192.168.244.195 on host 172.31.64.147...
  I1130 13:12:09.467066 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.244.201:9080/dial?request=hostname&protocol=udp&host=192.168.244.195&port=8081&tries=1'] Namespace:pod-network-test-2248 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:12:09.467087 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:12:09.467550 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:12:09.467595 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2248/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.244.201%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.244.195%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1130 13:12:09.508959 19 utils.go:356] Waiting for responses: map[]
  I1130 13:12:09.508998 19 utils.go:360] reached 192.168.244.195 after 0/1 tries
  I1130 13:12:09.509008 19 networking.go:42] Breadth first check of 192.168.81.169 on host 172.31.94.166...
  I1130 13:12:09.513423 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.244.201:9080/dial?request=hostname&protocol=udp&host=192.168.81.169&port=8081&tries=1'] Namespace:pod-network-test-2248 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:12:09.513453 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:12:09.513913 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:12:09.513952 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2248/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.244.201%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.81.169%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1130 13:12:09.559098 19 utils.go:356] Waiting for responses: map[]
  I1130 13:12:09.559141 19 utils.go:360] reached 192.168.81.169 after 0/1 tries
  I1130 13:12:09.559149 19 networking.go:53] Going to retry 0 out of 3 pods....
  I1130 13:12:09.559344 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2248" for this suite. @ 11/30/24 13:12:09.565
• [14.316 seconds]
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 11/30/24 13:12:09.572
  I1130 13:12:09.572895 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubelet-test @ 11/30/24 13:12:09.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:12:09.59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:12:09.594
  I1130 13:12:09.626207 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2248" for this suite. @ 11/30/24 13:12:09.631
• [0.067 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 11/30/24 13:12:09.639
  I1130 13:12:09.639761 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename var-expansion @ 11/30/24 13:12:09.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:12:09.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:12:09.659
  STEP: Creating a pod to test substitution in volume subpath @ 11/30/24 13:12:09.663
  E1130 13:12:10.094545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:11.094084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:12.094467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:13.094683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:12:13.686
  I1130 13:12:13.690904 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod var-expansion-13705326-d6a6-4971-9b6a-8f47ad1bc3e3 container dapi-container: <nil>
  STEP: delete the pod @ 11/30/24 13:12:13.699
  I1130 13:12:13.718548 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6065" for this suite. @ 11/30/24 13:12:13.723
• [4.091 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 11/30/24 13:12:13.73
  I1130 13:12:13.730481 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename aggregateddiscovery @ 11/30/24 13:12:13.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:12:13.748
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:12:13.752
  I1130 13:12:13.758914 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-6042" for this suite. @ 11/30/24 13:12:13.762
• [0.039 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 11/30/24 13:12:13.769
  I1130 13:12:13.769652 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename endpointslicemirroring @ 11/30/24 13:12:13.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:12:13.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:12:13.796
  STEP: mirroring a new custom Endpoint @ 11/30/24 13:12:13.821
  I1130 13:12:13.837827 19 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  E1130 13:12:14.095307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:15.095537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 11/30/24 13:12:15.843
  I1130 13:12:15.854915 19 endpointslicemirroring.go:171] Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E1130 13:12:16.096420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:17.096683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 11/30/24 13:12:17.86
  I1130 13:12:17.872217 19 endpointslicemirroring.go:194] Waiting for 0 EndpointSlices to exist, got 1
  E1130 13:12:18.097737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:19.097960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:12:19.878229 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-9379" for this suite. @ 11/30/24 13:12:19.882
• [6.120 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 11/30/24 13:12:19.889
  I1130 13:12:19.889933 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename gc @ 11/30/24 13:12:19.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:12:19.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:12:19.91
  STEP: create the rc @ 11/30/24 13:12:19.918
  W1130 13:12:19.923961      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1130 13:12:20.098526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:21.098904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:22.099831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:23.100354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:24.100880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:25.104104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 11/30/24 13:12:25.928
  STEP: wait for the rc to be deleted @ 11/30/24 13:12:25.939
  E1130 13:12:26.104884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:27.104977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:28.105168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:29.105312      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:30.105563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 11/30/24 13:12:30.945
  E1130 13:12:31.106333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:32.106520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:33.106752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:34.107685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:35.107828      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:36.108008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:37.108119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:38.109011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:39.109113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:40.109242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:41.109754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:42.110212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:43.110275      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:44.110390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:45.110500      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:46.111577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:47.111735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:48.111915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:49.112607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:50.112702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:51.112902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:52.113201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:53.113562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:54.113731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:55.113935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:56.114569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:57.114872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:58.115064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:12:59.115245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:00.115453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 11/30/24 13:13:00.955
  W1130 13:13:00.961338      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1130 13:13:00.961387 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1130 13:13:00.961445 19 delete.go:95] Deleting pod "simpletest.rc-259kv" in namespace "gc-3269"
  I1130 13:13:00.976009 19 delete.go:95] Deleting pod "simpletest.rc-28j5l" in namespace "gc-3269"
  I1130 13:13:00.991565 19 delete.go:95] Deleting pod "simpletest.rc-2bqhp" in namespace "gc-3269"
  I1130 13:13:01.003069 19 delete.go:95] Deleting pod "simpletest.rc-2bzzr" in namespace "gc-3269"
  I1130 13:13:01.018093 19 delete.go:95] Deleting pod "simpletest.rc-2wkwj" in namespace "gc-3269"
  I1130 13:13:01.029028 19 delete.go:95] Deleting pod "simpletest.rc-2zbrr" in namespace "gc-3269"
  I1130 13:13:01.046684 19 delete.go:95] Deleting pod "simpletest.rc-49qnc" in namespace "gc-3269"
  I1130 13:13:01.058487 19 delete.go:95] Deleting pod "simpletest.rc-5k77q" in namespace "gc-3269"
  I1130 13:13:01.071520 19 delete.go:95] Deleting pod "simpletest.rc-5m82q" in namespace "gc-3269"
  I1130 13:13:01.084987 19 delete.go:95] Deleting pod "simpletest.rc-5pv7d" in namespace "gc-3269"
  I1130 13:13:01.101085 19 delete.go:95] Deleting pod "simpletest.rc-62lkm" in namespace "gc-3269"
  E1130 13:13:01.116365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:13:01.117663 19 delete.go:95] Deleting pod "simpletest.rc-62tm5" in namespace "gc-3269"
  I1130 13:13:01.136747 19 delete.go:95] Deleting pod "simpletest.rc-6gh9v" in namespace "gc-3269"
  I1130 13:13:01.152040 19 delete.go:95] Deleting pod "simpletest.rc-6hkml" in namespace "gc-3269"
  I1130 13:13:01.168623 19 delete.go:95] Deleting pod "simpletest.rc-6jfvn" in namespace "gc-3269"
  I1130 13:13:01.180699 19 delete.go:95] Deleting pod "simpletest.rc-6x56m" in namespace "gc-3269"
  I1130 13:13:01.201485 19 delete.go:95] Deleting pod "simpletest.rc-7hjg2" in namespace "gc-3269"
  I1130 13:13:01.216929 19 delete.go:95] Deleting pod "simpletest.rc-89rct" in namespace "gc-3269"
  I1130 13:13:01.231587 19 delete.go:95] Deleting pod "simpletest.rc-8f9d8" in namespace "gc-3269"
  I1130 13:13:01.252595 19 delete.go:95] Deleting pod "simpletest.rc-8txpm" in namespace "gc-3269"
  I1130 13:13:01.266427 19 delete.go:95] Deleting pod "simpletest.rc-8xrnr" in namespace "gc-3269"
  I1130 13:13:01.281321 19 delete.go:95] Deleting pod "simpletest.rc-9rl9t" in namespace "gc-3269"
  I1130 13:13:01.309929 19 delete.go:95] Deleting pod "simpletest.rc-9tddw" in namespace "gc-3269"
  I1130 13:13:01.327645 19 delete.go:95] Deleting pod "simpletest.rc-9x4mc" in namespace "gc-3269"
  I1130 13:13:01.354754 19 delete.go:95] Deleting pod "simpletest.rc-bsjzv" in namespace "gc-3269"
  I1130 13:13:01.366262 19 delete.go:95] Deleting pod "simpletest.rc-c7447" in namespace "gc-3269"
  I1130 13:13:01.383402 19 delete.go:95] Deleting pod "simpletest.rc-cjtc2" in namespace "gc-3269"
  I1130 13:13:01.397788 19 delete.go:95] Deleting pod "simpletest.rc-clttx" in namespace "gc-3269"
  I1130 13:13:01.413848 19 delete.go:95] Deleting pod "simpletest.rc-cm46n" in namespace "gc-3269"
  I1130 13:13:01.425538 19 delete.go:95] Deleting pod "simpletest.rc-ctnfm" in namespace "gc-3269"
  I1130 13:13:01.438477 19 delete.go:95] Deleting pod "simpletest.rc-d6dzj" in namespace "gc-3269"
  I1130 13:13:01.455665 19 delete.go:95] Deleting pod "simpletest.rc-d84gg" in namespace "gc-3269"
  I1130 13:13:01.471343 19 delete.go:95] Deleting pod "simpletest.rc-dbwmj" in namespace "gc-3269"
  I1130 13:13:01.486021 19 delete.go:95] Deleting pod "simpletest.rc-dg87q" in namespace "gc-3269"
  I1130 13:13:01.505794 19 delete.go:95] Deleting pod "simpletest.rc-djb75" in namespace "gc-3269"
  I1130 13:13:01.518514 19 delete.go:95] Deleting pod "simpletest.rc-dql52" in namespace "gc-3269"
  I1130 13:13:01.534891 19 delete.go:95] Deleting pod "simpletest.rc-dwhct" in namespace "gc-3269"
  I1130 13:13:01.552921 19 delete.go:95] Deleting pod "simpletest.rc-fc8lk" in namespace "gc-3269"
  I1130 13:13:01.570974 19 delete.go:95] Deleting pod "simpletest.rc-ffm5l" in namespace "gc-3269"
  I1130 13:13:01.591002 19 delete.go:95] Deleting pod "simpletest.rc-ggg5x" in namespace "gc-3269"
  I1130 13:13:01.611607 19 delete.go:95] Deleting pod "simpletest.rc-h292w" in namespace "gc-3269"
  I1130 13:13:01.622571 19 delete.go:95] Deleting pod "simpletest.rc-h8kcz" in namespace "gc-3269"
  I1130 13:13:01.644167 19 delete.go:95] Deleting pod "simpletest.rc-j8xjk" in namespace "gc-3269"
  I1130 13:13:01.658291 19 delete.go:95] Deleting pod "simpletest.rc-jbmzv" in namespace "gc-3269"
  I1130 13:13:01.674355 19 delete.go:95] Deleting pod "simpletest.rc-jc87r" in namespace "gc-3269"
  I1130 13:13:01.701850 19 delete.go:95] Deleting pod "simpletest.rc-jkqn4" in namespace "gc-3269"
  I1130 13:13:01.721107 19 delete.go:95] Deleting pod "simpletest.rc-jlbsv" in namespace "gc-3269"
  I1130 13:13:01.734225 19 delete.go:95] Deleting pod "simpletest.rc-jph8n" in namespace "gc-3269"
  I1130 13:13:01.753784 19 delete.go:95] Deleting pod "simpletest.rc-jvdlp" in namespace "gc-3269"
  I1130 13:13:01.773870 19 delete.go:95] Deleting pod "simpletest.rc-k54vp" in namespace "gc-3269"
  I1130 13:13:01.786809 19 delete.go:95] Deleting pod "simpletest.rc-k5lnt" in namespace "gc-3269"
  I1130 13:13:01.800268 19 delete.go:95] Deleting pod "simpletest.rc-k5njg" in namespace "gc-3269"
  I1130 13:13:01.819961 19 delete.go:95] Deleting pod "simpletest.rc-k6zk7" in namespace "gc-3269"
  I1130 13:13:01.833071 19 delete.go:95] Deleting pod "simpletest.rc-kdfkl" in namespace "gc-3269"
  I1130 13:13:01.848180 19 delete.go:95] Deleting pod "simpletest.rc-khsmp" in namespace "gc-3269"
  I1130 13:13:01.868973 19 delete.go:95] Deleting pod "simpletest.rc-kp9dv" in namespace "gc-3269"
  I1130 13:13:01.893684 19 delete.go:95] Deleting pod "simpletest.rc-l6wgq" in namespace "gc-3269"
  I1130 13:13:01.908426 19 delete.go:95] Deleting pod "simpletest.rc-l7k2w" in namespace "gc-3269"
  I1130 13:13:01.926483 19 delete.go:95] Deleting pod "simpletest.rc-l7qmv" in namespace "gc-3269"
  I1130 13:13:01.947838 19 delete.go:95] Deleting pod "simpletest.rc-lnkg6" in namespace "gc-3269"
  I1130 13:13:01.965443 19 delete.go:95] Deleting pod "simpletest.rc-m4242" in namespace "gc-3269"
  I1130 13:13:01.979759 19 delete.go:95] Deleting pod "simpletest.rc-mc2ss" in namespace "gc-3269"
  I1130 13:13:01.993204 19 delete.go:95] Deleting pod "simpletest.rc-nxdxd" in namespace "gc-3269"
  I1130 13:13:02.004882 19 delete.go:95] Deleting pod "simpletest.rc-psw5q" in namespace "gc-3269"
  I1130 13:13:02.022820 19 delete.go:95] Deleting pod "simpletest.rc-px5xx" in namespace "gc-3269"
  I1130 13:13:02.033884 19 delete.go:95] Deleting pod "simpletest.rc-q2r4d" in namespace "gc-3269"
  I1130 13:13:02.048927 19 delete.go:95] Deleting pod "simpletest.rc-qf7ls" in namespace "gc-3269"
  I1130 13:13:02.063451 19 delete.go:95] Deleting pod "simpletest.rc-qfgkm" in namespace "gc-3269"
  I1130 13:13:02.075714 19 delete.go:95] Deleting pod "simpletest.rc-qhw76" in namespace "gc-3269"
  I1130 13:13:02.090162 19 delete.go:95] Deleting pod "simpletest.rc-qn8lb" in namespace "gc-3269"
  E1130 13:13:02.116812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:13:02.116998 19 delete.go:95] Deleting pod "simpletest.rc-qx5w4" in namespace "gc-3269"
  I1130 13:13:02.129865 19 delete.go:95] Deleting pod "simpletest.rc-qxq98" in namespace "gc-3269"
  I1130 13:13:02.164518 19 delete.go:95] Deleting pod "simpletest.rc-rlmdb" in namespace "gc-3269"
  I1130 13:13:02.210596 19 delete.go:95] Deleting pod "simpletest.rc-sckjh" in namespace "gc-3269"
  I1130 13:13:02.258898 19 delete.go:95] Deleting pod "simpletest.rc-stzfv" in namespace "gc-3269"
  I1130 13:13:02.313201 19 delete.go:95] Deleting pod "simpletest.rc-tcpwc" in namespace "gc-3269"
  I1130 13:13:02.363991 19 delete.go:95] Deleting pod "simpletest.rc-tfpt2" in namespace "gc-3269"
  I1130 13:13:02.410982 19 delete.go:95] Deleting pod "simpletest.rc-tj285" in namespace "gc-3269"
  I1130 13:13:02.459045 19 delete.go:95] Deleting pod "simpletest.rc-ttr4f" in namespace "gc-3269"
  I1130 13:13:02.514172 19 delete.go:95] Deleting pod "simpletest.rc-tvz9g" in namespace "gc-3269"
  I1130 13:13:02.563023 19 delete.go:95] Deleting pod "simpletest.rc-tw7bj" in namespace "gc-3269"
  I1130 13:13:02.614027 19 delete.go:95] Deleting pod "simpletest.rc-v627m" in namespace "gc-3269"
  I1130 13:13:02.662751 19 delete.go:95] Deleting pod "simpletest.rc-v9nxt" in namespace "gc-3269"
  I1130 13:13:02.711200 19 delete.go:95] Deleting pod "simpletest.rc-vc2p8" in namespace "gc-3269"
  I1130 13:13:02.764788 19 delete.go:95] Deleting pod "simpletest.rc-vdf8v" in namespace "gc-3269"
  I1130 13:13:02.816108 19 delete.go:95] Deleting pod "simpletest.rc-vhrzq" in namespace "gc-3269"
  I1130 13:13:02.869390 19 delete.go:95] Deleting pod "simpletest.rc-vjtnt" in namespace "gc-3269"
  I1130 13:13:02.910355 19 delete.go:95] Deleting pod "simpletest.rc-vplzh" in namespace "gc-3269"
  I1130 13:13:02.962359 19 delete.go:95] Deleting pod "simpletest.rc-w6zch" in namespace "gc-3269"
  I1130 13:13:03.010669 19 delete.go:95] Deleting pod "simpletest.rc-wdrnj" in namespace "gc-3269"
  I1130 13:13:03.059841 19 delete.go:95] Deleting pod "simpletest.rc-wgs5t" in namespace "gc-3269"
  I1130 13:13:03.116438 19 delete.go:95] Deleting pod "simpletest.rc-wjq7n" in namespace "gc-3269"
  E1130 13:13:03.117244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:13:03.164056 19 delete.go:95] Deleting pod "simpletest.rc-wrrd8" in namespace "gc-3269"
  I1130 13:13:03.207154 19 delete.go:95] Deleting pod "simpletest.rc-wwk66" in namespace "gc-3269"
  I1130 13:13:03.267455 19 delete.go:95] Deleting pod "simpletest.rc-wx482" in namespace "gc-3269"
  I1130 13:13:03.313572 19 delete.go:95] Deleting pod "simpletest.rc-x2trr" in namespace "gc-3269"
  I1130 13:13:03.366712 19 delete.go:95] Deleting pod "simpletest.rc-xj8dv" in namespace "gc-3269"
  I1130 13:13:03.408036 19 delete.go:95] Deleting pod "simpletest.rc-z8v9z" in namespace "gc-3269"
  I1130 13:13:03.461040 19 delete.go:95] Deleting pod "simpletest.rc-zf2xj" in namespace "gc-3269"
  I1130 13:13:03.515106 19 delete.go:95] Deleting pod "simpletest.rc-zngj9" in namespace "gc-3269"
  I1130 13:13:03.559798 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3269" for this suite. @ 11/30/24 13:13:03.601
• [43.773 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 11/30/24 13:13:03.671
  I1130 13:13:03.671298 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename cronjob @ 11/30/24 13:13:03.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:13:03.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:13:03.697
  STEP: Creating a ReplaceConcurrent cronjob @ 11/30/24 13:13:03.702
  STEP: Ensuring a job is scheduled @ 11/30/24 13:13:03.707
  E1130 13:13:04.121874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:05.119087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:06.119493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:07.119552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:08.119860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:09.119939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:10.120186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:11.120291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:12.120597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:13.121596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:14.122286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:15.122464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:16.122643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:17.122898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:18.123021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:19.123105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:20.123333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:21.123581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:22.124326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:23.124551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:24.125538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:25.125758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:26.126775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:27.127591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:28.128351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:29.128551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:30.128790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:31.129161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:32.130018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:33.130112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:34.130589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:35.130676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:36.131677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:37.131759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:38.132481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:39.132752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:40.133531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:41.133915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:42.134734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:43.135602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:44.135735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:45.136600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:46.137565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:47.137694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:48.138512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:49.138747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:50.138832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:51.138897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:52.139577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:53.139862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:54.140564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:55.140663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:56.141445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:57.141853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:58.142684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:13:59.143105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:00.143334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:01.143569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 11/30/24 13:14:01.713
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 11/30/24 13:14:01.717
  STEP: Ensuring the job is replaced with a new one @ 11/30/24 13:14:01.721
  E1130 13:14:02.143928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:03.144146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:04.144822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:05.145028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:06.145773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:07.146146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:08.146962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:09.147176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:10.148009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:11.148202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:12.149115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:13.149578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:14.149705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:15.150597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:16.151614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:17.152609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:18.152709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:19.152813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:20.153112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:21.153310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:22.153460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:23.153670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:24.153717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:25.153956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:26.154101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:27.154351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:28.154582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:29.154669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:30.155657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:31.155811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:32.156530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:33.156747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:34.156873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:35.157248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:36.157402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:37.157710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:38.157799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:39.157984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:40.158189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:41.158423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:42.159146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:43.159252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:44.159346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:45.159544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:46.160591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:47.160682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:48.160781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:49.160870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:50.161009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:51.161575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:52.161710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:53.161909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:54.162033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:55.162122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:56.162609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:57.162927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:58.163056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:14:59.163421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:00.163631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:01.163800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 11/30/24 13:15:01.727
  I1130 13:15:01.734555 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1488" for this suite. @ 11/30/24 13:15:01.738
• [118.076 seconds]
------------------------------
SS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:429
  STEP: Creating a kubernetes client @ 11/30/24 13:15:01.747
  I1130 13:15:01.747190 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pv @ 11/30/24 13:15:01.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:15:01.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:15:01.767
  STEP: Creating initial PV and PVC @ 11/30/24 13:15:01.771
  I1130 13:15:01.771101 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-7336" @ 11/30/24 13:15:01.785
  STEP: Listing PVCs in namespace "pv-7336" @ 11/30/24 13:15:01.791
  STEP: Patching the PV "pv-7336-6dlch" @ 11/30/24 13:15:01.794
  STEP: Patching the PVC "pvc-hbnhg" @ 11/30/24 13:15:01.819
  STEP: Getting PV "pv-7336-6dlch" @ 11/30/24 13:15:01.836
  STEP: Getting PVC "pvc-hbnhg" @ 11/30/24 13:15:01.848
  STEP: Deleting PVC "pvc-hbnhg" @ 11/30/24 13:15:01.855
  STEP: Confirm deletion of PVC "pvc-hbnhg" @ 11/30/24 13:15:01.87
  E1130 13:15:02.164776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:03.164952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-7336-6dlch" @ 11/30/24 13:15:03.88
  STEP: Confirm deletion of PV "pv-7336-6dlch" @ 11/30/24 13:15:03.89
  E1130 13:15:04.165780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:05.165992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 11/30/24 13:15:05.898
  I1130 13:15:05.898698 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-7336-tdgs5" @ 11/30/24 13:15:05.911
  STEP: Updating the PVC "pvc-tjvsd" @ 11/30/24 13:15:05.922
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-tjvsd=updated" @ 11/30/24 13:15:05.93
  STEP: Deleting PVC "pvc-tjvsd" via DeleteCollection @ 11/30/24 13:15:05.936
  STEP: Confirm deletion of PVC "pvc-tjvsd" @ 11/30/24 13:15:05.95
  E1130 13:15:06.166700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:07.167642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-7336-tdgs5" via DeleteCollection @ 11/30/24 13:15:07.958
  STEP: Confirm deletion of PV "pv-7336-tdgs5" @ 11/30/24 13:15:07.97
  E1130 13:15:08.167700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:09.168622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:15:09.979114 19 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I1130 13:15:09.979144 19 pv.go:205] Deleting PersistentVolumeClaim "pvc-tjvsd"
  I1130 13:15:09.983002 19 pv.go:193] Deleting PersistentVolume "pv-7336-tdgs5"
  I1130 13:15:09.987854 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-7336" for this suite. @ 11/30/24 13:15:09.992
• [8.254 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:312
  STEP: Creating a kubernetes client @ 11/30/24 13:15:10.001
  I1130 13:15:10.001411 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:15:10.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:15:10.016
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:15:10.019
  STEP: Setting up server cert @ 11/30/24 13:15:10.041
  E1130 13:15:10.169563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:15:10.383
  STEP: Deploying the webhook pod @ 11/30/24 13:15:10.394
  STEP: Wait for the deployment to be ready @ 11/30/24 13:15:10.407
  I1130 13:15:10.415087 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:15:11.169658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:12.169753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:15:12.428
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:15:12.44
  E1130 13:15:13.169818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:15:13.441220 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I1130 13:15:13.449929 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2437-crds.webhook.example.com via the AdmissionRegistration API @ 11/30/24 13:15:13.962
  STEP: Creating a custom resource while v1 is storage version @ 11/30/24 13:15:13.977
  E1130 13:15:14.170291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:15.170331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 11/30/24 13:15:16.01
  STEP: Patching the custom resource while v2 is storage version @ 11/30/24 13:15:16.022
  E1130 13:15:16.170694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:15:16.619764 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1388" for this suite. @ 11/30/24 13:15:16.623
  STEP: Destroying namespace "webhook-markers-60" for this suite. @ 11/30/24 13:15:16.632
• [6.639 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 11/30/24 13:15:16.64
  I1130 13:15:16.640816 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 13:15:16.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:15:16.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:15:16.66
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 13:15:16.663
  E1130 13:15:17.171584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:18.171707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:19.172614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:20.172854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:15:20.688
  I1130 13:15:20.692255 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod downwardapi-volume-9c6b83a2-eef7-474b-a00a-81d7627fb10b container client-container: <nil>
  STEP: delete the pod @ 11/30/24 13:15:20.711
  I1130 13:15:20.731867 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5406" for this suite. @ 11/30/24 13:15:20.735
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:890
  STEP: Creating a kubernetes client @ 11/30/24 13:15:20.742
  I1130 13:15:20.742468 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename daemonsets @ 11/30/24 13:15:20.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:15:20.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:15:20.764
  STEP: Creating simple DaemonSet "daemon-set" @ 11/30/24 13:15:20.791
  STEP: Check that daemon pods launch on every node of the cluster. @ 11/30/24 13:15:20.798
  I1130 13:15:20.806130 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:15:20.806169 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:15:20.810009 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 13:15:20.810036 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  E1130 13:15:21.173552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:15:21.803987 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:15:21.804026 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:15:21.811286 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1130 13:15:21.811318 19 fixtures.go:130] Node ip-172-31-64-147 is running 0 daemon pod, expected 1
  E1130 13:15:22.173798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:15:22.804233 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:15:22.804282 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:15:22.809038 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 13:15:22.809062 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 11/30/24 13:15:22.813
  I1130 13:15:22.817110 19 daemon_set.go:927] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 11/30/24 13:15:22.817
  I1130 13:15:22.828648 19 daemon_set.go:947] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 11/30/24 13:15:22.828
  I1130 13:15:22.830697 19 daemon_set.go:972] Observed &DaemonSet event: ADDED
  I1130 13:15:22.830764 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.830955 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.831041 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.831106 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.831124 19 daemon_set.go:965] Found daemon set daemon-set in namespace daemonsets-3600 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I1130 13:15:22.831134 19 daemon_set.go:976] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 11/30/24 13:15:22.831
  STEP: watching for the daemon set status to be patched @ 11/30/24 13:15:22.837
  I1130 13:15:22.838817 19 daemon_set.go:1016] Observed &DaemonSet event: ADDED
  I1130 13:15:22.838883 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.838940 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.839122 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.839196 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.839211 19 daemon_set.go:1012] Observed daemon set daemon-set in namespace daemonsets-3600 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I1130 13:15:22.839299 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1130 13:15:22.839323 19 daemon_set.go:1009] Found daemon set daemon-set in namespace daemonsets-3600 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I1130 13:15:22.839335 19 daemon_set.go:1020] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 11/30/24 13:15:22.845
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3600, will wait for the garbage collector to delete the pods @ 11/30/24 13:15:22.845
  I1130 13:15:22.906546 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.750032ms
  I1130 13:15:23.007692 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.135341ms
  E1130 13:15:23.174465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:24.175522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:15:24.613108 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 13:15:24.613146 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1130 13:15:24.616940 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38640"},"items":null}

  I1130 13:15:24.620956 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38640"},"items":null}

  I1130 13:15:24.636088 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3600" for this suite. @ 11/30/24 13:15:24.64
• [3.905 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 11/30/24 13:15:24.647
  I1130 13:15:24.647947 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:15:24.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:15:24.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:15:24.668
  STEP: Creating projection with secret that has name projected-secret-test-map-d2c1b9b9-b411-432b-8b55-9d901ff0aafd @ 11/30/24 13:15:24.671
  STEP: Creating a pod to test consume secrets @ 11/30/24 13:15:24.677
  E1130 13:15:25.175630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:26.176604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:27.177499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:28.177665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:15:28.703
  I1130 13:15:28.706768 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-projected-secrets-90524deb-ca97-45cb-b7da-a4f735272674 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 13:15:28.716
  I1130 13:15:28.737640 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4743" for this suite. @ 11/30/24 13:15:28.743
• [4.104 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 11/30/24 13:15:28.752
  I1130 13:15:28.752695 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename cronjob @ 11/30/24 13:15:28.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:15:28.769
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:15:28.773
  STEP: Creating a suspended cronjob @ 11/30/24 13:15:28.777
  STEP: Ensuring no jobs are scheduled @ 11/30/24 13:15:28.782
  E1130 13:15:29.178534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:30.178639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:31.178768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:32.179796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:33.180520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:34.181607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:35.181707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:36.181863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:37.181966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:38.182884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:39.183953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:40.184357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:41.184663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:42.184932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:43.185844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:44.186922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:45.187484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:46.187587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:47.187986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:48.188072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:49.188923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:50.189024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:51.189128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:52.189622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:53.190487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:54.191567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:55.192593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:56.192872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:57.193038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:58.193573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:15:59.193762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:00.193954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:01.194879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:02.195057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:03.195280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:04.195488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:05.196561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:06.196676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:07.196821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:08.197064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:09.197813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:10.198051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:11.198153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:12.199156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:13.199976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:14.200249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:15.200554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:16.200649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:17.201555      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:18.202577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:19.203651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:20.203762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:21.203819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:22.204483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:23.204523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:24.204724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:25.205569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:26.205707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:27.206619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:28.206916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:29.207099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:30.207348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:31.207560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:32.207694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:33.207760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:34.207993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:35.208649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:36.209596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:37.209697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:38.209787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:39.209886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:40.209986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:41.210521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:42.211589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:43.212291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:44.212411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:45.212984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:46.213184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:47.213198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:48.213465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:49.214439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:50.214657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:51.214871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:52.215213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:53.215423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:54.215821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:55.216705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:56.217612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:57.217837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:58.218069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:16:59.219017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:00.219118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:01.219604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:02.219696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:03.220306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:04.220502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:05.220963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:06.221589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:07.222606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:08.223315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:09.223544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:10.223556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:11.223614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:12.223939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:13.224591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:14.224959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:15.226045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:16.226153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:17.226975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:18.227144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:19.227917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:20.228056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:21.228698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:22.228824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:23.229830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:24.229897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:25.230420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:26.230800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:27.231685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:28.231774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:29.232658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:30.232851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:31.233327      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:32.233523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:33.233918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:34.234025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:35.234108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:36.234336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:37.234698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:38.234910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:39.235494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:40.235707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:41.235974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:42.236171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:43.237008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:44.237233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:45.238053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:46.238158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:47.239173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:48.239704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:49.240234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:50.240584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:51.241331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:52.241502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:53.242282      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:54.242488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:55.243006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:56.243264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:57.243787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:58.244083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:17:59.244347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:00.244681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:01.245257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:02.245507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:03.246262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:04.246447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:05.247183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:06.247486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:07.248356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:08.248535      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:09.248776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:10.248907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:11.249482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:12.249534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:13.250390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:14.250639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:15.250891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:16.251002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:17.251182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:18.251301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:19.251806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:20.251929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:21.251980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:22.252459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:23.252511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:24.252654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:25.252936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:26.253464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:27.253773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:28.253940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:29.254057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:30.254531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:31.254714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:32.254917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:33.255124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:34.255301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:35.255587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:36.255688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:37.255808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:38.256593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:39.256806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:40.257099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:41.257218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:42.257548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:43.257695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:44.257901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:45.258915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:46.259542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:47.259642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:48.259735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:49.259838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:50.259932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:51.260001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:52.260539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:53.260662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:54.260751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:55.260858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:56.260956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:57.261018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:58.261538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:18:59.262597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:00.262716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:01.262954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:02.263476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:03.263690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:04.263816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:05.263928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:06.264121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:07.264533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:08.264634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:09.264862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:10.264994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:11.265214      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:12.265420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:13.265671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:14.265744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:15.265863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:16.266668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:17.266944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:18.267078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:19.267331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:20.267721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:21.267968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:22.268984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:23.269069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:24.269159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:25.269238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:26.269602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:27.269685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:28.270516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:29.270623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:30.270720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:31.270828      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:32.271618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:33.272599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:34.272988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:35.273108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:36.273144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:37.273535      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:38.273771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:39.274024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:40.274412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:41.274712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:42.274704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:43.274934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:44.275143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:45.275394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:46.275662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:47.275881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:48.275969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:49.276041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:50.276211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:51.276414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:52.276670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:53.276784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:54.276875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:55.277597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:56.277790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:57.278136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:58.278340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:19:59.278467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:00.278546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:01.278644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:02.279219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:03.279893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:04.279985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:05.280888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:06.281006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:07.281592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:08.281709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:09.282584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:10.282700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:11.283591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:12.283746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:13.283847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:14.283965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:15.284045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:16.284349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:17.284602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:18.285615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:19.285742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:20.286674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:21.286781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:22.287681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:23.287852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:24.287998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:25.289027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:26.289121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:27.289531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:28.290161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 11/30/24 13:20:28.783
  STEP: Removing cronjob @ 11/30/24 13:20:28.788
  I1130 13:20:28.795189 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8444" for this suite. @ 11/30/24 13:20:28.799
• [300.054 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 11/30/24 13:20:28.807
  I1130 13:20:28.807164 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 11/30/24 13:20:28.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:20:28.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:20:28.831
  STEP: create the container to handle the HTTPGet hook request. @ 11/30/24 13:20:28.838
  E1130 13:20:29.290633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:30.291600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 11/30/24 13:20:30.864
  E1130 13:20:31.292137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:32.292252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 11/30/24 13:20:32.885
  STEP: delete the pod with lifecycle hook @ 11/30/24 13:20:32.904
  E1130 13:20:33.292361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:34.292540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:20:34.923682 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-2608" for this suite. @ 11/30/24 13:20:34.928
• [6.128 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 11/30/24 13:20:34.935
  I1130 13:20:34.935613 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 13:20:34.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:20:34.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:20:34.961
  STEP: Creating a pod to test emptydir volume type on node default medium @ 11/30/24 13:20:34.964
  E1130 13:20:35.293092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:36.293599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:20:36.985
  I1130 13:20:36.988639 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-029abc8c-c66c-485a-bb03-3b10231aee91 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 13:20:37.007
  I1130 13:20:37.025219 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9850" for this suite. @ 11/30/24 13:20:37.029
• [2.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1054
  STEP: Creating a kubernetes client @ 11/30/24 13:20:37.039
  I1130 13:20:37.039741 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename job @ 11/30/24 13:20:37.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:20:37.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:20:37.061
  STEP: Creating a job @ 11/30/24 13:20:37.067
  STEP: Ensure pods equal to parallelism count is attached to the job @ 11/30/24 13:20:37.073
  E1130 13:20:37.294258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:38.294491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching /status @ 11/30/24 13:20:39.079
  STEP: updating /status @ 11/30/24 13:20:39.088
  STEP: get /status @ 11/30/24 13:20:39.097
  I1130 13:20:39.101788 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2276" for this suite. @ 11/30/24 13:20:39.106
• [2.074 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 11/30/24 13:20:39.114
  I1130 13:20:39.114249 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 13:20:39.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:20:39.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:20:39.142
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 13:20:39.145
  E1130 13:20:39.294533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:40.294833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:41.295122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:42.295561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:20:43.182
  I1130 13:20:43.186238 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-bc114c44-a844-4578-9ce3-09a7adb979e4 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 13:20:43.194
  I1130 13:20:43.207960 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2892" for this suite. @ 11/30/24 13:20:43.212
• [4.108 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 11/30/24 13:20:43.221
  I1130 13:20:43.221924 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:20:43.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:20:43.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:20:43.24
  STEP: Creating secret with name s-test-opt-del-6fa26dc5-cca9-4e56-8755-b99c616c4a12 @ 11/30/24 13:20:43.247
  STEP: Creating secret with name s-test-opt-upd-1e50b1e5-2ea2-4dbb-ab8e-c99f190452b0 @ 11/30/24 13:20:43.252
  STEP: Creating the pod @ 11/30/24 13:20:43.258
  E1130 13:20:43.295841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:44.295984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:45.296732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-6fa26dc5-cca9-4e56-8755-b99c616c4a12 @ 11/30/24 13:20:45.307
  STEP: Updating secret s-test-opt-upd-1e50b1e5-2ea2-4dbb-ab8e-c99f190452b0 @ 11/30/24 13:20:45.316
  STEP: Creating secret with name s-test-opt-create-a0461039-ada8-4c48-8310-af68371e89ba @ 11/30/24 13:20:45.32
  STEP: waiting to observe update in volume @ 11/30/24 13:20:45.325
  E1130 13:20:46.297614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:47.297800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:48.298142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:49.298346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:50.298432      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:51.298699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:52.299027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:53.299950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:54.300036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:55.300148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:56.300533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:57.301601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:58.301784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:20:59.301886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:00.301987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:01.302157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:02.302420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:03.302643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:04.302831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:05.302985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:06.303508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:07.303820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:08.304051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:09.304206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:10.304430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:11.304653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:12.304974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:13.305148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:14.305512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:15.305695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:16.305856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:17.306570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:18.306921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:19.307171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:20.307563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:21.307762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:22.307859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:23.307946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:24.308152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:25.308393      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:26.308787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:27.308881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:28.309241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:29.309596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:30.309706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:31.309790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:32.310597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:33.310692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:34.310782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:35.310875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:36.310972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:37.311435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:38.311645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:39.311747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:40.312576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:41.312982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:42.312906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:43.313583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:44.313963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:45.314153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:46.314509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:47.314880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:48.315490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:49.315665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:50.315969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:51.316250      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:52.317222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:53.317501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:54.317672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:55.318627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:56.318839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:57.319908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:58.320608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:21:59.321581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:21:59.693721 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1634" for this suite. @ 11/30/24 13:21:59.697
• [76.483 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 11/30/24 13:21:59.705
  I1130 13:21:59.705688 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename namespaces @ 11/30/24 13:21:59.706
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:21:59.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:21:59.727
  STEP: Updating Namespace "namespaces-5953" @ 11/30/24 13:21:59.73
  I1130 13:21:59.741009 19 namespace.go:389] Namespace "namespaces-5953" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"d87efc80-85e9-45de-a155-d58a801812e9", "kubernetes.io/metadata.name":"namespaces-5953", "namespaces-5953":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I1130 13:21:59.741092 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5953" for this suite. @ 11/30/24 13:21:59.745
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:287
  STEP: Creating a kubernetes client @ 11/30/24 13:21:59.751
  I1130 13:21:59.751302 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename field-validation @ 11/30/24 13:21:59.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:21:59.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:21:59.769
  I1130 13:21:59.772922 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:22:00.322486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:01.322705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:02.323566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:02.860696 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8321" for this suite. @ 11/30/24 13:22:02.864
• [3.120 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 11/30/24 13:22:02.871
  I1130 13:22:02.871847 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename endpointslice @ 11/30/24 13:22:02.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:22:02.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:22:02.894
  STEP: getting /apis @ 11/30/24 13:22:02.897
  STEP: getting /apis/discovery.k8s.io @ 11/30/24 13:22:02.901
  STEP: getting /apis/discovery.k8s.iov1 @ 11/30/24 13:22:02.902
  STEP: creating @ 11/30/24 13:22:02.904
  STEP: getting @ 11/30/24 13:22:02.92
  STEP: listing @ 11/30/24 13:22:02.923
  STEP: watching @ 11/30/24 13:22:02.926
  I1130 13:22:02.926713 19 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 11/30/24 13:22:02.928
  STEP: cluster-wide watching @ 11/30/24 13:22:02.932
  I1130 13:22:02.932477 19 endpointslice.go:459] starting watch
  STEP: patching @ 11/30/24 13:22:02.933
  STEP: updating @ 11/30/24 13:22:02.939
  I1130 13:22:02.949553 19 endpointslice.go:482] waiting for watch events with expected annotations
  I1130 13:22:02.949585 19 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 11/30/24 13:22:02.949
  STEP: deleting a collection @ 11/30/24 13:22:02.963
  I1130 13:22:02.981345 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-6888" for this suite. @ 11/30/24 13:22:02.985
• [0.121 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 11/30/24 13:22:02.993
  I1130 13:22:02.993333 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 13:22:02.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:22:03.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:22:03.012
  STEP: set up a multi version CRD @ 11/30/24 13:22:03.015
  I1130 13:22:03.016242 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:22:03.324613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:04.324929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:05.325643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: rename a version @ 11/30/24 13:22:06.167
  STEP: check the new version name is served @ 11/30/24 13:22:06.18
  E1130 13:22:06.326694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 11/30/24 13:22:07.018
  E1130 13:22:07.326915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 11/30/24 13:22:07.629
  E1130 13:22:08.327903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:09.327944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:10.068208 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7479" for this suite. @ 11/30/24 13:22:10.075
• [7.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1075
  STEP: Creating a kubernetes client @ 11/30/24 13:22:10.084
  I1130 13:22:10.084112 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 13:22:10.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:22:10.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:22:10.103
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 11/30/24 13:22:10.106
  I1130 13:22:10.106913 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8564 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I1130 13:22:10.162020 19 builder.go:146] stderr: ""
  I1130 13:22:10.162060 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 11/30/24 13:22:10.162
  I1130 13:22:10.162214 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8564 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I1130 13:22:10.212469 19 builder.go:146] stderr: ""
  I1130 13:22:10.212515 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 11/30/24 13:22:10.212
  I1130 13:22:10.216256 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8564 delete pods e2e-test-httpd-pod'
  E1130 13:22:10.328542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:11.328611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:11.811914 19 builder.go:146] stderr: ""
  I1130 13:22:11.811949 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I1130 13:22:11.812064 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8564" for this suite. @ 11/30/24 13:22:11.816
• [1.741 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 11/30/24 13:22:11.824
  I1130 13:22:11.824818 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename custom-resource-definition @ 11/30/24 13:22:11.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:22:11.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:22:11.847
  I1130 13:22:11.850759 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:22:12.329147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:12.394013 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4575" for this suite. @ 11/30/24 13:22:12.399
• [0.582 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 11/30/24 13:22:12.407
  I1130 13:22:12.407294 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 13:22:12.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:22:12.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:22:12.428
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 11/30/24 13:22:12.431
  E1130 13:22:13.329525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:14.329625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:15.329724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:16.329811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:22:16.453
  I1130 13:22:16.457520 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-5c641fa7-e3cb-4ad9-a48c-e72b92f5135b container test-container: <nil>
  STEP: delete the pod @ 11/30/24 13:22:16.469
  I1130 13:22:16.488452 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1332" for this suite. @ 11/30/24 13:22:16.492
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 11/30/24 13:22:16.499
  I1130 13:22:16.499349 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename discovery @ 11/30/24 13:22:16.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:22:16.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:22:16.521
  STEP: Setting up server cert @ 11/30/24 13:22:16.526
  STEP: Requesting APIResourceList from "/api/v1" @ 11/30/24 13:22:16.85
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 11/30/24 13:22:16.852
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 11/30/24 13:22:16.853
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 11/30/24 13:22:16.855
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 11/30/24 13:22:16.856
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 11/30/24 13:22:16.857
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 11/30/24 13:22:16.859
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 11/30/24 13:22:16.861
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 11/30/24 13:22:16.862
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 11/30/24 13:22:16.864
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 11/30/24 13:22:16.865
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 11/30/24 13:22:16.866
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 11/30/24 13:22:16.868
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 11/30/24 13:22:16.869
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 11/30/24 13:22:16.871
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 11/30/24 13:22:16.872
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 11/30/24 13:22:16.873
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 11/30/24 13:22:16.875
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 11/30/24 13:22:16.876
  I1130 13:22:16.878332 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-246" for this suite. @ 11/30/24 13:22:16.882
• [0.391 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 11/30/24 13:22:16.89
  I1130 13:22:16.890208 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 13:22:16.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:22:16.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:22:16.907
  STEP: Creating pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365 @ 11/30/24 13:22:16.911
  E1130 13:22:17.330570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:18.330664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 11/30/24 13:22:18.932
  I1130 13:22:18.936663 19 container_probe.go:1749] Initial restart count of pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 is 0
  I1130 13:22:18.941085 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:19.331616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:20.331822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:20.946578 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:21.331928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:22.332033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:22.951865 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:23.332278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:24.332507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:24.956951 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:25.332610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:26.332897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:26.962851 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:27.333277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:28.333421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:28.967878 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:29.333524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:30.333758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:30.973609 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:31.334051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:32.334112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:32.978461 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:33.335037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:34.335609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:34.984066 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:35.335854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:36.336912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:36.989502 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:37.337646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:38.337845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:38.995996 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:39.338615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:40.339287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:41.000878 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:41.340288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:42.340491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:43.006067 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:43.341640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:44.342564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:45.010870 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:45.343389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:46.343539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:47.017133 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:47.344643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:48.344864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:49.022541 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:49.344955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:50.345198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:51.028128 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:51.345539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:52.346572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:53.033554 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:53.346865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:54.347095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:55.038839 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:55.347328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:56.347602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:57.045144 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:57.347698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:22:58.347898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:22:59.050750 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:22:59.347994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:00.348189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:01.056982 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:01.348289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:02.348671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:03.061610 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:03.348964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:04.349930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:05.067719 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:05.350004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:06.350558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:07.073434 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:07.350721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:08.351629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:09.078498 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:09.351703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:10.351807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:11.084094 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:11.352465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:12.352502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:13.089730 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:13.353192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:14.353290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:15.095944 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:15.354460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:16.354507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:17.101862 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:17.355171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:18.355286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:19.107828 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:19.356232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:20.356524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:21.113552 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:21.356958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:22.357778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:23.119167 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:23.358576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:24.359584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:25.124455 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:25.360567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:26.361565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:27.128975 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:27.362321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:28.362612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:29.136623 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:29.362907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:30.363101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:31.141930 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:31.363242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:32.363673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:33.147868 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:33.364241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:34.364522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:35.152918 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:35.365196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:36.365563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:37.158232 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:37.365629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:38.366566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:39.165644 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:39.366928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:40.367058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:41.170866 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:41.367092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:42.367512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:43.177089 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:43.367669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:44.367871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:45.182843 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:45.368016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:46.368569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:47.188809 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:47.369118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:48.369307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:49.194872 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:49.370028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:50.371064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:51.200221 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:51.371474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:52.371755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:53.206445 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:53.372571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:54.372782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:55.212313 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:55.373772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:56.373899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:57.217939 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:57.374123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:23:58.374347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:23:59.223277 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:23:59.374505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:00.374707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:01.229228 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:01.375589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:02.375909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:03.234533 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:03.376836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:04.377033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:05.240632 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:05.377979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:06.378180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:07.245776 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:07.378965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:08.379076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:09.251853 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:09.380083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:10.380419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:11.257930 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:11.381227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:12.381497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:13.263083 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:13.382288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:14.382482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:15.268476 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:15.382818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:16.383128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:17.274291 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:17.383482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:18.383692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:19.279879 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:19.384134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:20.384345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:21.286079 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:21.385511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:22.385827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:23.292251 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:23.386497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:24.386531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:25.297505 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:25.387575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:26.387703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:27.303262 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:27.388462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:28.388545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:29.308647 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:29.388883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:30.389587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:31.314978 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:31.390108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:32.390562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:33.320740 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:33.390907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:34.391000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:35.326630 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:35.391812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:36.392570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:37.332392 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:37.393560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:38.393868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:39.338633 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:39.393913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:40.394137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:41.343797 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:41.395072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:42.395509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:43.349203 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:43.396325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:44.396497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:45.354750 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:45.396913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:46.397101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:47.360621 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:47.397763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:48.397859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:49.365651 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:49.398765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:50.398896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:51.371443 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:51.399655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:52.400561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:53.377509 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:53.401624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:54.401813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:55.382824 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:55.401888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:56.402565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:57.388500 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:57.402696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:24:58.402987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:24:59.393833 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:24:59.403038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:00.403260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:01.400535 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:01.403582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:02.403811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:03.404682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:03.406120 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:04.404806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:05.405720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:05.412521 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:06.406531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:07.407011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:07.418206 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:08.407173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:09.407427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:09.423906 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:10.407982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:11.408615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:11.430220 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:12.409158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:13.409902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:13.436508 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:14.410023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:15.410591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:15.441955 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:16.410706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:17.411606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:17.447753 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:18.411812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:19.411999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:19.454582 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:20.412604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:21.412693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:21.459252 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:22.413629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:23.413842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:23.464404 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:24.414459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:25.414631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:25.470396 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:26.415346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:27.415622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:27.476355 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:28.416346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:29.416668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:29.481898 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:30.416876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:31.417432      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:31.488090 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:32.417558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:33.417806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:33.494365 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:34.418246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:35.419228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:35.501194 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:36.419546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:37.420608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:37.507468 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:38.421604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:39.421737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:39.513598 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:40.421844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:41.421978      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:41.519029 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:42.422051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:43.422833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:43.525334 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:44.423330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:45.423561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:45.530252 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:46.424236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:47.424611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:47.536441 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:48.424815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:49.425097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:49.542192 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:50.425363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:51.425554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:51.548118 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:52.426049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:53.426311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:53.554459 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:54.426404      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:55.426627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:55.559787 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:56.426954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:57.427561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:57.565668 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:25:58.427647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:25:59.427874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:25:59.570872 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:00.428034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:01.428256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:01.576643 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:02.428543      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:03.428598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:03.581651 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:04.429605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:05.429704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:05.587274 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:06.430593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:07.431571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:07.592564 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:08.432491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:09.432721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:09.598401 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:10.433253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:11.433539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:11.603982 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:12.433719      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:13.433954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:13.609806 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:14.434495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:15.434740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:15.614833 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:16.435566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:17.436216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:17.620986 19 container_probe.go:1759] Get pod busybox-70de8ef2-9b49-4e72-a51e-d6c45d74c993 in namespace container-probe-8365
  E1130 13:26:18.436959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:19.437567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 11/30/24 13:26:19.621
  I1130 13:26:19.637093 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8365" for this suite. @ 11/30/24 13:26:19.641
• [242.759 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 11/30/24 13:26:19.649
  I1130 13:26:19.649514 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 13:26:19.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:19.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:19.673
  STEP: Creating configMap configmap-483/configmap-test-b03eb7bc-5b62-41d5-b306-6219e4973640 @ 11/30/24 13:26:19.677
  STEP: Creating a pod to test consume configMaps @ 11/30/24 13:26:19.684
  E1130 13:26:20.437759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:21.437933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:22.438522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:23.438742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:26:23.71
  I1130 13:26:23.714954 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-configmaps-243e7ab3-df91-402d-997a-bfbc5c83c318 container env-test: <nil>
  STEP: delete the pod @ 11/30/24 13:26:23.737
  I1130 13:26:23.755695 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-483" for this suite. @ 11/30/24 13:26:23.759
• [4.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:838
  STEP: Creating a kubernetes client @ 11/30/24 13:26:23.768
  I1130 13:26:23.768721 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:26:23.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:23.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:23.789
  STEP: Setting up server cert @ 11/30/24 13:26:23.87
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:26:24.079
  STEP: Deploying the webhook pod @ 11/30/24 13:26:24.089
  STEP: Wait for the deployment to be ready @ 11/30/24 13:26:24.103
  I1130 13:26:24.118353 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:26:24.439753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:25.439835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:26:26.132
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:26:26.143
  E1130 13:26:26.440403      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:27.144429 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 11/30/24 13:26:27.153
  I1130 13:26:27.196823 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3706" for this suite. @ 11/30/24 13:26:27.2
  STEP: Destroying namespace "webhook-markers-3569" for this suite. @ 11/30/24 13:26:27.21
• [3.448 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 11/30/24 13:26:27.217
  I1130 13:26:27.217284 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 13:26:27.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:27.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:27.239
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 11/30/24 13:26:27.244
  E1130 13:26:27.441046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:28.441134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:29.441523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:30.441716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:26:31.275
  I1130 13:26:31.279736 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-4bfc457e-fc93-429b-884d-421d86cf22b9 container test-container: <nil>
  STEP: delete the pod @ 11/30/24 13:26:31.288
  I1130 13:26:31.311521 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1076" for this suite. @ 11/30/24 13:26:31.315
• [4.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 11/30/24 13:26:31.327
  I1130 13:26:31.327415 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename controllerrevisions @ 11/30/24 13:26:31.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:31.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:31.348
  STEP: Creating DaemonSet "e2e-699dw-daemon-set" @ 11/30/24 13:26:31.372
  STEP: Check that daemon pods launch on every node of the cluster. @ 11/30/24 13:26:31.379
  I1130 13:26:31.384654 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:26:31.384699 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:26:31.387723 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-699dw-daemon-set: 0
  I1130 13:26:31.387738 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  E1130 13:26:31.441967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:32.385328 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:26:32.385449 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:26:32.388797 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-699dw-daemon-set: 1
  I1130 13:26:32.388817 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  E1130 13:26:32.442952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:33.384917 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:26:33.384965 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:26:33.389273 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-699dw-daemon-set: 3
  I1130 13:26:33.389292 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset e2e-699dw-daemon-set
  STEP: Confirm DaemonSet "e2e-699dw-daemon-set" successfully created with "daemonset-name=e2e-699dw-daemon-set" label @ 11/30/24 13:26:33.393
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-699dw-daemon-set" @ 11/30/24 13:26:33.401
  I1130 13:26:33.404760 19 controller_revision.go:162] Located ControllerRevision: "e2e-699dw-daemon-set-5cbddc9f75"
  STEP: Patching ControllerRevision "e2e-699dw-daemon-set-5cbddc9f75" @ 11/30/24 13:26:33.408
  I1130 13:26:33.414355 19 controller_revision.go:173] e2e-699dw-daemon-set-5cbddc9f75 has been patched
  STEP: Create a new ControllerRevision @ 11/30/24 13:26:33.414
  I1130 13:26:33.421832 19 controller_revision.go:191] Created ControllerRevision: e2e-699dw-daemon-set-5b4c974c8c
  STEP: Confirm that there are two ControllerRevisions @ 11/30/24 13:26:33.421
  I1130 13:26:33.421887 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I1130 13:26:33.426552 19 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-699dw-daemon-set-5cbddc9f75" @ 11/30/24 13:26:33.426
  STEP: Confirm that there is only one ControllerRevision @ 11/30/24 13:26:33.434
  I1130 13:26:33.434991 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I1130 13:26:33.438791 19 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-699dw-daemon-set-5b4c974c8c" @ 11/30/24 13:26:33.442
  E1130 13:26:33.443598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:33.451473 19 controller_revision.go:220] e2e-699dw-daemon-set-5b4c974c8c has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 11/30/24 13:26:33.451
  W1130 13:26:33.459507      19 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 11/30/24 13:26:33.459
  I1130 13:26:33.459633 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  E1130 13:26:34.443784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:34.460029 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I1130 13:26:34.467890 19 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-699dw-daemon-set-5b4c974c8c=updated" @ 11/30/24 13:26:34.467
  STEP: Confirm that there is only one ControllerRevision @ 11/30/24 13:26:34.48
  I1130 13:26:34.480637 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I1130 13:26:34.485216 19 controller_revision.go:265] Found 1 ControllerRevisions
  I1130 13:26:34.488824 19 controller_revision.go:246] ControllerRevision "e2e-699dw-daemon-set-696b76b78" has revision 3
  STEP: Deleting DaemonSet "e2e-699dw-daemon-set" @ 11/30/24 13:26:34.495
  STEP: deleting DaemonSet.extensions e2e-699dw-daemon-set in namespace controllerrevisions-5962, will wait for the garbage collector to delete the pods @ 11/30/24 13:26:34.495
  I1130 13:26:34.559155 19 resources.go:139] Deleting DaemonSet.extensions e2e-699dw-daemon-set took: 8.797774ms
  I1130 13:26:34.659448 19 resources.go:163] Terminating DaemonSet.extensions e2e-699dw-daemon-set pods took: 100.290957ms
  E1130 13:26:35.444322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:35.764663 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-699dw-daemon-set: 0
  I1130 13:26:35.764698 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-699dw-daemon-set
  I1130 13:26:35.768657 19 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"40711"},"items":null}

  I1130 13:26:35.772817 19 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"40711"},"items":null}

  I1130 13:26:35.788001 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-5962" for this suite. @ 11/30/24 13:26:35.792
• [4.473 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 11/30/24 13:26:35.8
  I1130 13:26:35.800192 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename security-context-test @ 11/30/24 13:26:35.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:35.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:35.821
  E1130 13:26:36.444434      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:37.444859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:38.445091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:39.445319      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:39.860226 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9114" for this suite. @ 11/30/24 13:26:39.864
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:193
  STEP: Creating a kubernetes client @ 11/30/24 13:26:39.874
  I1130 13:26:39.874226 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename dns @ 11/30/24 13:26:39.874
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:39.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:39.896
  STEP: Creating a test headless service @ 11/30/24 13:26:39.899
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6171 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6171;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6171 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6171;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6171.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6171.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6171.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6171.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6171.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6171.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6171.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6171.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6171.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6171.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6171.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6171.svc;check="$$(dig +notcp +noall +answer +search 189.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.189_udp@PTR;check="$$(dig +tcp +noall +answer +search 189.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.189_tcp@PTR;sleep 1; done
   @ 11/30/24 13:26:39.919
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6171 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6171;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6171 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6171;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6171.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6171.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6171.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6171.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6171.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6171.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6171.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6171.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6171.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6171.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6171.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6171.svc;check="$$(dig +notcp +noall +answer +search 189.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.189_udp@PTR;check="$$(dig +tcp +noall +answer +search 189.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.189_tcp@PTR;sleep 1; done
   @ 11/30/24 13:26:39.919
  STEP: creating a pod to probe DNS @ 11/30/24 13:26:39.919
  STEP: submitting the pod to kubernetes @ 11/30/24 13:26:39.919
  E1130 13:26:40.445616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:41.445804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 11/30/24 13:26:41.941
  STEP: looking for the results for each expected name from probers @ 11/30/24 13:26:41.945
  I1130 13:26:41.951777 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:41.956156 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:41.960768 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6171 from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:41.965623 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6171 from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:41.970108 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-6171.svc from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:41.974399 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-6171.svc from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:41.978942 19 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6171.svc from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:41.983467 19 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6171.svc from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.006621 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.011623 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.016341 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6171 from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.021442 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6171 from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.025831 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-6171.svc from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.030352 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-6171.svc from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.035151 19 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6171.svc from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.039540 19 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6171.svc from pod dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74: the server could not find the requested resource (get pods dns-test-178b20f4-0bba-450f-a474-9eff8b610c74)
  I1130 13:26:42.057666 19 dns_common.go:489] Lookups using dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6171 wheezy_tcp@dns-test-service.dns-6171 wheezy_udp@dns-test-service.dns-6171.svc wheezy_tcp@dns-test-service.dns-6171.svc wheezy_udp@_http._tcp.dns-test-service.dns-6171.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6171.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6171 jessie_tcp@dns-test-service.dns-6171 jessie_udp@dns-test-service.dns-6171.svc jessie_tcp@dns-test-service.dns-6171.svc jessie_udp@_http._tcp.dns-test-service.dns-6171.svc jessie_tcp@_http._tcp.dns-test-service.dns-6171.svc]

  I1130 13:26:42.065112 19 dns_common.go:495] Pod client logs for webserver: 
  I1130 13:26:42.072021 19 dns_common.go:495] Pod client logs for querier: 
  I1130 13:26:42.079572 19 dns_common.go:495] Pod client logs for jessie-querier: 
  E1130 13:26:42.446119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:43.446401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:44.446615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:45.446723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:46.446833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:47.065845 19 dns_common.go:527] DNS probes using dns-6171/dns-test-178b20f4-0bba-450f-a474-9eff8b610c74 succeeded

  STEP: deleting the pod @ 11/30/24 13:26:47.065
  STEP: deleting the test service @ 11/30/24 13:26:47.089
  STEP: deleting the test headless service @ 11/30/24 13:26:47.129
  I1130 13:26:47.149102 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6171" for this suite. @ 11/30/24 13:26:47.162
• [7.297 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:166
  STEP: Creating a kubernetes client @ 11/30/24 13:26:47.171
  I1130 13:26:47.171424 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename field-validation @ 11/30/24 13:26:47.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:47.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:47.249
  I1130 13:26:47.253130 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:26:47.447688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:48.447807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:49.447912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W1130 13:26:49.790974      19 warnings.go:70] unknown field "alpha"
  W1130 13:26:49.790992      19 warnings.go:70] unknown field "beta"
  W1130 13:26:49.790996      19 warnings.go:70] unknown field "delta"
  W1130 13:26:49.790999      19 warnings.go:70] unknown field "epsilon"
  W1130 13:26:49.791002      19 warnings.go:70] unknown field "gamma"
  I1130 13:26:50.346479 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3091" for this suite. @ 11/30/24 13:26:50.35
• [3.189 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 11/30/24 13:26:50.36
  I1130 13:26:50.360603 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename endpointslice @ 11/30/24 13:26:50.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:50.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:50.385
  I1130 13:26:50.398630 19 endpointslice.go:1045] Endpoints addresses: [172.31.37.252 172.31.87.36] , ports: [6443]
  I1130 13:26:50.398658 19 endpointslice.go:1075] EndpointSlices addresses: [172.31.37.252 172.31.87.36] , ports: [6443]
  I1130 13:26:50.398762 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-5445" for this suite. @ 11/30/24 13:26:50.402
• [0.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 11/30/24 13:26:50.409
  I1130 13:26:50.409834 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 13:26:50.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:26:50.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:26:50.432
  STEP: Creating pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641 @ 11/30/24 13:26:50.435
  E1130 13:26:50.448736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:51.449862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:52.450596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 11/30/24 13:26:52.456
  I1130 13:26:52.459587 19 container_probe.go:1749] Initial restart count of pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c is 0
  I1130 13:26:52.463129 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:26:53.450685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:54.450783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:54.468806 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:26:55.451603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:56.452607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:56.473887 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:26:57.452947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:26:58.453194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:26:58.479456 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:26:59.453515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:00.453723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:00.484932 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:01.454008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:02.454275      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:02.491459 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:03.454612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:04.454865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:04.497464 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:05.455515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:06.455870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:06.503412 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:07.456456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:08.456564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:08.509175 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:09.456801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:10.456984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:10.515677 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:11.457443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:12.457921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:12.521416 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:13.458631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:14.458755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:14.527526 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:15.459768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:16.460617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:16.532946 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:17.460697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:18.460802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:18.538228 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:19.460886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:20.461594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:20.543955 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:21.461852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:22.462080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:22.550079 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:23.462203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:24.462441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:24.556330 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:25.463350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:26.463605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:26.561467 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:27.463748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:28.463958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:28.567478 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:29.464447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:30.464835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:30.573338 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:31.465331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:32.465534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:32.578729 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:33.465665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:34.466124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:34.584342 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:35.466193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:36.466616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:36.589882 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:37.466858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:38.467135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:38.595570 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:39.467363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:40.467617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:40.601709 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:41.468109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:42.468213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:42.607913 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:43.468574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:44.468814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:44.613349 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:45.468878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:46.469125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:46.620195 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:47.469765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:48.469856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:48.626522 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:49.470399      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:50.470600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:50.632547 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:51.471653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:52.471772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:52.638655 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:53.471866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:54.471997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:54.644321 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:55.472635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:56.472991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:56.649628 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:57.473523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:27:58.473629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:27:58.655514 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:27:59.473821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:00.474149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:00.661411 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:01.474599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:02.475035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:02.667671 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:03.475336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:04.475555      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:04.672985 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:05.475967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:06.476594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:06.678608 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:07.476799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:08.477580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:08.684328 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:09.477867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:10.479674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:10.689483 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:11.479932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:12.480107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:12.695946 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:13.480491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:14.480587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:14.700491 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:15.480682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:16.481031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:16.706323 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:17.481569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:18.481772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:18.712752 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:19.482586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:20.483715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:20.717522 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:21.484104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:22.484332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:22.723182 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:23.484969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:24.485608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:24.729067 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:25.485906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:26.486119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:26.734701 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:27.486495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:28.486708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:28.739293 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:29.487018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:30.487302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:30.745355 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:31.487979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:32.488095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:32.751363 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:33.488503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:34.488514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:34.757598 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:35.489470      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:36.489873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:36.765675 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:37.489938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:38.490034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:38.771022 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:39.490592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:40.490695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:40.777269 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:41.491154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:42.491252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:42.782444 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:43.491629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:44.491802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:44.788573 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:45.492324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:46.492405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:46.794040 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:47.492824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:48.493043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:48.799457 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:49.493135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:50.493245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:50.804356 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:51.494151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:52.494273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:52.810029 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:53.494511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:54.494610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:54.815883 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:55.494747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:56.495073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:56.821647 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:57.495241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:28:58.495472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:28:58.827624 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:28:59.496532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:00.496850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:00.833479 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:01.497388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:02.497596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:02.839273 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:03.497770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:04.497918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:04.844574 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:05.498285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:06.498947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:06.850306 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:07.499031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:08.499151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:08.855442 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:09.500130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:10.500611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:10.860905 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:11.500930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:12.501593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:12.866616 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:13.502386      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:14.502640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:14.871964 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:15.502825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:16.502993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:16.877662 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:17.503358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:18.503615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:18.883346 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:19.504022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:20.504322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:20.888847 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:21.505001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:22.505292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:22.895551 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:23.506216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:24.506452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:24.900681 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:25.507540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:26.508210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:26.907078 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:27.508534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:28.508613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:28.912048 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:29.509597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:30.509715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:30.917557 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:31.510496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:32.510729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:32.923631 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:33.510832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:34.510934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:34.930184 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:35.511595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:36.511949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:36.935313 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:37.512606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:38.512662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:38.941282 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:39.512766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:40.512863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:40.947140 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:41.513108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:42.513318      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:42.953439 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:43.514207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:44.514585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:44.958933 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:45.515672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:46.516049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:46.964591 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:47.516165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:48.516359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:48.969759 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:49.517431      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:50.517809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:50.975637 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:51.518057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:52.518653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:52.981568 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:53.519160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:54.519958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:54.987512 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:55.520059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:56.520862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:56.994082 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:57.521886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:29:58.522076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:29:59.000036 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:29:59.522531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:00.522642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:01.004984 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:01.522709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:02.522944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:03.010787 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:03.523222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:04.523451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:05.016080 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:05.523662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:06.524195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:07.021606 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:07.524314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:08.524584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:09.026736 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:09.525357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:10.525634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:11.032296 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:11.526152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:12.526347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:13.037982 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:13.526596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:14.526795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:15.043254 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:15.526956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:16.527734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:17.048150 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:17.527943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:18.528145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:19.053987 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:19.528354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:20.528900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:21.058511 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:21.529168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:22.529492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:23.063194 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:23.529526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:24.530560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:25.069145 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:25.531579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:26.532151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:27.074476 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:27.532649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:28.532977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:29.078670 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:29.533147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:30.533470      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:31.083769 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:31.534509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:32.534766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:33.089854 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:33.535410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:34.535569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:35.095654 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:35.536234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:36.536938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:37.100704 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:37.537235      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:38.537476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:39.106081 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:39.537648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:40.537893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:41.112055 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:41.538776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:42.538875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:43.117867 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:43.539358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:44.539502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:45.123959 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:45.540348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:46.540740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:47.128313 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:47.541573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:48.541678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:49.134339 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:49.542569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:50.543151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:51.140225 19 container_probe.go:1759] Get pod liveness-263e6fba-9aa7-41ba-849a-227ddcd3654c in namespace container-probe-2641
  E1130 13:30:51.543838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:52.543940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 11/30/24 13:30:53.14
  I1130 13:30:53.159731 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2641" for this suite. @ 11/30/24 13:30:53.163
• [242.761 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 11/30/24 13:30:53.171
  I1130 13:30:53.171282 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replicaset @ 11/30/24 13:30:53.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:30:53.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:30:53.191
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 11/30/24 13:30:53.197
  I1130 13:30:53.208490 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E1130 13:30:53.544168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:54.544445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:55.544648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:56.545000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:57.545278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:30:58.212395 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 11/30/24 13:30:58.212
  STEP: getting scale subresource @ 11/30/24 13:30:58.212
  STEP: updating a scale subresource @ 11/30/24 13:30:58.217
  STEP: verifying the replicaset Spec.Replicas was modified @ 11/30/24 13:30:58.222
  STEP: Patch a scale subresource @ 11/30/24 13:30:58.23
  I1130 13:30:58.246927 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3126" for this suite. @ 11/30/24 13:30:58.254
• [5.093 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:284
  STEP: Creating a kubernetes client @ 11/30/24 13:30:58.264
  I1130 13:30:58.264448 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename taint-single-pod @ 11/30/24 13:30:58.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:30:58.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:30:58.295
  I1130 13:30:58.299222 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1130 13:30:58.545361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:30:59.545626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:00.546687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:01.547446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:02.547596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:03.548591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:04.548699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:05.548821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:06.549217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:07.549872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:08.550675      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:09.550767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:10.551600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:11.552123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:12.552590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:13.552764      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:14.553340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:15.553547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:16.554617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:17.554820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:18.555681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:19.555821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:20.556686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:21.557237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:22.558150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:23.558248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:24.558405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:25.558499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:26.559212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:27.559474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:28.559552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:29.559639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:30.559867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:31.560198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:32.561066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:33.561593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:34.562600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:35.562801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:36.563825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:37.564078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:38.564143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:39.564337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:40.565070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:41.565632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:42.566304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:43.566507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:44.567420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:45.567665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:46.568698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:47.568768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:48.569557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:49.570568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:50.571594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:51.572110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:52.573111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:53.573461      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:54.573643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:55.573969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:56.574013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:31:57.574342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:31:58.300339 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1130 13:31:58.305607 19 taints.go:144] Starting informer...
  STEP: Starting pod... @ 11/30/24 13:31:58.305
  I1130 13:31:58.522264 19 taints.go:294] Pod is running on ip-172-31-64-147. Tainting Node
  STEP: Trying to apply a taint on the Node @ 11/30/24 13:31:58.522
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 11/30/24 13:31:58.536
  STEP: Waiting short time to make sure Pod is queued for deletion @ 11/30/24 13:31:58.541
  I1130 13:31:58.541662 19 taints.go:313] Pod wasn't evicted. Proceeding
  I1130 13:31:58.541676 19 taints.go:320] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 11/30/24 13:31:58.558
  E1130 13:31:58.575007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting some time to make sure that toleration time passed. @ 11/30/24 13:31:58.575
  E1130 13:31:59.575450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:00.575693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:01.576062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:02.576290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:03.576547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:04.577608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:05.577892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:06.578178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:07.579122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:08.579296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:09.579495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:10.579732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:11.580274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:12.581226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:13.581472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:14.581503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:15.582569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:16.582916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:17.583132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:18.583244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:19.583504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:20.584283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:21.585036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:22.585219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:23.585519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:24.586578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:25.586845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:26.587171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:27.587451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:28.587731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:29.587931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:30.589001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:31.589836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:32.590582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:33.590677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:34.591566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:35.591765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:36.592198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:37.592330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:38.592655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:39.592757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:40.593059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:41.593483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:42.593742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:43.593984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:44.594178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:45.594288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:46.594809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:47.595044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:48.595323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:49.595560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:50.595776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:51.596268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:52.596647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:53.596910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:54.597121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:55.597340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:56.597877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:57.598000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:58.599017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:32:59.599131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:00.599217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:01.600156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:02.600573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:03.600684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:04.600787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:05.600859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:06.601186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:07.601563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:08.602565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:09.602781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:10.602967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:11.603900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:12.604115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:33:13.576170 19 taints.go:329] Pod wasn't evicted. Test successful
  I1130 13:33:13.576341 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-5159" for this suite. @ 11/30/24 13:33:13.58
• [135.326 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 11/30/24 13:33:13.59
  I1130 13:33:13.590594 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 13:33:13.591
  E1130 13:33:13.604231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:33:13.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:33:13.611
  STEP: Creating configMap with name configmap-test-upd-792607f0-50f4-4901-b050-8d57df8c0d0e @ 11/30/24 13:33:13.618
  STEP: Creating the pod @ 11/30/24 13:33:13.623
  E1130 13:33:14.604430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:15.604544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-792607f0-50f4-4901-b050-8d57df8c0d0e @ 11/30/24 13:33:15.67
  STEP: waiting to observe update in volume @ 11/30/24 13:33:15.677
  E1130 13:33:16.605269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:17.606195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:18.606469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:19.606655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:20.606804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:21.607283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:22.607586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:23.607712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:24.608544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:25.608634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:26.609501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:27.609552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:28.609886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:29.609755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:30.610570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:31.610983      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:32.611547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:33.611754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:34.612566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:35.613557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:36.613872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:37.614612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:38.615573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:39.615662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:40.615795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:41.616415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:42.616653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:43.616986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:44.617241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:45.617473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:46.618013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:47.618096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:48.618754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:49.618841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:50.619787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:51.620050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:52.620536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:53.621593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:54.621821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:55.621944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:56.622331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:57.622623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:58.623033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:33:59.623248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:00.623398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:01.623956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:02.624820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:03.624987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:04.625101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:05.625183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:06.626090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:07.626842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:08.627156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:09.627228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:10.627484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:11.628436      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:12.629268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:13.629487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:14.630173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:15.630798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:16.631209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:17.631596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:18.631838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:19.631941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:20.632400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:21.633253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:34:22.007477 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5356" for this suite. @ 11/30/24 13:34:22.012
• [68.433 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 11/30/24 13:34:22.024
  I1130 13:34:22.024447 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 13:34:22.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:22.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:22.055
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 13:34:22.063
  E1130 13:34:22.633606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:23.634599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:24.634877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:25.635104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:34:26.097
  I1130 13:34:26.101519 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod downwardapi-volume-92f4a88c-39d2-48a6-9a5d-ebbe1345a7fb container client-container: <nil>
  STEP: delete the pod @ 11/30/24 13:34:26.118
  I1130 13:34:26.133770 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4041" for this suite. @ 11/30/24 13:34:26.138
• [4.122 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 11/30/24 13:34:26.146
  I1130 13:34:26.146824 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 13:34:26.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:26.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:26.164
  STEP: Creating secret with name secret-test-map-f78e48a7-92af-4c61-9313-1b1e31677442 @ 11/30/24 13:34:26.168
  STEP: Creating a pod to test consume secrets @ 11/30/24 13:34:26.174
  E1130 13:34:26.635538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:27.635648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:28.635874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:29.636116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:34:30.2
  I1130 13:34:30.205396 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-secrets-d98aea9d-945c-4eaa-aa13-80a59b583e77 container secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 13:34:30.213
  I1130 13:34:30.231408 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8077" for this suite. @ 11/30/24 13:34:30.236
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1044
  STEP: Creating a kubernetes client @ 11/30/24 13:34:30.243
  I1130 13:34:30.243340 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 13:34:30.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:30.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:30.264
  STEP: create deployment with httpd image @ 11/30/24 13:34:30.267
  I1130 13:34:30.267748 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-20 create -f -'
  I1130 13:34:30.336664 19 builder.go:146] stderr: ""
  I1130 13:34:30.336708 19 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 11/30/24 13:34:30.336
  I1130 13:34:30.336804 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-20 diff -f -'
  I1130 13:34:30.422566 19 builder.go:135] rc: 1
  I1130 13:34:30.422650 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-20 delete -f -'
  I1130 13:34:30.473077 19 builder.go:146] stderr: ""
  I1130 13:34:30.473117 19 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I1130 13:34:30.473393 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-20" for this suite. @ 11/30/24 13:34:30.477
• [0.243 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:167
  STEP: Creating a kubernetes client @ 11/30/24 13:34:30.486
  I1130 13:34:30.486207 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl-logs @ 11/30/24 13:34:30.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:30.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:30.507
  STEP: creating a pod @ 11/30/24 13:34:30.51
  I1130 13:34:30.511042 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-logs-378 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.52 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I1130 13:34:30.566008 19 builder.go:146] stderr: ""
  I1130 13:34:30.566046 19 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 11/30/24 13:34:30.566
  I1130 13:34:30.566144 19 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E1130 13:34:30.636589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:31.636802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:34:32.576257 19 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 11/30/24 13:34:32.576
  I1130 13:34:32.576392 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-logs-378 logs logs-generator logs-generator'
  I1130 13:34:32.629213 19 builder.go:146] stderr: ""
  I1130 13:34:32.629258 19 builder.go:147] stdout: "I1130 13:34:31.099886       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/wqs8 445\nI1130 13:34:31.300244       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/fj9 515\nI1130 13:34:31.500485       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/92m 553\nI1130 13:34:31.700778       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/dgrc 497\nI1130 13:34:31.900016       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/bp8q 428\nI1130 13:34:32.100317       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/cjc 270\nI1130 13:34:32.300489       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/gvrg 593\nI1130 13:34:32.500785       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/nql 259\n"
  STEP: limiting log lines @ 11/30/24 13:34:32.629
  I1130 13:34:32.629438 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-logs-378 logs logs-generator logs-generator --tail=1'
  E1130 13:34:32.637503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:34:32.689520 19 builder.go:146] stderr: ""
  I1130 13:34:32.689558 19 builder.go:147] stdout: "I1130 13:34:32.500785       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/nql 259\n"
  I1130 13:34:32.689568 19 logs.go:180] got output "I1130 13:34:32.500785       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/nql 259\n"
  STEP: limiting log bytes @ 11/30/24 13:34:32.689
  I1130 13:34:32.689688 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-logs-378 logs logs-generator logs-generator --limit-bytes=1'
  I1130 13:34:32.742533 19 builder.go:146] stderr: ""
  I1130 13:34:32.742569 19 builder.go:147] stdout: "I"
  I1130 13:34:32.742577 19 logs.go:186] got output "I"
  STEP: exposing timestamps @ 11/30/24 13:34:32.742
  I1130 13:34:32.742660 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-logs-378 logs logs-generator logs-generator --tail=1 --timestamps'
  I1130 13:34:32.794900 19 builder.go:146] stderr: ""
  I1130 13:34:32.794943 19 builder.go:147] stdout: "2024-11-30T13:34:32.700128369Z I1130 13:34:32.700025       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jdg 257\n"
  I1130 13:34:32.794955 19 logs.go:192] got output "2024-11-30T13:34:32.700128369Z I1130 13:34:32.700025       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jdg 257\n"
  STEP: restricting to a time range @ 11/30/24 13:34:32.794
  E1130 13:34:33.637887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:34.638061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:34:35.295111 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-logs-378 logs logs-generator logs-generator --since=1s'
  I1130 13:34:35.348206 19 builder.go:146] stderr: ""
  I1130 13:34:35.348247 19 builder.go:147] stdout: "I1130 13:34:34.500489       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/fb8 402\nI1130 13:34:34.700784       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/s4q 415\nI1130 13:34:34.900019       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/6xw 255\nI1130 13:34:35.100356       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/w69 345\nI1130 13:34:35.300501       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/jmb 560\n"
  I1130 13:34:35.348313 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-logs-378 logs logs-generator logs-generator --since=24h'
  I1130 13:34:35.402344 19 builder.go:146] stderr: ""
  I1130 13:34:35.402413 19 builder.go:147] stdout: "I1130 13:34:31.099886       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/wqs8 445\nI1130 13:34:31.300244       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/fj9 515\nI1130 13:34:31.500485       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/92m 553\nI1130 13:34:31.700778       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/dgrc 497\nI1130 13:34:31.900016       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/bp8q 428\nI1130 13:34:32.100317       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/cjc 270\nI1130 13:34:32.300489       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/gvrg 593\nI1130 13:34:32.500785       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/nql 259\nI1130 13:34:32.700025       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/jdg 257\nI1130 13:34:32.900417       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/pk4 435\nI1130 13:34:33.100714       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/22sh 344\nI1130 13:34:33.299959       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/qps5 360\nI1130 13:34:33.500251       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/lht 452\nI1130 13:34:33.700488       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/2552 574\nI1130 13:34:33.900783       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/vnw 334\nI1130 13:34:34.100019       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/xpsj 360\nI1130 13:34:34.300323       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/lb8 390\nI1130 13:34:34.500489       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/fb8 402\nI1130 13:34:34.700784       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/s4q 415\nI1130 13:34:34.900019       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/6xw 255\nI1130 13:34:35.100356       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/w69 345\nI1130 13:34:35.300501       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/jmb 560\n"
  I1130 13:34:35.402568 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-logs-378 delete pod logs-generator'
  E1130 13:34:35.638387      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:34:36.447027 19 builder.go:146] stderr: ""
  I1130 13:34:36.447071 19 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I1130 13:34:36.447235 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-378" for this suite. @ 11/30/24 13:34:36.452
• [5.973 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 11/30/24 13:34:36.458
  I1130 13:34:36.459003 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename validating-admission-policy @ 11/30/24 13:34:36.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:36.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:36.479
  STEP: creating a policy with variables @ 11/30/24 13:34:36.49
  STEP: waiting until the marker is denied @ 11/30/24 13:34:36.507
  E1130 13:34:36.639066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 11/30/24 13:34:36.817
  STEP: testing a non-replicated ReplicaSet not to be denied @ 11/30/24 13:34:36.832
  I1130 13:34:36.896750 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-8420" for this suite. @ 11/30/24 13:34:36.9
• [0.451 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3619
  STEP: Creating a kubernetes client @ 11/30/24 13:34:36.91
  I1130 13:34:36.910568 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 13:34:36.911
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:36.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:36.93
  STEP: creating a collection of services @ 11/30/24 13:34:36.934
  I1130 13:34:36.934171 19 service.go:3655] Creating e2e-svc-a-8bjvh
  I1130 13:34:36.944390 19 service.go:3655] Creating e2e-svc-b-h62h9
  I1130 13:34:36.956821 19 service.go:3655] Creating e2e-svc-c-wktv9
  STEP: deleting service collection @ 11/30/24 13:34:36.971
  I1130 13:34:37.002482 19 service.go:3690] Collection of services has been deleted
  I1130 13:34:37.002597 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7544" for this suite. @ 11/30/24 13:34:37.007
• [0.104 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 11/30/24 13:34:37.014
  I1130 13:34:37.014228 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 13:34:37.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:37.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:37.038
  STEP: creating the pod @ 11/30/24 13:34:37.041
  STEP: submitting the pod to kubernetes @ 11/30/24 13:34:37.041
  W1130 13:34:37.048743      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E1130 13:34:37.639674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:38.639784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 11/30/24 13:34:39.063
  STEP: updating the pod @ 11/30/24 13:34:39.068
  I1130 13:34:39.581857 19 pod_client.go:173] Successfully updated pod "pod-update-activedeadlineseconds-98cf6641-32b7-435c-82c6-1fb0fe22a4a2"
  E1130 13:34:39.639867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:40.639969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:41.640811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:42.641591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:34:43.595715 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5270" for this suite. @ 11/30/24 13:34:43.599
• [6.594 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:400
  STEP: Creating a kubernetes client @ 11/30/24 13:34:43.608
  I1130 13:34:43.608443 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:34:43.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:43.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:43.639
  E1130 13:34:43.641564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 11/30/24 13:34:43.666
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:34:43.787
  STEP: Deploying the webhook pod @ 11/30/24 13:34:43.797
  STEP: Wait for the deployment to be ready @ 11/30/24 13:34:43.811
  I1130 13:34:43.827796 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:34:44.641774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:45.641888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:34:45.841
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:34:45.857
  E1130 13:34:46.642173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:34:46.857578 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 11/30/24 13:34:46.867
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 11/30/24 13:34:46.881
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 11/30/24 13:34:46.887
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 11/30/24 13:34:46.899
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 11/30/24 13:34:46.914
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 11/30/24 13:34:46.921
  I1130 13:34:46.972056 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6603" for this suite. @ 11/30/24 13:34:46.976
  STEP: Destroying namespace "webhook-markers-7522" for this suite. @ 11/30/24 13:34:46.982
• [3.382 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:712
  STEP: Creating a kubernetes client @ 11/30/24 13:34:46.99
  I1130 13:34:46.990258 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:34:46.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:47.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:47.008
  STEP: Setting up server cert @ 11/30/24 13:34:47.031
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:34:47.295
  STEP: Deploying the webhook pod @ 11/30/24 13:34:47.302
  STEP: Wait for the deployment to be ready @ 11/30/24 13:34:47.317
  I1130 13:34:47.334242 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:34:47.642517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:48.642808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:34:49.348
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:34:49.358
  E1130 13:34:49.643847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:34:50.358330 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 11/30/24 13:34:50.367
  STEP: verifying the validating webhook match conditions @ 11/30/24 13:34:50.375
  STEP: updating the validating webhook match conditions @ 11/30/24 13:34:50.379
  STEP: verifying the validating webhook match conditions @ 11/30/24 13:34:50.388
  I1130 13:34:50.438024 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6705" for this suite. @ 11/30/24 13:34:50.442
  STEP: Destroying namespace "webhook-markers-1823" for this suite. @ 11/30/24 13:34:50.45
• [3.467 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 11/30/24 13:34:50.457
  I1130 13:34:50.457323 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:34:50.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:50.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:50.478
  STEP: Creating configMap with name configmap-projected-all-test-volume-85618c5c-b285-47e1-bb91-5cfa40c1d5d8 @ 11/30/24 13:34:50.481
  STEP: Creating secret with name secret-projected-all-test-volume-e1da79bb-dd24-4ffa-9c94-af6f85f6a861 @ 11/30/24 13:34:50.488
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 11/30/24 13:34:50.494
  E1130 13:34:50.644330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:51.645344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:52.645860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:53.646097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:34:54.521
  I1130 13:34:54.525506 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod projected-volume-b222330b-05c2-451e-9bc7-adbe14d5d44c container projected-all-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 13:34:54.532
  I1130 13:34:54.551947 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8785" for this suite. @ 11/30/24 13:34:54.556
• [4.106 seconds]
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:57
  STEP: Creating a kubernetes client @ 11/30/24 13:34:54.563
  I1130 13:34:54.563228 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename volumeattachment @ 11/30/24 13:34:54.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:54.58
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:54.584
  STEP: Create VolumeAttachment "va-e2e-b7b2c" on node "ip-172-31-4-119" @ 11/30/24 13:34:54.591
  STEP: Get VolumeAttachment "va-e2e-b7b2c" on node "ip-172-31-4-119" @ 11/30/24 13:34:54.597
  STEP: Patch VolumeAttachment "va-e2e-b7b2c" on node "ip-172-31-4-119" @ 11/30/24 13:34:54.6
  STEP: List VolumeAttachments with "va-e2e-b7b2c=patched" label @ 11/30/24 13:34:54.606
  STEP: Delete VolumeAttachment "va-e2e-b7b2c" on node "ip-172-31-4-119" @ 11/30/24 13:34:54.609
  STEP: Confirm deletion of VolumeAttachment "va-e2e-b7b2c" on node "ip-172-31-4-119" @ 11/30/24 13:34:54.616
  STEP: Create VolumeAttachment "va-e2e-v2p57" on node "ip-172-31-87-36" @ 11/30/24 13:34:54.624
  STEP: Update the VolumeAttachment "va-e2e-v2p57" on node "ip-172-31-87-36" with label "va-e2e=updated" @ 11/30/24 13:34:54.63
  STEP: Create VolumeAttachment "va-e2e-5mplr" on node "ip-172-31-94-166" @ 11/30/24 13:34:54.643
  E1130 13:34:54.646066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Update the VolumeAttachment "va-e2e-5mplr" on node "ip-172-31-94-166" with label "va-e2e=updated" @ 11/30/24 13:34:54.647
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 11/30/24 13:34:54.656
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 11/30/24 13:34:54.669
  I1130 13:34:54.673574 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-7570" for this suite. @ 11/30/24 13:34:54.677
• [0.121 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 11/30/24 13:34:54.684
  I1130 13:34:54.684479 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename events @ 11/30/24 13:34:54.685
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:54.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:54.703
  STEP: Create set of events @ 11/30/24 13:34:54.707
  STEP: get a list of Events with a label in the current namespace @ 11/30/24 13:34:54.721
  STEP: delete a list of events @ 11/30/24 13:34:54.725
  I1130 13:34:54.725407 19 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 11/30/24 13:34:54.748
  I1130 13:34:54.752097 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5117" for this suite. @ 11/30/24 13:34:54.757
• [0.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 11/30/24 13:34:54.765
  I1130 13:34:54.765127 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 13:34:54.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:54.781
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:54.785
  STEP: Creating secret with name secret-test-d34aea0a-3ed3-4cb8-9564-42c4b96f3e8c @ 11/30/24 13:34:54.788
  STEP: Creating a pod to test consume secrets @ 11/30/24 13:34:54.792
  E1130 13:34:55.646658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:56.646998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:57.647205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:34:58.647325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:34:58.817
  I1130 13:34:58.821786 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-secrets-892aef4d-7387-4293-a44b-0ce90c09d643 container secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 13:34:58.829
  I1130 13:34:58.846211 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9037" for this suite. @ 11/30/24 13:34:58.85
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1833
  STEP: Creating a kubernetes client @ 11/30/24 13:34:58.858
  I1130 13:34:58.858311 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 13:34:58.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:58.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:58.88
  STEP: starting the proxy server @ 11/30/24 13:34:58.883
  I1130 13:34:58.883838 19 util.go:585] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-812 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 11/30/24 13:34:58.916
  I1130 13:34:58.922713 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  I1130 13:34:58.923992 19 kubectl.go:2224] kubectl proxy stdout: Starting to serve on 127.0.0.1:38611

  I1130 13:34:58.923992 19 kubectl.go:2229] kubectl proxy stderr: W1130 13:34:58.916244     798 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-812" for this suite. @ 11/30/24 13:34:58.926
• [0.078 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:495
  STEP: Creating a kubernetes client @ 11/30/24 13:34:58.936
  I1130 13:34:58.936253 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:34:58.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:34:58.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:34:58.953
  STEP: Setting up server cert @ 11/30/24 13:34:58.978
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:34:59.363
  STEP: Deploying the webhook pod @ 11/30/24 13:34:59.369
  STEP: Wait for the deployment to be ready @ 11/30/24 13:34:59.385
  I1130 13:34:59.399734 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:34:59.648099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:00.648405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:35:01.413
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:35:01.425
  E1130 13:35:01.648487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:02.425394 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 11/30/24 13:35:02.434
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 11/30/24 13:35:02.454
  STEP: Creating a configMap that should not be mutated @ 11/30/24 13:35:02.461
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 11/30/24 13:35:02.473
  STEP: Creating a configMap that should be mutated @ 11/30/24 13:35:02.481
  I1130 13:35:02.548148 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1153" for this suite. @ 11/30/24 13:35:02.552
  STEP: Destroying namespace "webhook-markers-9801" for this suite. @ 11/30/24 13:35:02.562
• [3.633 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:52
  STEP: Creating a kubernetes client @ 11/30/24 13:35:02.569
  I1130 13:35:02.569251 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename dns @ 11/30/24 13:35:02.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:35:02.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:35:02.588
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 11/30/24 13:35:02.592
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 11/30/24 13:35:02.592
  STEP: creating a pod to probe DNS @ 11/30/24 13:35:02.592
  STEP: submitting the pod to kubernetes @ 11/30/24 13:35:02.592
  E1130 13:35:02.648927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:03.649063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 11/30/24 13:35:04.611
  STEP: looking for the results for each expected name from probers @ 11/30/24 13:35:04.615
  I1130 13:35:04.636430 19 dns_common.go:527] DNS probes using dns-5889/dns-test-d017fadb-532d-4ee6-955c-e5acbc73c929 succeeded

  STEP: deleting the pod @ 11/30/24 13:35:04.636
  E1130 13:35:04.649654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:04.650147 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-5889" for this suite. @ 11/30/24 13:35:04.655
• [2.094 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 11/30/24 13:35:04.663
  I1130 13:35:04.663699 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename namespaces @ 11/30/24 13:35:04.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:35:04.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:35:04.683
  STEP: Creating a test namespace @ 11/30/24 13:35:04.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:35:04.701
  STEP: Creating a pod in the namespace @ 11/30/24 13:35:04.705
  STEP: Waiting for the pod to have running status @ 11/30/24 13:35:04.713
  E1130 13:35:05.650162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:06.651136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 11/30/24 13:35:06.727
  STEP: Waiting for the namespace to be removed. @ 11/30/24 13:35:06.735
  E1130 13:35:07.651583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:08.651708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:09.651899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:10.652512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:11.652840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:12.653536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:13.653632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:14.653703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:15.653840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:16.653997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:17.654115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 11/30/24 13:35:17.74
  STEP: Verifying there are no pods in the namespace @ 11/30/24 13:35:17.754
  I1130 13:35:17.759214 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7482" for this suite. @ 11/30/24 13:35:17.762
  STEP: Destroying namespace "nsdeletetest-5161" for this suite. @ 11/30/24 13:35:17.769
  I1130 13:35:17.772616 19 framework.go:370] Namespace nsdeletetest-5161 was already deleted
  STEP: Destroying namespace "nsdeletetest-2405" for this suite. @ 11/30/24 13:35:17.772
• [13.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 11/30/24 13:35:17.78
  I1130 13:35:17.780282 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename csiinlinevolumes @ 11/30/24 13:35:17.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:35:17.797
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:35:17.8
  STEP: Creating two CSIDrivers @ 11/30/24 13:35:17.803
  STEP: Getting "inline-driver-1deb13c8-2971-4e17-a605-584f7f4d2926" & "inline-driver-582cc345-4964-4316-8576-2cbb3132330a" @ 11/30/24 13:35:17.823
  STEP: Patching the CSIDriver "inline-driver-582cc345-4964-4316-8576-2cbb3132330a" @ 11/30/24 13:35:17.831
  STEP: Updating the CSIDriver "inline-driver-582cc345-4964-4316-8576-2cbb3132330a" @ 11/30/24 13:35:17.837
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-7677" @ 11/30/24 13:35:17.847
  STEP: Deleting CSIDriver "inline-driver-1deb13c8-2971-4e17-a605-584f7f4d2926" @ 11/30/24 13:35:17.851
  STEP: Confirm deletion of CSIDriver "inline-driver-1deb13c8-2971-4e17-a605-584f7f4d2926" @ 11/30/24 13:35:17.858
  STEP: Deleting CSIDriver "inline-driver-582cc345-4964-4316-8576-2cbb3132330a" via DeleteCollection @ 11/30/24 13:35:17.862
  STEP: Confirm deletion of CSIDriver "inline-driver-582cc345-4964-4316-8576-2cbb3132330a" @ 11/30/24 13:35:17.871
  I1130 13:35:17.875484 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-7677" for this suite. @ 11/30/24 13:35:17.879
• [0.108 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:337
  STEP: Creating a kubernetes client @ 11/30/24 13:35:17.887
  I1130 13:35:17.887995 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 13:35:17.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:35:17.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:35:17.908
  STEP: creating a replication controller @ 11/30/24 13:35:17.911
  I1130 13:35:17.911655 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 create -f -'
  I1130 13:35:17.991133 19 builder.go:146] stderr: ""
  I1130 13:35:17.991170 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 11/30/24 13:35:17.991
  I1130 13:35:17.991334 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1130 13:35:18.041735 19 builder.go:146] stderr: ""
  I1130 13:35:18.041775 19 builder.go:147] stdout: "update-demo-nautilus-6tzbl update-demo-nautilus-rj8vv "
  I1130 13:35:18.041835 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get pods update-demo-nautilus-6tzbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:35:18.086626 19 builder.go:146] stderr: ""
  I1130 13:35:18.086667 19 builder.go:147] stdout: ""
  I1130 13:35:18.086678 19 kubectl.go:2502] update-demo-nautilus-6tzbl is created but not running
  E1130 13:35:18.654296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:19.654537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:20.654712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:21.655268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:22.655641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:23.087352 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1130 13:35:23.133589 19 builder.go:146] stderr: ""
  I1130 13:35:23.133625 19 builder.go:147] stdout: "update-demo-nautilus-6tzbl update-demo-nautilus-rj8vv "
  I1130 13:35:23.133670 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get pods update-demo-nautilus-6tzbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:35:23.176619 19 builder.go:146] stderr: ""
  I1130 13:35:23.176655 19 builder.go:147] stdout: "true"
  I1130 13:35:23.176717 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get pods update-demo-nautilus-6tzbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1130 13:35:23.219257 19 builder.go:146] stderr: ""
  I1130 13:35:23.219309 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1130 13:35:23.219321 19 kubectl.go:2393] validating pod update-demo-nautilus-6tzbl
  I1130 13:35:23.225957 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1130 13:35:23.226002 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1130 13:35:23.226015 19 kubectl.go:2520] update-demo-nautilus-6tzbl is verified up and running
  I1130 13:35:23.226057 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get pods update-demo-nautilus-rj8vv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1130 13:35:23.269094 19 builder.go:146] stderr: ""
  I1130 13:35:23.269128 19 builder.go:147] stdout: "true"
  I1130 13:35:23.269179 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get pods update-demo-nautilus-rj8vv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1130 13:35:23.313239 19 builder.go:146] stderr: ""
  I1130 13:35:23.313277 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1130 13:35:23.313288 19 kubectl.go:2393] validating pod update-demo-nautilus-rj8vv
  I1130 13:35:23.318920 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1130 13:35:23.318970 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1130 13:35:23.318982 19 kubectl.go:2520] update-demo-nautilus-rj8vv is verified up and running
  STEP: using delete to clean up resources @ 11/30/24 13:35:23.318
  I1130 13:35:23.319055 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 delete --grace-period=0 --force -f -'
  I1130 13:35:23.370675 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1130 13:35:23.370728 19 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I1130 13:35:23.370771 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get rc,svc -l name=update-demo --no-headers'
  I1130 13:35:23.436296 19 builder.go:146] stderr: "No resources found in kubectl-7907 namespace.\n"
  I1130 13:35:23.436519 19 builder.go:147] stdout: ""
  I1130 13:35:23.436602 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-7907 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I1130 13:35:23.521656 19 builder.go:146] stderr: ""
  I1130 13:35:23.521708 19 builder.go:147] stdout: ""
  I1130 13:35:23.522224 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7907" for this suite. @ 11/30/24 13:35:23.526
• [5.646 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
  STEP: Creating a kubernetes client @ 11/30/24 13:35:23.533
  I1130 13:35:23.533766 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubectl @ 11/30/24 13:35:23.541
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:35:23.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:35:23.564
  STEP: creating Agnhost RC @ 11/30/24 13:35:23.572
  I1130 13:35:23.572333 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8127 create -f -'
  E1130 13:35:23.656505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:23.668300 19 builder.go:146] stderr: ""
  I1130 13:35:23.668351 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 11/30/24 13:35:23.668
  E1130 13:35:24.656701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:24.672952 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1130 13:35:24.672981 19 framework.go:733] Found 0 / 1
  E1130 13:35:25.656987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:25.673811 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1130 13:35:25.673836 19 framework.go:733] Found 1 / 1
  I1130 13:35:25.673848 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 11/30/24 13:35:25.673
  I1130 13:35:25.677787 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1130 13:35:25.677807 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I1130 13:35:25.677849 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=kubectl-8127 patch pod agnhost-primary-26bsl -p {"metadata":{"annotations":{"x":"y"}}}'
  I1130 13:35:25.728525 19 builder.go:146] stderr: ""
  I1130 13:35:25.728573 19 builder.go:147] stdout: "pod/agnhost-primary-26bsl patched\n"
  STEP: checking annotations @ 11/30/24 13:35:25.728
  I1130 13:35:25.732478 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1130 13:35:25.732498 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I1130 13:35:25.732632 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8127" for this suite. @ 11/30/24 13:35:25.737
• [2.216 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:348
  STEP: Creating a kubernetes client @ 11/30/24 13:35:25.75
  I1130 13:35:25.750512 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename field-validation @ 11/30/24 13:35:25.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:35:25.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:35:25.769
  I1130 13:35:25.773493 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  W1130 13:35:25.774025      19 field_validation.go:421] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0050298e0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E1130 13:35:26.657411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:27.657534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W1130 13:35:28.309764      19 warnings.go:70] unknown field "alpha"
  W1130 13:35:28.309784      19 warnings.go:70] unknown field "beta"
  W1130 13:35:28.309787      19 warnings.go:70] unknown field "delta"
  W1130 13:35:28.309790      19 warnings.go:70] unknown field "epsilon"
  W1130 13:35:28.309793      19 warnings.go:70] unknown field "gamma"
  E1130 13:35:28.658383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:28.860422 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8476" for this suite. @ 11/30/24 13:35:28.865
• [3.122 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 11/30/24 13:35:28.872
  I1130 13:35:28.872519 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 13:35:28.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:35:28.888
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:35:28.893
  STEP: Creating pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165 @ 11/30/24 13:35:28.896
  E1130 13:35:29.658726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:30.659100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 11/30/24 13:35:30.914
  I1130 13:35:30.917965 19 container_probe.go:1749] Initial restart count of pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc is 0
  I1130 13:35:30.923518 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:31.659526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:32.659836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:32.929073 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:33.659880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:34.660594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:34.935002 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:35.660690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:36.661053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:36.940242 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:37.661611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:38.662600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:38.946540 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:39.662725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:40.663657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:40.952308 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:41.663763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:42.663887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:42.958351 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:43.664146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:44.664257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:44.963037 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:45.664767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:46.665281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:46.968934 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:47.665687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:48.665923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:48.974068 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:49.666207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:50.666468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:50.980200 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:51.667089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:52.667316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:52.986124 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:53.667781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:54.667859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:54.992085 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:55.668600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:56.669144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:56.997914 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:57.669523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:35:58.669615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:35:59.003130 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:35:59.669710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:00.669803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:01.008875 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:01.669863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:02.669946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:03.014189 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:03.670591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:04.670696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:05.019484 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:05.671597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:06.672146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:07.024838 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:07.672534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:08.672740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:09.030814 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:09.673610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:10.673833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:11.036412 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:11.674401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:12.674745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:13.042869 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:13.675627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:14.675856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:15.048461 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:15.676620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:16.677102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:17.054833 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:17.677202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:18.677464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:19.059783 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:19.677702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:20.677913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:21.065296 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:21.678276      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:22.678449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:23.071069 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:23.678722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:24.679528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:25.076549 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:25.680286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:26.681149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:27.082000 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:27.681281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:28.681421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:29.088125 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:29.681525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:30.681634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:31.094356 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:31.682294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:32.682718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:33.098724 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:33.683540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:34.683794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:35.105075 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  E1130 13:36:35.684760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:36.685155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:36:37.111565 19 container_probe.go:1759] Get pod test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc in namespace container-probe-1165
  I1130 13:36:37.111602 19 container_probe.go:1763] Restart count of pod container-probe-1165/test-grpc-6e9fbb63-4299-4ff3-8937-bd5b52b653cc is now 1 (1m6.193595593s elapsed)
  STEP: deleting the pod @ 11/30/24 13:36:37.111
  I1130 13:36:37.126789 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1165" for this suite. @ 11/30/24 13:36:37.131
• [68.265 seconds]
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 11/30/24 13:36:37.137
  I1130 13:36:37.137984 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename hostport @ 11/30/24 13:36:37.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:36:37.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:36:37.16
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 11/30/24 13:36:37.168
  E1130 13:36:37.685293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:38.685519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.64.147 on the node which pod1 resides and expect scheduled @ 11/30/24 13:36:39.187
  E1130 13:36:39.686455      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:40.686673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.64.147 but use UDP protocol on the node which pod2 resides @ 11/30/24 13:36:41.207
  E1130 13:36:41.687295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:42.687643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:43.687676      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:44.687925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:45.688671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:46.688949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:47.689072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:48.689196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:49.690082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:50.690599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:51.691258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:52.691686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:53.692314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:54.692544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 11/30/24 13:36:55.273
  I1130 13:36:55.273072 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.64.147 http://127.0.0.1:54323/hostname] Namespace:hostport-2463 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:36:55.273090 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:36:55.273620 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:36:55.273688 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2463/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.64.147+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.64.147, port: 54323 @ 11/30/24 13:36:55.329
  I1130 13:36:55.330023 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.64.147:54323/hostname] Namespace:hostport-2463 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:36:55.330046 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:36:55.330578 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:36:55.330661 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2463/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.64.147%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.64.147, port: 54323 UDP @ 11/30/24 13:36:55.374
  I1130 13:36:55.374062 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.64.147 54323] Namespace:hostport-2463 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:36:55.374078 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:36:55.374585 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:36:55.374636 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2463/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.64.147+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E1130 13:36:55.693223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:56.693535      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:57.693673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:58.693804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:36:59.693858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:00.422335 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-2463" for this suite. @ 11/30/24 13:37:00.427
• [23.298 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:164
  STEP: Creating a kubernetes client @ 11/30/24 13:37:00.436
  I1130 13:37:00.436031 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 13:37:00.436
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:37:00.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:37:00.456
  STEP: Discovering how many secrets are in namespace by default @ 11/30/24 13:37:00.459
  E1130 13:37:00.693933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:01.694057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:02.694605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:03.694929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:04.695321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 11/30/24 13:37:05.463
  E1130 13:37:05.695770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:06.696845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:07.697851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:08.698691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:09.699338      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 11/30/24 13:37:10.468
  STEP: Ensuring resource quota status is calculated @ 11/30/24 13:37:10.476
  E1130 13:37:10.700297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:11.700492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 11/30/24 13:37:12.482
  STEP: Ensuring resource quota status captures secret creation @ 11/30/24 13:37:12.493
  E1130 13:37:12.701350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:13.701555      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 11/30/24 13:37:14.499
  STEP: Ensuring resource quota status released usage @ 11/30/24 13:37:14.506
  E1130 13:37:14.702422      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:15.703117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:16.513270 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4591" for this suite. @ 11/30/24 13:37:16.517
• [16.090 seconds]
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 11/30/24 13:37:16.525
  I1130 13:37:16.525641 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 13:37:16.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:37:16.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:37:16.546
  STEP: creating the pod @ 11/30/24 13:37:16.549
  STEP: submitting the pod to kubernetes @ 11/30/24 13:37:16.55
  E1130 13:37:16.704105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:17.704327      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 11/30/24 13:37:18.572
  STEP: updating the pod @ 11/30/24 13:37:18.576
  E1130 13:37:18.704847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:19.089312 19 pod_client.go:173] Successfully updated pod "pod-update-41d8246e-20ae-4799-ab18-0fc09d496a6b"
  STEP: verifying the updated pod is in kubernetes @ 11/30/24 13:37:19.093
  I1130 13:37:19.099074 19 pods.go:391] Pod update OK
  I1130 13:37:19.099186 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6394" for this suite. @ 11/30/24 13:37:19.104
• [2.586 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:999
  STEP: Creating a kubernetes client @ 11/30/24 13:37:19.111
  I1130 13:37:19.111798 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename resourcequota @ 11/30/24 13:37:19.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:37:19.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:37:19.134
  STEP: Creating a ResourceQuota @ 11/30/24 13:37:19.138
  STEP: Getting a ResourceQuota @ 11/30/24 13:37:19.147
  STEP: Listing all ResourceQuotas with LabelSelector @ 11/30/24 13:37:19.152
  STEP: Patching the ResourceQuota @ 11/30/24 13:37:19.158
  STEP: Deleting a Collection of ResourceQuotas @ 11/30/24 13:37:19.17
  STEP: Verifying the deleted ResourceQuota @ 11/30/24 13:37:19.182
  I1130 13:37:19.186490 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5285" for this suite. @ 11/30/24 13:37:19.193
• [0.092 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 11/30/24 13:37:19.204
  I1130 13:37:19.204046 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename daemonsets @ 11/30/24 13:37:19.204
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:37:19.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:37:19.226
  I1130 13:37:19.256923 19 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I1130 13:37:19.262438 19 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I1130 13:37:19.269469 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:19.269504 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:19.272641 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 13:37:19.272660 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  E1130 13:37:19.704992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:20.267971 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:20.268016 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:20.272317 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 13:37:20.272336 19 fixtures.go:130] Node ip-172-31-4-119 is running 0 daemon pod, expected 1
  E1130 13:37:20.705078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:21.267984 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:21.268033 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:21.272002 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1130 13:37:21.272021 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  I1130 13:37:21.272035 19 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I1130 13:37:21.281880 19 daemon_set.go:102] Updating DaemonSet daemon-set
  E1130 13:37:21.705221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:22.294741 19 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I1130 13:37:22.306327 19 daemon_set.go:102] Updating DaemonSet daemon-set
  I1130 13:37:22.306383 19 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I1130 13:37:22.312637 19 daemon_set.go:1193] Wrong image for pod: daemon-set-v6dmm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I1130 13:37:22.312656 19 daemon_set.go:1198] Pod daemon-set-v6dmm is not available
  I1130 13:37:22.316457 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:22.316484 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1130 13:37:22.705610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:23.316067 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:23.316121 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1130 13:37:23.706519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:24.311168 19 daemon_set.go:1198] Pod daemon-set-mz2vw is not available
  I1130 13:37:24.315651 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-37-252 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1130 13:37:24.315683 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-87-36 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 11/30/24 13:37:24.329
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1818, will wait for the garbage collector to delete the pods @ 11/30/24 13:37:24.329
  I1130 13:37:24.389338 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 5.930729ms
  I1130 13:37:24.489567 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.220819ms
  E1130 13:37:24.707174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:25.708011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:37:25.795613 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1130 13:37:25.795666 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1130 13:37:25.801647 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"43607"},"items":null}

  I1130 13:37:25.806628 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"43607"},"items":null}

  I1130 13:37:25.822483 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1818" for this suite. @ 11/30/24 13:37:25.826
• [6.631 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 11/30/24 13:37:25.835
  I1130 13:37:25.835026 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:37:25.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:37:25.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:37:25.855
  STEP: Creating configMap with name projected-configmap-test-volume-0135ac3f-a727-49de-ab95-cb3958a5d92d @ 11/30/24 13:37:25.858
  STEP: Creating a pod to test consume configMaps @ 11/30/24 13:37:25.863
  E1130 13:37:26.708868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:27.709798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:28.710096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:29.710190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:37:29.891
  I1130 13:37:29.895598 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-projected-configmaps-86c06e07-cbf8-4680-9be9-b330323bbf99 container agnhost-container: <nil>
  STEP: delete the pod @ 11/30/24 13:37:29.908
  I1130 13:37:29.928156 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4246" for this suite. @ 11/30/24 13:37:29.932
• [4.104 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 11/30/24 13:37:29.939
  I1130 13:37:29.939390 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename chunking @ 11/30/24 13:37:29.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:37:29.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:37:29.959
  STEP: creating a large number of resources @ 11/30/24 13:37:29.963
  E1130 13:37:30.710521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:31.711232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:32.711506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:33.711817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:34.712465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:35.713310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:36.713605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:37.714244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:38.714319      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:39.715240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:40.715960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:41.716503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:42.716977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:43.717932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:44.718052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:45.718338      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:46.718739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 11/30/24 13:37:47.646
  I1130 13:37:47.695838 19 chunking.go:163] Retrieved 40/40 results with rv 44133 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 11/30/24 13:37:47.695
  E1130 13:37:47.718770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:48.719122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:49.719606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:50.720588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:51.720789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:52.721597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:53.722560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:54.722839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:55.723577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:56.723815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:57.723928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:58.724982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:37:59.725176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:00.725414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:01.726077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:02.726336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:03.726577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:04.726785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:05.726992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:06.727251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:38:07.702358 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:38:07.727466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:08.727553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:09.727787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:10.727902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:11.728645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:12.728734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:13.729063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:14.729154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:15.729224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:16.730207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:17.730292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:18.730602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:19.730799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:20.731583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:21.732027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:22.732231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:23.732461      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:24.732738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:25.733587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:26.734190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:38:27.702505 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:38:27.734635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:28.736505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:29.735646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:30.735841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:31.736289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:32.736567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:33.737569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:34.737788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:35.737881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:36.738499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:37.738548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:38.738856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:39.739000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:40.739100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:41.739351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:42.739502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:43.739605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:44.740579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:45.741693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:46.741831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:38:47.716893 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:38:47.741926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:48.742018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:49.742248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:50.742485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:51.742678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:52.742947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:53.743035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:54.743247      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:55.743437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:56.744186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:57.744455      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:58.745455      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:38:59.745108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:00.745399      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:01.745661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:02.745842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:03.746129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:04.746399      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:05.746535      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:06.747009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:39:07.701434 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:39:07.747496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:08.747687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:09.747859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:10.747987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:11.748459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:12.748585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:13.748714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:14.748847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:15.749884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:16.749930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:17.749984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:18.750537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:19.751595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:20.751828      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:21.752228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:22.752496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:23.752650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:24.752848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:25.753068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:26.753693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:39:27.702165 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:39:27.754229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:28.754345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:29.754588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:30.754813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:31.755137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:32.755485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:33.755704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:34.755897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:35.756143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:36.756514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:37.757584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:38.757693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:39.758065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:40.758186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:41.758261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:42.758332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:43.759201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:44.759421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:45.759523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:46.760015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:39:47.701728 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:39:47.760832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:48.761625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:49.762690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:50.763511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:51.764100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:52.764179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:53.764657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:54.764934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:55.765229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:56.765624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:57.765758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:58.766589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:39:59.766903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:00.767115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:01.767433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:02.767536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:03.767735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:04.768045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:05.768189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:06.768474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:40:07.702437 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:40:07.769478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:08.769512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:09.770572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:10.771578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:11.772011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:12.772227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:13.772334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:14.772684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:15.772876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:16.773247      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:17.773466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:18.773507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:19.773709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:20.774576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:21.774881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:22.775147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:23.775255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:24.775514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:25.775737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:26.776237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:40:27.702224 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:40:27.776297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:28.776658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:29.776871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:30.777224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:31.777561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:32.777720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:33.777810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:34.778852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:35.778959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:36.779056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:37.780115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:38.780177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:39.780276      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:40.780623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:41.781126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:42.781214      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:43.781560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:44.781807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:45.782561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:46.783049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:40:47.701939 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:40:47.783943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:48.784707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:49.784945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:50.785228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:51.785567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:52.785880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:53.786667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:54.786886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:55.787186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:56.787470      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:57.787703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:58.788557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:40:59.788751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:00.789798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:01.789863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:02.790642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:03.790734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:04.791574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:05.792564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:06.793102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:41:07.701589 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:41:07.793569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:08.794596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:09.795590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:10.795682      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:11.796256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:12.796422      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:13.796608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:14.797050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:15.797316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:16.797645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:17.797763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:18.797961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:19.798184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:20.798295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:21.798605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:22.798844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:23.799048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:24.799618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:25.799754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:26.799956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:41:27.702001 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:41:27.800121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:28.800227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:29.800975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:30.801079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:31.801333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:32.801518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:33.802565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:34.802799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:35.803032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:36.803327      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:37.804292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:38.804534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:39.805595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:40.805937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:41.806304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:42.806518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:43.806770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:44.806891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:45.807046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:46.807344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:41:47.701471 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:41:47.807726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:48.807957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:49.808205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:50.808471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:51.809439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:52.809551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:53.809616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:54.810610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:55.811651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:56.812173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:57.812283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:58.812575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:41:59.812885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:00.813570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:01.814035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:02.814569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:03.815641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:04.816569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:05.816765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:06.817181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:42:07.702451 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:42:07.817549      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:08.817618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:09.817876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:10.818831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:11.819447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:12.819805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:13.819898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:14.820568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:15.821561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:16.822065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:17.822288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:18.822498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:19.823575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:20.823765      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:21.824107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:22.824363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:23.824611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:24.824825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:25.825030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:26.825573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:42:27.702396 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:42:27.826475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:28.826930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:29.827160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:30.827417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:31.827737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:32.827991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:33.828186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:34.828410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:35.828527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:36.829307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:37.829493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:38.830562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:39.831579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:40.832571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:41.832695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:42.832886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:43.833156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:44.833448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:45.833648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:46.834012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:42:47.701716 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:42:47.834866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:48.835076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:49.835281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:50.835572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:51.836222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:52.836522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:53.836833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:54.837094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:55.837523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:56.837933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:57.838164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:58.838350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:42:59.838541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:00.838653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:01.839402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:02.839495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:03.839617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:04.840572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:05.841563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:06.841957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:43:07.701822 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:43:07.842883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:08.843127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:09.843317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:10.843518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:11.844099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:12.844572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:13.844805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:14.845110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:15.845398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:16.845516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:17.845757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:18.846095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:19.846325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:20.846561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:21.846935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:22.847136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:23.847446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:24.847658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:25.847796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:26.848323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:43:27.701869 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:43:27.848002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:28.848057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:29.848260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:30.848526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:31.849093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:32.849212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:33.849311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:34.849837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:35.849940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:36.850515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:37.851570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:38.852572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:39.852825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:40.853597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:41.854208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:42.854454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:43.854510      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:44.854768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:45.855093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:46.855438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:43:47.702782 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:43:47.855997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:48.856564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:49.856780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:50.857046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:51.857128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:52.857584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:53.857791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:54.858629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:55.859570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:56.859967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:57.860567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:58.861574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:43:59.862562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:00.862820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:01.863443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:02.863664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:03.863926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:04.864125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:05.864358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:06.864719      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:44:07.702423 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:44:07.865757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:08.865963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:09.866569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:10.866721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:11.867031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:12.867263      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:13.867611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:14.868631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:15.868718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:16.868908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:17.869038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:18.869239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:19.869708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:20.869806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:21.870026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:22.870579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:23.871571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:24.871751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:25.871949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:26.872468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:44:27.701612 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:44:27.872789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:28.873052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:29.873307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:30.873550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:31.874071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:32.874279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:33.874655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:34.875583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:35.875840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:36.876168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:37.876433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:38.876643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:39.876843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:40.877042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:41.877345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:42.877574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:43.877788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:44.878005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:45.878124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:46.879109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:44:47.702580 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQxMzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1130 13:44:47.879771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:48.880562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:49.880672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:50.881562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:51.882054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:52.882431      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:53.882674      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:54.882856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:55.883040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:56.883302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:57.883541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:58.883826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:44:59.884073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:00.884362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:01.884793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:02.885051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:03.885348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:04.885571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:05.885833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:06.886158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:45:07.701182 19 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I1130 13:45:07.701214 19 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 11/30/24 13:45:07.701
  STEP: retrieving all remaining pages @ 11/30/24 13:45:07.706
  I1130 13:45:07.711314 19 chunking.go:221] Retrieved 40/40 results with rv 44970 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQ5NzAsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  I1130 13:45:07.715311 19 chunking.go:221] Retrieved 40/40 results with rv 44970 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQ5NzAsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  I1130 13:45:07.720102 19 chunking.go:221] Retrieved 40/40 results with rv 44970 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQ5NzAsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  I1130 13:45:07.725049 19 chunking.go:221] Retrieved 40/40 results with rv 44970 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQ5NzAsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  I1130 13:45:07.729384 19 chunking.go:221] Retrieved 40/40 results with rv 44970 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQ5NzAsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  I1130 13:45:07.733789 19 chunking.go:221] Retrieved 40/40 results with rv 44970 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQ5NzAsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  I1130 13:45:07.737582 19 chunking.go:221] Retrieved 40/40 results with rv 44970 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NDQ5NzAsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  I1130 13:45:07.741857 19 chunking.go:221] Retrieved 40/40 results with rv 44970 and continue 
  I1130 13:45:07.741979 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-6838" for this suite. @ 11/30/24 13:45:07.746
• [457.815 seconds]
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 11/30/24 13:45:07.754
  I1130 13:45:07.754412 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir-wrapper @ 11/30/24 13:45:07.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:45:07.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:45:07.777
  E1130 13:45:07.887114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:08.887859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 11/30/24 13:45:09.812
  STEP: Cleaning up the configmap @ 11/30/24 13:45:09.82
  STEP: Cleaning up the pod @ 11/30/24 13:45:09.827
  I1130 13:45:09.843211 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-229" for this suite. @ 11/30/24 13:45:09.847
• [2.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:444
  STEP: Creating a kubernetes client @ 11/30/24 13:45:09.855
  I1130 13:45:09.855884 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename taint-multiple-pods @ 11/30/24 13:45:09.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:45:09.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:45:09.878
  I1130 13:45:09.881355 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1130 13:45:09.888738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:10.889738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:11.889879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:12.890578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:13.890804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:14.890942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:15.891108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:16.892099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:17.892771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:18.893561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:19.893975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:20.894155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:21.894947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:22.895362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:23.895930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:24.896280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:25.896971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:26.897547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:27.897609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:28.897882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:29.898867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:30.898979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:31.899030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:32.899087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:33.899120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:34.899740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:35.900642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:36.900742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:37.901459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:38.901567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:39.902317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:40.902544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:41.902721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:42.902903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:43.903610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:44.904569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:45.905413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:46.905552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:47.905623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:48.905761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:49.906680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:50.907077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:51.907463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:52.907605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:53.908561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:54.908776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:55.909456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:56.909509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:57.910647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:58.910748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:45:59.910971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:00.911091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:01.911557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:02.911828      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:03.912424      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:04.912611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:05.913671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:06.914261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:07.914716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:08.914963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:09.881831 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1130 13:46:09.887206 19 taints.go:144] Starting informer...
  STEP: Starting pods... @ 11/30/24 13:46:09.887
  E1130 13:46:09.915800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:10.107393 19 taints.go:463] Pod1 is running on ip-172-31-64-147. Tainting Node
  E1130 13:46:10.915933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:11.916070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:12.332599 19 taints.go:471] Pod2 is running on ip-172-31-64-147. Tainting Node
  STEP: Trying to apply a taint on the Node @ 11/30/24 13:46:12.332
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 11/30/24 13:46:12.346
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 11/30/24 13:46:12.351
  E1130 13:46:12.916865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:13.917094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:14.917335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:15.917679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:16.917790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:17.917931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:18.328552 19 taints.go:492] Noticed Pod "taint-eviction-b1" gets evicted.
  E1130 13:46:18.918060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:19.918502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:20.918706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:21.919081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:22.919151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:23.919260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:24.919430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:25.919517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:26.920568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:27.921567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:28.921673      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:29.922581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:30.922845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:31.923240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:32.923667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:33.923783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:34.923977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:35.924449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:36.924502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:37.924615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:38.352637 19 taints.go:492] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 11/30/24 13:46:38.364
  I1130 13:46:38.369567 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-4168" for this suite. @ 11/30/24 13:46:38.373
• [88.528 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:668
  STEP: Creating a kubernetes client @ 11/30/24 13:46:38.384
  I1130 13:46:38.384885 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pv @ 11/30/24 13:46:38.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:46:38.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:46:38.416
  STEP: Creating initial PV and PVC @ 11/30/24 13:46:38.42
  I1130 13:46:38.420169 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-6519" @ 11/30/24 13:46:38.438
  STEP: Listing PVCs in namespace "pv-6519" @ 11/30/24 13:46:38.443
  STEP: Reading "pvc-snr2g" Status @ 11/30/24 13:46:38.447
  STEP: Reading "pv-6519-jhqqn" Status @ 11/30/24 13:46:38.453
  STEP: Patching "pvc-snr2g" Status @ 11/30/24 13:46:38.458
  STEP: Patching "pv-6519-jhqqn" Status @ 11/30/24 13:46:38.465
  STEP: Updating "pvc-snr2g" Status @ 11/30/24 13:46:38.487
  STEP: Updating "pv-6519-jhqqn" Status @ 11/30/24 13:46:38.5
  I1130 13:46:38.511930 19 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I1130 13:46:38.511957 19 pv.go:205] Deleting PersistentVolumeClaim "pvc-snr2g"
  I1130 13:46:38.520387 19 pv.go:193] Deleting PersistentVolume "pv-6519-jhqqn"
  I1130 13:46:38.530282 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-6519" for this suite. @ 11/30/24 13:46:38.534
• [0.155 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 11/30/24 13:46:38.544
  I1130 13:46:38.544715 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 13:46:38.545
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:46:38.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:46:38.566
  I1130 13:46:38.613654 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5175" for this suite. @ 11/30/24 13:46:38.617
• [0.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 11/30/24 13:46:38.624
  I1130 13:46:38.624864 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename aggregateddiscovery @ 11/30/24 13:46:38.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:46:38.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:46:38.646
  I1130 13:46:38.650616 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:46:38.925645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:39.926417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:40.926511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:41.716595 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-4285" for this suite. @ 11/30/24 13:46:41.721
• [3.104 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 11/30/24 13:46:41.729
  I1130 13:46:41.729045 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 13:46:41.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:46:41.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:46:41.75
  STEP: Creating pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229 @ 11/30/24 13:46:41.754
  E1130 13:46:41.927089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:42.927318      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 11/30/24 13:46:43.773
  I1130 13:46:43.777243 19 container_probe.go:1749] Initial restart count of pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b is 0
  I1130 13:46:43.780549 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:43.928061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:44.928278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:45.786331 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:45.928714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:46.929113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:47.791275 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:47.929518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:48.930594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:49.796427 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:49.931593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:50.931701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:51.801699 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:51.931898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:52.932605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:53.806766 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:53.932989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:54.933147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:55.812240 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:55.933491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:56.934534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:57.817912 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:57.935333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:46:58.935577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:46:59.824319 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:46:59.935632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:00.935915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:01.830410 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:01.936737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:02.936960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:03.835727 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:03.938035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:04.938232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:05.841016 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:05.938481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:06.939533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:07.847233 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:07.940412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:08.940526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:09.852649 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:09.940852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:10.940946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:11.858212 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:11.941432      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:12.941512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:13.864060 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:13.942208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:14.942635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:15.870066 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:15.943355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:16.943560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:17.875448 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:17.943736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:18.943834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:19.880969 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:19.944278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:20.944624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:21.888863 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:21.945168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:22.945465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:23.894575 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:23.945865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:24.945993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:25.900092 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:25.946467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:26.947514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:27.905041 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:27.948221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:28.948420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:29.910774 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:29.948955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:30.949167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:31.916392 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:31.949511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:32.949542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:33.922362 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:33.950597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:34.950711      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:35.928026 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:35.951175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:36.951736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:37.933501 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:37.952766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:38.952862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:39.938780 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:39.952994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:40.953135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:41.944100 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:41.953153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:42.953604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:43.949809 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:43.953874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:44.954151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:45.955018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:45.955062 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:46.955234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:47.955493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:47.960522 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:48.955592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:49.955723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:49.965603 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:50.956631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:51.956845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:51.971673 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:52.957534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:53.957740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:53.977030 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:54.958065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:55.958770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:55.982584 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:56.959754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:57.959860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:57.988263 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:47:58.959978      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:47:59.960044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:47:59.994300 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:00.960179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:01.960508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:02.000390 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:02.961304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:03.961406      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:04.005725 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:04.961523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:05.961678      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:06.011838 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:06.961777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:07.961849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:08.016920 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:08.962595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:09.962884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:10.022918 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:10.963002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:11.963140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:12.028200 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:12.963423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:13.963550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:14.034139 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:14.964087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:15.964205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:16.039853 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:16.964901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:17.965002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:18.045713 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:18.965211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:19.965328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:20.051187 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:20.965485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:21.965618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:22.057463 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:22.966412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:23.966547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:24.063046 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:24.967060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:25.967262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:26.068212 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:26.968293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:27.968429      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:28.073763 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:28.968704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:29.968864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:30.079626 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:30.969523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:31.970437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:32.085637 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:32.970677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:33.970761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:34.091884 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:34.971610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:35.972572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:36.098097 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:36.973463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:37.973684      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:38.104508 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:38.974105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:39.974169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:40.110430 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:40.974192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:41.974599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:42.116056 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:42.974699      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:43.974887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:44.122050 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:44.974955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:45.975163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:46.127913 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:46.976229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:47.976445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:48.134317 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:48.976579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:49.976794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:50.140528 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:50.976927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:51.977400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:52.146696 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:52.977681      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:53.977767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:54.152390 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:54.978062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:55.979030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:56.158412 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:56.979497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:57.979696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:48:58.164321 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:48:58.979792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:48:59.980562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:00.169819 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:00.981570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:01.982565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:02.176750 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:02.982624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:03.983677      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:04.182306 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:04.984127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:05.984318      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:06.187873 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:06.984960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:07.985088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:08.194118 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:08.985633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:09.985823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:10.199922 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:10.986845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:11.987438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:12.206530 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:12.987704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:13.987835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:14.212474 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:14.988256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:15.988360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:16.217874 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:16.988498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:17.988650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:18.223671 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:18.989619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:19.989730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:20.229694 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:20.990469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:21.990532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:22.234968 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:22.990628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:23.990705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:24.240488 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:24.991652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:25.992611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:26.246725 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:26.992705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:27.992812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:28.251974 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:28.993882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:29.994002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:30.257829 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:30.994550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:31.994577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:32.263605 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:32.994879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:33.995208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:34.268548 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:34.995770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:35.996608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:36.273861 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:36.996954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:37.997193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:38.280590 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:38.997335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:39.997584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:40.286048 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:40.997894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:41.998187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:42.291968 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:42.998605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:43.998806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:44.297509 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:44.998929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:45.999060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:46.304211 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:46.999806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:48.000589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:48.310273 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:49.001588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:50.002594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:50.316099 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:51.002813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:52.003112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:52.321944 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:53.003660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:54.003882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:54.327509 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:55.004017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:56.004245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:56.332658 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:57.004531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:49:58.004638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:49:58.338279 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:49:59.004868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:00.004964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:00.343483 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:01.005192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:02.005571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:02.349202 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:03.006521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:04.006654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:04.355090 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:05.006930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:06.007154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:06.361113 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:07.007914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:08.008864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:08.365934 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:09.009600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:10.009692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:10.371318 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:11.009791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:12.010189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:12.375845 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:13.010523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:14.010628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:14.381660 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:15.011223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:16.011651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:16.386931 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:17.011824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:18.012600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:18.391834 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:19.013685      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:20.013863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:20.397661 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:21.014150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:22.014361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:22.403168 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:23.014849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:24.015201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:24.409349 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:25.016216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:26.016418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:26.415061 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:27.016570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:28.016793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:28.421064 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:29.017865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:30.018073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:30.426843 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:31.018212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:32.018543      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:32.432585 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:33.018772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:34.018868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:34.438479 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:35.018981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:36.019077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:36.444107 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:37.019629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:38.020599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:38.450280 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:39.020902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:40.020865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:40.455766 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:41.020891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:42.021075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:50:42.461064 19 container_probe.go:1759] Get pod test-grpc-62333b3a-49fe-477b-aa13-25fb8d48846b in namespace container-probe-6229
  E1130 13:50:43.021493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:44.021639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 11/30/24 13:50:44.461
  I1130 13:50:44.479338 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6229" for this suite. @ 11/30/24 13:50:44.486
• [242.767 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 11/30/24 13:50:44.495
  I1130 13:50:44.495866 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pod-network-test @ 11/30/24 13:50:44.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:50:44.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:50:44.526
  STEP: Performing setup for networking test in namespace pod-network-test-2167 @ 11/30/24 13:50:44.529
  STEP: creating a selector @ 11/30/24 13:50:44.529
  STEP: Creating the service pods in kubernetes @ 11/30/24 13:50:44.529
  I1130 13:50:44.529447 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1130 13:50:45.021766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:46.021917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:47.022018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:48.022226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:49.022548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:50.022900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:51.023047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:52.023387      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:53.023638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:54.023866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:55.024073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:56.024174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:57.024778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:58.024866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:50:59.024948      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:00.025069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:01.025110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:02.025527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:03.026479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:04.027199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:05.027538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:06.027644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 11/30/24 13:51:06.65
  E1130 13:51:07.027827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:08.027927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:08.690870 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I1130 13:51:08.690908 19 utils.go:496] Going to poll 192.168.62.22 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I1130 13:51:08.694050 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.62.22 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2167 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:51:08.694088 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:51:08.694575 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:51:08.694622 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2167/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.62.22+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1130 13:51:09.028917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:09.743801 19 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I1130 13:51:09.743846 19 utils.go:496] Going to poll 192.168.244.226 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I1130 13:51:09.748993 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.244.226 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2167 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:51:09.749017 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:51:09.749440 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:51:09.749484 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2167/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.244.226+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1130 13:51:10.029898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:10.791446 19 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I1130 13:51:10.791519 19 utils.go:496] Going to poll 192.168.81.158 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I1130 13:51:10.796004 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.81.158 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2167 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:51:10.796027 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:51:10.796489 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:51:10.796555 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2167/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.81.158+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1130 13:51:11.030834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:11.837823 19 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I1130 13:51:11.837951 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2167" for this suite. @ 11/30/24 13:51:11.842
• [27.356 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 11/30/24 13:51:11.852
  I1130 13:51:11.852498 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 13:51:11.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:11.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:11.874
  STEP: Create set of pods @ 11/30/24 13:51:11.878
  I1130 13:51:11.887090 19 pods.go:871] created test-pod-1
  I1130 13:51:11.895324 19 pods.go:871] created test-pod-2
  I1130 13:51:11.905765 19 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 11/30/24 13:51:11.905
  E1130 13:51:12.030968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:13.031064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 11/30/24 13:51:13.945
  I1130 13:51:13.950082 19 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E1130 13:51:14.031156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:14.950890 19 pods.go:1140] Pod quantity 2 is different from expected quantity 0
  E1130 13:51:15.032005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:15.951060 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1380" for this suite. @ 11/30/24 13:51:15.955
• [4.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 11/30/24 13:51:15.964
  I1130 13:51:15.964194 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replicaset @ 11/30/24 13:51:15.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:15.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:15.984
  STEP: Create a Replicaset @ 11/30/24 13:51:15.992
  STEP: Verify that the required pods have come up. @ 11/30/24 13:51:15.997
  I1130 13:51:16.001235 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E1130 13:51:16.032491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:17.033512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:18.033523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:19.034609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:20.034963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:21.005735 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 11/30/24 13:51:21.005
  STEP: Getting /status @ 11/30/24 13:51:21.005
  I1130 13:51:21.009405 19 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 11/30/24 13:51:21.009
  I1130 13:51:21.018727 19 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 11/30/24 13:51:21.018
  I1130 13:51:21.020735 19 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I1130 13:51:21.020807 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I1130 13:51:21.020871 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I1130 13:51:21.021036 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I1130 13:51:21.021087 19 replica_set.go:682] Found replicaset test-rs in namespace replicaset-2085 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I1130 13:51:21.021096 19 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 11/30/24 13:51:21.021
  I1130 13:51:21.021138 19 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I1130 13:51:21.028543 19 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 11/30/24 13:51:21.028
  I1130 13:51:21.030337 19 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I1130 13:51:21.030420 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I1130 13:51:21.030477 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I1130 13:51:21.030602 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I1130 13:51:21.030622 19 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-2085 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1130 13:51:21.030684 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I1130 13:51:21.030699 19 replica_set.go:718] Found replicaset test-rs in namespace replicaset-2085 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I1130 13:51:21.030708 19 replica_set.go:729] Replicaset test-rs has a patched status
  I1130 13:51:21.030794 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-2085" for this suite. @ 11/30/24 13:51:21.034
  E1130 13:51:21.035334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [5.076 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 11/30/24 13:51:21.04
  I1130 13:51:21.040677 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sysctl @ 11/30/24 13:51:21.041
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:21.056
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:21.06
  STEP: Creating a pod with one valid and two invalid sysctls @ 11/30/24 13:51:21.064
  I1130 13:51:21.071589 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-3089" for this suite. @ 11/30/24 13:51:21.075
• [0.041 seconds]
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 11/30/24 13:51:21.081
  I1130 13:51:21.081809 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 13:51:21.082
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:21.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:21.104
  STEP: Creating the pod @ 11/30/24 13:51:21.108
  E1130 13:51:22.036394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:23.036557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:23.672344 19 pod_client.go:173] Successfully updated pod "labelsupdate9ee809e7-9ee2-48ae-be20-441cbd49c418"
  E1130 13:51:24.037226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:25.037441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:26.038332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:27.038522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:27.700385 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6980" for this suite. @ 11/30/24 13:51:27.705
• [6.631 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 11/30/24 13:51:27.713
  I1130 13:51:27.713592 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 13:51:27.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:27.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:27.734
  I1130 13:51:27.740177 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:51:28.039120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 11/30/24 13:51:29.021
  I1130 13:51:29.021293 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 create -f -'
  E1130 13:51:29.039722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:29.096055 19 builder.go:146] stderr: ""
  I1130 13:51:29.096094 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8124-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I1130 13:51:29.096146 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 delete e2e-test-crd-publish-openapi-8124-crds test-foo'
  I1130 13:51:29.160869 19 builder.go:146] stderr: ""
  I1130 13:51:29.160910 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8124-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I1130 13:51:29.160990 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 apply -f -'
  I1130 13:51:29.221408 19 builder.go:146] stderr: ""
  I1130 13:51:29.221448 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8124-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I1130 13:51:29.221498 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 delete e2e-test-crd-publish-openapi-8124-crds test-foo'
  I1130 13:51:29.274224 19 builder.go:146] stderr: ""
  I1130 13:51:29.274262 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-8124-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 11/30/24 13:51:29.274
  I1130 13:51:29.274345 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 create -f -'
  I1130 13:51:29.320292 19 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 11/30/24 13:51:29.32
  I1130 13:51:29.320518 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 create -f -'
  I1130 13:51:29.366706 19 builder.go:135] rc: 1
  I1130 13:51:29.366791 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 apply -f -'
  I1130 13:51:29.421322 19 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 11/30/24 13:51:29.421
  I1130 13:51:29.421505 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 create -f -'
  I1130 13:51:29.466827 19 builder.go:135] rc: 1
  I1130 13:51:29.466912 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 --namespace=crd-publish-openapi-5761 apply -f -'
  I1130 13:51:29.520137 19 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 11/30/24 13:51:29.52
  I1130 13:51:29.520266 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 explain e2e-test-crd-publish-openapi-8124-crds'
  I1130 13:51:29.561741 19 builder.go:146] stderr: ""
  I1130 13:51:29.561787 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8124-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 11/30/24 13:51:29.562
  I1130 13:51:29.562125 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 explain e2e-test-crd-publish-openapi-8124-crds.metadata'
  I1130 13:51:29.608313 19 builder.go:146] stderr: ""
  I1130 13:51:29.608442 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8124-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I1130 13:51:29.608741 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 explain e2e-test-crd-publish-openapi-8124-crds.spec'
  I1130 13:51:29.651199 19 builder.go:146] stderr: ""
  I1130 13:51:29.651237 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8124-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I1130 13:51:29.651327 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 explain e2e-test-crd-publish-openapi-8124-crds.spec.bars'
  I1130 13:51:29.694026 19 builder.go:146] stderr: ""
  I1130 13:51:29.694078 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-8124-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 11/30/24 13:51:29.694
  I1130 13:51:29.694275 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=crd-publish-openapi-5761 explain e2e-test-crd-publish-openapi-8124-crds.spec.bars2'
  I1130 13:51:29.735621 19 builder.go:135] rc: 1
  E1130 13:51:30.039849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:30.969169 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5761" for this suite. @ 11/30/24 13:51:30.977
• [3.271 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:329
  STEP: Creating a kubernetes client @ 11/30/24 13:51:30.984
  I1130 13:51:30.984517 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:51:30.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:31.001
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:31.005
  STEP: Setting up server cert @ 11/30/24 13:51:31.028
  E1130 13:51:31.040661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:51:31.21
  STEP: Deploying the webhook pod @ 11/30/24 13:51:31.221
  STEP: Wait for the deployment to be ready @ 11/30/24 13:51:31.235
  I1130 13:51:31.242399 19 deployment.go:222] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1130 13:51:32.041567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:33.041689      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:51:33.256
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:51:33.268
  E1130 13:51:34.041795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:34.269188 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I1130 13:51:34.277969 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3492-crds.webhook.example.com via the AdmissionRegistration API @ 11/30/24 13:51:34.79
  STEP: Creating a custom resource that should be mutated by the webhook @ 11/30/24 13:51:34.806
  E1130 13:51:35.042593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:36.042882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:37.042938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:37.416621 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2639" for this suite. @ 11/30/24 13:51:37.421
  STEP: Destroying namespace "webhook-markers-8297" for this suite. @ 11/30/24 13:51:37.428
• [6.452 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 11/30/24 13:51:37.436
  I1130 13:51:37.436819 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename custom-resource-definition @ 11/30/24 13:51:37.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:37.453
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:37.457
  I1130 13:51:37.461065 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:51:38.043882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:38.487944 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3946" for this suite. @ 11/30/24 13:51:38.493
• [1.066 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:167
  STEP: Creating a kubernetes client @ 11/30/24 13:51:38.502
  I1130 13:51:38.502832 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename disruption @ 11/30/24 13:51:38.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:38.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:38.522
  STEP: Waiting for the pdb to be processed @ 11/30/24 13:51:38.532
  E1130 13:51:39.044580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:40.044843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 11/30/24 13:51:40.537
  STEP: Waiting for all pods to be running @ 11/30/24 13:51:40.546
  I1130 13:51:40.555351 19 disruption.go:691] running pods: 0 < 1
  E1130 13:51:41.045007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:42.045449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 11/30/24 13:51:42.55
  STEP: Waiting for the pdb to be processed @ 11/30/24 13:51:42.567
  STEP: Patching PodDisruptionBudget status @ 11/30/24 13:51:42.575
  STEP: Waiting for the pdb to be processed @ 11/30/24 13:51:42.587
  I1130 13:51:42.592129 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9660" for this suite. @ 11/30/24 13:51:42.596
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 11/30/24 13:51:42.603
  I1130 13:51:42.603045 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 13:51:42.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:42.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:42.624
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 13:51:42.63
  E1130 13:51:43.045538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:44.045627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:45.046424      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:46.046574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:51:46.679
  I1130 13:51:46.684297 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-58de0414-218c-41bb-91d4-a99899e993de container client-container: <nil>
  STEP: delete the pod @ 11/30/24 13:51:46.692
  I1130 13:51:46.708257 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4097" for this suite. @ 11/30/24 13:51:46.712
• [4.117 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 11/30/24 13:51:46.72
  I1130 13:51:46.720539 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 13:51:46.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:46.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:46.744
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 11/30/24 13:51:46.748
  E1130 13:51:47.047414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:48.047610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:49.048304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:50.048472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:51:50.779
  I1130 13:51:50.784463 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-32bc5f6c-7f4e-46a2-a8f6-c4ee4570879b container test-container: <nil>
  STEP: delete the pod @ 11/30/24 13:51:50.792
  I1130 13:51:50.812461 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1470" for this suite. @ 11/30/24 13:51:50.817
• [4.105 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 11/30/24 13:51:50.825
  I1130 13:51:50.825382 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename downward-api @ 11/30/24 13:51:50.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:50.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:50.847
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 13:51:50.85
  E1130 13:51:51.049082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:52.049322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:53.050029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:54.050602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:51:54.879
  I1130 13:51:54.882873 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-942bdb74-fef0-44c1-941d-96659ad59bc0 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 13:51:54.89
  I1130 13:51:54.908068 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5962" for this suite. @ 11/30/24 13:51:54.912
• [4.092 seconds]
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 11/30/24 13:51:54.918
  I1130 13:51:54.918048 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename replication-controller @ 11/30/24 13:51:54.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:54.933
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:54.938
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 11/30/24 13:51:54.943
  E1130 13:51:55.051199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:56.051264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 11/30/24 13:51:56.967
  STEP: Then the orphan pod is adopted @ 11/30/24 13:51:56.973
  E1130 13:51:57.051744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:51:57.982757 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9671" for this suite. @ 11/30/24 13:51:57.987
• [3.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 11/30/24 13:51:57.995
  I1130 13:51:57.995623 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename configmap @ 11/30/24 13:51:57.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:51:58.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:51:58.018
  STEP: Creating configMap with name cm-test-opt-del-3a5c13fd-cb69-4589-a605-1f5b0c8bacc7 @ 11/30/24 13:51:58.026
  STEP: Creating configMap with name cm-test-opt-upd-da050faf-24ee-4c3f-b8c8-31dc6ea542a7 @ 11/30/24 13:51:58.031
  STEP: Creating the pod @ 11/30/24 13:51:58.037
  E1130 13:51:58.051869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:51:59.052460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:00.052683      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-3a5c13fd-cb69-4589-a605-1f5b0c8bacc7 @ 11/30/24 13:52:00.091
  STEP: Updating configmap cm-test-opt-upd-da050faf-24ee-4c3f-b8c8-31dc6ea542a7 @ 11/30/24 13:52:00.098
  STEP: Creating configMap with name cm-test-opt-create-ebdace0b-404c-446a-b144-96398c7fb591 @ 11/30/24 13:52:00.103
  STEP: waiting to observe update in volume @ 11/30/24 13:52:00.11
  E1130 13:52:01.053002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:02.053185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:03.053529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:04.054585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:05.054709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:06.054944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:07.055212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:08.055471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:09.055588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:10.055721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:11.055847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:12.056011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:13.056211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:14.056342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:15.056528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:16.056686      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:17.056950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:18.057027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:19.057336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:20.057524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:21.057881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:22.058337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:23.058544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:24.058635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:25.058740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:26.058864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:27.059537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:28.059598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:29.060597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:30.060714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:31.060809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:32.060902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:33.061533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:34.061643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:35.061738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:36.061834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:37.062906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:38.063131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:39.063516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:40.063747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:41.064777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:42.065179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:43.065459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:44.065653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:45.065907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:46.066143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:47.066306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:48.066448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:49.067088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:50.067345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:51.067561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:52.067768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:53.067944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:54.068638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:55.069599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:56.070597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:57.071522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:58.071628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:52:59.072587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:00.072833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:01.072836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:02.073036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:03.073594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:04.073837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:05.074118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:06.074231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:07.075035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:08.075141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:09.075310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:10.075540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:11.075668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:12.075761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:13.076083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:14.076306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:15.077353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:16.077598      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:17.077593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:18.077829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:19.078755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:20.078889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:21.079622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:22.080594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:23.081573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:24.081697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:25.082220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:26.082342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:27.083181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:28.083363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:29.083790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:30.084119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:31.084654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:32.084783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:32.569663 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1863" for this suite. @ 11/30/24 13:53:32.574
• [94.586 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2157
  STEP: Creating a kubernetes client @ 11/30/24 13:53:32.582
  I1130 13:53:32.582258 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 13:53:32.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:53:32.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:53:32.604
  STEP: creating service in namespace services-2829 @ 11/30/24 13:53:32.607
  STEP: creating service affinity-clusterip in namespace services-2829 @ 11/30/24 13:53:32.607
  STEP: creating replication controller affinity-clusterip in namespace services-2829 @ 11/30/24 13:53:32.62
  I1130 13:53:32.629904      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-2829, replica count: 3
  E1130 13:53:33.085017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:34.085353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:35.085616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:35.680415      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 13:53:35.690226 19 resource.go:361] Creating new exec pod
  E1130 13:53:36.086416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:37.086608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:38.087240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:38.704543 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2829 exec execpod-affinityhm65c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I1130 13:53:38.846722 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  I1130 13:53:38.846780 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 13:53:38.846861 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2829 exec execpod-affinityhm65c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.133 80'
  I1130 13:53:38.934213 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.133 80\nConnection to 10.152.183.133 80 port [tcp/http] succeeded!\n"
  I1130 13:53:38.934255 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 13:53:38.934345 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2829 exec execpod-affinityhm65c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.133:80/ ; done'
  I1130 13:53:39.069245 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.133:80/\n"
  I1130 13:53:39.069298 19 builder.go:147] stdout: "\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc\naffinity-clusterip-2vtgc"
  I1130 13:53:39.069310 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069318 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069324 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069329 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069340 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069346 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069352 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069359 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069382 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069387 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069392 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069398 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069404 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069410 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069416 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069422 19 service.go:242] Received response from host: affinity-clusterip-2vtgc
  I1130 13:53:39.069557 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-2829, will wait for the garbage collector to delete the pods @ 11/30/24 13:53:39.085
  E1130 13:53:39.087435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:39.149056 19 resources.go:139] Deleting ReplicationController affinity-clusterip took: 9.654873ms
  I1130 13:53:39.249879 19 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 100.819379ms
  E1130 13:53:40.087788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:41.088344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:42.089383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:42.369201 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2829" for this suite. @ 11/30/24 13:53:42.373
• [9.800 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 11/30/24 13:53:42.382
  I1130 13:53:42.382164 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename deployment @ 11/30/24 13:53:42.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:53:42.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:53:42.399
  I1130 13:53:42.412647 19 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E1130 13:53:43.089486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:44.089547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:45.089640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:46.089725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:47.090014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:47.418479 19 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 11/30/24 13:53:47.418
  I1130 13:53:47.418661 19 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 11/30/24 13:53:47.429
  E1130 13:53:48.090494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:49.090636      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:49.451651 19 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=13) "deployment-32",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e48df09d-cc24-432a-a26f-c32b7a60e2d6",
      ResourceVersion: (string) (len=5) "47463",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868571627,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571627,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571628,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571627,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571627,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571628,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571627,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=75) "ReplicaSet \"test-cleanup-deployment-898f8f847\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1130 13:53:49.457290 19 deployment.go:39] New ReplicaSet "test-cleanup-deployment-898f8f847" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=33) "test-cleanup-deployment-898f8f847",
      GenerateName: (string) "",
      Namespace: (string) (len=13) "deployment-32",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9f10aa3a-3581-4fd0-aca4-302db1e0786f",
      ResourceVersion: (string) (len=5) "47453",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868571627,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "898f8f847"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "e48df09d-cc24-432a-a26f-c32b7a60e2d6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571627,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 34 38 64 66 30  39 64 2d 63 63 32 34 2d  |\"e48df09d-cc24-|
              00000120  34 33 32 61 2d 61 32 36  66 2d 63 33 32 62 37 61  |432a-a26f-c32b7a|
              00000130  36 30 65 32 64 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |60e2d6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571628,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "898f8f847"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "898f8f847",
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1130 13:53:49.463420 19 deployment.go:67] Pod "test-cleanup-deployment-898f8f847-mmbf8" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=39) "test-cleanup-deployment-898f8f847-mmbf8",
      GenerateName: (string) (len=34) "test-cleanup-deployment-898f8f847-",
      Namespace: (string) (len=13) "deployment-32",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2c22984d-8eb6-4435-a2b3-603ba2ec5d95",
      ResourceVersion: (string) (len=5) "47452",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868571627,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "898f8f847"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=33) "test-cleanup-deployment-898f8f847",
          UID: (types.UID) (len=36) "9f10aa3a-3581-4fd0-aca4-302db1e0786f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571627,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 66  31 30 61 61 33 61 2d 33  |d\":\"9f10aa3a-3|
              00000090  35 38 31 2d 34 66 64 30  2d 61 63 61 34 2d 33 30  |581-4fd0-aca4-30|
              000000a0  32 64 62 31 65 30 37 38  36 66 5c 22 7d 22 3a 7b  |2db1e0786f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571628,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 34  34 2e 32 35 32 5c 22 7d  |2.168.244.252\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9n94b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9n94b",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-64-147",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571628,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571627,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571628,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571628,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63868571627,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.64.147",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.64.147"
        }
      },
      PodIP: (string) (len=15) "192.168.244.252",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.244.252"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63868571627,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63868571627,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6",
          ContainerID: (string) (len=77) "containerd://126c1e5d3a7d412e479506be58ae30cbbd4447406395859efe118438cc69a130",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-9n94b",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1130 13:53:49.464568 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-32" for this suite. @ 11/30/24 13:53:49.471
• [7.098 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:341
  STEP: Creating a kubernetes client @ 11/30/24 13:53:49.48
  I1130 13:53:49.480189 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename cronjob @ 11/30/24 13:53:49.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:53:49.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:53:49.5
  STEP: Creating a cronjob @ 11/30/24 13:53:49.504
  STEP: creating @ 11/30/24 13:53:49.504
  STEP: getting @ 11/30/24 13:53:49.509
  STEP: listing @ 11/30/24 13:53:49.513
  STEP: watching @ 11/30/24 13:53:49.517
  I1130 13:53:49.517837 19 cronjob.go:370] starting watch
  STEP: cluster-wide listing @ 11/30/24 13:53:49.519
  STEP: cluster-wide watching @ 11/30/24 13:53:49.522
  I1130 13:53:49.522879 19 cronjob.go:382] starting watch
  STEP: patching @ 11/30/24 13:53:49.524
  STEP: updating @ 11/30/24 13:53:49.531
  I1130 13:53:49.541945 19 cronjob.go:406] waiting for watch events with expected annotations
  I1130 13:53:49.541989 19 cronjob.go:420] saw patched and updated annotations
  STEP: patching /status @ 11/30/24 13:53:49.542
  STEP: updating /status @ 11/30/24 13:53:49.547
  STEP: get /status @ 11/30/24 13:53:49.556
  STEP: deleting @ 11/30/24 13:53:49.56
  STEP: deleting a collection @ 11/30/24 13:53:49.578
  I1130 13:53:49.591706 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1856" for this suite. @ 11/30/24 13:53:49.596
• [0.123 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 11/30/24 13:53:49.603
  I1130 13:53:49.603402 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pods @ 11/30/24 13:53:49.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:53:49.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:53:49.623
  STEP: creating a Pod with a static label @ 11/30/24 13:53:49.632
  STEP: watching for Pod to be ready @ 11/30/24 13:53:49.64
  I1130 13:53:49.642339 19 pods.go:945] observed Pod pod-test in namespace pods-3528 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I1130 13:53:49.649462 19 pods.go:945] observed Pod pod-test in namespace pods-3528 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:49 +0000 UTC  }]
  I1130 13:53:49.667030 19 pods.go:945] observed Pod pod-test in namespace pods-3528 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:49 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:49 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:49 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:49 +0000 UTC  }]
  E1130 13:53:50.091526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:51.074998 19 pods.go:948] Found Pod pod-test in namespace pods-3528 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:51 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-11-30 13:53:49 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 11/30/24 13:53:51.079
  STEP: getting the Pod and ensuring that it's patched @ 11/30/24 13:53:51.09
  E1130 13:53:51.091809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: replacing the Pod's status Ready condition to False @ 11/30/24 13:53:51.096
  STEP: check the Pod again to ensure its Ready conditions are False @ 11/30/24 13:53:51.108
  STEP: deleting the Pod via a Collection with a LabelSelector @ 11/30/24 13:53:51.108
  STEP: watching for the Pod to be deleted @ 11/30/24 13:53:51.119
  I1130 13:53:51.121530 19 pods.go:1058] observed event type MODIFIED
  E1130 13:53:52.092521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:53.092671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:53.092692 19 pods.go:1058] observed event type MODIFIED
  I1130 13:53:53.223171 19 pods.go:1058] observed event type MODIFIED
  I1130 13:53:54.087501 19 pods.go:1058] observed event type MODIFIED
  E1130 13:53:54.093050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:54.097897 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3528" for this suite. @ 11/30/24 13:53:54.103
• [4.507 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2216
  STEP: Creating a kubernetes client @ 11/30/24 13:53:54.11
  I1130 13:53:54.110744 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename services @ 11/30/24 13:53:54.111
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:53:54.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:53:54.132
  STEP: creating service in namespace services-2701 @ 11/30/24 13:53:54.135
  STEP: creating service affinity-nodeport-transition in namespace services-2701 @ 11/30/24 13:53:54.135
  STEP: creating replication controller affinity-nodeport-transition in namespace services-2701 @ 11/30/24 13:53:54.155
  I1130 13:53:54.163650      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2701, replica count: 3
  E1130 13:53:55.093529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:56.093631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:57.093990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:53:57.215417      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1130 13:53:57.229090 19 resource.go:361] Creating new exec pod
  E1130 13:53:58.094200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:53:59.094328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:00.094463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:54:00.250877 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2701 exec execpod-affinitysqn5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I1130 13:54:00.337469 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  I1130 13:54:00.337531 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 13:54:00.337614 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2701 exec execpod-affinitysqn5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.188 80'
  I1130 13:54:00.420540 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.188 80\nConnection to 10.152.183.188 80 port [tcp/http] succeeded!\n"
  I1130 13:54:00.420582 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 13:54:00.420664 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2701 exec execpod-affinitysqn5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.94.166 32026'
  I1130 13:54:00.505934 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.94.166 32026\nConnection to 172.31.94.166 32026 port [tcp/*] succeeded!\n"
  I1130 13:54:00.505985 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 13:54:00.506124 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2701 exec execpod-affinitysqn5j -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.4.119 32026'
  I1130 13:54:00.594893 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.4.119 32026\nConnection to 172.31.4.119 32026 port [tcp/*] succeeded!\n"
  I1130 13:54:00.594937 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1130 13:54:00.607644 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2701 exec execpod-affinitysqn5j -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.4.119:32026/ ; done'
  I1130 13:54:00.763887 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n"
  I1130 13:54:00.763938 19 builder.go:147] stdout: "\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-b267v\naffinity-nodeport-transition-b267v\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-b267v\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-zdk2q\naffinity-nodeport-transition-b267v\naffinity-nodeport-transition-zdk2q\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-b267v\naffinity-nodeport-transition-zdk2q\naffinity-nodeport-transition-b267v\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-b267v"
  I1130 13:54:00.763950 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.763958 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.763964 19 service.go:242] Received response from host: affinity-nodeport-transition-b267v
  I1130 13:54:00.763971 19 service.go:242] Received response from host: affinity-nodeport-transition-b267v
  I1130 13:54:00.763977 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.763982 19 service.go:242] Received response from host: affinity-nodeport-transition-b267v
  I1130 13:54:00.763988 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.763993 19 service.go:242] Received response from host: affinity-nodeport-transition-zdk2q
  I1130 13:54:00.763999 19 service.go:242] Received response from host: affinity-nodeport-transition-b267v
  I1130 13:54:00.764008 19 service.go:242] Received response from host: affinity-nodeport-transition-zdk2q
  I1130 13:54:00.764013 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.764018 19 service.go:242] Received response from host: affinity-nodeport-transition-b267v
  I1130 13:54:00.764023 19 service.go:242] Received response from host: affinity-nodeport-transition-zdk2q
  I1130 13:54:00.764028 19 service.go:242] Received response from host: affinity-nodeport-transition-b267v
  I1130 13:54:00.764034 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.764040 19 service.go:242] Received response from host: affinity-nodeport-transition-b267v
  I1130 13:54:00.775393 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2122482875 --namespace=services-2701 exec execpod-affinitysqn5j -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.4.119:32026/ ; done'
  I1130 13:54:00.938986 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.4.119:32026/\n"
  I1130 13:54:00.939031 19 builder.go:147] stdout: "\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg\naffinity-nodeport-transition-ggrtg"
  I1130 13:54:00.939048 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939056 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939062 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939068 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939075 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939081 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939086 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939091 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939097 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939102 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939107 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939116 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939121 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939127 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939133 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939138 19 service.go:242] Received response from host: affinity-nodeport-transition-ggrtg
  I1130 13:54:00.939227 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2701, will wait for the garbage collector to delete the pods @ 11/30/24 13:54:00.955
  I1130 13:54:01.018318 19 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 9.192325ms
  E1130 13:54:01.095071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:54:01.119287 19 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 100.966797ms
  E1130 13:54:02.095580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:03.095829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:04.096513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:54:04.242255 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2701" for this suite. @ 11/30/24 13:54:04.246
• [10.142 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 11/30/24 13:54:04.252
  I1130 13:54:04.253009 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:54:04.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:04.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:04.274
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 13:54:04.278
  E1130 13:54:05.096710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:06.096995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:54:06.299
  I1130 13:54:06.304921 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-ada96184-ed9a-41a4-a702-de78e535fcb1 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 13:54:06.317
  I1130 13:54:06.344682 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2412" for this suite. @ 11/30/24 13:54:06.349
• [2.105 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 11/30/24 13:54:06.357
  I1130 13:54:06.357914 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-runtime @ 11/30/24 13:54:06.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:06.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:06.381
  STEP: create the container @ 11/30/24 13:54:06.385
  W1130 13:54:06.394053      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 11/30/24 13:54:06.394
  E1130 13:54:07.097495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:08.098505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 11/30/24 13:54:08.413
  STEP: the container should be terminated @ 11/30/24 13:54:08.418
  STEP: the termination message should be set @ 11/30/24 13:54:08.418
  I1130 13:54:08.418150 19 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 11/30/24 13:54:08.418
  I1130 13:54:08.443733 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4562" for this suite. @ 11/30/24 13:54:08.448
• [2.097 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 11/30/24 13:54:08.455
  I1130 13:54:08.455593 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-pred @ 11/30/24 13:54:08.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:08.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:08.474
  I1130 13:54:08.478307 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I1130 13:54:08.486248 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1130 13:54:08.489697 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-4-119 before test
  I1130 13:54:08.495774 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-24r2d from ingress-nginx-kubernetes-worker started at 2024-11-30 12:02:13 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.495791 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1130 13:54:08.495798 19 predicates.go:957] calico-node-m9zjm from kube-system started at 2024-11-30 12:09:48 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.495805 19 predicates.go:959] 	Container calico-node ready: true, restart count 1
  I1130 13:54:08.495811 19 predicates.go:957] sonobuoy-e2e-job-046772c140634943 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 13:54:08.495816 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I1130 13:54:08.495821 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 13:54:08.495826 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-rn6l7 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 13:54:08.495831 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 13:54:08.495836 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1130 13:54:08.495842 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-64-147 before test
  I1130 13:54:08.500713 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-v6hbp from ingress-nginx-kubernetes-worker started at 2024-11-30 13:46:38 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.500732 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1130 13:54:08.500738 19 predicates.go:957] calico-node-5dksp from kube-system started at 2024-11-30 12:09:37 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.500744 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1130 13:54:08.500750 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-11-30 12:13:35 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.500754 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I1130 13:54:08.500760 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-sv7v4 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 13:54:08.500817 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 13:54:08.500823 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1130 13:54:08.500831 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-94-166 before test
  I1130 13:54:08.506559 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-5gx7b from ingress-nginx-kubernetes-worker started at 2024-11-30 11:59:40 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.506576 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 2
  I1130 13:54:08.506583 19 predicates.go:957] calico-node-n82d2 from kube-system started at 2024-11-30 12:08:48 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.506588 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1130 13:54:08.506594 19 predicates.go:957] coredns-5b4857d7c8-d9dkl from kube-system started at 2024-11-30 11:59:41 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.506600 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I1130 13:54:08.506606 19 predicates.go:957] kube-state-metrics-5d7bdccd49-hn4gf from kube-system started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.506611 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 5
  I1130 13:54:08.506616 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-w2q4q from kube-system started at 2024-11-30 11:59:41 +0000 UTC (2 container statuses recorded)
  I1130 13:54:08.506621 19 predicates.go:959] 	Container metrics-server ready: true, restart count 0
  I1130 13:54:08.506626 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I1130 13:54:08.506631 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-6hwh9 from kubernetes-dashboard started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.506636 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I1130 13:54:08.506642 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-d5v6d from kubernetes-dashboard started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 13:54:08.506651 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 2
  I1130 13:54:08.506657 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-x97pk from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 13:54:08.506661 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 13:54:08.506683 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-4-119 @ 11/30/24 13:54:08.523
  STEP: verifying the node has the label node ip-172-31-64-147 @ 11/30/24 13:54:08.537
  STEP: verifying the node has the label node ip-172-31-94-166 @ 11/30/24 13:54:08.551
  I1130 13:54:08.568295 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-24r2d requesting resource cpu=0m on Node ip-172-31-4-119
  I1130 13:54:08.568533 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-5gx7b requesting resource cpu=0m on Node ip-172-31-94-166
  I1130 13:54:08.568546 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-v6hbp requesting resource cpu=0m on Node ip-172-31-64-147
  I1130 13:54:08.568556 19 predicates.go:372] Pod calico-node-5dksp requesting resource cpu=250m on Node ip-172-31-64-147
  I1130 13:54:08.568663 19 predicates.go:372] Pod calico-node-m9zjm requesting resource cpu=250m on Node ip-172-31-4-119
  I1130 13:54:08.568672 19 predicates.go:372] Pod calico-node-n82d2 requesting resource cpu=250m on Node ip-172-31-94-166
  I1130 13:54:08.568679 19 predicates.go:372] Pod coredns-5b4857d7c8-d9dkl requesting resource cpu=100m on Node ip-172-31-94-166
  I1130 13:54:08.568685 19 predicates.go:372] Pod kube-state-metrics-5d7bdccd49-hn4gf requesting resource cpu=0m on Node ip-172-31-94-166
  I1130 13:54:08.568692 19 predicates.go:372] Pod metrics-server-v0.7.1-6c77d69467-w2q4q requesting resource cpu=5m on Node ip-172-31-94-166
  I1130 13:54:08.568698 19 predicates.go:372] Pod dashboard-metrics-scraper-64757cf48d-6hwh9 requesting resource cpu=0m on Node ip-172-31-94-166
  I1130 13:54:08.568711 19 predicates.go:372] Pod kubernetes-dashboard-7b6b7bcb5d-d5v6d requesting resource cpu=0m on Node ip-172-31-94-166
  I1130 13:54:08.568887 19 predicates.go:372] Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-64-147
  I1130 13:54:08.568918 19 predicates.go:372] Pod sonobuoy-e2e-job-046772c140634943 requesting resource cpu=0m on Node ip-172-31-4-119
  I1130 13:54:08.568925 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-rn6l7 requesting resource cpu=0m on Node ip-172-31-4-119
  I1130 13:54:08.568932 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-sv7v4 requesting resource cpu=0m on Node ip-172-31-64-147
  I1130 13:54:08.568938 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-x97pk requesting resource cpu=0m on Node ip-172-31-94-166
  STEP: Starting Pods to consume most of the cluster CPU. @ 11/30/24 13:54:08.568
  I1130 13:54:08.568975 19 predicates.go:382] Creating a pod which consumes cpu=1225m on Node ip-172-31-4-119
  I1130 13:54:08.578416 19 predicates.go:382] Creating a pod which consumes cpu=1225m on Node ip-172-31-64-147
  I1130 13:54:08.587675 19 predicates.go:382] Creating a pod which consumes cpu=1151m on Node ip-172-31-94-166
  E1130 13:54:09.099451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:10.099562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 11/30/24 13:54:10.615
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-16ae8806-72a0-4704-9be1-0d4ea2049b1d.180cc3716fa5ec9f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7748/filler-pod-16ae8806-72a0-4704-9be1-0d4ea2049b1d to ip-172-31-94-166] @ 11/30/24 13:54:10.619
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-16ae8806-72a0-4704-9be1-0d4ea2049b1d.180cc3718d008308], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 11/30/24 13:54:10.619
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-16ae8806-72a0-4704-9be1-0d4ea2049b1d.180cc3718ddd3eea], Reason = [Created], Message = [Created container filler-pod-16ae8806-72a0-4704-9be1-0d4ea2049b1d] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-16ae8806-72a0-4704-9be1-0d4ea2049b1d.180cc3719004041e], Reason = [Started], Message = [Started container filler-pod-16ae8806-72a0-4704-9be1-0d4ea2049b1d] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ab522087-3b19-4b68-a436-4ba2af1ee689.180cc3716f1e53e4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7748/filler-pod-ab522087-3b19-4b68-a436-4ba2af1ee689 to ip-172-31-64-147] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ab522087-3b19-4b68-a436-4ba2af1ee689.180cc3718b9530c4], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ab522087-3b19-4b68-a436-4ba2af1ee689.180cc3718cbbbd4e], Reason = [Created], Message = [Created container filler-pod-ab522087-3b19-4b68-a436-4ba2af1ee689] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ab522087-3b19-4b68-a436-4ba2af1ee689.180cc3718fa12c7a], Reason = [Started], Message = [Started container filler-pod-ab522087-3b19-4b68-a436-4ba2af1ee689] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-eaba7ef3-e2cf-440f-852c-628b80897b39.180cc3716e902e84], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7748/filler-pod-eaba7ef3-e2cf-440f-852c-628b80897b39 to ip-172-31-4-119] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-eaba7ef3-e2cf-440f-852c-628b80897b39.180cc3718b2d5402], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-eaba7ef3-e2cf-440f-852c-628b80897b39.180cc3718c5d8f14], Reason = [Created], Message = [Created container filler-pod-eaba7ef3-e2cf-440f-852c-628b80897b39] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-eaba7ef3-e2cf-440f-852c-628b80897b39.180cc3718e9da40b], Reason = [Started], Message = [Started container filler-pod-eaba7ef3-e2cf-440f-852c-628b80897b39] @ 11/30/24 13:54:10.62
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.180cc371e86c1afb], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] @ 11/30/24 13:54:10.633
  E1130 13:54:11.100516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label node off the node ip-172-31-4-119 @ 11/30/24 13:54:11.634
  STEP: verifying the node doesn't have the label node @ 11/30/24 13:54:11.645
  STEP: removing the label node off the node ip-172-31-64-147 @ 11/30/24 13:54:11.65
  STEP: verifying the node doesn't have the label node @ 11/30/24 13:54:11.664
  STEP: removing the label node off the node ip-172-31-94-166 @ 11/30/24 13:54:11.669
  STEP: verifying the node doesn't have the label node @ 11/30/24 13:54:11.682
  I1130 13:54:11.687214 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-7748" for this suite. @ 11/30/24 13:54:11.693
• [3.246 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 11/30/24 13:54:11.701
  I1130 13:54:11.701595 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename pod-network-test @ 11/30/24 13:54:11.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:11.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:11.721
  STEP: Performing setup for networking test in namespace pod-network-test-3171 @ 11/30/24 13:54:11.725
  STEP: creating a selector @ 11/30/24 13:54:11.725
  STEP: Creating the service pods in kubernetes @ 11/30/24 13:54:11.725
  I1130 13:54:11.725106 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1130 13:54:12.100821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:13.100941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:14.101014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:15.101123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:16.102112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:17.103127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:18.103244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:19.103358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:20.104018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:21.104402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:22.105355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:23.105579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 11/30/24 13:54:23.813
  E1130 13:54:24.106202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:25.106442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:54:25.838517 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I1130 13:54:25.838550 19 networking.go:42] Breadth first check of 192.168.62.58 on host 172.31.4.119...
  I1130 13:54:25.842599 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.244.202:9080/dial?request=hostname&protocol=http&host=192.168.62.58&port=8083&tries=1'] Namespace:pod-network-test-3171 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:54:25.842626 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:54:25.843069 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:54:25.843111 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3171/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.244.202%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.62.58%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1130 13:54:25.887630 19 utils.go:356] Waiting for responses: map[]
  I1130 13:54:25.887663 19 utils.go:360] reached 192.168.62.58 after 0/1 tries
  I1130 13:54:25.887672 19 networking.go:42] Breadth first check of 192.168.244.249 on host 172.31.64.147...
  I1130 13:54:25.892341 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.244.202:9080/dial?request=hostname&protocol=http&host=192.168.244.249&port=8083&tries=1'] Namespace:pod-network-test-3171 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:54:25.892363 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:54:25.892777 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:54:25.892822 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3171/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.244.202%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.244.249%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1130 13:54:25.934241 19 utils.go:356] Waiting for responses: map[]
  I1130 13:54:25.934288 19 utils.go:360] reached 192.168.244.249 after 0/1 tries
  I1130 13:54:25.934301 19 networking.go:42] Breadth first check of 192.168.81.177 on host 172.31.94.166...
  I1130 13:54:25.939075 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.244.202:9080/dial?request=hostname&protocol=http&host=192.168.81.177&port=8083&tries=1'] Namespace:pod-network-test-3171 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:54:25.939096 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:54:25.939514 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:54:25.939616 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3171/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.244.202%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.81.177%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1130 13:54:25.986456 19 utils.go:356] Waiting for responses: map[]
  I1130 13:54:25.986493 19 utils.go:360] reached 192.168.81.177 after 0/1 tries
  I1130 13:54:25.986503 19 networking.go:53] Going to retry 0 out of 3 pods....
  I1130 13:54:25.986603 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3171" for this suite. @ 11/30/24 13:54:25.991
• [14.298 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 11/30/24 13:54:25.999
  I1130 13:54:25.999741 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-runtime @ 11/30/24 13:54:26
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:26.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:26.023
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 11/30/24 13:54:26.036
  E1130 13:54:26.106580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:27.107046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:28.108081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:29.108749      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:30.109521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:31.110278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:32.111333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:33.112354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:34.112651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:35.112934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:36.113986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:37.114118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:38.114604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:39.115261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:40.115772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:41.115932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:42.116067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 11/30/24 13:54:42.127
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 11/30/24 13:54:42.133
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 11/30/24 13:54:42.142
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 11/30/24 13:54:42.142
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 11/30/24 13:54:42.17
  E1130 13:54:43.116303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:44.116542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:45.116793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 11/30/24 13:54:45.194
  E1130 13:54:46.117063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 11/30/24 13:54:46.205
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 11/30/24 13:54:46.212
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 11/30/24 13:54:46.212
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 11/30/24 13:54:46.245
  E1130 13:54:47.117092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 11/30/24 13:54:47.255
  E1130 13:54:48.117786      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:49.117989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 11/30/24 13:54:49.268
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 11/30/24 13:54:49.277
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 11/30/24 13:54:49.277
  I1130 13:54:49.304312 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3407" for this suite. @ 11/30/24 13:54:49.308
• [23.316 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 11/30/24 13:54:49.316
  I1130 13:54:49.316402 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename watch @ 11/30/24 13:54:49.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:49.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:49.337
  STEP: creating a watch on configmaps with a certain label @ 11/30/24 13:54:49.341
  STEP: creating a new configmap @ 11/30/24 13:54:49.343
  STEP: modifying the configmap once @ 11/30/24 13:54:49.348
  STEP: changing the label value of the configmap @ 11/30/24 13:54:49.359
  STEP: Expecting to observe a delete notification for the watched object @ 11/30/24 13:54:49.367
  I1130 13:54:49.367646 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7129  ed91d91e-d24a-4052-9abe-ecd4618dc76c 48165 0 2024-11-30 13:54:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-11-30 13:54:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:54:49.367947 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7129  ed91d91e-d24a-4052-9abe-ecd4618dc76c 48166 0 2024-11-30 13:54:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-11-30 13:54:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:54:49.368036 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7129  ed91d91e-d24a-4052-9abe-ecd4618dc76c 48167 0 2024-11-30 13:54:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-11-30 13:54:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 11/30/24 13:54:49.368
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 11/30/24 13:54:49.376
  E1130 13:54:50.118579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:51.119623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:52.119700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:53.120050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:54.120574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:55.120783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:56.120913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:57.121359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:58.121492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:54:59.121625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 11/30/24 13:54:59.377
  STEP: modifying the configmap a third time @ 11/30/24 13:54:59.388
  STEP: deleting the configmap @ 11/30/24 13:54:59.397
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 11/30/24 13:54:59.404
  I1130 13:54:59.404776 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7129  ed91d91e-d24a-4052-9abe-ecd4618dc76c 48209 0 2024-11-30 13:54:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-11-30 13:54:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:54:59.404897 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7129  ed91d91e-d24a-4052-9abe-ecd4618dc76c 48210 0 2024-11-30 13:54:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-11-30 13:54:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:54:59.404993 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7129  ed91d91e-d24a-4052-9abe-ecd4618dc76c 48211 0 2024-11-30 13:54:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-11-30 13:54:59 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:54:59.405090 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7129" for this suite. @ 11/30/24 13:54:59.409
• [10.101 seconds]
------------------------------
SSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 11/30/24 13:54:59.417
  I1130 13:54:59.417933 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename events @ 11/30/24 13:54:59.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:59.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:59.437
  STEP: Create set of events @ 11/30/24 13:54:59.44
  I1130 13:54:59.446010 19 core_events.go:198] created test-event-1
  I1130 13:54:59.450569 19 core_events.go:198] created test-event-2
  I1130 13:54:59.456095 19 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 11/30/24 13:54:59.456
  STEP: delete collection of events @ 11/30/24 13:54:59.459
  I1130 13:54:59.459782 19 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 11/30/24 13:54:59.483
  I1130 13:54:59.483155 19 core_events.go:230] requesting list of events to confirm quantity
  I1130 13:54:59.487700 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4766" for this suite. @ 11/30/24 13:54:59.491
• [0.082 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 11/30/24 13:54:59.5
  I1130 13:54:59.500614 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename ingress @ 11/30/24 13:54:59.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:59.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:59.52
  STEP: getting /apis @ 11/30/24 13:54:59.523
  STEP: getting /apis/networking.k8s.io @ 11/30/24 13:54:59.527
  STEP: getting /apis/networking.k8s.iov1 @ 11/30/24 13:54:59.529
  STEP: creating @ 11/30/24 13:54:59.53
  STEP: getting @ 11/30/24 13:54:59.551
  STEP: listing @ 11/30/24 13:54:59.558
  STEP: watching @ 11/30/24 13:54:59.562
  I1130 13:54:59.562475 19 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 11/30/24 13:54:59.564
  STEP: cluster-wide watching @ 11/30/24 13:54:59.568
  I1130 13:54:59.568755 19 ingress.go:198] starting watch
  STEP: patching @ 11/30/24 13:54:59.57
  STEP: updating @ 11/30/24 13:54:59.579
  I1130 13:54:59.591014 19 ingress.go:221] waiting for watch events with expected annotations
  I1130 13:54:59.591057 19 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 11/30/24 13:54:59.591
  STEP: updating /status @ 11/30/24 13:54:59.596
  STEP: get /status @ 11/30/24 13:54:59.605
  STEP: deleting @ 11/30/24 13:54:59.612
  STEP: deleting a collection @ 11/30/24 13:54:59.632
  I1130 13:54:59.650597 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-3504" for this suite. @ 11/30/24 13:54:59.655
• [0.161 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 11/30/24 13:54:59.661
  I1130 13:54:59.661813 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:54:59.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:54:59.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:54:59.687
  STEP: Creating the pod @ 11/30/24 13:54:59.69
  E1130 13:55:00.121788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:01.121855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:02.122576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:02.243183 19 pod_client.go:173] Successfully updated pod "labelsupdate0ef0bbc3-cc94-47fa-b405-f9740960ff76"
  E1130 13:55:03.123061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:04.123342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:04.259644 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4688" for this suite. @ 11/30/24 13:55:04.264
• [4.611 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 11/30/24 13:55:04.272
  I1130 13:55:04.272764 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename container-probe @ 11/30/24 13:55:04.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:04.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:04.294
  STEP: Creating pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069 @ 11/30/24 13:55:04.297
  E1130 13:55:05.123691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:06.123815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 11/30/24 13:55:06.318
  I1130 13:55:06.322468 19 container_probe.go:1749] Initial restart count of pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 is 0
  I1130 13:55:06.326701 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:07.124708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:08.124912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:08.332308 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:09.125226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:10.125468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:10.336882 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:11.125633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:12.126590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:12.341964 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:13.126687      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:14.126879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:14.347283 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:15.127166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:16.127472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:16.352656 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:17.127529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:18.127907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:18.358361 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:19.128009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:20.128619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:20.364307 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:21.129531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:22.130585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:22.370279 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:23.131610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:24.131654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:24.376399 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  E1130 13:55:25.131753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:26.131857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:26.381971 19 container_probe.go:1759] Get pod liveness-3e128d65-c30f-428e-ba9a-53140610dac2 in namespace container-probe-3069
  I1130 13:55:26.382012 19 container_probe.go:1763] Restart count of pod container-probe-3069/liveness-3e128d65-c30f-428e-ba9a-53140610dac2 is now 1 (20.059516333s elapsed)
  STEP: deleting the pod @ 11/30/24 13:55:26.382
  I1130 13:55:26.399262 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3069" for this suite. @ 11/30/24 13:55:26.404
• [22.141 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 11/30/24 13:55:26.414
  I1130 13:55:26.414133 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename conformance-tests @ 11/30/24 13:55:26.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:26.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:26.435
  STEP: Getting node addresses @ 11/30/24 13:55:26.44
  I1130 13:55:26.440602 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I1130 13:55:26.451216 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-5944" for this suite. @ 11/30/24 13:55:26.455
• [0.049 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 11/30/24 13:55:26.463
  I1130 13:55:26.463646 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename sched-pred @ 11/30/24 13:55:26.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:26.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:26.485
  I1130 13:55:26.489641 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I1130 13:55:26.498411 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1130 13:55:26.502550 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-4-119 before test
  I1130 13:55:26.508164 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-24r2d from ingress-nginx-kubernetes-worker started at 2024-11-30 12:02:13 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.508189 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1130 13:55:26.508305 19 predicates.go:957] calico-node-m9zjm from kube-system started at 2024-11-30 12:09:48 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.508315 19 predicates.go:959] 	Container calico-node ready: true, restart count 1
  I1130 13:55:26.508320 19 predicates.go:957] sonobuoy-e2e-job-046772c140634943 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 13:55:26.508324 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I1130 13:55:26.508328 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 13:55:26.508334 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-rn6l7 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 13:55:26.508338 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 13:55:26.508342 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1130 13:55:26.508347 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-64-147 before test
  I1130 13:55:26.514255 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-v6hbp from ingress-nginx-kubernetes-worker started at 2024-11-30 13:46:38 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.514278 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1130 13:55:26.514287 19 predicates.go:957] calico-node-5dksp from kube-system started at 2024-11-30 12:09:37 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.514292 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1130 13:55:26.514298 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-11-30 12:13:35 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.514314 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I1130 13:55:26.514320 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-sv7v4 from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 13:55:26.514325 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 13:55:26.514334 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1130 13:55:26.514339 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-94-166 before test
  I1130 13:55:26.520681 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-5gx7b from ingress-nginx-kubernetes-worker started at 2024-11-30 11:59:40 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.520704 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 2
  I1130 13:55:26.520711 19 predicates.go:957] calico-node-n82d2 from kube-system started at 2024-11-30 12:08:48 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.520720 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1130 13:55:26.520738 19 predicates.go:957] coredns-5b4857d7c8-d9dkl from kube-system started at 2024-11-30 11:59:41 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.520743 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I1130 13:55:26.520748 19 predicates.go:957] kube-state-metrics-5d7bdccd49-hn4gf from kube-system started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.520755 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 5
  I1130 13:55:26.520761 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-w2q4q from kube-system started at 2024-11-30 11:59:41 +0000 UTC (2 container statuses recorded)
  I1130 13:55:26.520767 19 predicates.go:959] 	Container metrics-server ready: true, restart count 0
  I1130 13:55:26.520772 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I1130 13:55:26.520777 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-6hwh9 from kubernetes-dashboard started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.520781 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I1130 13:55:26.520787 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-d5v6d from kubernetes-dashboard started at 2024-11-30 12:01:17 +0000 UTC (1 container statuses recorded)
  I1130 13:55:26.520791 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 2
  I1130 13:55:26.520796 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-31bb1696a5214149-x97pk from sonobuoy started at 2024-11-30 12:13:37 +0000 UTC (2 container statuses recorded)
  I1130 13:55:26.520848 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1130 13:55:26.520853 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 11/30/24 13:55:26.52
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.180cc38395490167], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] @ 11/30/24 13:55:26.548
  E1130 13:55:27.132613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:27.551686 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8284" for this suite. @ 11/30/24 13:55:27.556
• [1.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 11/30/24 13:55:27.57
  I1130 13:55:27.570683 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename projected @ 11/30/24 13:55:27.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:27.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:27.597
  STEP: Creating a pod to test downward API volume plugin @ 11/30/24 13:55:27.601
  E1130 13:55:28.132776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:29.133829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:55:29.622
  I1130 13:55:29.626536 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod downwardapi-volume-1b207b1b-2db7-49dc-ade1-8ba335913125 container client-container: <nil>
  STEP: delete the pod @ 11/30/24 13:55:29.634
  I1130 13:55:29.652271 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4394" for this suite. @ 11/30/24 13:55:29.656
• [2.093 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 11/30/24 13:55:29.663
  I1130 13:55:29.663544 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename subpath @ 11/30/24 13:55:29.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:29.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:29.686
  STEP: Setting up data @ 11/30/24 13:55:29.689
  STEP: Creating pod pod-subpath-test-configmap-8ftr @ 11/30/24 13:55:29.701
  STEP: Creating a pod to test atomic-volume-subpath @ 11/30/24 13:55:29.701
  E1130 13:55:30.134782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:31.135027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:32.135307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:33.135599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:34.135719      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:35.135823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:36.136634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:37.136827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:38.137117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:39.137398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:40.138286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:41.138413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:42.138506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:43.138601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:44.139200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:45.139236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:46.139543      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:47.139630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:48.140170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:49.140261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:50.140363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:51.140498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:55:51.779
  I1130 13:55:51.783783 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-subpath-test-configmap-8ftr container test-container-subpath-configmap-8ftr: <nil>
  STEP: delete the pod @ 11/30/24 13:55:51.791
  STEP: Deleting pod pod-subpath-test-configmap-8ftr @ 11/30/24 13:55:51.809
  I1130 13:55:51.809519 19 delete.go:62] Deleting pod "pod-subpath-test-configmap-8ftr" in namespace "subpath-464"
  I1130 13:55:51.813042 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-464" for this suite. @ 11/30/24 13:55:51.817
• [22.162 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:569
  STEP: Creating a kubernetes client @ 11/30/24 13:55:51.825
  I1130 13:55:51.825420 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:55:51.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:51.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:51.845
  STEP: Setting up server cert @ 11/30/24 13:55:51.869
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:55:52.01
  STEP: Deploying the webhook pod @ 11/30/24 13:55:52.02
  STEP: Wait for the deployment to be ready @ 11/30/24 13:55:52.033
  I1130 13:55:52.045967 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:55:52.141161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:53.141590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:55:54.059
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:55:54.071
  E1130 13:55:54.141779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:55.071583 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  E1130 13:55:55.142094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Listing all of the created validation webhooks @ 11/30/24 13:55:55.152
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 11/30/24 13:55:55.185
  STEP: Deleting the collection of validation webhooks @ 11/30/24 13:55:55.208
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 11/30/24 13:55:55.265
  I1130 13:55:55.318631 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1514" for this suite. @ 11/30/24 13:55:55.322
  STEP: Destroying namespace "webhook-markers-7455" for this suite. @ 11/30/24 13:55:55.331
• [3.519 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 11/30/24 13:55:55.345
  I1130 13:55:55.345039 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubelet-test @ 11/30/24 13:55:55.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:55.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:55.363
  E1130 13:55:56.142316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:57.142640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:55:57.397068 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-769" for this suite. @ 11/30/24 13:55:57.401
• [2.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 11/30/24 13:55:57.409
  I1130 13:55:57.409656 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename watch @ 11/30/24 13:55:57.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:57.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:57.43
  STEP: creating a new configmap @ 11/30/24 13:55:57.435
  STEP: modifying the configmap once @ 11/30/24 13:55:57.441
  STEP: modifying the configmap a second time @ 11/30/24 13:55:57.451
  STEP: deleting the configmap @ 11/30/24 13:55:57.459
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 11/30/24 13:55:57.467
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 11/30/24 13:55:57.469
  I1130 13:55:57.469200 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5228  f2fdb911-2f53-460a-b3eb-41115ffd3df0 48687 0 2024-11-30 13:55:57 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-11-30 13:55:57 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:55:57.469302 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5228  f2fdb911-2f53-460a-b3eb-41115ffd3df0 48688 0 2024-11-30 13:55:57 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-11-30 13:55:57 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:55:57.469399 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5228" for this suite. @ 11/30/24 13:55:57.473
• [0.070 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 11/30/24 13:55:57.479
  I1130 13:55:57.479864 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename tables @ 11/30/24 13:55:57.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:57.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:57.498
  I1130 13:55:57.505395 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-3995" for this suite. @ 11/30/24 13:55:57.509
• [0.038 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 11/30/24 13:55:57.518
  I1130 13:55:57.518343 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename var-expansion @ 11/30/24 13:55:57.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:55:57.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:55:57.537
  STEP: creating the pod @ 11/30/24 13:55:57.54
  STEP: waiting for pod running @ 11/30/24 13:55:57.548
  E1130 13:55:58.143693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:55:59.143817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 11/30/24 13:55:59.562
  I1130 13:55:59.566791 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3311 PodName:var-expansion-9e847432-5053-42ad-9ef6-40c62885c489 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:55:59.566815 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:55:59.567210 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:55:59.567249 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-3311/pods/var-expansion-9e847432-5053-42ad-9ef6-40c62885c489/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 11/30/24 13:55:59.612
  I1130 13:55:59.617639 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3311 PodName:var-expansion-9e847432-5053-42ad-9ef6-40c62885c489 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1130 13:55:59.617666 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  I1130 13:55:59.618069 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1130 13:55:59.618107 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-3311/pods/var-expansion-9e847432-5053-42ad-9ef6-40c62885c489/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 11/30/24 13:55:59.658
  E1130 13:56:00.144083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:56:00.173458 19 pod_client.go:173] Successfully updated pod "var-expansion-9e847432-5053-42ad-9ef6-40c62885c489"
  STEP: waiting for annotated pod running @ 11/30/24 13:56:00.173
  STEP: deleting the pod gracefully @ 11/30/24 13:56:00.177
  I1130 13:56:00.177577 19 delete.go:62] Deleting pod "var-expansion-9e847432-5053-42ad-9ef6-40c62885c489" in namespace "var-expansion-3311"
  I1130 13:56:00.187215 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-9e847432-5053-42ad-9ef6-40c62885c489" to be fully deleted
  E1130 13:56:01.144269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:02.144628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:03.144871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:04.145001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:05.145110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:06.145355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:07.146079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:08.146253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:09.146446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:10.146634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:11.147600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:12.147932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:13.148551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:14.148680      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:15.149539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:16.150606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:17.150630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:18.150864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:19.150951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:20.151047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:21.152049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:22.152353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:23.152550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:24.152787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:25.152964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:26.153179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:27.153227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:28.153471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:29.153572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:30.153919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:31.154082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:32.154510      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:56:32.288700 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3311" for this suite. @ 11/30/24 13:56:32.293
• [34.782 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 11/30/24 13:56:32.3
  I1130 13:56:32.300815 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename watch @ 11/30/24 13:56:32.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:56:32.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:56:32.32
  STEP: creating a watch on configmaps with label A @ 11/30/24 13:56:32.324
  STEP: creating a watch on configmaps with label B @ 11/30/24 13:56:32.325
  STEP: creating a watch on configmaps with label A or B @ 11/30/24 13:56:32.327
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 11/30/24 13:56:32.328
  I1130 13:56:32.334173 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9024  2e9844dc-ac75-4e31-bf0f-ec1ad549ec4f 48831 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:56:32.334336 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9024  2e9844dc-ac75-4e31-bf0f-ec1ad549ec4f 48831 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 11/30/24 13:56:32.334
  I1130 13:56:32.343241 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9024  2e9844dc-ac75-4e31-bf0f-ec1ad549ec4f 48832 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:56:32.343315 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9024  2e9844dc-ac75-4e31-bf0f-ec1ad549ec4f 48832 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 11/30/24 13:56:32.343
  I1130 13:56:32.353583 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9024  2e9844dc-ac75-4e31-bf0f-ec1ad549ec4f 48833 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:56:32.353654 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9024  2e9844dc-ac75-4e31-bf0f-ec1ad549ec4f 48833 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 11/30/24 13:56:32.353
  I1130 13:56:32.361181 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9024  2e9844dc-ac75-4e31-bf0f-ec1ad549ec4f 48834 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:56:32.361232 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9024  2e9844dc-ac75-4e31-bf0f-ec1ad549ec4f 48834 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 11/30/24 13:56:32.361
  I1130 13:56:32.366280 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9024  6f0d111d-7345-4312-a9c0-5df8aa204a08 48835 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:56:32.366355 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9024  6f0d111d-7345-4312-a9c0-5df8aa204a08 48835 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1130 13:56:33.155152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:34.155304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:35.155471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:36.155679      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:37.156238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:38.156483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:39.156631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:40.156842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:41.156962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:42.157250      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 11/30/24 13:56:42.366
  I1130 13:56:42.375737 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9024  6f0d111d-7345-4312-a9c0-5df8aa204a08 48875 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1130 13:56:42.375785 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9024  6f0d111d-7345-4312-a9c0-5df8aa204a08 48875 0 2024-11-30 13:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-11-30 13:56:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1130 13:56:43.157975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:44.158092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:45.158195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:46.158362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:47.158613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:48.158810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:49.158911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:50.159112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:51.159655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:52.159731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:56:52.376336 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9024" for this suite. @ 11/30/24 13:56:52.382
• [20.091 seconds]
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 11/30/24 13:56:52.391
  I1130 13:56:52.391988 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename secrets @ 11/30/24 13:56:52.392
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:56:52.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:56:52.413
  STEP: Creating secret with name secret-test-map-74bca155-2227-4557-a8a0-5e31c6a87046 @ 11/30/24 13:56:52.417
  STEP: Creating a pod to test consume secrets @ 11/30/24 13:56:52.422
  E1130 13:56:53.159858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:54.159960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:55.160884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:56.161065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:56:56.446
  I1130 13:56:56.450595 19 output.go:196] Trying to get logs from node ip-172-31-64-147 pod pod-secrets-fc2756bb-320d-4102-90fd-f87381ccec00 container secret-volume-test: <nil>
  STEP: delete the pod @ 11/30/24 13:56:56.467
  I1130 13:56:56.487753 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2795" for this suite. @ 11/30/24 13:56:56.491
• [4.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 11/30/24 13:56:56.499
  I1130 13:56:56.499825 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 11/30/24 13:56:56.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:56:56.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:56:56.52
  STEP: set up a multi version CRD @ 11/30/24 13:56:56.523
  I1130 13:56:56.523863 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  E1130 13:56:57.161529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:58.161825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:56:59.162737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 11/30/24 13:56:59.735
  STEP: check the unserved version gets removed @ 11/30/24 13:56:59.752
  E1130 13:57:00.162963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 11/30/24 13:57:00.526
  E1130 13:57:01.163884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:02.164290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:57:03.052946 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7417" for this suite. @ 11/30/24 13:57:03.059
• [6.567 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:235
  STEP: Creating a kubernetes client @ 11/30/24 13:57:03.067
  I1130 13:57:03.067364 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:57:03.067
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:57:03.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:57:03.088
  STEP: Setting up server cert @ 11/30/24 13:57:03.113
  E1130 13:57:03.164581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:57:03.45
  STEP: Deploying the webhook pod @ 11/30/24 13:57:03.459
  STEP: Wait for the deployment to be ready @ 11/30/24 13:57:03.474
  I1130 13:57:03.486925 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:57:04.164717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:05.164974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:57:05.501
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:57:05.513
  E1130 13:57:06.165163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:57:06.514014 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 11/30/24 13:57:06.523
  STEP: create a namespace for the webhook @ 11/30/24 13:57:06.538
  STEP: create a configmap should be unconditionally rejected by the webhook @ 11/30/24 13:57:06.554
  I1130 13:57:06.630570 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-755" for this suite. @ 11/30/24 13:57:06.634
  STEP: Destroying namespace "webhook-markers-678" for this suite. @ 11/30/24 13:57:06.641
  STEP: Destroying namespace "fail-closed-namespace-6625" for this suite. @ 11/30/24 13:57:06.649
• [3.588 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 11/30/24 13:57:06.655
  I1130 13:57:06.655871 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubelet-test @ 11/30/24 13:57:06.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:57:06.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:57:06.676
  E1130 13:57:07.165985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:08.166216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:57:08.708759 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5620" for this suite. @ 11/30/24 13:57:08.714
• [2.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 11/30/24 13:57:08.725
  I1130 13:57:08.725599 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename emptydir @ 11/30/24 13:57:08.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:57:08.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:57:08.753
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 11/30/24 13:57:08.756
  E1130 13:57:09.166358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:10.166591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 11/30/24 13:57:10.776
  I1130 13:57:10.780418 19 output.go:196] Trying to get logs from node ip-172-31-4-119 pod pod-9837513f-56fb-44fa-83f3-c1c17004436c container test-container: <nil>
  STEP: delete the pod @ 11/30/24 13:57:10.8
  I1130 13:57:10.815540 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9441" for this suite. @ 11/30/24 13:57:10.819
• [2.101 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 11/30/24 13:57:10.826
  I1130 13:57:10.826228 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename server-version @ 11/30/24 13:57:10.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:57:10.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:57:10.848
  STEP: Request ServerVersion @ 11/30/24 13:57:10.851
  STEP: Confirm major version @ 11/30/24 13:57:10.852
  I1130 13:57:10.852613 19 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 11/30/24 13:57:10.852
  I1130 13:57:10.852673 19 server_version.go:58] cleanMinorVersion: 31
  I1130 13:57:10.852684 19 server_version.go:62] Minor version: 31
  I1130 13:57:10.852777 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-6841" for this suite. @ 11/30/24 13:57:10.857
• [0.038 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:863
  STEP: Creating a kubernetes client @ 11/30/24 13:57:10.863
  I1130 13:57:10.863960 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename webhook @ 11/30/24 13:57:10.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:57:10.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:57:10.887
  STEP: Setting up server cert @ 11/30/24 13:57:10.91
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 11/30/24 13:57:11.036
  STEP: Deploying the webhook pod @ 11/30/24 13:57:11.042
  STEP: Wait for the deployment to be ready @ 11/30/24 13:57:11.055
  I1130 13:57:11.062820 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1130 13:57:11.167052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:12.167434      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 11/30/24 13:57:13.078
  STEP: Verifying the service has paired with the endpoint @ 11/30/24 13:57:13.09
  E1130 13:57:13.168475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:57:14.091496 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 11/30/24 13:57:14.1
  STEP: create the configmap with a random name @ 11/30/24 13:57:14.119
  STEP: verify the configmap is mutated @ 11/30/24 13:57:14.129
  STEP: create the configmap with 'skip-me' name @ 11/30/24 13:57:14.13
  E1130 13:57:14.168764      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:57:14.194241 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1690" for this suite. @ 11/30/24 13:57:14.198
  STEP: Destroying namespace "webhook-markers-7454" for this suite. @ 11/30/24 13:57:14.205
• [3.348 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:905
  STEP: Creating a kubernetes client @ 11/30/24 13:57:14.212
  I1130 13:57:14.212201 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename statefulset @ 11/30/24 13:57:14.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:57:14.228
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:57:14.232
  STEP: Creating service test in namespace statefulset-4665 @ 11/30/24 13:57:14.235
  STEP: Creating statefulset ss in namespace statefulset-4665 @ 11/30/24 13:57:14.241
  I1130 13:57:14.252197 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E1130 13:57:15.169772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:16.169877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:17.170655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:18.170771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:19.170869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:20.170957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:21.171069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:22.171723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:23.172584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:24.172940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:57:24.254035 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 11/30/24 13:57:24.262
  STEP: updating a scale subresource @ 11/30/24 13:57:24.266
  STEP: verifying the statefulset Spec.Replicas was modified @ 11/30/24 13:57:24.271
  STEP: Patch a scale subresource @ 11/30/24 13:57:24.275
  STEP: verifying the statefulset Spec.Replicas was modified @ 11/30/24 13:57:24.282
  I1130 13:57:24.288679 19 statefulset.go:138] Deleting all statefulset in ns statefulset-4665
  I1130 13:57:24.294354 19 rest.go:150] Scaling statefulset ss to 0
  E1130 13:57:25.173034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:26.173222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:27.173726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:28.174577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:29.174852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:30.175062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:31.176056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:32.176487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:33.176803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:34.177062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:57:34.312264 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1130 13:57:34.316440 19 rest.go:88] Deleting statefulset ss
  I1130 13:57:34.334407 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4665" for this suite. @ 11/30/24 13:57:34.338
• [20.133 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 11/30/24 13:57:34.345
  I1130 13:57:34.345491 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename kubelet-test @ 11/30/24 13:57:34.346
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:57:34.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:57:34.367
  E1130 13:57:35.177428      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:36.177563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:37.177770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1130 13:57:38.177822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1130 13:57:38.387101 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2019" for this suite. @ 11/30/24 13:57:38.391
• [4.054 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:115
  STEP: Creating a kubernetes client @ 11/30/24 13:57:38.399
  I1130 13:57:38.399820 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-2122482875
  STEP: Building a namespace api object, basename field-validation @ 11/30/24 13:57:38.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 11/30/24 13:57:38.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 11/30/24 13:57:38.417
  STEP: apply creating a deployment @ 11/30/24 13:57:38.421
  I1130 13:57:38.438204 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2419" for this suite. @ 11/30/24 13:57:38.442
• [0.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I1130 13:57:38.451930 19 suites.go:34] Running AfterSuite actions on node 1
  I1130 13:57:38.451963 19 util.go:607] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:158
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:612
[ReportAfterSuite] PASSED [0.028 seconds]
------------------------------

Ran 404 of 6605 Specs in 6231.744 seconds
SUCCESS! -- 404 Passed | 0 Failed | 0 Pending | 6201 Skipped
PASS

Ginkgo ran 1 suite in 1h43m52.597287523s
Test Suite Passed
