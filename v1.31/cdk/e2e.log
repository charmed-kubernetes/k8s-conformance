  I1026 12:10:08.325304      19 e2e.go:109] Starting e2e run "4f86a21b-dd31-4e45-b53e-bf3ec6810827" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1729944607 - will randomize all specs

Will run 404 of 6605 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:154
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I1026 12:10:08.490949 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:10:08.491916 19 helper.go:48] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I1026 12:10:08.529115 19 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I1026 12:10:08.535486 19 e2e.go:153] 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  I1026 12:10:08.535519 19 e2e.go:245] e2e test version: v1.31.2
  I1026 12:10:08.537095 19 e2e.go:254] kube-apiserver version: v1.31.2
  I1026 12:10:08.537179 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:10:08.541622 19 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.051 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 10/26/24 12:10:08.72
  I1026 12:10:08.720841 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:10:08.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:10:08.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:10:08.748
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 10/26/24 12:10:08.752
  STEP: Saw pod success @ 10/26/24 12:10:18.802
  I1026 12:10:18.806191 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-59d55163-8906-4ee1-9a38-4a70f67e3258 container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:10:18.824
  I1026 12:10:18.845818 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4300" for this suite. @ 10/26/24 12:10:18.849
• [10.137 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:838
  STEP: Creating a kubernetes client @ 10/26/24 12:10:18.857
  I1026 12:10:18.857706 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:10:18.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:10:18.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:10:18.881
  STEP: Setting up server cert @ 10/26/24 12:10:18.909
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:10:19.244
  STEP: Deploying the webhook pod @ 10/26/24 12:10:19.255
  STEP: Wait for the deployment to be ready @ 10/26/24 12:10:19.27
  I1026 12:10:19.285738 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 10/26/24 12:10:21.3
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:10:21.312
  I1026 12:10:22.312151 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 10/26/24 12:10:22.321
  I1026 12:10:22.368104 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6054" for this suite. @ 10/26/24 12:10:22.373
  STEP: Destroying namespace "webhook-markers-9685" for this suite. @ 10/26/24 12:10:22.382
• [3.537 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 10/26/24 12:10:22.395
  I1026 12:10:22.395299 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename svcaccounts @ 10/26/24 12:10:22.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:10:22.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:10:22.414
  STEP: Creating ServiceAccount "e2e-sa-jnwgl"  @ 10/26/24 12:10:22.417
  I1026 12:10:22.423272 19 service_accounts.go:825] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-jnwgl"  @ 10/26/24 12:10:22.423
  I1026 12:10:22.439590 19 service_accounts.go:839] AutomountServiceAccountToken: true
  I1026 12:10:22.439701 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4700" for this suite. @ 10/26/24 12:10:22.443
• [0.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 10/26/24 12:10:22.451
  I1026 12:10:22.451129 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 12:10:22.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:10:22.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:10:22.471
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 10/26/24 12:10:22.475
  I1026 12:10:22.475641 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:10:23.924912 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:10:28.928749 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7370" for this suite. @ 10/26/24 12:10:28.94
• [6.501 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 10/26/24 12:10:28.952
  I1026 12:10:28.952194 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:10:28.952
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:10:28.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:10:28.971
  STEP: Creating configMap with name configmap-test-upd-2ac16d01-ee43-47e6-9b80-85a2540f82a4 @ 10/26/24 12:10:28.977
  STEP: Creating the pod @ 10/26/24 12:10:28.982
  STEP: Updating configmap configmap-test-upd-2ac16d01-ee43-47e6-9b80-85a2540f82a4 @ 10/26/24 12:10:31.016
  STEP: waiting to observe update in volume @ 10/26/24 12:10:31.02
  I1026 12:11:39.356800 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6420" for this suite. @ 10/26/24 12:11:39.361
• [70.415 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:398
  STEP: Creating a kubernetes client @ 10/26/24 12:11:39.367
  I1026 12:11:39.367848 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 12:11:39.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:11:39.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:11:39.388
  STEP: Counting existing ResourceQuota @ 10/26/24 12:11:39.393
  STEP: Creating a ResourceQuota @ 10/26/24 12:11:44.397
  STEP: Ensuring resource quota status is calculated @ 10/26/24 12:11:44.402
  STEP: Creating a ReplicationController @ 10/26/24 12:11:46.407
  STEP: Ensuring resource quota status captures replication controller creation @ 10/26/24 12:11:46.418
  STEP: Deleting a ReplicationController @ 10/26/24 12:11:48.423
  STEP: Ensuring resource quota status released usage @ 10/26/24 12:11:48.431
  I1026 12:11:50.436611 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8753" for this suite. @ 10/26/24 12:11:50.44
• [11.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3209
  STEP: Creating a kubernetes client @ 10/26/24 12:11:50.448
  I1026 12:11:50.448490 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 12:11:50.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:11:50.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:11:50.465
  STEP: creating an Endpoint @ 10/26/24 12:11:50.471
  STEP: waiting for available Endpoint @ 10/26/24 12:11:50.475
  STEP: listing all Endpoints @ 10/26/24 12:11:50.476
  STEP: updating the Endpoint @ 10/26/24 12:11:50.479
  STEP: fetching the Endpoint @ 10/26/24 12:11:50.485
  STEP: patching the Endpoint @ 10/26/24 12:11:50.488
  STEP: fetching the Endpoint @ 10/26/24 12:11:50.494
  STEP: deleting the Endpoint by Collection @ 10/26/24 12:11:50.497
  STEP: waiting for Endpoint deletion @ 10/26/24 12:11:50.504
  STEP: fetching the Endpoint @ 10/26/24 12:11:50.505
  I1026 12:11:50.508521 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5726" for this suite. @ 10/26/24 12:11:50.511
• [0.069 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 10/26/24 12:11:50.517
  I1026 12:11:50.517476 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 10/26/24 12:11:50.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:11:50.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:11:50.535
  STEP: Setting up the test @ 10/26/24 12:11:50.537
  STEP: Creating hostNetwork=false pod @ 10/26/24 12:11:50.537
  STEP: Creating hostNetwork=true pod @ 10/26/24 12:11:52.56
  STEP: Running the test @ 10/26/24 12:11:56.585
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 10/26/24 12:11:56.585
  I1026 12:11:56.585320 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.585339 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.585869 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.585916 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I1026 12:11:56.628735 19 exec_util.go:111] Exec stderr: ""
  I1026 12:11:56.628771 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.628780 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.629150 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.629189 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I1026 12:11:56.669181 19 exec_util.go:111] Exec stderr: ""
  I1026 12:11:56.669251 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.669260 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.669696 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.669736 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I1026 12:11:56.709818 19 exec_util.go:111] Exec stderr: ""
  I1026 12:11:56.709850 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.709858 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.710190 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.710225 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I1026 12:11:56.745438 19 exec_util.go:111] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 10/26/24 12:11:56.745
  I1026 12:11:56.745523 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.745531 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.745867 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.745901 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I1026 12:11:56.776919 19 exec_util.go:111] Exec stderr: ""
  I1026 12:11:56.776957 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.776977 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.777368 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.777405 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  I1026 12:11:56.812744 19 exec_util.go:111] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 10/26/24 12:11:56.812
  I1026 12:11:56.812803 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.812811 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.813182 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.813226 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I1026 12:11:56.858194 19 exec_util.go:111] Exec stderr: ""
  I1026 12:11:56.858256 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.858278 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.858647 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.858773 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  I1026 12:11:56.893947 19 exec_util.go:111] Exec stderr: ""
  I1026 12:11:56.893981 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.893992 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.894347 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.894392 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I1026 12:11:56.921349 19 exec_util.go:111] Exec stderr: ""
  I1026 12:11:56.921381 19 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1547 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:11:56.921391 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:11:56.921822 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:11:56.921859 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1547/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  I1026 12:11:56.957655 19 exec_util.go:111] Exec stderr: ""
  I1026 12:11:56.957827 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-1547" for this suite. @ 10/26/24 12:11:56.963
• [6.452 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:905
  STEP: Creating a kubernetes client @ 10/26/24 12:11:56.97
  I1026 12:11:56.970166 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename statefulset @ 10/26/24 12:11:56.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:11:56.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:11:56.986
  STEP: Creating service test in namespace statefulset-9468 @ 10/26/24 12:11:56.988
  STEP: Creating statefulset ss in namespace statefulset-9468 @ 10/26/24 12:11:56.995
  I1026 12:11:57.005038 19 wait.go:40] Found 0 stateful pods, waiting for 1
  I1026 12:12:07.010554 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 10/26/24 12:12:07.017
  STEP: updating a scale subresource @ 10/26/24 12:12:07.02
  STEP: verifying the statefulset Spec.Replicas was modified @ 10/26/24 12:12:07.026
  STEP: Patch a scale subresource @ 10/26/24 12:12:07.029
  STEP: verifying the statefulset Spec.Replicas was modified @ 10/26/24 12:12:07.042
  I1026 12:12:07.048538 19 statefulset.go:138] Deleting all statefulset in ns statefulset-9468
  I1026 12:12:07.052204 19 rest.go:150] Scaling statefulset ss to 0
  I1026 12:12:17.071355 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1026 12:12:17.075045 19 rest.go:88] Deleting statefulset ss
  I1026 12:12:17.089531 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9468" for this suite. @ 10/26/24 12:12:17.092
• [20.131 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 10/26/24 12:12:17.101
  I1026 12:12:17.101202 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir-wrapper @ 10/26/24 12:12:17.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:12:17.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:12:17.117
  STEP: Cleaning up the secret @ 10/26/24 12:12:19.156
  STEP: Cleaning up the configmap @ 10/26/24 12:12:19.163
  STEP: Cleaning up the pod @ 10/26/24 12:12:19.171
  I1026 12:12:19.187258 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-306" for this suite. @ 10/26/24 12:12:19.191
• [2.097 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 10/26/24 12:12:19.199
  I1026 12:12:19.199220 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename deployment @ 10/26/24 12:12:19.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:12:19.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:12:19.22
  I1026 12:12:19.221771 19 deployment.go:1645] Creating simple deployment test-new-deployment
  I1026 12:12:19.235895 19 deployment.go:222] deployment "test-new-deployment" doesn't have the required revision set
  STEP: getting scale subresource @ 10/26/24 12:12:21.251
  STEP: updating a scale subresource @ 10/26/24 12:12:21.255
  STEP: verifying the deployment Spec.Replicas was modified @ 10/26/24 12:12:21.261
  STEP: Patch a scale subresource @ 10/26/24 12:12:21.264
  I1026 12:12:21.281427 19 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6331",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0cd3894e-9e57-4538-81c3-09cce7d32fac",
      ResourceVersion: (string) (len=4) "4727",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865541539,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-64bcfc6446\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1026 12:12:21.289813 19 deployment.go:39] New ReplicaSet "test-new-deployment-64bcfc6446" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-64bcfc6446",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6331",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6e754406-2a8a-4e52-935e-b0a860279cec",
      ResourceVersion: (string) (len=4) "4731",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865541539,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "0cd3894e-9e57-4538-81c3-09cce7d32fac",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 63 64 33 38 39  34 65 2d 39 65 35 37 2d  |\"0cd3894e-9e57-|
              00000120  34 35 33 38 2d 38 31 63  33 2d 30 39 63 63 65 37  |4538-81c3-09cce7|
              00000130  64 33 32 66 61 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |d32fac\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:12:21.299500 19 deployment.go:67] Pod "test-new-deployment-64bcfc6446-g6slx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-64bcfc6446-g6slx",
      GenerateName: (string) (len=31) "test-new-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6331",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "322d3ca1-6f18-4068-9a0e-5f143c38c5b3",
      ResourceVersion: (string) (len=4) "4730",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865541541,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "6e754406-2a8a-4e52-935e-b0a860279cec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 65  37 35 34 34 30 36 2d 32  |d\":\"6e754406-2|
              00000090  61 38 61 2d 34 65 35 32  2d 39 33 35 65 2d 62 30  |a8a-4e52-935e-b0|
              000000a0  61 38 36 30 32 37 39 63  65 63 5c 22 7d 22 3a 7b  |a860279cec\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-479tb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-479tb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541541,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:12:21.300453 19 deployment.go:67] Pod "test-new-deployment-64bcfc6446-sh9sx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-64bcfc6446-sh9sx",
      GenerateName: (string) (len=31) "test-new-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6331",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d3f5239b-3175-4d01-aade-4f0f15d9d78a",
      ResourceVersion: (string) (len=4) "4721",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865541539,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "6e754406-2a8a-4e52-935e-b0a860279cec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 65  37 35 34 34 30 36 2d 32  |d\":\"6e754406-2|
              00000090  61 38 61 2d 34 65 35 32  2d 39 33 35 65 2d 62 30  |a8a-4e52-935e-b0|
              000000a0  61 38 36 30 32 37 39 63  65 63 5c 22 7d 22 3a 7b  |a860279cec\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 39  2e 31 33 36 5c 22 7d 22  |2.168.29.136\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-l8jb7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-l8jb7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541540,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865541539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.136",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.136"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865541539,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865541539,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://1defe3e44084b598e097b0eb69997c38e9525164e36df90699dc527d5a20d572",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-l8jb7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:12:21.301951 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6331" for this suite. @ 10/26/24 12:12:21.312
• [2.130 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 10/26/24 12:12:21.329
  I1026 12:12:21.329314 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename proxy @ 10/26/24 12:12:21.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:12:21.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:12:21.356
  STEP: starting an echo server on multiple ports @ 10/26/24 12:12:21.368
  STEP: creating replication controller proxy-service-8mn79 in namespace proxy-4570 @ 10/26/24 12:12:21.368
  I1026 12:12:21.377425      19 runners.go:193] Created replication controller with name: proxy-service-8mn79, namespace: proxy-4570, replica count: 1
  I1026 12:12:22.428189      19 runners.go:193] proxy-service-8mn79 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 12:12:23.428970      19 runners.go:193] proxy-service-8mn79 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 12:12:23.432858 19 proxy.go:230] setup took 2.072944816s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 10/26/24 12:12:23.432
  I1026 12:12:23.439375 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.172436ms)
  I1026 12:12:23.439953 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 6.679599ms)
  I1026 12:12:23.439968 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 6.905642ms)
  I1026 12:12:23.439990 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 7.052244ms)
  I1026 12:12:23.440196 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 6.826174ms)
  I1026 12:12:23.440341 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 7.242886ms)
  I1026 12:12:23.440638 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 7.468777ms)
  I1026 12:12:23.440801 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.740323ms)
  I1026 12:12:23.449371 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 16.350251ms)
  I1026 12:12:23.449375 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 16.230576ms)
  I1026 12:12:23.449390 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 16.139471ms)
  I1026 12:12:23.452127 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 18.778161ms)
  I1026 12:12:23.452127 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 18.81332ms)
  I1026 12:12:23.452169 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 18.877786ms)
  I1026 12:12:23.452526 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 19.300902ms)
  I1026 12:12:23.452615 19 proxy.go:558] (0) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 19.493228ms)
  I1026 12:12:23.457820 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.084031ms)
  I1026 12:12:23.457824 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 4.876109ms)
  I1026 12:12:23.457850 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 4.98587ms)
  I1026 12:12:23.457863 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.162617ms)
  I1026 12:12:23.457997 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 5.014474ms)
  I1026 12:12:23.458353 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 5.388417ms)
  I1026 12:12:23.458366 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 5.352636ms)
  I1026 12:12:23.458525 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 5.773549ms)
  I1026 12:12:23.458696 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.904321ms)
  I1026 12:12:23.459266 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 6.460101ms)
  I1026 12:12:23.459651 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 6.875255ms)
  I1026 12:12:23.460139 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 7.259258ms)
  I1026 12:12:23.460369 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.527503ms)
  I1026 12:12:23.460383 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 7.560915ms)
  I1026 12:12:23.460790 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 7.872326ms)
  I1026 12:12:23.461031 19 proxy.go:558] (1) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 8.364539ms)
  I1026 12:12:23.464842 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.776894ms)
  I1026 12:12:23.464848 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.749324ms)
  I1026 12:12:23.465860 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 4.495079ms)
  I1026 12:12:23.465860 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 4.616363ms)
  I1026 12:12:23.465876 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 4.613195ms)
  I1026 12:12:23.465887 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 4.570777ms)
  I1026 12:12:23.466733 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 5.518969ms)
  I1026 12:12:23.466739 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.454354ms)
  I1026 12:12:23.466751 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 5.696816ms)
  I1026 12:12:23.466800 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.500297ms)
  I1026 12:12:23.467535 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 6.41666ms)
  I1026 12:12:23.467551 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 6.360384ms)
  I1026 12:12:23.468425 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 7.275759ms)
  I1026 12:12:23.468718 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 7.55092ms)
  I1026 12:12:23.468731 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 7.398974ms)
  I1026 12:12:23.468743 19 proxy.go:558] (2) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.608461ms)
  I1026 12:12:23.472187 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.379857ms)
  I1026 12:12:23.472604 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 3.825524ms)
  I1026 12:12:23.473022 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 4.262913ms)
  I1026 12:12:23.473571 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 4.475421ms)
  I1026 12:12:23.473807 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 4.873998ms)
  I1026 12:12:23.474107 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.157281ms)
  I1026 12:12:23.474715 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.684153ms)
  I1026 12:12:23.475243 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 6.249407ms)
  I1026 12:12:23.475557 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 6.54184ms)
  I1026 12:12:23.475570 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 6.589566ms)
  I1026 12:12:23.475586 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.621679ms)
  I1026 12:12:23.475615 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 6.762374ms)
  I1026 12:12:23.475628 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 6.744738ms)
  I1026 12:12:23.475959 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 6.913961ms)
  I1026 12:12:23.476275 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 7.448759ms)
  I1026 12:12:23.476726 19 proxy.go:558] (3) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.646555ms)
  I1026 12:12:23.481764 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 5.020217ms)
  I1026 12:12:23.482068 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 5.256403ms)
  I1026 12:12:23.482143 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.127608ms)
  I1026 12:12:23.482173 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.141727ms)
  I1026 12:12:23.482484 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 5.647347ms)
  I1026 12:12:23.482730 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.870954ms)
  I1026 12:12:23.482747 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 5.702106ms)
  I1026 12:12:23.482799 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 5.917062ms)
  I1026 12:12:23.482809 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 6.016341ms)
  I1026 12:12:23.482910 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 5.912661ms)
  I1026 12:12:23.483004 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 6.082062ms)
  I1026 12:12:23.483764 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 6.782565ms)
  I1026 12:12:23.483783 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 6.843157ms)
  I1026 12:12:23.483969 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 7.011044ms)
  I1026 12:12:23.485131 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 8.231654ms)
  I1026 12:12:23.485248 19 proxy.go:558] (4) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 8.184551ms)
  I1026 12:12:23.489294 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 4.021375ms)
  I1026 12:12:23.489756 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 4.160769ms)
  I1026 12:12:23.489759 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 4.235488ms)
  I1026 12:12:23.490005 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 4.447305ms)
  I1026 12:12:23.490382 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 4.838756ms)
  I1026 12:12:23.490494 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.083577ms)
  I1026 12:12:23.490502 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.12098ms)
  I1026 12:12:23.490511 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 4.902687ms)
  I1026 12:12:23.491648 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.07567ms)
  I1026 12:12:23.491659 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 6.304566ms)
  I1026 12:12:23.491664 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 6.037779ms)
  I1026 12:12:23.492180 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 6.713626ms)
  I1026 12:12:23.492292 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 6.96616ms)
  I1026 12:12:23.493088 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 7.582556ms)
  I1026 12:12:23.493408 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 7.925445ms)
  I1026 12:12:23.493421 19 proxy.go:558] (5) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 7.99015ms)
  I1026 12:12:23.496904 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 3.450371ms)
  I1026 12:12:23.497015 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.577676ms)
  I1026 12:12:23.497379 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 3.750256ms)
  I1026 12:12:23.498145 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 4.576601ms)
  I1026 12:12:23.498587 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 5.054677ms)
  I1026 12:12:23.498622 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 4.914495ms)
  I1026 12:12:23.498892 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.307038ms)
  I1026 12:12:23.499308 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 5.584901ms)
  I1026 12:12:23.499446 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 5.801794ms)
  I1026 12:12:23.499582 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.891811ms)
  I1026 12:12:23.499739 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 6.263268ms)
  I1026 12:12:23.499755 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 6.203416ms)
  I1026 12:12:23.500169 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 6.552024ms)
  I1026 12:12:23.500844 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.349448ms)
  I1026 12:12:23.501072 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 7.332298ms)
  I1026 12:12:23.501170 19 proxy.go:558] (6) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 7.513222ms)
  I1026 12:12:23.505149 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.937268ms)
  I1026 12:12:23.505156 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 3.864417ms)
  I1026 12:12:23.505180 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 3.937713ms)
  I1026 12:12:23.506410 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 4.887204ms)
  I1026 12:12:23.506420 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 4.933044ms)
  I1026 12:12:23.506525 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 4.971394ms)
  I1026 12:12:23.506602 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 5.271726ms)
  I1026 12:12:23.506717 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 5.284441ms)
  I1026 12:12:23.507081 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 5.607209ms)
  I1026 12:12:23.507200 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 5.662996ms)
  I1026 12:12:23.507501 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 6.114412ms)
  I1026 12:12:23.507621 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 6.1647ms)
  I1026 12:12:23.508580 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 7.074749ms)
  I1026 12:12:23.508630 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 7.258397ms)
  I1026 12:12:23.508874 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.525683ms)
  I1026 12:12:23.509329 19 proxy.go:558] (7) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 7.923014ms)
  I1026 12:12:23.512858 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.47999ms)
  I1026 12:12:23.513226 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.821217ms)
  I1026 12:12:23.514006 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 4.654493ms)
  I1026 12:12:23.514027 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 4.499023ms)
  I1026 12:12:23.514154 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 4.546477ms)
  I1026 12:12:23.514275 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 4.692511ms)
  I1026 12:12:23.514635 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 4.994511ms)
  I1026 12:12:23.514639 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.07442ms)
  I1026 12:12:23.515137 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 5.51572ms)
  I1026 12:12:23.515147 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 5.59778ms)
  I1026 12:12:23.515412 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 5.987007ms)
  I1026 12:12:23.517004 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.5489ms)
  I1026 12:12:23.517009 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 7.538455ms)
  I1026 12:12:23.517020 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 7.530274ms)
  I1026 12:12:23.517145 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 7.489718ms)
  I1026 12:12:23.517183 19 proxy.go:558] (8) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 7.67083ms)
  I1026 12:12:23.521226 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 3.960163ms)
  I1026 12:12:23.521498 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 4.295486ms)
  I1026 12:12:23.521704 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 4.467759ms)
  I1026 12:12:23.522665 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 5.260258ms)
  I1026 12:12:23.522775 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 5.236317ms)
  I1026 12:12:23.523515 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 6.029367ms)
  I1026 12:12:23.523524 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.110725ms)
  I1026 12:12:23.523668 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 6.367315ms)
  I1026 12:12:23.523992 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 6.644481ms)
  I1026 12:12:23.524017 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.587976ms)
  I1026 12:12:23.525944 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 8.48932ms)
  I1026 12:12:23.526133 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 8.661793ms)
  I1026 12:12:23.526157 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 8.646551ms)
  I1026 12:12:23.526168 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 8.844107ms)
  I1026 12:12:23.526178 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 8.683014ms)
  I1026 12:12:23.526158 19 proxy.go:558] (9) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 8.788168ms)
  I1026 12:12:23.530151 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.852697ms)
  I1026 12:12:23.530180 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.96243ms)
  I1026 12:12:23.530641 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 4.438294ms)
  I1026 12:12:23.531346 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 4.822455ms)
  I1026 12:12:23.531701 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.257193ms)
  I1026 12:12:23.531816 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 5.421949ms)
  I1026 12:12:23.531838 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 5.346011ms)
  I1026 12:12:23.531959 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 5.473527ms)
  I1026 12:12:23.531975 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 5.663903ms)
  I1026 12:12:23.532068 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 5.657484ms)
  I1026 12:12:23.532090 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.582962ms)
  I1026 12:12:23.532888 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 6.52495ms)
  I1026 12:12:23.533576 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.249388ms)
  I1026 12:12:23.533800 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 7.452581ms)
  I1026 12:12:23.533964 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 7.5852ms)
  I1026 12:12:23.534223 19 proxy.go:558] (10) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 7.683125ms)
  I1026 12:12:23.539464 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.098452ms)
  I1026 12:12:23.539463 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 5.181215ms)
  I1026 12:12:23.539744 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 5.410188ms)
  I1026 12:12:23.540263 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.779757ms)
  I1026 12:12:23.540343 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.964043ms)
  I1026 12:12:23.540521 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 6.019298ms)
  I1026 12:12:23.540842 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 6.419004ms)
  I1026 12:12:23.540856 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 6.389873ms)
  I1026 12:12:23.541322 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.873614ms)
  I1026 12:12:23.541408 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 7.095684ms)
  I1026 12:12:23.541423 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.014253ms)
  I1026 12:12:23.541687 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 7.322883ms)
  I1026 12:12:23.541753 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 7.358386ms)
  I1026 12:12:23.541757 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 7.513568ms)
  I1026 12:12:23.542643 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 8.119376ms)
  I1026 12:12:23.542646 19 proxy.go:558] (11) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 8.108786ms)
  I1026 12:12:23.547984 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.003163ms)
  I1026 12:12:23.547973 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 5.053953ms)
  I1026 12:12:23.548102 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 5.255948ms)
  I1026 12:12:23.548076 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 5.207717ms)
  I1026 12:12:23.548227 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 5.435409ms)
  I1026 12:12:23.548448 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.713969ms)
  I1026 12:12:23.548793 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 6.127167ms)
  I1026 12:12:23.549410 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 6.458791ms)
  I1026 12:12:23.549426 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 6.526607ms)
  I1026 12:12:23.549454 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.473825ms)
  I1026 12:12:23.549880 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.948322ms)
  I1026 12:12:23.549892 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 7.009376ms)
  I1026 12:12:23.550170 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 7.339362ms)
  I1026 12:12:23.550411 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.634878ms)
  I1026 12:12:23.550809 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 7.993932ms)
  I1026 12:12:23.551141 19 proxy.go:558] (12) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 8.389463ms)
  I1026 12:12:23.555815 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 4.507417ms)
  I1026 12:12:23.555809 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 4.563988ms)
  I1026 12:12:23.555836 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 4.576191ms)
  I1026 12:12:23.556055 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 4.64984ms)
  I1026 12:12:23.556195 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 4.903837ms)
  I1026 12:12:23.556208 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 5.035657ms)
  I1026 12:12:23.556481 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 5.264791ms)
  I1026 12:12:23.556481 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.06127ms)
  I1026 12:12:23.556492 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 5.216321ms)
  I1026 12:12:23.556503 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.16179ms)
  I1026 12:12:23.557010 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.684617ms)
  I1026 12:12:23.557768 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 6.379372ms)
  I1026 12:12:23.558030 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 6.566037ms)
  I1026 12:12:23.558159 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 6.725231ms)
  I1026 12:12:23.559122 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 7.674536ms)
  I1026 12:12:23.559305 19 proxy.go:558] (13) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 7.932446ms)
  I1026 12:12:23.563356 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 3.980704ms)
  I1026 12:12:23.564401 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 4.733371ms)
  I1026 12:12:23.564398 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 4.983017ms)
  I1026 12:12:23.564430 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 4.897448ms)
  I1026 12:12:23.564475 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 4.89291ms)
  I1026 12:12:23.566869 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 7.215357ms)
  I1026 12:12:23.566915 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 7.27694ms)
  I1026 12:12:23.569108 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 9.599359ms)
  I1026 12:12:23.569288 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 9.838289ms)
  I1026 12:12:23.569289 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 9.692854ms)
  I1026 12:12:23.570427 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 10.938884ms)
  I1026 12:12:23.570433 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 10.965455ms)
  I1026 12:12:23.571786 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 12.458843ms)
  I1026 12:12:23.571795 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 12.164011ms)
  I1026 12:12:23.573294 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 13.743953ms)
  I1026 12:12:23.573436 19 proxy.go:558] (14) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 13.869901ms)
  I1026 12:12:23.581545 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 7.944385ms)
  I1026 12:12:23.581545 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 7.920007ms)
  I1026 12:12:23.581566 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 7.778945ms)
  I1026 12:12:23.582958 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 9.240182ms)
  I1026 12:12:23.583306 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 9.536171ms)
  I1026 12:12:23.583406 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 9.75086ms)
  I1026 12:12:23.583665 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 9.911343ms)
  I1026 12:12:23.584247 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 10.673532ms)
  I1026 12:12:23.584263 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 10.791407ms)
  I1026 12:12:23.584272 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 10.763879ms)
  I1026 12:12:23.584563 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 10.75571ms)
  I1026 12:12:23.584935 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 11.195712ms)
  I1026 12:12:23.585753 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 11.890156ms)
  I1026 12:12:23.585753 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 12.210468ms)
  I1026 12:12:23.586879 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 13.17755ms)
  I1026 12:12:23.586880 19 proxy.go:558] (15) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 13.039029ms)
  I1026 12:12:23.594185 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 7.244961ms)
  I1026 12:12:23.594313 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 7.394016ms)
  I1026 12:12:23.595127 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 7.980894ms)
  I1026 12:12:23.595912 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 8.868631ms)
  I1026 12:12:23.597009 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 9.935527ms)
  I1026 12:12:23.597046 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 10.021226ms)
  I1026 12:12:23.597158 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 10.06297ms)
  I1026 12:12:23.597385 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 10.193855ms)
  I1026 12:12:23.597387 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 10.260377ms)
  I1026 12:12:23.597550 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 10.389905ms)
  I1026 12:12:23.597550 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 10.542696ms)
  I1026 12:12:23.597937 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 10.954891ms)
  I1026 12:12:23.598936 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 11.971733ms)
  I1026 12:12:23.598950 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 11.893047ms)
  I1026 12:12:23.599582 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 12.470212ms)
  I1026 12:12:23.599593 19 proxy.go:558] (16) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 12.417523ms)
  I1026 12:12:23.603465 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 3.81388ms)
  I1026 12:12:23.605935 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 6.319473ms)
  I1026 12:12:23.606820 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 6.994184ms)
  I1026 12:12:23.606820 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 6.96465ms)
  I1026 12:12:23.606835 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 6.931121ms)
  I1026 12:12:23.607468 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 7.629659ms)
  I1026 12:12:23.607929 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 8.05863ms)
  I1026 12:12:23.609878 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 10.127237ms)
  I1026 12:12:23.609897 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 10.199157ms)
  I1026 12:12:23.609907 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 10.188714ms)
  I1026 12:12:23.609908 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 10.019263ms)
  I1026 12:12:23.609915 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 10.181096ms)
  I1026 12:12:23.609992 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 10.219788ms)
  I1026 12:12:23.610007 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 10.216747ms)
  I1026 12:12:23.610016 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 10.098026ms)
  I1026 12:12:23.610017 19 proxy.go:558] (17) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 10.209384ms)
  I1026 12:12:23.615476 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 5.201752ms)
  I1026 12:12:23.617235 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 7.010893ms)
  I1026 12:12:23.617249 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 6.993958ms)
  I1026 12:12:23.617280 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 7.15058ms)
  I1026 12:12:23.617292 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 7.142967ms)
  I1026 12:12:23.617803 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 7.495689ms)
  I1026 12:12:23.617835 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 7.631055ms)
  I1026 12:12:23.618292 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 8.113368ms)
  I1026 12:12:23.618304 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 8.224982ms)
  I1026 12:12:23.618881 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 8.799029ms)
  I1026 12:12:23.619454 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 9.07633ms)
  I1026 12:12:23.619722 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 9.485253ms)
  I1026 12:12:23.620763 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 10.440516ms)
  I1026 12:12:23.621725 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 11.388265ms)
  I1026 12:12:23.621960 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 11.596859ms)
  I1026 12:12:23.623012 19 proxy.go:558] (18) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 12.848903ms)
  I1026 12:12:23.628881 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 5.666605ms)
  I1026 12:12:23.629028 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 5.90087ms)
  I1026 12:12:23.630426 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">test<... (200; 7.065999ms)
  I1026 12:12:23.632243 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:1080/proxy/rewriteme">... (200; 9.131335ms)
  I1026 12:12:23.632438 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj:160/proxy/: foo (200; 9.244852ms)
  I1026 12:12:23.632471 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/http:proxy-service-8mn79-9jpgj:162/proxy/: bar (200; 9.315002ms)
  I1026 12:12:23.632483 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname2/proxy/: bar (200; 9.307954ms)
  I1026 12:12:23.632501 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:460/proxy/: tls baz (200; 9.213497ms)
  I1026 12:12:23.632507 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:462/proxy/: tls qux (200; 9.199241ms)
  I1026 12:12:23.632513 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/proxy-service-8mn79-9jpgj/proxy/rewriteme">test</a> (200; 9.185734ms)
  I1026 12:12:23.632526 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname1/proxy/: tls baz (200; 9.17601ms)
  I1026 12:12:23.632517 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/services/http:proxy-service-8mn79:portname1/proxy/: foo (200; 9.27553ms)
  I1026 12:12:23.632559 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/: <a href="/api/v1/namespaces/proxy-4570/pods/https:proxy-service-8mn79-9jpgj:443/proxy/tlsrewritem... (200; 9.180754ms)
  I1026 12:12:23.632569 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/services/https:proxy-service-8mn79:tlsportname2/proxy/: tls qux (200; 9.525131ms)
  I1026 12:12:23.633538 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname2/proxy/: bar (200; 10.265206ms)
  I1026 12:12:23.633634 19 proxy.go:558] (19) /api/v1/namespaces/proxy-4570/services/proxy-service-8mn79:portname1/proxy/: foo (200; 10.405672ms)
  STEP: deleting ReplicationController proxy-service-8mn79 in namespace proxy-4570, will wait for the garbage collector to delete the pods @ 10/26/24 12:12:23.633
  I1026 12:12:23.696840 19 resources.go:139] Deleting ReplicationController proxy-service-8mn79 took: 8.91001ms
  I1026 12:12:23.797568 19 resources.go:163] Terminating ReplicationController proxy-service-8mn79 pods took: 100.724073ms
  I1026 12:12:26.298404 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-4570" for this suite. @ 10/26/24 12:12:26.302
• [4.980 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 10/26/24 12:12:26.309
  I1026 12:12:26.309479 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replication-controller @ 10/26/24 12:12:26.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:12:26.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:12:26.326
  STEP: creating a ReplicationController @ 10/26/24 12:12:26.332
  STEP: waiting for RC to be added @ 10/26/24 12:12:26.337
  STEP: waiting for available Replicas @ 10/26/24 12:12:26.337
  STEP: patching ReplicationController @ 10/26/24 12:12:28.212
  STEP: waiting for RC to be modified @ 10/26/24 12:12:28.219
  STEP: patching ReplicationController status @ 10/26/24 12:12:28.219
  STEP: waiting for RC to be modified @ 10/26/24 12:12:28.224
  STEP: waiting for available Replicas @ 10/26/24 12:12:28.224
  STEP: fetching ReplicationController status @ 10/26/24 12:12:28.229
  STEP: patching ReplicationController scale @ 10/26/24 12:12:28.232
  STEP: waiting for RC to be modified @ 10/26/24 12:12:28.238
  STEP: waiting for ReplicationController's scale to be the max amount @ 10/26/24 12:12:28.238
  STEP: fetching ReplicationController; ensuring that it's patched @ 10/26/24 12:12:30.308
  STEP: updating ReplicationController status @ 10/26/24 12:12:30.313
  STEP: waiting for RC to be modified @ 10/26/24 12:12:30.317
  STEP: listing all ReplicationControllers @ 10/26/24 12:12:30.318
  STEP: checking that ReplicationController has expected values @ 10/26/24 12:12:30.32
  STEP: deleting ReplicationControllers by collection @ 10/26/24 12:12:30.32
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 10/26/24 12:12:30.33
  I1026 12:12:30.376162 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E1026 12:12:30.376267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-7009" for this suite. @ 10/26/24 12:12:30.379
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 10/26/24 12:12:30.388
  I1026 12:12:30.388357 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename ingressclass @ 10/26/24 12:12:30.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:12:30.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:12:30.407
  STEP: getting /apis @ 10/26/24 12:12:30.409
  STEP: getting /apis/networking.k8s.io @ 10/26/24 12:12:30.411
  STEP: getting /apis/networking.k8s.iov1 @ 10/26/24 12:12:30.412
  STEP: creating @ 10/26/24 12:12:30.413
  STEP: getting @ 10/26/24 12:12:30.426
  STEP: listing @ 10/26/24 12:12:30.429
  STEP: watching @ 10/26/24 12:12:30.431
  I1026 12:12:30.431923 19 ingressclass.go:348] starting watch
  STEP: patching @ 10/26/24 12:12:30.432
  STEP: updating @ 10/26/24 12:12:30.437
  I1026 12:12:30.443409 19 ingressclass.go:364] waiting for watch events with expected annotations
  I1026 12:12:30.443435 19 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 10/26/24 12:12:30.443
  STEP: deleting a collection @ 10/26/24 12:12:30.454
  I1026 12:12:30.472201 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-6" for this suite. @ 10/26/24 12:12:30.476
• [0.095 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 10/26/24 12:12:30.483
  I1026 12:12:30.483188 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir-wrapper @ 10/26/24 12:12:30.483
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:12:30.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:12:30.499
  STEP: Creating 50 configmaps @ 10/26/24 12:12:30.501
  STEP: Creating RC which spawns configmap-volume pods @ 10/26/24 12:12:30.738
  I1026 12:12:30.866298 19 resource.go:87] Pod name wrapped-volume-race-64a6f2bb-0478-4b5e-87ff-7c0f5315fed4: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 10/26/24 12:12:30.866
  E1026 12:12:31.376946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:32.377036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:33.378055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:34.378233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 10/26/24 12:12:34.936
  I1026 12:12:34.949995 19 resource.go:87] Pod name wrapped-volume-race-4d4e8d7d-be8e-4e8a-8462-370a25ca6931: Found 0 pods out of 5
  E1026 12:12:35.378631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:36.378842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:37.379920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:38.380290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:39.380977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:12:39.957663 19 resource.go:87] Pod name wrapped-volume-race-4d4e8d7d-be8e-4e8a-8462-370a25ca6931: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 10/26/24 12:12:39.957
  STEP: Creating RC which spawns configmap-volume pods @ 10/26/24 12:12:39.978
  I1026 12:12:39.992369 19 resource.go:87] Pod name wrapped-volume-race-d9b253fb-392a-4920-971b-eeb129df116f: Found 0 pods out of 5
  E1026 12:12:40.381901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:41.382058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:42.382186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:43.382489      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:44.382751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:12:45.000474 19 resource.go:87] Pod name wrapped-volume-race-d9b253fb-392a-4920-971b-eeb129df116f: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 10/26/24 12:12:45
  STEP: deleting ReplicationController wrapped-volume-race-d9b253fb-392a-4920-971b-eeb129df116f in namespace emptydir-wrapper-692, will wait for the garbage collector to delete the pods @ 10/26/24 12:12:45.018
  I1026 12:12:45.079432 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-d9b253fb-392a-4920-971b-eeb129df116f took: 6.992831ms
  I1026 12:12:45.180127 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-d9b253fb-392a-4920-971b-eeb129df116f pods took: 100.690338ms
  E1026 12:12:45.383759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:46.384302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-4d4e8d7d-be8e-4e8a-8462-370a25ca6931 in namespace emptydir-wrapper-692, will wait for the garbage collector to delete the pods @ 10/26/24 12:12:46.581
  I1026 12:12:46.643483 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-4d4e8d7d-be8e-4e8a-8462-370a25ca6931 took: 7.142527ms
  I1026 12:12:46.743561 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-4d4e8d7d-be8e-4e8a-8462-370a25ca6931 pods took: 100.07483ms
  E1026 12:12:47.385347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-64a6f2bb-0478-4b5e-87ff-7c0f5315fed4 in namespace emptydir-wrapper-692, will wait for the garbage collector to delete the pods @ 10/26/24 12:12:47.844
  I1026 12:12:47.907807 19 resources.go:139] Deleting ReplicationController wrapped-volume-race-64a6f2bb-0478-4b5e-87ff-7c0f5315fed4 took: 8.290818ms
  I1026 12:12:48.008549 19 resources.go:163] Terminating ReplicationController wrapped-volume-race-64a6f2bb-0478-4b5e-87ff-7c0f5315fed4 pods took: 100.736419ms
  E1026 12:12:48.387833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:49.388084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 10/26/24 12:12:49.609
  I1026 12:12:49.936028 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-692" for this suite. @ 10/26/24 12:12:49.94
• [19.463 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:796
  STEP: Creating a kubernetes client @ 10/26/24 12:12:49.946
  I1026 12:12:49.946545 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename statefulset @ 10/26/24 12:12:49.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:12:49.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:12:49.966
  STEP: Creating service test in namespace statefulset-4277 @ 10/26/24 12:12:49.968
  STEP: Looking for a node to schedule stateful set and pod @ 10/26/24 12:12:49.975
  STEP: Creating pod with conflicting port in namespace statefulset-4277 @ 10/26/24 12:12:49.978
  STEP: Waiting until pod test-pod will start running in namespace statefulset-4277 @ 10/26/24 12:12:49.985
  E1026 12:12:50.388576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:51.388819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:52.389885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:53.390042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-4277 @ 10/26/24 12:12:53.999
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4277 @ 10/26/24 12:12:54.005
  I1026 12:12:54.017935 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4277, name: ss-0, uid: 945a4e0d-78e3-4574-92fc-c06bab12c59e, status phase: Pending. Waiting for statefulset controller to delete.
  I1026 12:12:54.039947 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4277, name: ss-0, uid: 945a4e0d-78e3-4574-92fc-c06bab12c59e, status phase: Failed. Waiting for statefulset controller to delete.
  I1026 12:12:54.047945 19 statefulset.go:869] Observed stateful pod in namespace: statefulset-4277, name: ss-0, uid: 945a4e0d-78e3-4574-92fc-c06bab12c59e, status phase: Failed. Waiting for statefulset controller to delete.
  I1026 12:12:54.055254 19 statefulset.go:863] Observed delete event for stateful pod ss-0 in namespace statefulset-4277
  STEP: Removing pod with conflicting port in namespace statefulset-4277 @ 10/26/24 12:12:54.055
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4277 and will be in running state @ 10/26/24 12:12:54.082
  E1026 12:12:54.390833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:55.391052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:12:56.090507 19 statefulset.go:138] Deleting all statefulset in ns statefulset-4277
  I1026 12:12:56.094621 19 rest.go:150] Scaling statefulset ss to 0
  E1026 12:12:56.391826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:57.392035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:58.392970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:12:59.393121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:00.393827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:01.393889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:02.394875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:03.394962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:04.395869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:05.395981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:13:06.106772 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1026 12:13:06.110393 19 rest.go:88] Deleting statefulset ss
  I1026 12:13:06.124184 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4277" for this suite. @ 10/26/24 12:13:06.126
• [16.186 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 10/26/24 12:13:06.132
  I1026 12:13:06.132984 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 12:13:06.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:13:06.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:13:06.153
  STEP: Creating secret with name secret-test-b9e0282f-3cd8-4732-893a-d25eae13f1d6 @ 10/26/24 12:13:06.154
  STEP: Creating a pod to test consume secrets @ 10/26/24 12:13:06.16
  E1026 12:13:06.396812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:07.396945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:08.397008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:09.397162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:13:10.18
  I1026 12:13:10.184785 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-secrets-b62a0197-fc81-4202-b0bc-b08bbb135de7 container secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:13:10.198
  I1026 12:13:10.216339 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5056" for this suite. @ 10/26/24 12:13:10.22
• [4.094 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 10/26/24 12:13:10.227
  I1026 12:13:10.227370 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 12:13:10.227
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:13:10.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:13:10.243
  STEP: set up a multi version CRD @ 10/26/24 12:13:10.244
  I1026 12:13:10.244901 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:13:10.397519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:11.397917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:12.398735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: rename a version @ 10/26/24 12:13:13.336
  STEP: check the new version name is served @ 10/26/24 12:13:13.348
  E1026 12:13:13.399243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 10/26/24 12:13:14.104
  E1026 12:13:14.399303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 10/26/24 12:13:14.705
  E1026 12:13:15.399353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:16.402021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:13:17.150466 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1933" for this suite. @ 10/26/24 12:13:17.157
• [6.940 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 10/26/24 12:13:17.167
  I1026 12:13:17.167102 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:13:17.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:13:17.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:13:17.187
  STEP: Creating projection with secret that has name projected-secret-test-map-9ee615ea-9886-4148-8085-dc057d867211 @ 10/26/24 12:13:17.19
  STEP: Creating a pod to test consume secrets @ 10/26/24 12:13:17.194
  E1026 12:13:17.402274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:18.402791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:19.403315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:20.403724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:13:21.216
  I1026 12:13:21.221718 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-secrets-4fd00316-804e-4d2e-aeb9-b6afcc7c2bcc container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:13:21.233
  I1026 12:13:21.249613 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9769" for this suite. @ 10/26/24 12:13:21.254
• [4.094 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 10/26/24 12:13:21.261
  I1026 12:13:21.261188 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename cronjob @ 10/26/24 12:13:21.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:13:21.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:13:21.285
  STEP: Creating a suspended cronjob @ 10/26/24 12:13:21.288
  STEP: Ensuring no jobs are scheduled @ 10/26/24 12:13:21.294
  E1026 12:13:21.404420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:22.404504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:23.405066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:24.405897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:25.406749      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:26.406838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:27.406918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:28.406976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:29.407047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:30.407894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:31.408457      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:32.408652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:33.409094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:34.409301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:35.409630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:36.409846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:37.409946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:38.410029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:39.410371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:40.410585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:41.411388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:42.412202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:43.412426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:44.412798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:45.412869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:46.413180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:47.414229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:48.414737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:49.415648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:50.415823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:51.415925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:52.416891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:53.417221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:54.417348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:55.417772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:56.417942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:57.418364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:58.419103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:13:59.419305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:00.419458      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:01.420360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:02.420535      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:03.420837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:04.421079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:05.421606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:06.421815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:07.421864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:08.422058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:09.422880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:10.423056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:11.423167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:12.423506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:13.423846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:14.424869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:15.425873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:16.425998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:17.426871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:18.427091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:19.427335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:20.427593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:21.427800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:22.428588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:23.429155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:24.430193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:25.430385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:26.430769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:27.430874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:28.431801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:29.432899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:30.433098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:31.433216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:32.434121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:33.435040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:34.435883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:35.436873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:36.437862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:37.438052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:38.438104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:39.438329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:40.438622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:41.438856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:42.439032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:43.439806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:44.439956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:45.440090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:46.440358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:47.440481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:48.441070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:49.441194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:50.441324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:51.441428      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:52.441614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:53.441707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:54.441879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:55.441973      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:56.442848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:57.443334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:58.443742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:14:59.443838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:00.443937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:01.444903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:02.445003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:03.445047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:04.445826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:05.445936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:06.446123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:07.446970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:08.447161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:09.447465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:10.447841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:11.448065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:12.449163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:13.449478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:14.449701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:15.449853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:16.450088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:17.450180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:18.451106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:19.451261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:20.452210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:21.452392      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:22.452852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:23.453173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:24.453274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:25.453456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:26.453837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:27.454892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:28.455217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:29.455909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:30.456020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:31.456169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:32.456908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:33.457046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:34.457836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:35.457958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:36.458070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:37.458313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:38.459141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:39.459895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:40.460167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:41.461070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:42.461391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:43.462374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:44.463423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:45.463522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:46.464363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:47.464436      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:48.464600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:49.464900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:50.464993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:51.465910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:52.466009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:53.467033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:54.467161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:55.467367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:56.467532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:57.467781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:58.468776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:15:59.468997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:00.469174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:01.469401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:02.470369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:03.471146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:04.472175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:05.473224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:06.473344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:07.473443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:08.474146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:09.474220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:10.474369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:11.474929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:12.475253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:13.476036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:14.476937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:15.477028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:16.477436      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:17.477649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:18.478145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:19.478335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:20.479258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:21.479429      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:22.480306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:23.481227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:24.481333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:25.481893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:26.482014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:27.482109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:28.483179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:29.483291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:30.484042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:31.484149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:32.484587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:33.484876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:34.485904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:35.486889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:36.486975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:37.487245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:38.488162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:39.488339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:40.489134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:41.489300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:42.489545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:43.489779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:44.489834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:45.490022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:46.490420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:47.490618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:48.491653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:49.491811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:50.491891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:51.492977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:52.493879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:53.493998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:54.494064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:55.494866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:56.495868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:57.496116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:58.497172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:16:59.497346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:00.497445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:01.497632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:02.497810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:03.498872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:04.499476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:05.500019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:06.500127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:07.500877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:08.501827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:09.502889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:10.502983      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:11.503866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:12.504459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:13.505163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:14.506025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:15.506252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:16.506773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:17.507109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:18.507155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:19.507466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:20.508446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:21.508520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:22.509566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:23.509769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:24.509816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:25.510022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:26.510923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:27.511113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:28.511651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:29.511813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:30.512631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:31.512829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:32.512895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:33.513384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:34.513875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:35.513955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:36.514889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:37.515865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:38.516634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:39.516836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:40.517473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:41.517568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:42.517660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:43.518048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:44.518127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:45.518896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:46.519266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:47.519451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:48.519572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:49.519812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:50.519933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:51.520123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:52.521025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:53.521137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:54.521378      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:55.521520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:56.521539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:57.521658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:58.521746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:17:59.521922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:00.522105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:01.522207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:02.522891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:03.522992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:04.523823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:05.523901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:06.524694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:07.524810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:08.525315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:09.525414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:10.525870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:11.526094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:12.526372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:13.527184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:14.527800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:15.527996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:16.528876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:17.528957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:18.529288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:19.529438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:20.530046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 10/26/24 12:18:21.294
  STEP: Removing cronjob @ 10/26/24 12:18:21.299
  I1026 12:18:21.306689 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7639" for this suite. @ 10/26/24 12:18:21.311
• [300.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:127
  STEP: Creating a kubernetes client @ 10/26/24 12:18:21.319
  I1026 12:18:21.319870 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-preemption @ 10/26/24 12:18:21.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:18:21.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:18:21.343
  I1026 12:18:21.361059 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1026 12:18:21.530962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:22.531108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:23.532133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:24.532880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:25.533692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:26.533809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:27.534268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:28.535199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:29.535761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:30.535971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:31.536887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:32.536976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:33.537332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:34.537469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:35.538097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:36.538386      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:37.538500      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:38.538913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:39.539527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:40.539760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:41.540437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:42.540564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:43.540672      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:44.540801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:45.541459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:46.541739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:47.542714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:48.542805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:49.543608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:50.543743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:51.544700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:52.544802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:53.545502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:54.545889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:55.546404      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:56.546589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:57.547561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:58.548328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:18:59.549397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:00.549502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:01.550427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:02.550704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:03.550928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:04.551039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:05.551578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:06.551736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:07.552340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:08.553257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:09.553376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:10.553901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:11.554536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:12.554870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:13.555232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:14.555344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:15.556082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:16.556871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:17.556908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:18.557126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:19.557892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:20.558093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:19:21.366620 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 10/26/24 12:19:21.37
  I1026 12:19:21.393576 19 preemption.go:175] Created pod: pod0-0-sched-preemption-low-priority
  I1026 12:19:21.400187 19 preemption.go:175] Created pod: pod0-1-sched-preemption-medium-priority
  I1026 12:19:21.416402 19 preemption.go:175] Created pod: pod1-0-sched-preemption-medium-priority
  I1026 12:19:21.424911 19 preemption.go:175] Created pod: pod1-1-sched-preemption-medium-priority
  I1026 12:19:21.439575 19 preemption.go:175] Created pod: pod2-0-sched-preemption-medium-priority
  I1026 12:19:21.449763 19 preemption.go:175] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 10/26/24 12:19:21.449
  E1026 12:19:21.558436      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:22.558984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 10/26/24 12:19:23.483
  E1026 12:19:23.559775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:24.559875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:25.560370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:26.560630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:27.560819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:19:27.570963 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-2105" for this suite. @ 10/26/24 12:19:27.576
• [66.263 seconds]
------------------------------
SS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 10/26/24 12:19:27.582
  I1026 12:19:27.582873 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename events @ 10/26/24 12:19:27.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:19:27.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:19:27.605
  STEP: creating a test event @ 10/26/24 12:19:27.608
  STEP: listing all events in all namespaces @ 10/26/24 12:19:27.614
  STEP: patching the test event @ 10/26/24 12:19:27.624
  STEP: fetching the test event @ 10/26/24 12:19:27.633
  STEP: updating the test event @ 10/26/24 12:19:27.638
  STEP: getting the test event @ 10/26/24 12:19:27.65
  STEP: deleting the test event @ 10/26/24 12:19:27.654
  STEP: listing all events in all namespaces @ 10/26/24 12:19:27.662
  I1026 12:19:27.676905 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-3473" for this suite. @ 10/26/24 12:19:27.681
• [0.105 seconds]
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 10/26/24 12:19:27.687
  I1026 12:19:27.687850 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename init-container @ 10/26/24 12:19:27.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:19:27.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:19:27.709
  STEP: creating the pod @ 10/26/24 12:19:27.712
  I1026 12:19:27.712390 19 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E1026 12:19:28.560954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:29.561058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:30.561270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:31.561389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:32.561478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:33.562339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:34.562440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:35.562549      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:36.562625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:37.562821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:38.562920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:39.563030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:40.563110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:41.563903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:42.564004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:43.564086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:44.564210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:45.564310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:46.564401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:47.564875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:48.565122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:49.565898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:50.566007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:51.566207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:52.566969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:53.567704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:54.567883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:55.568044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:56.568121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:57.568249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:58.569335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:19:59.569508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:00.569601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:01.569883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:02.570116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:03.570151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:04.570462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:05.570701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:06.570928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:07.571141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:08.571632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:20:09.086206 19 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ed4b2264-b106-4a84-99a9-592f522ca364", GenerateName:"", Namespace:"init-container-1366", SelfLink:"", UID:"874973b8-a575-4b32-b4c8-fe15986c1c88", ResourceVersion:"6868", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 12, 19, 27, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"712382748"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 12, 19, 27, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005194df8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 12, 20, 9, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc005194e40), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-d9jqs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004d51c40), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil), Image:(*v1.ImageVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-d9jqs", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-d9jqs", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.10", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-d9jqs", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001908d68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-30-144", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00032c280), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001908df0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001908e10)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001908e18), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001908e1c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0044b2230), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.October, 26, 12, 19, 28, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.October, 26, 12, 19, 27, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.October, 26, 12, 19, 27, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.October, 26, 12, 19, 27, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.October, 26, 12, 19, 27, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.30.144", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.31.30.144"}}, PodIP:"192.168.29.154", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.29.154"}}, StartTime:time.Date(2024, time.October, 26, 12, 19, 27, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00004d420)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00004d490)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://3b2ca2462f739787264ce39ef22f4fd31731c965472f7a6c35c67c3ee4d19b8c", Started:(*bool)(0xc001908eca), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-d9jqs", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0044b2250)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004d51cc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc001908edd), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-d9jqs", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0044b2260)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004d51ca0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.10", ImageID:"", ContainerID:"", Started:(*bool)(0xc001908e94), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-d9jqs", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc0044b2240)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I1026 12:20:09.086344 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1366" for this suite. @ 10/26/24 12:20:09.092
• [41.412 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 10/26/24 12:20:09.1
  I1026 12:20:09.100108 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:20:09.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:09.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:09.125
  STEP: Creating configMap with name configmap-projected-all-test-volume-afdf1ddc-6500-4640-a145-13a9afc2ef49 @ 10/26/24 12:20:09.129
  STEP: Creating secret with name secret-projected-all-test-volume-fd0773b6-006d-4f84-a1e5-8a89f12e6193 @ 10/26/24 12:20:09.135
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 10/26/24 12:20:09.14
  E1026 12:20:09.572283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:10.572833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:11.573504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:12.573572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:20:13.165
  I1026 12:20:13.170638 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod projected-volume-51202932-8040-444f-a5af-0b65ee0c2855 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:20:13.188
  I1026 12:20:13.204897 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4605" for this suite. @ 10/26/24 12:20:13.208
• [4.119 seconds]
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:174
  STEP: Creating a kubernetes client @ 10/26/24 12:20:13.218
  I1026 12:20:13.218736 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-webhook @ 10/26/24 12:20:13.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:13.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:13.243
  STEP: Setting up server cert @ 10/26/24 12:20:13.249
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 10/26/24 12:20:13.552
  STEP: Deploying the custom resource conversion webhook pod @ 10/26/24 12:20:13.561
  E1026 12:20:13.574205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Wait for the deployment to be ready @ 10/26/24 12:20:13.575
  I1026 12:20:13.587737 19 deployment.go:222] new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  E1026 12:20:14.574848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:15.575904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:20:15.603
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:20:15.615
  E1026 12:20:16.576885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:20:16.616083 19 util.go:420] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I1026 12:20:16.625097 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:20:17.577795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:18.578406      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 10/26/24 12:20:19.203
  STEP: Create a v2 custom resource @ 10/26/24 12:20:19.221
  STEP: List CRs in v1 @ 10/26/24 12:20:19.25
  STEP: List CRs in v2 @ 10/26/24 12:20:19.255
  E1026 12:20:19.578571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:20:19.818221 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-6902" for this suite. @ 10/26/24 12:20:19.822
• [6.616 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:878
  STEP: Creating a kubernetes client @ 10/26/24 12:20:19.835
  I1026 12:20:19.835030 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename job @ 10/26/24 12:20:19.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:19.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:19.859
  STEP: Creating a job @ 10/26/24 12:20:19.864
  STEP: Ensuring active pods == parallelism @ 10/26/24 12:20:19.871
  E1026 12:20:20.578641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:21.578855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete a job @ 10/26/24 12:20:21.878
  STEP: deleting Job.batch foo in namespace job-6641, will wait for the garbage collector to delete the pods @ 10/26/24 12:20:21.878
  I1026 12:20:21.942499 19 resources.go:139] Deleting Job.batch foo took: 9.282951ms
  I1026 12:20:22.042621 19 resources.go:163] Terminating Job.batch foo pods took: 100.102171ms
  E1026 12:20:22.579822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 10/26/24 12:20:23.143
  I1026 12:20:23.147637 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6641" for this suite. @ 10/26/24 12:20:23.152
• [3.324 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 10/26/24 12:20:23.158
  I1026 12:20:23.158935 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename chunking @ 10/26/24 12:20:23.159
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:23.177
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:23.18
  STEP: creating a large number of resources @ 10/26/24 12:20:23.184
  E1026 12:20:23.579783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:24.580825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:25.581858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:26.582583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:27.583319      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:28.583611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:29.584596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:30.584769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:31.585637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:32.586299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:33.586627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:34.587628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:35.587730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:36.588626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:37.589354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:38.589937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:39.590548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:40.590864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 10/26/24 12:20:40.867
  I1026 12:20:40.914876 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I1026 12:20:40.966395 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  I1026 12:20:41.014725 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  I1026 12:20:41.063762 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  I1026 12:20:41.116296 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  I1026 12:20:41.165904 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  I1026 12:20:41.214908 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  I1026 12:20:41.266366 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  I1026 12:20:41.315614 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  I1026 12:20:41.364608 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  I1026 12:20:41.415923 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  I1026 12:20:41.466009 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  I1026 12:20:41.514946 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  I1026 12:20:41.566360 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  E1026 12:20:41.591659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:20:41.614771 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  I1026 12:20:41.664638 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  I1026 12:20:41.716256 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  I1026 12:20:41.764779 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  I1026 12:20:41.814340 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  I1026 12:20:41.866817 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  I1026 12:20:41.914867 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  I1026 12:20:41.964670 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  I1026 12:20:42.015786 19 chunking.go:98] Retrieved 17/17 results with rv 7543 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Mywic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  I1026 12:20:42.064720 19 chunking.go:98] Retrieved 9/17 results with rv 7543 and continue 
  I1026 12:20:42.114807 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I1026 12:20:42.166955 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  I1026 12:20:42.216898 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  I1026 12:20:42.265006 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  I1026 12:20:42.316454 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  I1026 12:20:42.364533 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  I1026 12:20:42.414081 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  I1026 12:20:42.466541 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  I1026 12:20:42.514623 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  I1026 12:20:42.565046 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  E1026 12:20:42.592239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:20:42.616392 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  I1026 12:20:42.664893 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  I1026 12:20:42.714946 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  I1026 12:20:42.766232 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  I1026 12:20:42.814635 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  I1026 12:20:42.864147 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  I1026 12:20:42.915956 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  I1026 12:20:42.965296 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  I1026 12:20:43.015216 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  I1026 12:20:43.066503 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  I1026 12:20:43.114348 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  I1026 12:20:43.165048 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  I1026 12:20:43.216164 19 chunking.go:98] Retrieved 17/17 results with rv 7546 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0Niwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  I1026 12:20:43.265130 19 chunking.go:98] Retrieved 9/17 results with rv 7546 and continue 
  I1026 12:20:43.314799 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I1026 12:20:43.365926 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDMzXHUwMDAwIn0
  I1026 12:20:43.414724 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDUwXHUwMDAwIn0
  I1026 12:20:43.464743 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDY3XHUwMDAwIn0
  I1026 12:20:43.515771 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMDg0XHUwMDAwIn0
  I1026 12:20:43.564640 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTAxXHUwMDAwIn0
  E1026 12:20:43.592737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:20:43.614579 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTE4XHUwMDAwIn0
  I1026 12:20:43.665761 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTM1XHUwMDAwIn0
  I1026 12:20:43.714503 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTUyXHUwMDAwIn0
  I1026 12:20:43.764387 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTY5XHUwMDAwIn0
  I1026 12:20:43.816073 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMTg2XHUwMDAwIn0
  I1026 12:20:43.864980 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjAzXHUwMDAwIn0
  I1026 12:20:43.914615 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjIwXHUwMDAwIn0
  I1026 12:20:43.965996 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjM3XHUwMDAwIn0
  I1026 12:20:44.014751 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjU0XHUwMDAwIn0
  I1026 12:20:44.064929 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjcxXHUwMDAwIn0
  I1026 12:20:44.116472 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMjg4XHUwMDAwIn0
  I1026 12:20:44.164826 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzA1XHUwMDAwIn0
  I1026 12:20:44.214764 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzIyXHUwMDAwIn0
  I1026 12:20:44.266611 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzM5XHUwMDAwIn0
  I1026 12:20:44.314770 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzU2XHUwMDAwIn0
  I1026 12:20:44.364517 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzczXHUwMDAwIn0
  I1026 12:20:44.415445 19 chunking.go:98] Retrieved 17/17 results with rv 7548 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6NzU0OCwic3RhcnQiOiJ0ZW1wbGF0ZS0wMzkwXHUwMDAwIn0
  I1026 12:20:44.464581 19 chunking.go:98] Retrieved 9/17 results with rv 7548 and continue 
  STEP: retrieving those results all at once @ 10/26/24 12:20:44.464
  I1026 12:20:44.519948 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-896" for this suite. @ 10/26/24 12:20:44.565
  E1026 12:20:44.593126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [21.460 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 10/26/24 12:20:44.619
  I1026 12:20:44.619035 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:20:44.619
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:44.64
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:44.643
  STEP: Creating projection with secret that has name projected-secret-test-c77f481f-3fd4-4436-9673-c4c032973930 @ 10/26/24 12:20:44.646
  STEP: Creating a pod to test consume secrets @ 10/26/24 12:20:44.651
  E1026 12:20:45.593247      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:46.593342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:47.593901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:48.593958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:20:48.678
  I1026 12:20:48.683493 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-secrets-ff859972-7bcd-4115-85af-345aeb0e59d7 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:20:48.701
  I1026 12:20:48.717338 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6550" for this suite. @ 10/26/24 12:20:48.722
• [4.112 seconds]
------------------------------
S
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 10/26/24 12:20:48.73
  I1026 12:20:48.730596 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename endpointslice @ 10/26/24 12:20:48.731
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:48.751
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:48.754
  STEP: getting /apis @ 10/26/24 12:20:48.759
  STEP: getting /apis/discovery.k8s.io @ 10/26/24 12:20:48.763
  STEP: getting /apis/discovery.k8s.iov1 @ 10/26/24 12:20:48.764
  STEP: creating @ 10/26/24 12:20:48.766
  STEP: getting @ 10/26/24 12:20:48.783
  STEP: listing @ 10/26/24 12:20:48.786
  STEP: watching @ 10/26/24 12:20:48.79
  I1026 12:20:48.790641 19 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 10/26/24 12:20:48.792
  STEP: cluster-wide watching @ 10/26/24 12:20:48.796
  I1026 12:20:48.796533 19 endpointslice.go:459] starting watch
  STEP: patching @ 10/26/24 12:20:48.798
  STEP: updating @ 10/26/24 12:20:48.803
  I1026 12:20:48.811932 19 endpointslice.go:482] waiting for watch events with expected annotations
  I1026 12:20:48.811957 19 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 10/26/24 12:20:48.812
  STEP: deleting a collection @ 10/26/24 12:20:48.826
  I1026 12:20:48.843997 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8322" for this suite. @ 10/26/24 12:20:48.847
• [0.124 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 10/26/24 12:20:48.855
  I1026 12:20:48.855079 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:20:48.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:48.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:48.873
  STEP: Creating projection with secret that has name projected-secret-test-957a530e-0c9b-4b26-bbff-783291287645 @ 10/26/24 12:20:48.877
  STEP: Creating a pod to test consume secrets @ 10/26/24 12:20:48.881
  E1026 12:20:49.594076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:50.594172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:51.594822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:52.595889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:20:52.908
  I1026 12:20:52.915830 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-secrets-c0d595e3-eac8-4384-816f-6d4ae4bf7892 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:20:52.923
  I1026 12:20:52.939437 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-903" for this suite. @ 10/26/24 12:20:52.945
• [4.098 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 10/26/24 12:20:52.953
  I1026 12:20:52.953663 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:20:52.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:52.973
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:52.977
  STEP: Creating configMap with name configmap-test-volume-53f0ed82-60cc-4ba2-a4cc-5255f982c866 @ 10/26/24 12:20:52.982
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:20:52.987
  E1026 12:20:53.596757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:54.596830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:55.597840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:20:56.598067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:20:57.019
  I1026 12:20:57.023695 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-configmaps-f69801b0-367d-4b97-a6e6-075923addf68 container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:20:57.03
  I1026 12:20:57.049008 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2767" for this suite. @ 10/26/24 12:20:57.052
• [4.107 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 10/26/24 12:20:57.061
  I1026 12:20:57.061224 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename deployment @ 10/26/24 12:20:57.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:20:57.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:20:57.086
  STEP: creating a Deployment @ 10/26/24 12:20:57.093
  STEP: waiting for Deployment to be created @ 10/26/24 12:20:57.098
  STEP: waiting for all Replicas to be Ready @ 10/26/24 12:20:57.099
  I1026 12:20:57.101405 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1026 12:20:57.101432 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1026 12:20:57.118768 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1026 12:20:57.118794 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1026 12:20:57.137702 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1026 12:20:57.137725 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1026 12:20:57.157277 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I1026 12:20:57.157308 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E1026 12:20:57.598482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:20:58.133764 19 deployment.go:246] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I1026 12:20:58.133800 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I1026 12:20:58.182098 19 deployment.go:248] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 10/26/24 12:20:58.182
  I1026 12:20:58.196244 19 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 10/26/24 12:20:58.196
  I1026 12:20:58.198057 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0
  I1026 12:20:58.198079 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0
  I1026 12:20:58.198089 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0
  I1026 12:20:58.198105 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0
  I1026 12:20:58.198113 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0
  I1026 12:20:58.198118 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0
  I1026 12:20:58.198177 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0
  I1026 12:20:58.198185 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 0
  I1026 12:20:58.198191 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:20:58.198201 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:20:58.198259 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:58.198312 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:58.198322 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:58.198328 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:58.209822 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:58.209848 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:58.233608 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:58.233626 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:58.250852 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:20:58.250876 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  E1026 12:20:58.599426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:20:59.205603 19 deployment.go:309] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:59.205637 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:20:59.236630 19 deployment.go:311] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  STEP: listing Deployments @ 10/26/24 12:20:59.236
  I1026 12:20:59.241278 19 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 10/26/24 12:20:59.241
  I1026 12:20:59.252566 19 deployment.go:360] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 10/26/24 12:20:59.252
  I1026 12:20:59.265625 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1026 12:20:59.266345 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1026 12:20:59.279500 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1026 12:20:59.291873 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1026 12:20:59.308884 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I1026 12:20:59.320868 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E1026 12:20:59.600406      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:21:00.175636 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I1026 12:21:00.203127 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  I1026 12:21:00.245225 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I1026 12:21:00.249621 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E1026 12:21:00.601251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:01.601912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:02.602096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:21:03.163275 19 deployment.go:389] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 10/26/24 12:21:03.187
  STEP: fetching the DeploymentStatus @ 10/26/24 12:21:03.195
  I1026 12:21:03.200538 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:21:03.200571 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:21:03.200580 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:21:03.200649 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:21:03.200715 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:21:03.200724 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 1
  I1026 12:21:03.200779 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:21:03.200835 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 3
  I1026 12:21:03.200843 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:21:03.200850 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 2
  I1026 12:21:03.200889 19 deployment.go:449] observed Deployment test-deployment in namespace deployment-4924 with ReadyReplicas 3
  STEP: deleting the Deployment @ 10/26/24 12:21:03.2
  I1026 12:21:03.210778 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.210822 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.210863 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211027 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211040 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211050 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211091 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211158 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211202 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211212 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211284 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211294 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211307 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.211367 19 deployment.go:475] observed event type MODIFIED
  I1026 12:21:03.215707 19 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I1026 12:21:03.219317 19 deployment.go:657] ReplicaSet "test-deployment-6c86c7f765":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-6c86c7f765",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4924",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3321f353-37e4-443b-a1b0-ba63a044d827",
      ResourceVersion: (string) (len=4) "8283",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542059,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "c5a6fe80-00d8-4eac-bd1f-8192f9f93475",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 63 35 61 36  66 65 38 30 2d 30 30 64  |":\"c5a6fe80-00d|
              00000130  38 2d 34 65 61 63 2d 62  64 31 66 2d 38 31 39 32  |8-4eac-bd1f-8192|
              00000140  66 39 66 39 33 34 37 35  5c 22 7d 22 3a 7b 7d 7d  |f9f93475\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542063,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I1026 12:21:03.223858 19 deployment.go:669] pod: "test-deployment-6c86c7f765-fkqcz":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6c86c7f765-fkqcz",
      GenerateName: (string) (len=27) "test-deployment-6c86c7f765-",
      Namespace: (string) (len=15) "deployment-4924",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f3fb0770-fb22-4da5-9c9a-29ea085a87c6",
      ResourceVersion: (string) (len=4) "8230",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542059,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6c86c7f765",
          UID: (types.UID) (len=36) "3321f353-37e4-443b-a1b0-ba63a044d827",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  33 33 32 31 66 33 35 33  |uid\":\"3321f353|
              000000a0  2d 33 37 65 34 2d 34 34  33 62 2d 61 31 62 30 2d  |-37e4-443b-a1b0-|
              000000b0  62 61 36 33 61 30 34 34  64 38 32 37 5c 22 7d 22  |ba63a044d827\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 39  2e 31 36 31 5c 22 7d 22  |2.168.29.161\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hcjll",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hcjll",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.161",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.161"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542059,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865542059,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://aef0162835b002ccacc302950e5210e94a3b518cc463fbd7e84fe774f171f21d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-hcjll",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I1026 12:21:03.224928 19 deployment.go:669] pod: "test-deployment-6c86c7f765-n6s8w":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6c86c7f765-n6s8w",
      GenerateName: (string) (len=27) "test-deployment-6c86c7f765-",
      Namespace: (string) (len=15) "deployment-4924",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "38e1f120-b1d7-4d91-8f72-854d23c1a7aa",
      ResourceVersion: (string) (len=4) "8280",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542060,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6c86c7f765"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6c86c7f765",
          UID: (types.UID) (len=36) "3321f353-37e4-443b-a1b0-ba63a044d827",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  33 33 32 31 66 33 35 33  |uid\":\"3321f353|
              000000a0  2d 33 37 65 34 2d 34 34  33 62 2d 61 31 62 30 2d  |-37e4-443b-a1b0-|
              000000b0  62 61 36 33 61 30 34 34  64 38 32 37 5c 22 7d 22  |ba63a044d827\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542063,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 36  2e 37 39 5c 22 7d 22 3a  |2.168.46.79\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2c2f6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2c2f6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542063,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542063,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542063,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.104",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.104"
        }
      },
      PodIP: (string) (len=13) "192.168.46.79",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.46.79"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542060,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865542062,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b23eb28729b696f5bbe40141bd4e91d44fc4d0c17b3716be5f637b75d4550285",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-2c2f6",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I1026 12:21:03.225741 19 deployment.go:657] ReplicaSet "test-deployment-6ccdbb4d8c":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-6ccdbb4d8c",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4924",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cae1e7e1-aa89-450b-9e09-ed63e38b25e2",
      ResourceVersion: (string) (len=4) "8291",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542058,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6ccdbb4d8c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "c5a6fe80-00d8-4eac-bd1f-8192f9f93475",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542063,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 63 35 61 36  66 65 38 30 2d 30 30 64  |":\"c5a6fe80-00d|
              00000130  38 2d 34 65 61 63 2d 62  64 31 66 2d 38 31 39 32  |8-4eac-bd1f-8192|
              00000140  66 39 66 39 33 34 37 35  5c 22 7d 22 3a 7b 7d 7d  |f9f93475\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542063,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=22) "test-deployment-static": (string) (len=4) "true",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6ccdbb4d8c"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "6ccdbb4d8c",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=26) "registry.k8s.io/pause:3.10",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I1026 12:21:03.231348 19 deployment.go:669] pod: "test-deployment-6ccdbb4d8c-l9trf":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-6ccdbb4d8c-l9trf",
      GenerateName: (string) (len=27) "test-deployment-6ccdbb4d8c-",
      Namespace: (string) (len=15) "deployment-4924",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2e785bcc-e820-4fb4-b071-faefe2c67893",
      ResourceVersion: (string) (len=4) "8287",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542059,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542065,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "6ccdbb4d8c",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-6ccdbb4d8c",
          UID: (types.UID) (len=36) "cae1e7e1-aa89-450b-9e09-ed63e38b25e2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  63 61 65 31 65 37 65 31  |uid\":\"cae1e7e1|
              000000a0  2d 61 61 38 39 2d 34 35  30 62 2d 39 65 30 39 2d  |-aa89-450b-9e09-|
              000000b0  65 64 36 33 65 33 38 62  32 35 65 32 5c 22 7d 22  |ed63e38b25e2\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=662) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 36  2e 37 38 5c 22 7d 22 3a  |2.168.46.78\"}":|
              00000270  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000280  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000290  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nc9kr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=26) "registry.k8s.io/pause:3.10",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nc9kr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542060,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.104",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.104"
        }
      },
      PodIP: (string) (len=13) "192.168.46.78",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.46.78"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542059,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865542059,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=26) "registry.k8s.io/pause:3.10",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a",
          ContainerID: (string) (len=77) "containerd://f145c9c8179978bb2608775d9324ea301d293295b0aed54f4c947c31c931e5b3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-nc9kr",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I1026 12:21:03.238554 19 deployment.go:657] ReplicaSet "test-deployment-77bdf6fb4b":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-77bdf6fb4b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4924",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f2cc2d67-10b5-4dd6-9378-1caaae1af51e",
      ResourceVersion: (string) (len=4) "8178",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542057,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "77bdf6fb4b",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "c5a6fe80-00d8-4eac-bd1f-8192f9f93475",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 63 35 61 36  66 65 38 30 2d 30 30 64  |":\"c5a6fe80-00d|
              00000130  38 2d 34 65 61 63 2d 62  64 31 66 2d 38 31 39 32  |8-4eac-bd1f-8192|
              00000140  66 39 66 39 33 34 37 35  5c 22 7d 22 3a 7b 7d 7d  |f9f93475\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542059,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "77bdf6fb4b",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "77bdf6fb4b",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I1026 12:21:03.243408 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4924" for this suite. @ 10/26/24 12:21:03.248
• [6.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 10/26/24 12:21:03.254
  I1026 12:21:03.254154 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:21:03.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:03.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:03.274
  STEP: Creating configMap with name cm-test-opt-del-1a0f6083-e5b8-4dec-976c-917ded2ea017 @ 10/26/24 12:21:03.28
  STEP: Creating configMap with name cm-test-opt-upd-95258545-df36-4b0d-b8e2-e014bd845686 @ 10/26/24 12:21:03.287
  STEP: Creating the pod @ 10/26/24 12:21:03.292
  E1026 12:21:03.602665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:04.602840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-1a0f6083-e5b8-4dec-976c-917ded2ea017 @ 10/26/24 12:21:05.34
  STEP: Updating configmap cm-test-opt-upd-95258545-df36-4b0d-b8e2-e014bd845686 @ 10/26/24 12:21:05.347
  STEP: Creating configMap with name cm-test-opt-create-266edf12-4d64-49cd-ab0a-9409bede751c @ 10/26/24 12:21:05.353
  STEP: waiting to observe update in volume @ 10/26/24 12:21:05.358
  E1026 12:21:05.603877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:06.603978      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:07.604592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:08.604829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:21:09.396313 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4671" for this suite. @ 10/26/24 12:21:09.4
• [6.153 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 10/26/24 12:21:09.407
  I1026 12:21:09.407290 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 12:21:09.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:09.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:09.427
  I1026 12:21:09.431187 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:21:09.605741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:10.605741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 10/26/24 12:21:10.679
  I1026 12:21:10.679312 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-8842 --namespace=crd-publish-openapi-8842 create -f -'
  E1026 12:21:11.606669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:12.606872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:21:12.738159 19 builder.go:146] stderr: ""
  I1026 12:21:12.738212 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1637-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I1026 12:21:12.738259 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-8842 --namespace=crd-publish-openapi-8842 delete e2e-test-crd-publish-openapi-1637-crds test-cr'
  I1026 12:21:12.798804 19 builder.go:146] stderr: ""
  I1026 12:21:12.798850 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1637-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I1026 12:21:12.798889 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-8842 --namespace=crd-publish-openapi-8842 apply -f -'
  I1026 12:21:12.852934 19 builder.go:146] stderr: ""
  I1026 12:21:12.853002 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1637-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I1026 12:21:12.853048 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-8842 --namespace=crd-publish-openapi-8842 delete e2e-test-crd-publish-openapi-1637-crds test-cr'
  I1026 12:21:12.902642 19 builder.go:146] stderr: ""
  I1026 12:21:12.902712 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-1637-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 10/26/24 12:21:12.902
  I1026 12:21:12.902776 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-8842 explain e2e-test-crd-publish-openapi-1637-crds'
  I1026 12:21:12.944151 19 builder.go:146] stderr: ""
  I1026 12:21:12.944190 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-1637-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E1026 12:21:13.607509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:21:14.173726 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8842" for this suite. @ 10/26/24 12:21:14.18
• [4.780 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 10/26/24 12:21:14.188
  I1026 12:21:14.188168 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:21:14.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:14.202
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:14.204
  STEP: Creating configMap with name configmap-test-volume-map-6583008e-05fd-4aa4-a015-b16579ad985d @ 10/26/24 12:21:14.207
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:21:14.212
  E1026 12:21:14.607908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:15.608124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:16.608245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:17.608366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:21:18.239
  I1026 12:21:18.243714 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-configmaps-0ef7f632-ec06-43ab-9b77-674fc36c60ac container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:21:18.254
  I1026 12:21:18.275412 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6975" for this suite. @ 10/26/24 12:21:18.279
• [4.098 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 10/26/24 12:21:18.286
  I1026 12:21:18.286855 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:21:18.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:18.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:18.306
  STEP: Creating the pod @ 10/26/24 12:21:18.307
  E1026 12:21:18.608452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:19.608825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:20.609537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:21:20.853832 19 pod_client.go:173] Successfully updated pod "annotationupdated72e90c6-8189-4a85-848b-29b96b375f02"
  E1026 12:21:21.609939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:22.610054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:21:22.871190 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5119" for this suite. @ 10/26/24 12:21:22.875
• [4.596 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 10/26/24 12:21:22.882
  I1026 12:21:22.882851 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename csistoragecapacity @ 10/26/24 12:21:22.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:22.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:22.902
  STEP: getting /apis @ 10/26/24 12:21:22.904
  STEP: getting /apis/storage.k8s.io @ 10/26/24 12:21:22.907
  STEP: getting /apis/storage.k8s.io/v1 @ 10/26/24 12:21:22.908
  STEP: creating @ 10/26/24 12:21:22.909
  STEP: watching @ 10/26/24 12:21:22.926
  I1026 12:21:22.926790 19 csistoragecapacity.go:143] starting watch
  STEP: getting @ 10/26/24 12:21:22.932
  STEP: listing in namespace @ 10/26/24 12:21:22.935
  STEP: listing across namespaces @ 10/26/24 12:21:22.939
  STEP: patching @ 10/26/24 12:21:22.942
  STEP: updating @ 10/26/24 12:21:22.946
  I1026 12:21:22.951162 19 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I1026 12:21:22.951454 19 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 10/26/24 12:21:22.951
  STEP: deleting a collection @ 10/26/24 12:21:22.964
  I1026 12:21:22.981776 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-1326" for this suite. @ 10/26/24 12:21:22.986
• [0.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 10/26/24 12:21:22.993
  I1026 12:21:22.993922 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename subpath @ 10/26/24 12:21:22.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:23.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:23.013
  STEP: Setting up data @ 10/26/24 12:21:23.015
  STEP: Creating pod pod-subpath-test-downwardapi-hwgb @ 10/26/24 12:21:23.025
  STEP: Creating a pod to test atomic-volume-subpath @ 10/26/24 12:21:23.025
  E1026 12:21:23.610599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:24.610832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:25.610959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:26.611047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:27.611152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:28.611205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:29.612139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:30.612266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:31.612365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:32.612592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:33.612775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:34.612877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:35.613017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:36.613115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:37.613826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:38.614872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:39.614996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:40.615426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:41.615521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:42.615994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:43.616289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:44.617169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:45.617865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:46.618007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:21:47.096
  I1026 12:21:47.100875 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-subpath-test-downwardapi-hwgb container test-container-subpath-downwardapi-hwgb: <nil>
  STEP: delete the pod @ 10/26/24 12:21:47.106
  STEP: Deleting pod pod-subpath-test-downwardapi-hwgb @ 10/26/24 12:21:47.124
  I1026 12:21:47.124828 19 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-hwgb" in namespace "subpath-2995"
  I1026 12:21:47.128664 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2995" for this suite. @ 10/26/24 12:21:47.132
• [24.144 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:258
  STEP: Creating a kubernetes client @ 10/26/24 12:21:47.138
  I1026 12:21:47.138507 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:21:47.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:47.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:47.157
  STEP: Setting up server cert @ 10/26/24 12:21:47.178
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:21:47.387
  STEP: Deploying the webhook pod @ 10/26/24 12:21:47.397
  STEP: Wait for the deployment to be ready @ 10/26/24 12:21:47.409
  I1026 12:21:47.416489 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:21:47.618836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:48.619915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:21:49.433
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:21:49.444
  E1026 12:21:49.620624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:21:50.444386 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 10/26/24 12:21:50.452
  STEP: create a pod that should be updated by the webhook @ 10/26/24 12:21:50.467
  I1026 12:21:50.538650 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9109" for this suite. @ 10/26/24 12:21:50.541
  STEP: Destroying namespace "webhook-markers-7799" for this suite. @ 10/26/24 12:21:50.548
• [3.416 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 10/26/24 12:21:50.554
  I1026 12:21:50.554988 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:21:50.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:50.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:50.571
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 10/26/24 12:21:50.573
  E1026 12:21:50.620994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:51.621182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:21:52.591
  I1026 12:21:52.594457 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-68ca39d6-7790-4d56-9096-0bc8a378fc4d container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:21:52.602
  I1026 12:21:52.618122 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8102" for this suite. @ 10/26/24 12:21:52.621
  E1026 12:21:52.621227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [2.073 seconds]
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 10/26/24 12:21:52.627
  I1026 12:21:52.627770 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pod-network-test @ 10/26/24 12:21:52.628
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:21:52.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:21:52.644
  STEP: Performing setup for networking test in namespace pod-network-test-4526 @ 10/26/24 12:21:52.645
  STEP: creating a selector @ 10/26/24 12:21:52.645
  STEP: Creating the service pods in kubernetes @ 10/26/24 12:21:52.645
  I1026 12:21:52.645702 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1026 12:21:53.621914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:54.622106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:55.622181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:56.622408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:57.622841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:58.622938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:21:59.623035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:00.623890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:01.624022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:02.624106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:03.624204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:04.624262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:05.624831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:06.624925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:07.625030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:08.625143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:09.625265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:10.625877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:11.626007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:12.626130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:13.626185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:14.626894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 10/26/24 12:22:14.754
  E1026 12:22:15.627156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:16.627264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:22:16.789885 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I1026 12:22:16.789919 19 utils.go:496] Going to poll 192.168.29.166 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I1026 12:22:16.792281 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.29.166:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4526 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:22:16.792299 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:22:16.792718 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:22:16.792758 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4526/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.29.166%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I1026 12:22:16.840186 19 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I1026 12:22:16.840232 19 utils.go:496] Going to poll 192.168.46.82 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I1026 12:22:16.843942 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.46.82:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4526 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:22:16.843959 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:22:16.844338 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:22:16.844374 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4526/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.46.82%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I1026 12:22:16.885842 19 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I1026 12:22:16.885875 19 utils.go:496] Going to poll 192.168.232.74 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  I1026 12:22:16.889070 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.232.74:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4526 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:22:16.889084 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:22:16.889443 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:22:16.889484 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4526/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.232.74%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I1026 12:22:16.929449 19 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I1026 12:22:16.929556 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4526" for this suite. @ 10/26/24 12:22:16.933
• [24.313 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:90
  STEP: Creating a kubernetes client @ 10/26/24 12:22:16.94
  I1026 12:22:16.940950 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename disruption @ 10/26/24 12:22:16.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:22:16.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:22:16.956
  STEP: Creating a kubernetes client @ 10/26/24 12:22:16.959
  I1026 12:22:16.959112 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename disruption-2 @ 10/26/24 12:22:16.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:22:16.974
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:22:16.976
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:22:16.982
  E1026 12:22:17.627360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:18.627924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:22:18.993
  E1026 12:22:19.628418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:20.628601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:22:21.002
  E1026 12:22:21.629064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:22.629286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 10/26/24 12:22:23.007
  STEP: listing a collection of PDBs in namespace disruption-9296 @ 10/26/24 12:22:23.01
  STEP: deleting a collection of PDBs @ 10/26/24 12:22:23.014
  STEP: Waiting for the PDB collection to be deleted @ 10/26/24 12:22:23.028
  I1026 12:22:23.032358 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-7019" for this suite. @ 10/26/24 12:22:23.036
  I1026 12:22:23.044250 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9296" for this suite. @ 10/26/24 12:22:23.047
• [6.114 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:107
  STEP: Creating a kubernetes client @ 10/26/24 12:22:23.055
  I1026 12:22:23.055032 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename job @ 10/26/24 12:22:23.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:22:23.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:22:23.071
  STEP: Looking for a node to schedule job pod @ 10/26/24 12:22:23.073
  STEP: Creating a job @ 10/26/24 12:22:23.076
  STEP: Ensuring job fails @ 10/26/24 12:22:23.082
  E1026 12:22:23.629946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:24.630170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:25.631094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:26.631215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:22:27.091485 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8584" for this suite. @ 10/26/24 12:22:27.095
• [4.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 10/26/24 12:22:27.103
  I1026 12:22:27.103040 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename cronjob @ 10/26/24 12:22:27.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:22:27.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:22:27.12
  STEP: Creating a ForbidConcurrent cronjob @ 10/26/24 12:22:27.122
  STEP: Ensuring a job is scheduled @ 10/26/24 12:22:27.127
  E1026 12:22:27.632221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:28.632291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:29.632394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:30.632618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:31.632844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:32.633626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:33.634365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:34.634899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:35.635792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:36.635824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:37.635970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:38.636032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:39.637057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:40.637280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:41.637380      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:42.637608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:43.637768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:44.637974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:45.638054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:46.638162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:47.638815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:48.638966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:49.639196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:50.639317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:51.639835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:52.640087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:53.640198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:54.640315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:55.640433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:56.640645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:57.641620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:58.641881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:22:59.642824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:00.642890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 10/26/24 12:23:01.133
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 10/26/24 12:23:01.136
  STEP: Ensuring no more jobs are scheduled @ 10/26/24 12:23:01.14
  STEP: Removing cronjob @ 10/26/24 12:23:01.143
  I1026 12:23:01.149816 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-868" for this suite. @ 10/26/24 12:23:01.153
• [34.058 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1044
  STEP: Creating a kubernetes client @ 10/26/24 12:23:01.16
  I1026 12:23:01.160992 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:23:01.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:01.18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:01.182
  STEP: create deployment with httpd image @ 10/26/24 12:23:01.185
  I1026 12:23:01.185230 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4254 create -f -'
  I1026 12:23:01.251176 19 builder.go:146] stderr: ""
  I1026 12:23:01.251211 19 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 10/26/24 12:23:01.251
  I1026 12:23:01.251275 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4254 diff -f -'
  E1026 12:23:01.643753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:02.644641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:03.644900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:04.644977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:05.548887 19 builder.go:135] rc: 1
  I1026 12:23:05.548970 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4254 delete -f -'
  I1026 12:23:05.599138 19 builder.go:146] stderr: ""
  I1026 12:23:05.599172 19 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I1026 12:23:05.599289 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4254" for this suite. @ 10/26/24 12:23:05.602
• [4.448 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 10/26/24 12:23:05.609
  I1026 12:23:05.609099 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename svcaccounts @ 10/26/24 12:23:05.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:05.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:05.628
  E1026 12:23:05.645813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:05.659828 19 service_accounts.go:253] created pod pod-service-account-defaultsa
  I1026 12:23:05.659848 19 service_accounts.go:267] pod pod-service-account-defaultsa service account token volume mount: true
  I1026 12:23:05.672037 19 service_accounts.go:253] created pod pod-service-account-mountsa
  I1026 12:23:05.672060 19 service_accounts.go:267] pod pod-service-account-mountsa service account token volume mount: true
  I1026 12:23:05.681996 19 service_accounts.go:253] created pod pod-service-account-nomountsa
  I1026 12:23:05.682014 19 service_accounts.go:267] pod pod-service-account-nomountsa service account token volume mount: false
  I1026 12:23:05.688414 19 service_accounts.go:253] created pod pod-service-account-defaultsa-mountspec
  I1026 12:23:05.688432 19 service_accounts.go:267] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I1026 12:23:05.700404 19 service_accounts.go:253] created pod pod-service-account-mountsa-mountspec
  I1026 12:23:05.700420 19 service_accounts.go:267] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I1026 12:23:05.712047 19 service_accounts.go:253] created pod pod-service-account-nomountsa-mountspec
  I1026 12:23:05.712066 19 service_accounts.go:267] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I1026 12:23:05.741200 19 service_accounts.go:253] created pod pod-service-account-defaultsa-nomountspec
  I1026 12:23:05.741217 19 service_accounts.go:267] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I1026 12:23:05.747978 19 service_accounts.go:253] created pod pod-service-account-mountsa-nomountspec
  I1026 12:23:05.747995 19 service_accounts.go:267] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I1026 12:23:05.757823 19 service_accounts.go:253] created pod pod-service-account-nomountsa-nomountspec
  I1026 12:23:05.757845 19 service_accounts.go:267] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I1026 12:23:05.757925 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8752" for this suite. @ 10/26/24 12:23:05.763
• [0.162 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:348
  STEP: Creating a kubernetes client @ 10/26/24 12:23:05.77
  I1026 12:23:05.771088 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename field-validation @ 10/26/24 12:23:05.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:05.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:05.793
  I1026 12:23:05.794819 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  W1026 12:23:05.795329      19 field_validation.go:421] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0013ff160 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E1026 12:23:06.646829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:07.646938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W1026 12:23:08.329842      19 warnings.go:70] unknown field "alpha"
  W1026 12:23:08.329871      19 warnings.go:70] unknown field "beta"
  W1026 12:23:08.329875      19 warnings.go:70] unknown field "delta"
  W1026 12:23:08.329877      19 warnings.go:70] unknown field "epsilon"
  W1026 12:23:08.329880      19 warnings.go:70] unknown field "gamma"
  E1026 12:23:08.647496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:08.877635 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7832" for this suite. @ 10/26/24 12:23:08.883
• [3.122 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 10/26/24 12:23:08.893
  I1026 12:23:08.893431 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 12:23:08.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:08.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:08.913
  STEP: creating secret secrets-3414/secret-test-2f06c171-3830-4abc-9a7b-769263f266fd @ 10/26/24 12:23:08.915
  STEP: Creating a pod to test consume secrets @ 10/26/24 12:23:08.92
  E1026 12:23:09.647841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:10.648041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:11.649048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:12.649280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:23:12.942
  I1026 12:23:12.945760 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-configmaps-b8dc24d0-d809-44cd-87fa-0501f88c8c2e container env-test: <nil>
  STEP: delete the pod @ 10/26/24 12:23:12.953
  I1026 12:23:12.972881 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3414" for this suite. @ 10/26/24 12:23:12.976
• [4.089 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 10/26/24 12:23:12.982
  I1026 12:23:12.982751 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:23:12.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:12.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:13.002
  STEP: Creating projection with secret that has name projected-secret-test-1a025f78-cc82-431b-9ec3-779002ce5907 @ 10/26/24 12:23:13.004
  STEP: Creating a pod to test consume secrets @ 10/26/24 12:23:13.009
  E1026 12:23:13.649436      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:14.649693      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:15.649807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:16.650007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:23:17.033
  I1026 12:23:17.037475 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-secrets-83fd3a4b-d8c4-4fc0-87c6-f126a4d18e23 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:23:17.046
  I1026 12:23:17.064841 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1463" for this suite. @ 10/26/24 12:23:17.068
• [4.094 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 10/26/24 12:23:17.076
  I1026 12:23:17.076438 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 12:23:17.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:17.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:17.095
  STEP: creating a Pod with a static label @ 10/26/24 12:23:17.101
  STEP: watching for Pod to be ready @ 10/26/24 12:23:17.108
  I1026 12:23:17.109907 19 pods.go:945] observed Pod pod-test in namespace pods-3487 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I1026 12:23:17.113636 19 pods.go:945] observed Pod pod-test in namespace pods-3487 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:17 +0000 UTC  }]
  I1026 12:23:17.137874 19 pods.go:945] observed Pod pod-test in namespace pods-3487 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:17 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:17 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:17 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:17 +0000 UTC  }]
  E1026 12:23:17.650404      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:18.365386 19 pods.go:948] Found Pod pod-test in namespace pods-3487 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:18 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:23:17 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 10/26/24 12:23:18.369
  STEP: getting the Pod and ensuring that it's patched @ 10/26/24 12:23:18.378
  STEP: replacing the Pod's status Ready condition to False @ 10/26/24 12:23:18.382
  STEP: check the Pod again to ensure its Ready conditions are False @ 10/26/24 12:23:18.393
  STEP: deleting the Pod via a Collection with a LabelSelector @ 10/26/24 12:23:18.393
  STEP: watching for the Pod to be deleted @ 10/26/24 12:23:18.404
  I1026 12:23:18.407880 19 pods.go:1058] observed event type MODIFIED
  E1026 12:23:18.651423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:19.652189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:20.366937 19 pods.go:1058] observed event type MODIFIED
  I1026 12:23:20.506243 19 pods.go:1058] observed event type MODIFIED
  E1026 12:23:20.652572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:21.378988 19 pods.go:1058] observed event type MODIFIED
  I1026 12:23:21.385836 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3487" for this suite. @ 10/26/24 12:23:21.389
• [4.322 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 10/26/24 12:23:21.398
  I1026 12:23:21.398836 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename gc @ 10/26/24 12:23:21.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:21.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:21.416
  STEP: create the rc @ 10/26/24 12:23:21.421
  W1026 12:23:21.425718      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1026 12:23:21.653133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:22.653221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:23.654279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:24.654969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:25.655624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:26.656089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 10/26/24 12:23:27.431
  STEP: wait for the rc to be deleted @ 10/26/24 12:23:27.441
  E1026 12:23:27.663648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:28.452895 19 garbage_collector.go:670] 80 pods remaining
  I1026 12:23:28.452922 19 garbage_collector.go:677] 80 pods has nil DeletionTimestamp
  I1026 12:23:28.452929 19 garbage_collector.go:678] 
  E1026 12:23:28.664549      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:29.453045 19 garbage_collector.go:670] 71 pods remaining
  I1026 12:23:29.453095 19 garbage_collector.go:677] 71 pods has nil DeletionTimestamp
  I1026 12:23:29.453103 19 garbage_collector.go:678] 
  E1026 12:23:29.664875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:30.452086 19 garbage_collector.go:670] 60 pods remaining
  I1026 12:23:30.452110 19 garbage_collector.go:677] 60 pods has nil DeletionTimestamp
  I1026 12:23:30.452116 19 garbage_collector.go:678] 
  E1026 12:23:30.665867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:31.455478 19 garbage_collector.go:670] 40 pods remaining
  I1026 12:23:31.455514 19 garbage_collector.go:677] 40 pods has nil DeletionTimestamp
  I1026 12:23:31.455521 19 garbage_collector.go:678] 
  E1026 12:23:31.667050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:32.469840 19 garbage_collector.go:670] 30 pods remaining
  I1026 12:23:32.469872 19 garbage_collector.go:677] 30 pods has nil DeletionTimestamp
  I1026 12:23:32.469879 19 garbage_collector.go:678] 
  E1026 12:23:32.667478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:33.448375 19 garbage_collector.go:670] 20 pods remaining
  I1026 12:23:33.448399 19 garbage_collector.go:677] 20 pods has nil DeletionTimestamp
  I1026 12:23:33.448405 19 garbage_collector.go:678] 
  E1026 12:23:33.667529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 10/26/24 12:23:34.455
  W1026 12:23:34.459522      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1026 12:23:34.459564 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1026 12:23:34.481482 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9695" for this suite. @ 10/26/24 12:23:34.489
• [13.097 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 10/26/24 12:23:34.495
  I1026 12:23:34.495887 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:23:34.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:34.516
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:34.519
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 12:23:34.52
  E1026 12:23:34.667876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:35.668035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:23:36.541
  I1026 12:23:36.545340 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-3cf4038b-ecae-4b5d-a057-32d7b4db4e65 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 12:23:36.551
  I1026 12:23:36.567849 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-911" for this suite. @ 10/26/24 12:23:36.571
• [2.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:337
  STEP: Creating a kubernetes client @ 10/26/24 12:23:36.578
  I1026 12:23:36.578056 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename security-context @ 10/26/24 12:23:36.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:36.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:36.598
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 10/26/24 12:23:36.599
  E1026 12:23:36.668763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:37.668844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:23:38.618
  I1026 12:23:38.621248 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod security-context-6ddab536-d96c-44f3-a5f0-d5dbfaaf64d8 container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:23:38.629
  I1026 12:23:38.645826 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-3230" for this suite. @ 10/26/24 12:23:38.649
• [2.077 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 10/26/24 12:23:38.655
  I1026 12:23:38.655308 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 12:23:38.655
  E1026 12:23:38.668832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:38.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:38.672
  STEP: Create set of pods @ 10/26/24 12:23:38.675
  I1026 12:23:38.682789 19 pods.go:871] created test-pod-1
  I1026 12:23:38.691321 19 pods.go:871] created test-pod-2
  I1026 12:23:38.699812 19 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 10/26/24 12:23:38.699
  E1026 12:23:39.668957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:40.669068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 10/26/24 12:23:40.738
  I1026 12:23:40.740990 19 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  E1026 12:23:41.669969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:41.742049 19 pods.go:1140] Pod quantity 2 is different from expected quantity 0
  E1026 12:23:42.670999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:42.742116 19 pods.go:1140] Pod quantity 1 is different from expected quantity 0
  E1026 12:23:43.672006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:43.740957 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2003" for this suite. @ 10/26/24 12:23:43.745
• [5.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 10/26/24 12:23:43.757
  I1026 12:23:43.757436 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename namespaces @ 10/26/24 12:23:43.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:43.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:43.775
  STEP: Read namespace status @ 10/26/24 12:23:43.783
  I1026 12:23:43.788854 19 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 10/26/24 12:23:43.788
  I1026 12:23:43.794818 19 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 10/26/24 12:23:43.794
  I1026 12:23:43.804536 19 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I1026 12:23:43.804619 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-555" for this suite. @ 10/26/24 12:23:43.808
• [0.060 seconds]
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 10/26/24 12:23:43.817
  I1026 12:23:43.817423 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename var-expansion @ 10/26/24 12:23:43.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:43.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:43.837
  STEP: Creating a pod to test env composition @ 10/26/24 12:23:43.843
  E1026 12:23:44.672081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:45.672201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:46.672292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:47.672401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:23:47.868
  I1026 12:23:47.871959 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod var-expansion-ae45ff20-cc5c-4306-9761-e84052902cf0 container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 12:23:47.881
  I1026 12:23:47.898285 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9971" for this suite. @ 10/26/24 12:23:47.901
• [4.092 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1756
  STEP: Creating a kubernetes client @ 10/26/24 12:23:47.909
  I1026 12:23:47.909815 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:23:47.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:47.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:47.927
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 10/26/24 12:23:47.93
  I1026 12:23:47.930095 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-1040 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I1026 12:23:47.985508 19 builder.go:146] stderr: ""
  I1026 12:23:47.985533 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 10/26/24 12:23:47.985
  I1026 12:23:47.988515 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-1040 delete pods e2e-test-httpd-pod'
  E1026 12:23:48.673369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:49.430119 19 builder.go:146] stderr: ""
  I1026 12:23:49.430155 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I1026 12:23:49.430276 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1040" for this suite. @ 10/26/24 12:23:49.435
• [1.534 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 10/26/24 12:23:49.443
  I1026 12:23:49.443906 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename aggregateddiscovery @ 10/26/24 12:23:49.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:49.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:49.469
  I1026 12:23:49.473472 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:23:49.673893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:50.674780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:51.674818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:23:52.526038 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-5190" for this suite. @ 10/26/24 12:23:52.529
• [3.093 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 10/26/24 12:23:52.537
  I1026 12:23:52.537140 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename namespaces @ 10/26/24 12:23:52.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:52.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:23:52.555
  STEP: Creating a test namespace @ 10/26/24 12:23:52.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:23:52.569
  STEP: Creating a pod in the namespace @ 10/26/24 12:23:52.571
  STEP: Waiting for the pod to have running status @ 10/26/24 12:23:52.581
  E1026 12:23:52.675358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:53.676358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 10/26/24 12:23:54.591
  STEP: Waiting for the namespace to be removed. @ 10/26/24 12:23:54.598
  E1026 12:23:54.676950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:55.677506      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:56.678057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:57.678106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:58.678400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:23:59.678624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:00.679111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:01.680086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:02.680568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:03.680911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:04.681834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 10/26/24 12:24:05.602
  STEP: Verifying there are no pods in the namespace @ 10/26/24 12:24:05.618
  I1026 12:24:05.623453 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3215" for this suite. @ 10/26/24 12:24:05.628
  STEP: Destroying namespace "nsdeletetest-6539" for this suite. @ 10/26/24 12:24:05.636
  I1026 12:24:05.640588 19 framework.go:370] Namespace nsdeletetest-6539 was already deleted
  STEP: Destroying namespace "nsdeletetest-2815" for this suite. @ 10/26/24 12:24:05.64
• [13.110 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:246
  STEP: Creating a kubernetes client @ 10/26/24 12:24:05.646
  I1026 12:24:05.646874 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename dns @ 10/26/24 12:24:05.647
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:05.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:05.665
  STEP: Creating a test headless service @ 10/26/24 12:24:05.666
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2260.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2260.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 10/26/24 12:24:05.671
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2260.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2260.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 10/26/24 12:24:05.671
  STEP: creating a pod to probe DNS @ 10/26/24 12:24:05.671
  STEP: submitting the pod to kubernetes @ 10/26/24 12:24:05.671
  E1026 12:24:05.682743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:06.683149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:07.683241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:08.683910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:09.684898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:10.685841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:11.686909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 12:24:11.706
  STEP: looking for the results for each expected name from probers @ 10/26/24 12:24:11.709
  I1026 12:24:11.727895 19 dns_common.go:527] DNS probes using dns-2260/dns-test-1616b8d5-01b2-4008-a34d-5baf58260729 succeeded

  STEP: deleting the pod @ 10/26/24 12:24:11.728
  STEP: deleting the test headless service @ 10/26/24 12:24:11.739
  I1026 12:24:11.755612 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2260" for this suite. @ 10/26/24 12:24:11.758
• [6.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 10/26/24 12:24:11.766
  I1026 12:24:11.766611 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 12:24:11.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:11.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:11.782
  STEP: Creating secret with name secret-test-map-1beebbc7-9707-4a9a-b9ba-d0a586224c41 @ 10/26/24 12:24:11.783
  STEP: Creating a pod to test consume secrets @ 10/26/24 12:24:11.789
  E1026 12:24:12.687034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:13.687286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:14.687419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:15.687578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:24:15.813
  I1026 12:24:15.816876 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-secrets-2240ee1f-f555-4e1f-9784-8d6ed785081e container secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:24:15.824
  I1026 12:24:15.842357 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9694" for this suite. @ 10/26/24 12:24:15.845
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 10/26/24 12:24:15.854
  I1026 12:24:15.854428 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 12:24:15.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:15.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:15.872
  STEP: creating the pod @ 10/26/24 12:24:15.874
  STEP: submitting the pod to kubernetes @ 10/26/24 12:24:15.874
  E1026 12:24:16.687725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:17.687936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 10/26/24 12:24:17.893
  STEP: updating the pod @ 10/26/24 12:24:17.896
  I1026 12:24:18.410240 19 pod_client.go:173] Successfully updated pod "pod-update-8583c4a1-caef-42f9-a9ae-b00d505c58e8"
  STEP: verifying the updated pod is in kubernetes @ 10/26/24 12:24:18.413
  I1026 12:24:18.417530 19 pods.go:391] Pod update OK
  I1026 12:24:18.417647 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7040" for this suite. @ 10/26/24 12:24:18.423
• [2.576 seconds]
------------------------------
SS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 10/26/24 12:24:18.43
  I1026 12:24:18.430276 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename deployment @ 10/26/24 12:24:18.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:18.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:18.448
  I1026 12:24:18.460398 19 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E1026 12:24:18.687991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:19.688207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:20.688303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:21.688463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:22.688880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:24:23.465216 19 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 10/26/24 12:24:23.465
  I1026 12:24:23.465290 19 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 10/26/24 12:24:23.472
  I1026 12:24:23.484740 19 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5353",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d65e7452-d9b9-45ab-b616-2a84b9382eee",
      ResourceVersion: (string) (len=5) "12583",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542263,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542263,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1026 12:24:23.488191 19 deployment.go:41] New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  I1026 12:24:23.488209 19 deployment.go:44] All old ReplicaSets of Deployment "test-cleanup-deployment":
  I1026 12:24:23.488426 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5353",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8597ac38-0dfc-43c1-82c0-7a608e57b3fa",
      ResourceVersion: (string) (len=5) "12585",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542258,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "pod": (string) (len=5) "httpd",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "d65e7452-d9b9-45ab-b616-2a84b9382eee",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542258,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542259,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542263,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 64 36 35 65 37 34 35  |"uid\":\"d65e745|
              00000040  32 2d 64 39 62 39 2d 34  35 61 62 2d 62 36 31 36  |2-d9b9-45ab-b616|
              00000050  2d 32 61 38 34 62 39 33  38 32 65 65 65 5c 22 7d  |-2a84b9382eee\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:24:23.493563 19 deployment.go:67] Pod "test-cleanup-controller-d2wpq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-d2wpq",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-5353",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1ecd3fd3-80b9-493c-9f20-a2f18a2ad03f",
      ResourceVersion: (string) (len=5) "12559",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542258,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "8597ac38-0dfc-43c1-82c0-7a608e57b3fa",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542258,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  38 35 39 37 61 63 33 38  |uid\":\"8597ac38|
              00000080  2d 30 64 66 63 2d 34 33  63 31 2d 38 32 63 30 2d  |-0dfc-43c1-82c0-|
              00000090  37 61 36 30 38 65 35 37  62 33 66 61 5c 22 7d 22  |7a608e57b3fa\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542259,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 36  2e 31 31 39 5c 22 7d 22  |2.168.46.119\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8mpr4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8mpr4",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542259,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542258,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542259,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542259,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542258,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.104",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.104"
        }
      },
      PodIP: (string) (len=14) "192.168.46.119",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.46.119"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542258,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865542259,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://51920753c0683178f531ef07338b9a5e9f04071c5dae883f6ee25be2810a7552",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-8mpr4",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:24:23.494625 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5353" for this suite. @ 10/26/24 12:24:23.501
• [5.078 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1513
  STEP: Creating a kubernetes client @ 10/26/24 12:24:23.508
  I1026 12:24:23.508361 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 12:24:23.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:23.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:23.534
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-8687 @ 10/26/24 12:24:23.537
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 10/26/24 12:24:23.555
  STEP: creating service externalsvc in namespace services-8687 @ 10/26/24 12:24:23.555
  STEP: creating replication controller externalsvc in namespace services-8687 @ 10/26/24 12:24:23.578
  I1026 12:24:23.587280      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8687, replica count: 2
  E1026 12:24:23.689914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:24.690913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:25.691019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:24:26.638977      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 10/26/24 12:24:26.643
  I1026 12:24:26.663847 19 resource.go:361] Creating new exec pod
  E1026 12:24:26.691561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:27.691750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:24:28.680583 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-8687 exec execpodzdkxd -- /bin/sh -x -c nslookup nodeport-service.services-8687.svc.cluster.local'
  E1026 12:24:28.692014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:24:28.821772 19 builder.go:146] stderr: "+ nslookup nodeport-service.services-8687.svc.cluster.local\n"
  I1026 12:24:28.821958 19 builder.go:147] stdout: "Server:\t\t10.152.183.57\nAddress:\t10.152.183.57#53\n\nnodeport-service.services-8687.svc.cluster.local\tcanonical name = externalsvc.services-8687.svc.cluster.local.\nName:\texternalsvc.services-8687.svc.cluster.local\nAddress: 10.152.183.185\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-8687, will wait for the garbage collector to delete the pods @ 10/26/24 12:24:28.822
  I1026 12:24:28.839524 19 resources.go:139] Deleting ReplicationController externalsvc took: 5.581126ms
  I1026 12:24:28.940285 19 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.754536ms
  E1026 12:24:29.692351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:30.692410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:24:31.562807 19 service.go:1524] Cleaning up the NodePort to ExternalName test service
  I1026 12:24:31.573366 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8687" for this suite. @ 10/26/24 12:24:31.577
• [8.080 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:495
  STEP: Creating a kubernetes client @ 10/26/24 12:24:31.588
  I1026 12:24:31.588818 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:24:31.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:31.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:31.604
  STEP: Setting up server cert @ 10/26/24 12:24:31.629
  E1026 12:24:31.692924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:24:32.344
  STEP: Deploying the webhook pod @ 10/26/24 12:24:32.377
  STEP: Wait for the deployment to be ready @ 10/26/24 12:24:32.393
  I1026 12:24:32.403712 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:24:32.693897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:33.694003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:24:34.415
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:24:34.426
  E1026 12:24:34.694897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:24:35.426759 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 10/26/24 12:24:35.433
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 10/26/24 12:24:35.451
  STEP: Creating a configMap that should not be mutated @ 10/26/24 12:24:35.458
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 10/26/24 12:24:35.468
  STEP: Creating a configMap that should be mutated @ 10/26/24 12:24:35.475
  I1026 12:24:35.534613 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9171" for this suite. @ 10/26/24 12:24:35.538
  STEP: Destroying namespace "webhook-markers-6850" for this suite. @ 10/26/24 12:24:35.547
• [3.965 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 10/26/24 12:24:35.553
  I1026 12:24:35.553570 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:24:35.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:35.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:35.57
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 12:24:35.571
  E1026 12:24:35.695420      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:36.695891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:37.696494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:38.697363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:24:39.596
  I1026 12:24:39.601718 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-052b6770-fdbf-4da3-8815-27e9fdfa0773 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 12:24:39.609
  I1026 12:24:39.630416 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7709" for this suite. @ 10/26/24 12:24:39.634
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 10/26/24 12:24:39.642
  I1026 12:24:39.642670 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename apf @ 10/26/24 12:24:39.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:39.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:39.66
  STEP: getting /apis @ 10/26/24 12:24:39.662
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 10/26/24 12:24:39.665
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 10/26/24 12:24:39.665
  STEP: creating @ 10/26/24 12:24:39.666
  STEP: getting @ 10/26/24 12:24:39.684
  STEP: listing @ 10/26/24 12:24:39.693
  STEP: watching @ 10/26/24 12:24:39.696
  I1026 12:24:39.696656 19 flowcontrol.go:394] starting watch
  STEP: patching @ 10/26/24 12:24:39.697
  E1026 12:24:39.697376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating @ 10/26/24 12:24:39.702
  I1026 12:24:39.710463 19 flowcontrol.go:422] waiting for watch events with expected annotations
  STEP: getting /status @ 10/26/24 12:24:39.71
  STEP: patching /status @ 10/26/24 12:24:39.713
  STEP: updating /status @ 10/26/24 12:24:39.718
  STEP: deleting @ 10/26/24 12:24:39.748
  STEP: deleting a collection @ 10/26/24 12:24:39.765
  I1026 12:24:39.786050 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-2534" for this suite. @ 10/26/24 12:24:39.789
• [0.154 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 10/26/24 12:24:39.796
  I1026 12:24:39.796910 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pod-network-test @ 10/26/24 12:24:39.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:39.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:39.813
  STEP: Performing setup for networking test in namespace pod-network-test-6007 @ 10/26/24 12:24:39.815
  STEP: creating a selector @ 10/26/24 12:24:39.815
  STEP: Creating the service pods in kubernetes @ 10/26/24 12:24:39.815
  I1026 12:24:39.815312 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1026 12:24:40.697839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:41.698031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:42.698130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:43.698243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:44.698337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:45.698528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:46.698712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:47.698867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:48.698946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:49.699112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:50.699215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:51.699909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 10/26/24 12:24:51.892
  E1026 12:24:52.700381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:53.700476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:24:53.909656 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I1026 12:24:53.909706 19 networking.go:42] Breadth first check of 192.168.29.159 on host 172.31.30.144...
  I1026 12:24:53.912653 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.29.160:9080/dial?request=hostname&protocol=udp&host=192.168.29.159&port=8081&tries=1'] Namespace:pod-network-test-6007 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:24:53.912700 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:24:53.913115 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:24:53.913159 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6007/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.29.160%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.29.159%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1026 12:24:53.959494 19 utils.go:356] Waiting for responses: map[]
  I1026 12:24:53.959527 19 utils.go:360] reached 192.168.29.159 after 0/1 tries
  I1026 12:24:53.959537 19 networking.go:42] Breadth first check of 192.168.46.121 on host 172.31.35.104...
  I1026 12:24:53.963455 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.29.160:9080/dial?request=hostname&protocol=udp&host=192.168.46.121&port=8081&tries=1'] Namespace:pod-network-test-6007 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:24:53.963479 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:24:53.963837 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:24:53.963881 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6007/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.29.160%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.46.121%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1026 12:24:54.004775 19 utils.go:356] Waiting for responses: map[]
  I1026 12:24:54.004807 19 utils.go:360] reached 192.168.46.121 after 0/1 tries
  I1026 12:24:54.004815 19 networking.go:42] Breadth first check of 192.168.232.111 on host 172.31.8.187...
  I1026 12:24:54.008026 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.29.160:9080/dial?request=hostname&protocol=udp&host=192.168.232.111&port=8081&tries=1'] Namespace:pod-network-test-6007 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:24:54.008040 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:24:54.008348 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:24:54.008385 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6007/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.29.160%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.232.111%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1026 12:24:54.046731 19 utils.go:356] Waiting for responses: map[]
  I1026 12:24:54.046756 19 utils.go:360] reached 192.168.232.111 after 0/1 tries
  I1026 12:24:54.046764 19 networking.go:53] Going to retry 0 out of 3 pods....
  I1026 12:24:54.046904 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6007" for this suite. @ 10/26/24 12:24:54.051
• [14.261 seconds]
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 10/26/24 12:24:54.058
  I1026 12:24:54.058415 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:24:54.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:24:54.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:24:54.076
  STEP: Creating secret with name s-test-opt-del-53a17dc9-d49d-4b1a-a71a-9d2ccda97774 @ 10/26/24 12:24:54.081
  STEP: Creating secret with name s-test-opt-upd-09179491-2333-433e-a98f-a81f5992591c @ 10/26/24 12:24:54.085
  STEP: Creating the pod @ 10/26/24 12:24:54.089
  E1026 12:24:54.700600      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:55.701655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-53a17dc9-d49d-4b1a-a71a-9d2ccda97774 @ 10/26/24 12:24:56.131
  STEP: Updating secret s-test-opt-upd-09179491-2333-433e-a98f-a81f5992591c @ 10/26/24 12:24:56.138
  STEP: Creating secret with name s-test-opt-create-06a3e1d9-582c-4d3e-9931-1f95ec49f7bf @ 10/26/24 12:24:56.143
  STEP: waiting to observe update in volume @ 10/26/24 12:24:56.15
  E1026 12:24:56.701803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:57.702020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:58.702634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:24:59.702866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:00.702921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:01.703032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:02.704029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:03.704152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:04.704920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:05.705532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:06.706615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:07.706840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:08.706945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:09.707622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:10.708366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:11.708470      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:12.708522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:13.709445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:14.710175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:15.710365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:16.711144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:17.711266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:18.712215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:19.712332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:20.713205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:21.713290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:22.713398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:23.714395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:24.714871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:25.715860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:26.716861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:27.717097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:28.717923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:29.718157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:30.718818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:31.719027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:32.719154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:33.719312      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:34.719427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:35.719540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:36.720123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:37.720394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:38.720524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:39.720644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:40.720935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:41.721033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:42.721155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:43.721957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:44.722991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:45.723090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:46.723171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:47.723210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:48.723768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:49.723843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:50.723929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:51.724000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:52.724217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:53.724342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:54.724864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:55.725912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:56.725986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:57.726090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:58.726130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:25:59.726914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:00.727150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:01.727916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:02.728012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:03.729018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:04.729152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:05.729264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:06.502094 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-297" for this suite. @ 10/26/24 12:26:06.506
• [72.454 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 10/26/24 12:26:06.513
  I1026 12:26:06.513742 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 12:26:06.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:26:06.534
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:26:06.536
  I1026 12:26:06.538312 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:26:06.729887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:07.730661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 10/26/24 12:26:07.742
  I1026 12:26:07.742551 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-6828 --namespace=crd-publish-openapi-6828 create -f -'
  E1026 12:26:08.730907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:09.731127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:09.805363 19 builder.go:146] stderr: ""
  I1026 12:26:09.805401 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-953-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I1026 12:26:09.805456 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-6828 --namespace=crd-publish-openapi-6828 delete e2e-test-crd-publish-openapi-953-crds test-cr'
  I1026 12:26:09.866811 19 builder.go:146] stderr: ""
  I1026 12:26:09.866846 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-953-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I1026 12:26:09.866896 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-6828 --namespace=crd-publish-openapi-6828 apply -f -'
  I1026 12:26:09.921935 19 builder.go:146] stderr: ""
  I1026 12:26:09.921966 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-953-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I1026 12:26:09.922016 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-6828 --namespace=crd-publish-openapi-6828 delete e2e-test-crd-publish-openapi-953-crds test-cr'
  I1026 12:26:09.970217 19 builder.go:146] stderr: ""
  I1026 12:26:09.970249 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-953-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 10/26/24 12:26:09.97
  I1026 12:26:09.970301 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-6828 explain e2e-test-crd-publish-openapi-953-crds'
  I1026 12:26:10.010575 19 builder.go:146] stderr: ""
  I1026 12:26:10.010625 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-953-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E1026 12:26:10.731814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:11.278396 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6828" for this suite. @ 10/26/24 12:26:11.302
• [4.809 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:754
  STEP: Creating a kubernetes client @ 10/26/24 12:26:11.322
  I1026 12:26:11.322586 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename statefulset @ 10/26/24 12:26:11.323
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:26:11.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:26:11.354
  STEP: Creating service test in namespace statefulset-5599 @ 10/26/24 12:26:11.361
  STEP: Creating stateful set ss in namespace statefulset-5599 @ 10/26/24 12:26:11.367
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5599 @ 10/26/24 12:26:11.375
  I1026 12:26:11.381275 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E1026 12:26:11.732832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:12.733888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:13.734896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:14.735891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:15.735989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:16.736220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:17.736907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:18.737353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:19.737900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:20.738131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:21.380889 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 10/26/24 12:26:21.38
  I1026 12:26:21.385123 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-5599 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 12:26:21.482650 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 12:26:21.482709 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 12:26:21.482720 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1026 12:26:21.486874 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1026 12:26:21.738216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:22.738436      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:23.738779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:24.739013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:25.739106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:26.739193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:27.739379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:28.739482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:29.739708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:30.739813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:31.489131 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I1026 12:26:31.489176 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I1026 12:26:31.507124 19 resource.go:168] POD   NODE              PHASE    GRACE  CONDITIONS
  I1026 12:26:31.507175 19 resource.go:175] ss-0  ip-172-31-35-104  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:12 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:11 +0000 UTC  }]
  I1026 12:26:31.507183 19 resource.go:178] 
  I1026 12:26:31.507190 19 statefulset.go:2413] StatefulSet ss has not reached scale 3, at 1
  E1026 12:26:31.740533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:32.512133 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 8.996114677s
  E1026 12:26:32.740576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:33.517763 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 7.990628375s
  E1026 12:26:33.740886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:34.524780 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 6.984730181s
  E1026 12:26:34.741048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:35.530467 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 5.978614757s
  E1026 12:26:35.741885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:36.535516 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 4.972807284s
  E1026 12:26:36.742880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:37.541128 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 3.967763564s
  E1026 12:26:37.743499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:38.546511 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 2.961989738s
  E1026 12:26:38.743849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:39.551825 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 1.956799268s
  E1026 12:26:39.743948      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:40.557862 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 950.634035ms
  E1026 12:26:40.744013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5599 @ 10/26/24 12:26:41.558
  I1026 12:26:41.564919 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-5599 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1026 12:26:41.646145 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1026 12:26:41.646191 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 12:26:41.646202 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1026 12:26:41.646279 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-5599 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1026 12:26:41.735025 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I1026 12:26:41.735067 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 12:26:41.735076 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1026 12:26:41.735125 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-5599 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1026 12:26:41.744385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:41.810075 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I1026 12:26:41.810118 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 12:26:41.810130 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1026 12:26:41.815852 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:26:41.815873 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:26:41.815880 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 10/26/24 12:26:41.815
  I1026 12:26:41.819815 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-5599 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 12:26:41.905060 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 12:26:41.905123 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 12:26:41.905134 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1026 12:26:41.905196 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-5599 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 12:26:41.998850 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 12:26:41.998883 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 12:26:41.998892 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1026 12:26:41.998929 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-5599 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 12:26:42.084419 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 12:26:42.084449 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 12:26:42.084459 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1026 12:26:42.084468 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I1026 12:26:42.090498 19 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E1026 12:26:42.744898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:43.744938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:44.745919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:45.746899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:46.747880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:47.748008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:48.748376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:49.748567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:50.748882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:26:51.749863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:52.094254 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I1026 12:26:52.094286 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I1026 12:26:52.094293 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I1026 12:26:52.107936 19 resource.go:168] POD   NODE              PHASE    GRACE  CONDITIONS
  I1026 12:26:52.107982 19 resource.go:175] ss-0  ip-172-31-35-104  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:12 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:42 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:42 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:11 +0000 UTC  }]
  I1026 12:26:52.108001 19 resource.go:175] ss-1  ip-172-31-8-187   Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:32 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:42 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:42 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:31 +0000 UTC  }]
  I1026 12:26:52.108020 19 resource.go:175] ss-2  ip-172-31-30-144  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:32 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:42 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:42 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-10-26 12:26:31 +0000 UTC  }]
  I1026 12:26:52.108025 19 resource.go:178] 
  I1026 12:26:52.108031 19 statefulset.go:2413] StatefulSet ss has not reached scale 0, at 3
  E1026 12:26:52.750349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:53.114987 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 8.995923365s
  E1026 12:26:53.750912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:54.120413 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 7.989436372s
  E1026 12:26:54.751142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:55.126550 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 6.984196264s
  E1026 12:26:55.751335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:56.132834 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 5.977879991s
  E1026 12:26:56.751422      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:57.139816 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 4.971084574s
  E1026 12:26:57.751607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:58.145250 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 3.964691927s
  E1026 12:26:58.751755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:26:59.152559 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 2.958268962s
  E1026 12:26:59.751872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:27:00.158099 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 1.951665923s
  E1026 12:27:00.752887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:27:01.162871 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 0 for another 946.391202ms
  E1026 12:27:01.753715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5599 @ 10/26/24 12:27:02.163
  I1026 12:27:02.169657 19 rest.go:150] Scaling statefulset ss to 0
  I1026 12:27:02.177779 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1026 12:27:02.182047 19 statefulset.go:138] Deleting all statefulset in ns statefulset-5599
  I1026 12:27:02.188044 19 rest.go:150] Scaling statefulset ss to 0
  I1026 12:27:02.195617 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1026 12:27:02.198814 19 rest.go:88] Deleting statefulset ss
  I1026 12:27:02.214276 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5599" for this suite. @ 10/26/24 12:27:02.217
• [50.901 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 10/26/24 12:27:02.223
  I1026 12:27:02.223510 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename security-context-test @ 10/26/24 12:27:02.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:02.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:02.247
  E1026 12:27:02.754648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:03.755512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:04.756218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:05.756465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:27:06.287576 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4463" for this suite. @ 10/26/24 12:27:06.293
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:331
  STEP: Creating a kubernetes client @ 10/26/24 12:27:06.301
  I1026 12:27:06.301499 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 12:27:06.302
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:06.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:06.321
  E1026 12:27:06.756541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:07.756906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:08.757117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:09.757168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:10.757310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:11.758206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:12.758491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:13.758579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:14.759488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:15.759658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:16.760045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:17.760809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:18.761503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:19.762216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:20.763295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:21.763370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:22.763471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 10/26/24 12:27:23.331
  E1026 12:27:23.763583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:24.763888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:25.764808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:26.764813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:27.765920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 10/26/24 12:27:28.337
  STEP: Ensuring resource quota status is calculated @ 10/26/24 12:27:28.343
  E1026 12:27:28.766009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:29.766915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 10/26/24 12:27:30.348
  STEP: Ensuring resource quota status captures configMap creation @ 10/26/24 12:27:30.362
  E1026 12:27:30.767932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:31.768059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 10/26/24 12:27:32.367
  STEP: Ensuring resource quota status released usage @ 10/26/24 12:27:32.374
  E1026 12:27:32.769053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:33.769116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:27:34.379549 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8148" for this suite. @ 10/26/24 12:27:34.383
• [28.089 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 10/26/24 12:27:34.391
  I1026 12:27:34.391109 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename ingress @ 10/26/24 12:27:34.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:34.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:34.412
  STEP: getting /apis @ 10/26/24 12:27:34.416
  STEP: getting /apis/networking.k8s.io @ 10/26/24 12:27:34.419
  STEP: getting /apis/networking.k8s.iov1 @ 10/26/24 12:27:34.42
  STEP: creating @ 10/26/24 12:27:34.422
  STEP: getting @ 10/26/24 12:27:34.44
  STEP: listing @ 10/26/24 12:27:34.448
  STEP: watching @ 10/26/24 12:27:34.454
  I1026 12:27:34.454368 19 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 10/26/24 12:27:34.455
  STEP: cluster-wide watching @ 10/26/24 12:27:34.459
  I1026 12:27:34.459519 19 ingress.go:198] starting watch
  STEP: patching @ 10/26/24 12:27:34.461
  STEP: updating @ 10/26/24 12:27:34.467
  I1026 12:27:34.475568 19 ingress.go:221] waiting for watch events with expected annotations
  I1026 12:27:34.475597 19 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 10/26/24 12:27:34.475
  STEP: updating /status @ 10/26/24 12:27:34.488
  STEP: get /status @ 10/26/24 12:27:34.496
  STEP: deleting @ 10/26/24 12:27:34.503
  STEP: deleting a collection @ 10/26/24 12:27:34.521
  I1026 12:27:34.541086 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-2281" for this suite. @ 10/26/24 12:27:34.545
• [0.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1791
  STEP: Creating a kubernetes client @ 10/26/24 12:27:34.553
  I1026 12:27:34.553383 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:27:34.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:34.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:34.574
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 10/26/24 12:27:34.577
  I1026 12:27:34.577978 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4185 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I1026 12:27:34.634209 19 builder.go:146] stderr: ""
  I1026 12:27:34.634234 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 10/26/24 12:27:34.634
  E1026 12:27:34.769885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:35.770013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:36.770239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:37.770362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:38.770601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 10/26/24 12:27:39.684
  I1026 12:27:39.684830 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4185 get pod e2e-test-httpd-pod -o json'
  I1026 12:27:39.725726 19 builder.go:146] stderr: ""
  I1026 12:27:39.725823 19 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-10-26T12:27:34Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4185\",\n        \"resourceVersion\": \"13760\",\n        \"uid\": \"5c9535bb-347f-4e8d-a97d-6135999a079e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-gwgz2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-30-144\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-gwgz2\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-10-26T12:27:35Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-10-26T12:27:34Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-10-26T12:27:35Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-10-26T12:27:35Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-10-26T12:27:34Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://ff0f2a7602460cbc53190b311455ef0a121169b7b70eb068746d1ca7fb2a7406\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-10-26T12:27:35Z\"\n                    }\n                },\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-gwgz2\",\n                        \"readOnly\": true,\n                        \"recursiveReadOnly\": \"Disabled\"\n                    }\n                ]\n            }\n        ],\n        \"hostIP\": \"172.31.30.144\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.31.30.144\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.29.164\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.29.164\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-10-26T12:27:34Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 10/26/24 12:27:39.725
  I1026 12:27:39.725907 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4185 replace -f -'
  E1026 12:27:39.771345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:27:39.815390 19 builder.go:146] stderr: ""
  I1026 12:27:39.815418 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 10/26/24 12:27:39.815
  I1026 12:27:39.820387 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4185 delete pods e2e-test-httpd-pod'
  E1026 12:27:40.771287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:41.771423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:27:41.867263 19 builder.go:146] stderr: ""
  I1026 12:27:41.867297 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I1026 12:27:41.867403 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4185" for this suite. @ 10/26/24 12:27:41.872
• [7.327 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 10/26/24 12:27:41.88
  I1026 12:27:41.880229 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename prestop @ 10/26/24 12:27:41.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:41.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:41.901
  STEP: Creating server pod server in namespace prestop-6336 @ 10/26/24 12:27:41.904
  STEP: Waiting for pods to come up. @ 10/26/24 12:27:41.914
  E1026 12:27:42.771549      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:43.771801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-6336 @ 10/26/24 12:27:43.935
  E1026 12:27:44.771894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:45.772003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 10/26/24 12:27:45.95
  E1026 12:27:46.772108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:47.772229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:48.772447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:49.772658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:50.772900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:27:50.968287 19 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 10/26/24 12:27:50.968
  I1026 12:27:50.985692 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-6336" for this suite. @ 10/26/24 12:27:50.989
• [9.117 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 10/26/24 12:27:50.996
  I1026 12:27:50.996976 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename aggregateddiscovery @ 10/26/24 12:27:50.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:51.019
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:51.022
  I1026 12:27:51.029249 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-2922" for this suite. @ 10/26/24 12:27:51.034
• [0.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 10/26/24 12:27:51.043
  I1026 12:27:51.043907 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:27:51.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:51.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:51.063
  STEP: Creating configMap with name projected-configmap-test-volume-e1724220-9a22-489f-a0ae-5afaaa12b8c2 @ 10/26/24 12:27:51.066
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:27:51.071
  E1026 12:27:51.773014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:52.773114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:27:53.096
  I1026 12:27:53.100841 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-configmaps-87aa305e-1190-4432-adb1-17eeb2de21e6 container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:27:53.108
  I1026 12:27:53.129358 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8145" for this suite. @ 10/26/24 12:27:53.133
• [2.095 seconds]
------------------------------
S
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 10/26/24 12:27:53.138
  I1026 12:27:53.139006 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 12:27:53.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:53.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:53.161
  STEP: creating the pod @ 10/26/24 12:27:53.164
  STEP: submitting the pod to kubernetes @ 10/26/24 12:27:53.164
  STEP: verifying QOS class is set on the pod @ 10/26/24 12:27:53.171
  I1026 12:27:53.179499 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2329" for this suite. @ 10/26/24 12:27:53.183
• [0.053 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 10/26/24 12:27:53.191
  I1026 12:27:53.191744 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:27:53.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:53.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:53.214
  STEP: Creating configMap with name configmap-test-volume-map-23578f66-48ae-4e98-aabe-c5d6ab22af69 @ 10/26/24 12:27:53.217
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:27:53.222
  E1026 12:27:53.773206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:54.773304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:27:55.248
  I1026 12:27:55.254307 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-configmaps-2c89d540-6e60-47c3-a53b-d03e082b0e16 container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:27:55.262
  I1026 12:27:55.278113 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8922" for this suite. @ 10/26/24 12:27:55.281
• [2.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 10/26/24 12:27:55.29
  I1026 12:27:55.290913 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 12:27:55.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:27:55.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:27:55.311
  STEP: set up a multi version CRD @ 10/26/24 12:27:55.314
  I1026 12:27:55.314933 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:27:55.773903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:56.774903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:27:57.775112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 10/26/24 12:27:58.439
  STEP: check the unserved version gets removed @ 10/26/24 12:27:58.456
  E1026 12:27:58.775254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 10/26/24 12:27:59.184
  E1026 12:27:59.775466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:00.775910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:28:01.666139 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6667" for this suite. @ 10/26/24 12:28:01.674
• [6.392 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 10/26/24 12:28:01.682
  I1026 12:28:01.682812 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:28:01.683
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:28:01.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:28:01.706
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 12:28:01.709
  E1026 12:28:01.776833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:02.776938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:03.777124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:04.777171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:28:05.738
  I1026 12:28:05.742927 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-fa3690da-9180-410e-8613-8ae2eac25dd9 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 12:28:05.75
  I1026 12:28:05.767398 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7684" for this suite. @ 10/26/24 12:28:05.771
  E1026 12:28:05.777191      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 10/26/24 12:28:05.78
  I1026 12:28:05.780972 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename runtimeclass @ 10/26/24 12:28:05.781
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:28:05.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:28:05.803
  I1026 12:28:05.813496 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4592" for this suite. @ 10/26/24 12:28:05.816
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 10/26/24 12:28:05.823
  I1026 12:28:05.823889 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename gc @ 10/26/24 12:28:05.824
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:28:05.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:28:05.844
  STEP: create the rc @ 10/26/24 12:28:05.852
  W1026 12:28:05.857202      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1026 12:28:06.777416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:07.780810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:08.781572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:09.784093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:10.785898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:11.803764      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 10/26/24 12:28:11.861
  STEP: wait for the rc to be deleted @ 10/26/24 12:28:11.898
  E1026 12:28:12.804443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:13.804971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:14.805177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:15.805897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:16.806035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 10/26/24 12:28:16.903
  E1026 12:28:17.806831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:18.807113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:19.807328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:20.807496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:21.807619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:22.807741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:23.808044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:24.808150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:25.808295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:26.808666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:27.809107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:28.809294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:29.809331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:30.809517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:31.810386      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:32.810697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:33.810804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:34.811375      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:35.811481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:36.811745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:37.811810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:38.812213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:39.812316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:40.812504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:41.812606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:42.812827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:43.813095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:44.813625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:45.813799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:46.813894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 10/26/24 12:28:46.915
  W1026 12:28:46.921207      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1026 12:28:46.921234 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1026 12:28:46.921288 19 delete.go:95] Deleting pod "simpletest.rc-25z2g" in namespace "gc-9466"
  I1026 12:28:46.933334 19 delete.go:95] Deleting pod "simpletest.rc-2bgb2" in namespace "gc-9466"
  I1026 12:28:46.945258 19 delete.go:95] Deleting pod "simpletest.rc-4h2dg" in namespace "gc-9466"
  I1026 12:28:46.959627 19 delete.go:95] Deleting pod "simpletest.rc-4tw7n" in namespace "gc-9466"
  I1026 12:28:46.982059 19 delete.go:95] Deleting pod "simpletest.rc-55kr4" in namespace "gc-9466"
  I1026 12:28:46.993103 19 delete.go:95] Deleting pod "simpletest.rc-59n6d" in namespace "gc-9466"
  I1026 12:28:47.002908 19 delete.go:95] Deleting pod "simpletest.rc-5j9p8" in namespace "gc-9466"
  I1026 12:28:47.016391 19 delete.go:95] Deleting pod "simpletest.rc-5nhrp" in namespace "gc-9466"
  I1026 12:28:47.027568 19 delete.go:95] Deleting pod "simpletest.rc-62j6w" in namespace "gc-9466"
  I1026 12:28:47.041267 19 delete.go:95] Deleting pod "simpletest.rc-66b94" in namespace "gc-9466"
  I1026 12:28:47.053481 19 delete.go:95] Deleting pod "simpletest.rc-672zq" in namespace "gc-9466"
  I1026 12:28:47.069662 19 delete.go:95] Deleting pod "simpletest.rc-75wkz" in namespace "gc-9466"
  I1026 12:28:47.084162 19 delete.go:95] Deleting pod "simpletest.rc-7lfxx" in namespace "gc-9466"
  I1026 12:28:47.095119 19 delete.go:95] Deleting pod "simpletest.rc-7wbtq" in namespace "gc-9466"
  I1026 12:28:47.106404 19 delete.go:95] Deleting pod "simpletest.rc-85x8p" in namespace "gc-9466"
  I1026 12:28:47.117663 19 delete.go:95] Deleting pod "simpletest.rc-88zx4" in namespace "gc-9466"
  I1026 12:28:47.128914 19 delete.go:95] Deleting pod "simpletest.rc-8qgm4" in namespace "gc-9466"
  I1026 12:28:47.140197 19 delete.go:95] Deleting pod "simpletest.rc-8tc44" in namespace "gc-9466"
  I1026 12:28:47.156233 19 delete.go:95] Deleting pod "simpletest.rc-922q2" in namespace "gc-9466"
  I1026 12:28:47.170156 19 delete.go:95] Deleting pod "simpletest.rc-99vdb" in namespace "gc-9466"
  I1026 12:28:47.189423 19 delete.go:95] Deleting pod "simpletest.rc-9g72b" in namespace "gc-9466"
  I1026 12:28:47.200464 19 delete.go:95] Deleting pod "simpletest.rc-9vmz2" in namespace "gc-9466"
  I1026 12:28:47.213810 19 delete.go:95] Deleting pod "simpletest.rc-blg6b" in namespace "gc-9466"
  I1026 12:28:47.229818 19 delete.go:95] Deleting pod "simpletest.rc-csw8n" in namespace "gc-9466"
  I1026 12:28:47.244493 19 delete.go:95] Deleting pod "simpletest.rc-cxqvh" in namespace "gc-9466"
  I1026 12:28:47.258282 19 delete.go:95] Deleting pod "simpletest.rc-d2cvw" in namespace "gc-9466"
  I1026 12:28:47.284033 19 delete.go:95] Deleting pod "simpletest.rc-dq55b" in namespace "gc-9466"
  I1026 12:28:47.304498 19 delete.go:95] Deleting pod "simpletest.rc-dqlnj" in namespace "gc-9466"
  I1026 12:28:47.324861 19 delete.go:95] Deleting pod "simpletest.rc-dzlwx" in namespace "gc-9466"
  I1026 12:28:47.336384 19 delete.go:95] Deleting pod "simpletest.rc-f6lmd" in namespace "gc-9466"
  I1026 12:28:47.348237 19 delete.go:95] Deleting pod "simpletest.rc-f6q4s" in namespace "gc-9466"
  I1026 12:28:47.365735 19 delete.go:95] Deleting pod "simpletest.rc-ffjw5" in namespace "gc-9466"
  I1026 12:28:47.377786 19 delete.go:95] Deleting pod "simpletest.rc-fgm9l" in namespace "gc-9466"
  I1026 12:28:47.393053 19 delete.go:95] Deleting pod "simpletest.rc-fgtfg" in namespace "gc-9466"
  I1026 12:28:47.405331 19 delete.go:95] Deleting pod "simpletest.rc-fz8m4" in namespace "gc-9466"
  I1026 12:28:47.419537 19 delete.go:95] Deleting pod "simpletest.rc-g6988" in namespace "gc-9466"
  I1026 12:28:47.432205 19 delete.go:95] Deleting pod "simpletest.rc-gcfp7" in namespace "gc-9466"
  I1026 12:28:47.447345 19 delete.go:95] Deleting pod "simpletest.rc-gf5gs" in namespace "gc-9466"
  I1026 12:28:47.457965 19 delete.go:95] Deleting pod "simpletest.rc-gtvsj" in namespace "gc-9466"
  I1026 12:28:47.472273 19 delete.go:95] Deleting pod "simpletest.rc-j2598" in namespace "gc-9466"
  I1026 12:28:47.484133 19 delete.go:95] Deleting pod "simpletest.rc-j4qhk" in namespace "gc-9466"
  I1026 12:28:47.499798 19 delete.go:95] Deleting pod "simpletest.rc-j62fp" in namespace "gc-9466"
  I1026 12:28:47.514982 19 delete.go:95] Deleting pod "simpletest.rc-jkcvt" in namespace "gc-9466"
  I1026 12:28:47.530365 19 delete.go:95] Deleting pod "simpletest.rc-jmjcb" in namespace "gc-9466"
  I1026 12:28:47.540948 19 delete.go:95] Deleting pod "simpletest.rc-jpjw4" in namespace "gc-9466"
  I1026 12:28:47.553359 19 delete.go:95] Deleting pod "simpletest.rc-k99z6" in namespace "gc-9466"
  I1026 12:28:47.565403 19 delete.go:95] Deleting pod "simpletest.rc-kh85q" in namespace "gc-9466"
  I1026 12:28:47.579819 19 delete.go:95] Deleting pod "simpletest.rc-kk2qt" in namespace "gc-9466"
  I1026 12:28:47.591296 19 delete.go:95] Deleting pod "simpletest.rc-ksnrv" in namespace "gc-9466"
  I1026 12:28:47.606524 19 delete.go:95] Deleting pod "simpletest.rc-l2xbv" in namespace "gc-9466"
  I1026 12:28:47.620895 19 delete.go:95] Deleting pod "simpletest.rc-l6ssj" in namespace "gc-9466"
  I1026 12:28:47.634112 19 delete.go:95] Deleting pod "simpletest.rc-l8skw" in namespace "gc-9466"
  I1026 12:28:47.650799 19 delete.go:95] Deleting pod "simpletest.rc-mc4jw" in namespace "gc-9466"
  I1026 12:28:47.665295 19 delete.go:95] Deleting pod "simpletest.rc-mn8vw" in namespace "gc-9466"
  I1026 12:28:47.681252 19 delete.go:95] Deleting pod "simpletest.rc-nh7gw" in namespace "gc-9466"
  I1026 12:28:47.695911 19 delete.go:95] Deleting pod "simpletest.rc-nnt59" in namespace "gc-9466"
  I1026 12:28:47.708057 19 delete.go:95] Deleting pod "simpletest.rc-ns666" in namespace "gc-9466"
  I1026 12:28:47.721706 19 delete.go:95] Deleting pod "simpletest.rc-nwpmr" in namespace "gc-9466"
  I1026 12:28:47.733239 19 delete.go:95] Deleting pod "simpletest.rc-p679v" in namespace "gc-9466"
  I1026 12:28:47.749408 19 delete.go:95] Deleting pod "simpletest.rc-p9nq9" in namespace "gc-9466"
  I1026 12:28:47.765606 19 delete.go:95] Deleting pod "simpletest.rc-pnzww" in namespace "gc-9466"
  I1026 12:28:47.781928 19 delete.go:95] Deleting pod "simpletest.rc-pppdb" in namespace "gc-9466"
  I1026 12:28:47.792923 19 delete.go:95] Deleting pod "simpletest.rc-q5f52" in namespace "gc-9466"
  I1026 12:28:47.807936 19 delete.go:95] Deleting pod "simpletest.rc-q6vfc" in namespace "gc-9466"
  E1026 12:28:47.814382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:28:47.822193 19 delete.go:95] Deleting pod "simpletest.rc-qq8fl" in namespace "gc-9466"
  I1026 12:28:47.832817 19 delete.go:95] Deleting pod "simpletest.rc-qqtsc" in namespace "gc-9466"
  I1026 12:28:47.847161 19 delete.go:95] Deleting pod "simpletest.rc-rfkbn" in namespace "gc-9466"
  I1026 12:28:47.870663 19 delete.go:95] Deleting pod "simpletest.rc-rsdcg" in namespace "gc-9466"
  I1026 12:28:47.927241 19 delete.go:95] Deleting pod "simpletest.rc-s2mdw" in namespace "gc-9466"
  I1026 12:28:47.973731 19 delete.go:95] Deleting pod "simpletest.rc-sk255" in namespace "gc-9466"
  I1026 12:28:48.027711 19 delete.go:95] Deleting pod "simpletest.rc-sm2xs" in namespace "gc-9466"
  I1026 12:28:48.073856 19 delete.go:95] Deleting pod "simpletest.rc-snwxp" in namespace "gc-9466"
  I1026 12:28:48.116983 19 delete.go:95] Deleting pod "simpletest.rc-t4n77" in namespace "gc-9466"
  I1026 12:28:48.166108 19 delete.go:95] Deleting pod "simpletest.rc-t6tv6" in namespace "gc-9466"
  I1026 12:28:48.219937 19 delete.go:95] Deleting pod "simpletest.rc-tcdpt" in namespace "gc-9466"
  I1026 12:28:48.268701 19 delete.go:95] Deleting pod "simpletest.rc-thltf" in namespace "gc-9466"
  I1026 12:28:48.323217 19 delete.go:95] Deleting pod "simpletest.rc-tjg57" in namespace "gc-9466"
  I1026 12:28:48.370944 19 delete.go:95] Deleting pod "simpletest.rc-tlsn5" in namespace "gc-9466"
  I1026 12:28:48.416803 19 delete.go:95] Deleting pod "simpletest.rc-tlzjc" in namespace "gc-9466"
  I1026 12:28:48.467950 19 delete.go:95] Deleting pod "simpletest.rc-vd5kn" in namespace "gc-9466"
  I1026 12:28:48.518293 19 delete.go:95] Deleting pod "simpletest.rc-vmnvq" in namespace "gc-9466"
  I1026 12:28:48.570664 19 delete.go:95] Deleting pod "simpletest.rc-wdbj7" in namespace "gc-9466"
  I1026 12:28:48.622155 19 delete.go:95] Deleting pod "simpletest.rc-wfq4f" in namespace "gc-9466"
  I1026 12:28:48.678255 19 delete.go:95] Deleting pod "simpletest.rc-wthh7" in namespace "gc-9466"
  I1026 12:28:48.722263 19 delete.go:95] Deleting pod "simpletest.rc-wzn52" in namespace "gc-9466"
  I1026 12:28:48.771342 19 delete.go:95] Deleting pod "simpletest.rc-x52hb" in namespace "gc-9466"
  I1026 12:28:48.815115 19 delete.go:95] Deleting pod "simpletest.rc-x7cbn" in namespace "gc-9466"
  E1026 12:28:48.815274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:28:48.872018 19 delete.go:95] Deleting pod "simpletest.rc-xcbmc" in namespace "gc-9466"
  I1026 12:28:48.916944 19 delete.go:95] Deleting pod "simpletest.rc-xgrks" in namespace "gc-9466"
  I1026 12:28:48.970918 19 delete.go:95] Deleting pod "simpletest.rc-xjmjj" in namespace "gc-9466"
  I1026 12:28:49.015867 19 delete.go:95] Deleting pod "simpletest.rc-xkltr" in namespace "gc-9466"
  I1026 12:28:49.071771 19 delete.go:95] Deleting pod "simpletest.rc-xs4rz" in namespace "gc-9466"
  I1026 12:28:49.118214 19 delete.go:95] Deleting pod "simpletest.rc-z5lrh" in namespace "gc-9466"
  I1026 12:28:49.173084 19 delete.go:95] Deleting pod "simpletest.rc-zcqvn" in namespace "gc-9466"
  I1026 12:28:49.218852 19 delete.go:95] Deleting pod "simpletest.rc-zd52s" in namespace "gc-9466"
  I1026 12:28:49.268084 19 delete.go:95] Deleting pod "simpletest.rc-zjfpk" in namespace "gc-9466"
  I1026 12:28:49.320908 19 delete.go:95] Deleting pod "simpletest.rc-znp7h" in namespace "gc-9466"
  I1026 12:28:49.371592 19 delete.go:95] Deleting pod "simpletest.rc-zq6tn" in namespace "gc-9466"
  I1026 12:28:49.417884 19 delete.go:95] Deleting pod "simpletest.rc-zs4wq" in namespace "gc-9466"
  I1026 12:28:49.474860 19 delete.go:95] Deleting pod "simpletest.rc-zxj62" in namespace "gc-9466"
  I1026 12:28:49.522283 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9466" for this suite. @ 10/26/24 12:28:49.559
• [43.791 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 10/26/24 12:28:49.615
  I1026 12:28:49.615439 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:28:49.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:28:49.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:28:49.664
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 10/26/24 12:28:49.676
  E1026 12:28:49.816852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:50.816845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:51.817593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:52.818548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:28:53.709
  I1026 12:28:53.713985 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-ee47f9df-ae03-4d31-bc7f-979c1f044eb1 container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:28:53.721
  I1026 12:28:53.743254 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1894" for this suite. @ 10/26/24 12:28:53.747
• [4.140 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:746
  STEP: Creating a kubernetes client @ 10/26/24 12:28:53.755
  I1026 12:28:53.755668 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 12:28:53.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:28:53.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:28:53.778
  STEP: Creating a ResourceQuota with terminating scope @ 10/26/24 12:28:53.781
  STEP: Ensuring ResourceQuota status is calculated @ 10/26/24 12:28:53.786
  E1026 12:28:53.818637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:54.818864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 10/26/24 12:28:55.791
  STEP: Ensuring ResourceQuota status is calculated @ 10/26/24 12:28:55.797
  E1026 12:28:55.818941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:56.819661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 10/26/24 12:28:57.801
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 10/26/24 12:28:57.816
  E1026 12:28:57.820288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:58.820430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:28:59.820459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 10/26/24 12:28:59.821
  E1026 12:29:00.820849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:01.821011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 10/26/24 12:29:01.826
  STEP: Ensuring resource quota status released the pod usage @ 10/26/24 12:29:01.843
  E1026 12:29:02.821182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:03.821272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 10/26/24 12:29:03.85
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 10/26/24 12:29:03.863
  E1026 12:29:04.821373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:05.821476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 10/26/24 12:29:05.868
  E1026 12:29:06.821640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:07.821840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 10/26/24 12:29:07.874
  STEP: Ensuring resource quota status released the pod usage @ 10/26/24 12:29:07.885
  E1026 12:29:08.822465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:09.822594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:09.890345 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1755" for this suite. @ 10/26/24 12:29:09.894
• [16.148 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 10/26/24 12:29:09.903
  I1026 12:29:09.903269 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename security-context-test @ 10/26/24 12:29:09.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:29:09.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:29:09.924
  E1026 12:29:10.823055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:11.823387      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:12.823508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:13.824565      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:13.952452 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4282" for this suite. @ 10/26/24 12:29:13.958
• [4.063 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 10/26/24 12:29:13.966
  I1026 12:29:13.966733 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename daemonsets @ 10/26/24 12:29:13.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:29:13.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:29:13.99
  I1026 12:29:14.015200 19 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 10/26/24 12:29:14.021
  I1026 12:29:14.024430 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:14.024466 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:14.030593 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:29:14.030614 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 12:29:14.824873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:15.027194 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:15.027231 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:15.030473 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1026 12:29:15.030497 19 fixtures.go:130] Node ip-172-31-35-104 is running 0 daemon pod, expected 1
  E1026 12:29:15.824972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:16.027708 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:16.027747 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:16.031147 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 12:29:16.031167 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 10/26/24 12:29:16.048
  STEP: Check that daemon pods images are updated. @ 10/26/24 12:29:16.06
  I1026 12:29:16.065277 19 daemon_set.go:1193] Wrong image for pod: daemon-set-kvxlh. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1026 12:29:16.065298 19 daemon_set.go:1193] Wrong image for pod: daemon-set-p9tms. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1026 12:29:16.065304 19 daemon_set.go:1193] Wrong image for pod: daemon-set-rfmws. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1026 12:29:16.071574 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:16.071602 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1026 12:29:16.825899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:17.066912 19 daemon_set.go:1198] Pod daemon-set-hjcfm is not available
  I1026 12:29:17.066942 19 daemon_set.go:1193] Wrong image for pod: daemon-set-p9tms. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1026 12:29:17.066949 19 daemon_set.go:1193] Wrong image for pod: daemon-set-rfmws. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1026 12:29:17.071394 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:17.071425 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1026 12:29:17.826403      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:18.065537 19 daemon_set.go:1198] Pod daemon-set-5xw2p is not available
  I1026 12:29:18.065568 19 daemon_set.go:1193] Wrong image for pod: daemon-set-rfmws. Expected: registry.k8s.io/e2e-test-images/agnhost:2.52, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I1026 12:29:18.069114 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:18.069145 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1026 12:29:18.826893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:19.065262 19 daemon_set.go:1198] Pod daemon-set-ldzcz is not available
  I1026 12:29:19.069994 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:19.070031 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 10/26/24 12:29:19.07
  I1026 12:29:19.073715 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:19.073739 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:19.078447 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1026 12:29:19.078468 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 12:29:19.827228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:20.075609 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:20.075653 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:29:20.080719 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 12:29:20.080740 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 10/26/24 12:29:20.099
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7483, will wait for the garbage collector to delete the pods @ 10/26/24 12:29:20.099
  I1026 12:29:20.161366 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.316467ms
  I1026 12:29:20.262349 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.978865ms
  E1026 12:29:20.827981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:21.828694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:22.828894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:22.967182 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:29:22.967215 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1026 12:29:22.970883 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16896"},"items":null}

  I1026 12:29:22.975564 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16896"},"items":null}

  I1026 12:29:22.991709 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7483" for this suite. @ 10/26/24 12:29:22.995
• [9.037 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 10/26/24 12:29:23.004
  I1026 12:29:23.004801 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:29:23.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:29:23.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:29:23.025
  STEP: Creating a pod to test downward api env vars @ 10/26/24 12:29:23.028
  E1026 12:29:23.829077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:24.829308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:25.829411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:26.830204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:29:27.051
  I1026 12:29:27.057032 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downward-api-45999555-9f9c-441d-a533-ddcefd33ad28 container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 12:29:27.063
  I1026 12:29:27.079589 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8009" for this suite. @ 10/26/24 12:29:27.084
• [4.086 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 10/26/24 12:29:27.09
  I1026 12:29:27.090828 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-runtime @ 10/26/24 12:29:27.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:29:27.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:29:27.11
  STEP: create the container @ 10/26/24 12:29:27.113
  W1026 12:29:27.121106      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 10/26/24 12:29:27.121
  E1026 12:29:27.831209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:28.831408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 10/26/24 12:29:29.136
  STEP: the container should be terminated @ 10/26/24 12:29:29.139
  STEP: the termination message should be set @ 10/26/24 12:29:29.139
  I1026 12:29:29.140007 19 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 10/26/24 12:29:29.14
  I1026 12:29:29.157652 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5668" for this suite. @ 10/26/24 12:29:29.164
• [2.081 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:907
  STEP: Creating a kubernetes client @ 10/26/24 12:29:29.171
  I1026 12:29:29.171428 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename job @ 10/26/24 12:29:29.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:29:29.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:29:29.193
  STEP: Creating a job @ 10/26/24 12:29:29.196
  STEP: Ensuring active pods == parallelism @ 10/26/24 12:29:29.203
  E1026 12:29:29.832221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:30.832456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 10/26/24 12:29:31.21
  I1026 12:29:31.728409 19 pod_client.go:173] Successfully updated pod "adopt-release-dz5zt"
  STEP: Checking that the Job readopts the Pod @ 10/26/24 12:29:31.728
  E1026 12:29:31.832551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:32.832850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 10/26/24 12:29:33.736
  E1026 12:29:33.832887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:34.247378 19 pod_client.go:173] Successfully updated pod "adopt-release-dz5zt"
  STEP: Checking that the Job releases the Pod @ 10/26/24 12:29:34.247
  E1026 12:29:34.833830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:35.834724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:29:36.257372 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1131" for this suite. @ 10/26/24 12:29:36.261
• [7.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 10/26/24 12:29:36.27
  I1026 12:29:36.270534 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:29:36.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:29:36.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:29:36.292
  STEP: Creating configMap with name projected-configmap-test-volume-e3ecec3f-718f-47bc-a7cd-b8f9398e54bd @ 10/26/24 12:29:36.297
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:29:36.304
  E1026 12:29:36.834896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:37.834910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:38.835904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:39.836023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:29:40.326
  I1026 12:29:40.332096 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-projected-configmaps-c774a919-8e01-4c4f-95c8-6a3f90f0e938 container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:29:40.351
  I1026 12:29:40.367284 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-36" for this suite. @ 10/26/24 12:29:40.371
• [4.109 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 10/26/24 12:29:40.379
  I1026 12:29:40.379331 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:29:40.379
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:29:40.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:29:40.401
  STEP: Creating configMap with name projected-configmap-test-volume-map-cc851d95-d796-4812-8f6b-424c7ac2ac7f @ 10/26/24 12:29:40.404
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:29:40.409
  E1026 12:29:40.840961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:41.839624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:29:42.43
  I1026 12:29:42.433563 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-projected-configmaps-b7dd11b6-e94b-4371-9ab7-dd9f2d6479fe container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:29:42.441
  I1026 12:29:42.460467 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2393" for this suite. @ 10/26/24 12:29:42.466
• [2.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 10/26/24 12:29:42.478
  I1026 12:29:42.478878 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename subpath @ 10/26/24 12:29:42.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:29:42.508
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:29:42.512
  STEP: Setting up data @ 10/26/24 12:29:42.516
  STEP: Creating pod pod-subpath-test-configmap-dnwg @ 10/26/24 12:29:42.536
  STEP: Creating a pod to test atomic-volume-subpath @ 10/26/24 12:29:42.536
  E1026 12:29:42.839982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:43.840090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:44.841113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:45.841252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:46.841347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:47.841468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:48.841573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:49.841830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:50.842367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:51.843071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:52.843158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:53.844124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:54.844243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:55.844344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:56.844418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:57.844509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:58.844899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:29:59.845002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:00.845103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:01.845200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:02.846124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:03.846262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:04.847077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:05.847212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:30:06.618
  I1026 12:30:06.623753 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-subpath-test-configmap-dnwg container test-container-subpath-configmap-dnwg: <nil>
  STEP: delete the pod @ 10/26/24 12:30:06.631
  STEP: Deleting pod pod-subpath-test-configmap-dnwg @ 10/26/24 12:30:06.647
  I1026 12:30:06.647265 19 delete.go:62] Deleting pod "pod-subpath-test-configmap-dnwg" in namespace "subpath-4635"
  I1026 12:30:06.652308 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4635" for this suite. @ 10/26/24 12:30:06.656
• [24.186 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 10/26/24 12:30:06.664
  I1026 12:30:06.664794 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-runtime @ 10/26/24 12:30:06.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:06.685
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:06.688
  STEP: create the container @ 10/26/24 12:30:06.693
  W1026 12:30:06.702878      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 10/26/24 12:30:06.702
  E1026 12:30:06.848203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:07.849049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:08.849988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 10/26/24 12:30:09.72
  STEP: the container should be terminated @ 10/26/24 12:30:09.723
  STEP: the termination message should be set @ 10/26/24 12:30:09.723
  I1026 12:30:09.723973 19 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 10/26/24 12:30:09.723
  I1026 12:30:09.743891 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4630" for this suite. @ 10/26/24 12:30:09.748
• [3.093 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 10/26/24 12:30:09.758
  I1026 12:30:09.758026 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename watch @ 10/26/24 12:30:09.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:09.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:09.78
  STEP: creating a watch on configmaps with a certain label @ 10/26/24 12:30:09.783
  STEP: creating a new configmap @ 10/26/24 12:30:09.784
  STEP: modifying the configmap once @ 10/26/24 12:30:09.789
  STEP: changing the label value of the configmap @ 10/26/24 12:30:09.798
  STEP: Expecting to observe a delete notification for the watched object @ 10/26/24 12:30:09.805
  I1026 12:30:09.806045 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5194  9511dc39-6209-40d6-a25e-ad1440af187a 17322 0 2024-10-26 12:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-10-26 12:30:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 12:30:09.806159 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5194  9511dc39-6209-40d6-a25e-ad1440af187a 17323 0 2024-10-26 12:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-10-26 12:30:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 12:30:09.806212 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5194  9511dc39-6209-40d6-a25e-ad1440af187a 17324 0 2024-10-26 12:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-10-26 12:30:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 10/26/24 12:30:09.806
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 10/26/24 12:30:09.815
  E1026 12:30:09.850038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:10.850221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:11.850490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:12.850701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:13.850853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:14.851089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:15.851328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:16.851423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:17.851576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:18.852524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 10/26/24 12:30:19.815
  STEP: modifying the configmap a third time @ 10/26/24 12:30:19.827
  STEP: deleting the configmap @ 10/26/24 12:30:19.836
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 10/26/24 12:30:19.844
  I1026 12:30:19.844959 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5194  9511dc39-6209-40d6-a25e-ad1440af187a 17367 0 2024-10-26 12:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-10-26 12:30:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 12:30:19.845059 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5194  9511dc39-6209-40d6-a25e-ad1440af187a 17368 0 2024-10-26 12:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-10-26 12:30:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 12:30:19.845191 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5194  9511dc39-6209-40d6-a25e-ad1440af187a 17369 0 2024-10-26 12:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-10-26 12:30:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 12:30:19.845316 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5194" for this suite. @ 10/26/24 12:30:19.848
  E1026 12:30:19.852978      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [10.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 10/26/24 12:30:19.856
  I1026 12:30:19.856033 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename var-expansion @ 10/26/24 12:30:19.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:19.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:19.879
  E1026 12:30:20.853825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:21.853924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:21.902830 19 delete.go:62] Deleting pod "var-expansion-05a391ff-e377-48b8-9787-74ff2b7e8f2f" in namespace "var-expansion-9746"
  I1026 12:30:21.913063 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-05a391ff-e377-48b8-9787-74ff2b7e8f2f" to be fully deleted
  E1026 12:30:22.854020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:23.854865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:23.923071 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9746" for this suite. @ 10/26/24 12:30:23.928
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:119
  STEP: Creating a kubernetes client @ 10/26/24 12:30:23.938
  I1026 12:30:23.938634 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename dns @ 10/26/24 12:30:23.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:23.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:23.959
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3088.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3088.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 10/26/24 12:30:23.962
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3088.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3088.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 10/26/24 12:30:23.962
  STEP: creating a pod to probe /etc/hosts @ 10/26/24 12:30:23.962
  STEP: submitting the pod to kubernetes @ 10/26/24 12:30:23.962
  E1026 12:30:24.855002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:25.855113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 12:30:25.981
  STEP: looking for the results for each expected name from probers @ 10/26/24 12:30:25.986
  I1026 12:30:26.005189 19 dns_common.go:527] DNS probes using dns-3088/dns-test-b9f9ea2b-985d-4a47-80ba-2aa6f27c801b succeeded

  STEP: deleting the pod @ 10/26/24 12:30:26.005
  I1026 12:30:26.017112 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3088" for this suite. @ 10/26/24 12:30:26.02
• [2.090 seconds]
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 10/26/24 12:30:26.028
  I1026 12:30:26.028456 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename svcaccounts @ 10/26/24 12:30:26.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:26.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:26.048
  E1026 12:30:26.855200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:27.855303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 10/26/24 12:30:28.083
  I1026 12:30:28.083093 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9459 pod-service-account-d5c3d423-f555-45f1-b194-9ccb49a0a8fb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 10/26/24 12:30:28.178
  I1026 12:30:28.178986 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9459 pod-service-account-d5c3d423-f555-45f1-b194-9ccb49a0a8fb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 10/26/24 12:30:28.273
  I1026 12:30:28.273519 19 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9459 pod-service-account-d5c3d423-f555-45f1-b194-9ccb49a0a8fb -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I1026 12:30:28.369944 19 service_accounts.go:114] Got root ca configmap in namespace "svcaccounts-9459"
  I1026 12:30:28.372238 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9459" for this suite. @ 10/26/24 12:30:28.377
• [2.359 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 10/26/24 12:30:28.387
  I1026 12:30:28.387784 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename proxy @ 10/26/24 12:30:28.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:28.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:28.408
  I1026 12:30:28.411231 19 proxy.go:387] Creating pod...
  E1026 12:30:28.855907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:29.856033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:30.431967 19 proxy.go:411] Creating service...
  I1026 12:30:30.446936 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/pods/agnhost/proxy?method=DELETE
  I1026 12:30:30.453962 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I1026 12:30:30.453989 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/pods/agnhost/proxy?method=OPTIONS
  I1026 12:30:30.458138 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I1026 12:30:30.458166 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/pods/agnhost/proxy?method=PATCH
  I1026 12:30:30.462026 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I1026 12:30:30.462041 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/pods/agnhost/proxy?method=POST
  I1026 12:30:30.467714 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I1026 12:30:30.467741 19 proxy.go:448] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/pods/agnhost/proxy?method=PUT
  I1026 12:30:30.472330 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I1026 12:30:30.472355 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/services/e2e-proxy-test-service/proxy?method=DELETE
  I1026 12:30:30.477763 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I1026 12:30:30.477795 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I1026 12:30:30.485654 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I1026 12:30:30.485711 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/services/e2e-proxy-test-service/proxy?method=PATCH
  I1026 12:30:30.491785 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I1026 12:30:30.491807 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/services/e2e-proxy-test-service/proxy?method=POST
  I1026 12:30:30.496427 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I1026 12:30:30.496450 19 proxy.go:459] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/services/e2e-proxy-test-service/proxy?method=PUT
  I1026 12:30:30.503549 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I1026 12:30:30.503574 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/pods/agnhost/proxy?method=GET
  I1026 12:30:30.507114 19 proxy.go:487] http.Client request:GET StatusCode:301
  I1026 12:30:30.507139 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/services/e2e-proxy-test-service/proxy?method=GET
  I1026 12:30:30.512017 19 proxy.go:487] http.Client request:GET StatusCode:301
  I1026 12:30:30.512037 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/pods/agnhost/proxy?method=HEAD
  I1026 12:30:30.516850 19 proxy.go:487] http.Client request:HEAD StatusCode:301
  I1026 12:30:30.516887 19 proxy.go:479] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3185/services/e2e-proxy-test-service/proxy?method=HEAD
  I1026 12:30:30.521884 19 proxy.go:487] http.Client request:HEAD StatusCode:301
  I1026 12:30:30.521996 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-3185" for this suite. @ 10/26/24 12:30:30.526
• [2.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 10/26/24 12:30:30.532
  I1026 12:30:30.532689 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:30:30.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:30.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:30.554
  STEP: Creating configMap with name configmap-test-volume-map-5ca8e726-5701-42d5-b44e-f03ec419e4a9 @ 10/26/24 12:30:30.557
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:30:30.564
  E1026 12:30:30.856491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:31.857285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:30:32.584
  I1026 12:30:32.588931 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-configmaps-1e1c6629-da62-425b-a818-74e945014203 container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:30:32.595
  I1026 12:30:32.616325 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5747" for this suite. @ 10/26/24 12:30:32.621
• [2.098 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:878
  STEP: Creating a kubernetes client @ 10/26/24 12:30:32.63
  I1026 12:30:32.630669 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:30:32.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:32.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:32.654
  STEP: validating api versions @ 10/26/24 12:30:32.657
  I1026 12:30:32.657794 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-832 api-versions'
  I1026 12:30:32.699875 19 builder.go:146] stderr: ""
  I1026 12:30:32.699901 19 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I1026 12:30:32.700041 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-832" for this suite. @ 10/26/24 12:30:32.704
• [0.081 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 10/26/24 12:30:32.711
  I1026 12:30:32.711639 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename deployment @ 10/26/24 12:30:32.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:32.73
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:32.733
  I1026 12:30:32.745818 19 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E1026 12:30:32.858101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:33.858876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:34.859013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:35.859100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:36.859213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:37.750061 19 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 10/26/24 12:30:37.75
  I1026 12:30:37.750138 19 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E1026 12:30:37.860240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:38.860425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:39.755836 19 deployment.go:921] Creating deployment "test-rollover-deployment"
  I1026 12:30:39.765735 19 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E1026 12:30:39.860931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:40.861148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:41.776635 19 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I1026 12:30:41.785747 19 deployment.go:943] Ensure that both replica sets have 1 created replica
  I1026 12:30:41.794637 19 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I1026 12:30:41.803361 19 deployment.go:313] Updating deployment test-rollover-deployment
  I1026 12:30:41.803391 19 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E1026 12:30:41.862070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:42.862257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:43.812727 19 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I1026 12:30:43.819776 19 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I1026 12:30:43.830168 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1026 12:30:43.830219 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 12:30:43.863261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:44.863413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:45.840420 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1026 12:30:45.840470 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 12:30:45.864414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:46.864551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:47.838463 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1026 12:30:47.838522 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 12:30:47.865470      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:48.865742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:49.842120 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1026 12:30:49.842178 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 12:30:49.866179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:50.866379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:51.840157 19 deployment.go:94] all replica sets need to contain the pod-template-hash label
  I1026 12:30:51.840221 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 12, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 12, 30, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5f974d7468\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 12:30:51.867345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:52.867502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:30:53.839075 19 deployment.go:94] 
  I1026 12:30:53.839115 19 deployment.go:974] Ensure that both old replica sets have no replicas
  I1026 12:30:53.853042 19 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8555",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "08183618-ad8e-45c8-a2b9-a99696fd6703",
      ResourceVersion: (string) (len=5) "17737",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542639,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542639,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542639,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542639,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5f974d7468\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1026 12:30:53.857609 19 deployment.go:39] New ReplicaSet "test-rollover-deployment-5f974d7468" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5f974d7468",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8555",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bd0058cc-8e14-4897-858c-963792071fc5",
      ResourceVersion: (string) (len=5) "17725",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "08183618-ad8e-45c8-a2b9-a99696fd6703",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 38 31 38 33 36  31 38 2d 61 64 38 65 2d  |\"08183618-ad8e-|
              00000120  34 35 63 38 2d 61 32 62  39 2d 61 39 39 36 39 36  |45c8-a2b9-a99696|
              00000130  66 64 36 37 30 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |fd6703\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:30:53.858139 19 deployment.go:44] All old ReplicaSets of Deployment "test-rollover-deployment":
  I1026 12:30:53.858411 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8555",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8c3e3d54-0ca3-4e81-8fcf-346e24cd2ce9",
      ResourceVersion: (string) (len=5) "17736",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542632,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "08183618-ad8e-45c8-a2b9-a99696fd6703",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542632,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  30 38 31 38 33 36 31 38  2d 61 64 38 65 2d 34 35  |08183618-ad8e-45|
              000000c0  63 38 2d 61 32 62 39 2d  61 39 39 36 39 36 66 64  |c8-a2b9-a99696fd|
              000000d0  36 37 30 33 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |6703\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542653,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:30:53.859554 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-55f4dbffff",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8555",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "eac292ee-6b69-4ae3-aa51-4f3675fb532c",
      ResourceVersion: (string) (len=5) "17691",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542639,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "08183618-ad8e-45c8-a2b9-a99696fd6703",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 38 31 38 33 36  31 38 2d 61 64 38 65 2d  |\"08183618-ad8e-|
              00000120  34 35 63 38 2d 61 32 62  39 2d 61 39 39 36 39 36  |45c8-a2b9-a99696|
              00000130  66 64 36 37 30 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |fd6703\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "55f4dbffff"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:30:53.865028 19 deployment.go:67] Pod "test-rollover-deployment-5f974d7468-np9zx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5f974d7468-np9zx",
      GenerateName: (string) (len=36) "test-rollover-deployment-5f974d7468-",
      Namespace: (string) (len=15) "deployment-8555",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "98a7c85f-62be-43cb-9282-fc5545d60ee9",
      ResourceVersion: (string) (len=5) "17702",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5f974d7468"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5f974d7468",
          UID: (types.UID) (len=36) "bd0058cc-8e14-4897-858c-963792071fc5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 64  30 30 35 38 63 63 2d 38  |d\":\"bd0058cc-8|
              00000090  65 31 34 2d 34 38 39 37  2d 38 35 38 63 2d 39 36  |e14-4897-858c-96|
              000000a0  33 37 39 32 30 37 31 66  63 35 5c 22 7d 22 3a 7b  |3792071fc5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 39  2e 31 35 35 5c 22 7d 22  |2.168.29.155\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pm5fs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pm5fs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542643,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865542641,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.155",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.155"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865542641,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865542642,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6",
          ContainerID: (string) (len=77) "containerd://4eb369c767239a0402c95b5b12cccb92aaf79049628fc4f672fa714c1a0574cf",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-pm5fs",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:30:53.866870 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E1026 12:30:53.867979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "deployment-8555" for this suite. @ 10/26/24 12:30:53.872
• [21.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 10/26/24 12:30:53.881
  I1026 12:30:53.881351 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:30:53.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:53.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:53.903
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 12:30:53.907
  E1026 12:30:54.868131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:55.868512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:56.868851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:57.868923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:30:57.935
  I1026 12:30:57.939011 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod downwardapi-volume-f61193d3-92f3-4b06-a5cb-3536b4e25333 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 12:30:57.947
  I1026 12:30:57.966242 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1475" for this suite. @ 10/26/24 12:30:57.969
• [4.097 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 10/26/24 12:30:57.978
  I1026 12:30:57.978410 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:30:57.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:30:57.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:30:58
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 10/26/24 12:30:58.003
  E1026 12:30:58.869996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:30:59.870093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:00.870999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:01.871113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:31:02.029
  I1026 12:31:02.034326 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-ece1ac7c-11e6-4442-aca8-be61a9fa85ff container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:31:02.042
  I1026 12:31:02.062004 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-469" for this suite. @ 10/26/24 12:31:02.066
• [4.097 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 10/26/24 12:31:02.075
  I1026 12:31:02.075354 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:31:02.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:31:02.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:31:02.099
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 12:31:02.103
  E1026 12:31:02.872164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:03.873163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:04.873277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:05.873664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:31:06.132
  I1026 12:31:06.139832 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-34709d5d-146e-44ee-abe7-af1ea163ef1f container client-container: <nil>
  STEP: delete the pod @ 10/26/24 12:31:06.154
  I1026 12:31:06.170545 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4086" for this suite. @ 10/26/24 12:31:06.175
• [4.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:821
  STEP: Creating a kubernetes client @ 10/26/24 12:31:06.184
  I1026 12:31:06.184827 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 12:31:06.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:31:06.21
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:31:06.214
  STEP: creating service multi-endpoint-test in namespace services-4620 @ 10/26/24 12:31:06.221
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4620 to expose endpoints map[] @ 10/26/24 12:31:06.237
  I1026 12:31:06.243438 19 service.go:4267] Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  E1026 12:31:06.873904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:31:07.253516 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-4620 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-4620 @ 10/26/24 12:31:07.253
  E1026 12:31:07.874906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:08.875870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4620 to expose endpoints map[pod1:[100]] @ 10/26/24 12:31:09.278
  I1026 12:31:09.292199 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-4620 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-4620 @ 10/26/24 12:31:09.292
  E1026 12:31:09.876954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:10.877897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4620 to expose endpoints map[pod1:[100] pod2:[101]] @ 10/26/24 12:31:11.309
  I1026 12:31:11.325311 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-4620 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 10/26/24 12:31:11.325
  I1026 12:31:11.325363 19 resource.go:361] Creating new exec pod
  E1026 12:31:11.878024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:12.878199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:13.879015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:31:14.342422 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-4620 exec execpodwqgxn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I1026 12:31:14.429170 19 builder.go:146] stderr: "+ + nc -v -t -w 2 multi-endpoint-test 80\necho hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  I1026 12:31:14.429229 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:31:14.429312 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-4620 exec execpodwqgxn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.231 80'
  I1026 12:31:14.514294 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.231 80\nConnection to 10.152.183.231 80 port [tcp/http] succeeded!\n"
  I1026 12:31:14.514340 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:31:14.514410 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-4620 exec execpodwqgxn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I1026 12:31:14.595951 19 builder.go:146] stderr: "+ + echonc hostName -v\n -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  I1026 12:31:14.595999 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:31:14.596066 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-4620 exec execpodwqgxn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.231 81'
  I1026 12:31:14.674849 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.231 81\nConnection to 10.152.183.231 81 port [tcp/*] succeeded!\n"
  I1026 12:31:14.674888 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-4620 @ 10/26/24 12:31:14.674
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4620 to expose endpoints map[pod2:[101]] @ 10/26/24 12:31:14.694
  I1026 12:31:14.705480 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-4620 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-4620 @ 10/26/24 12:31:14.705
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4620 to expose endpoints map[] @ 10/26/24 12:31:14.725
  I1026 12:31:14.736851 19 service.go:4299] successfully validated that service multi-endpoint-test in namespace services-4620 exposes endpoints map[]
  I1026 12:31:14.751658 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4620" for this suite. @ 10/26/24 12:31:14.754
• [8.579 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 10/26/24 12:31:14.764
  I1026 12:31:14.764319 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replicaset @ 10/26/24 12:31:14.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:31:14.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:31:14.786
  I1026 12:31:14.804463 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E1026 12:31:14.880426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:15.880225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:16.880380      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:17.880444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:18.880613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:31:19.812260 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 10/26/24 12:31:19.812
  STEP: Scaling up "test-rs" replicaset @ 10/26/24 12:31:19.812
  I1026 12:31:19.824538 19 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 10/26/24 12:31:19.824
  I1026 12:31:19.833025 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6274 with ReadyReplicas 1, AvailableReplicas 1
  I1026 12:31:19.849921 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6274 with ReadyReplicas 1, AvailableReplicas 1
  I1026 12:31:19.871625 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6274 with ReadyReplicas 1, AvailableReplicas 1
  E1026 12:31:19.880834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:31:19.886963 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6274 with ReadyReplicas 1, AvailableReplicas 1
  E1026 12:31:20.881237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:31:21.193057 19 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-6274 with ReadyReplicas 2, AvailableReplicas 2
  I1026 12:31:21.368933 19 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-6274 with ReadyReplicas 3 found true
  I1026 12:31:21.369059 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6274" for this suite. @ 10/26/24 12:31:21.374
• [6.617 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 10/26/24 12:31:21.381
  I1026 12:31:21.381438 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename init-container @ 10/26/24 12:31:21.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:31:21.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:31:21.406
  STEP: creating the pod @ 10/26/24 12:31:21.409
  I1026 12:31:21.409979 19 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E1026 12:31:21.881365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:22.881451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:23.882065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:31:24.195435 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9566" for this suite. @ 10/26/24 12:31:24.2
• [2.826 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 10/26/24 12:31:24.207
  I1026 12:31:24.207413 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:31:24.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:31:24.225
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:31:24.228
  STEP: Creating a pod to test downward api env vars @ 10/26/24 12:31:24.231
  E1026 12:31:24.882143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:25.882903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:26.882998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:27.883068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:31:28.258
  I1026 12:31:28.263327 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod downward-api-4179011c-31b6-423b-9ba7-8513be2561b1 container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 12:31:28.27
  I1026 12:31:28.287192 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6398" for this suite. @ 10/26/24 12:31:28.292
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 10/26/24 12:31:28.299
  I1026 12:31:28.299135 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename tables @ 10/26/24 12:31:28.299
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:31:28.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:31:28.32
  I1026 12:31:28.326279 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-3074" for this suite. @ 10/26/24 12:31:28.33
• [0.039 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 10/26/24 12:31:28.338
  I1026 12:31:28.338271 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:31:28.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:31:28.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:31:28.358
  STEP: Creating Pod @ 10/26/24 12:31:28.361
  E1026 12:31:28.883442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:29.883502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 10/26/24 12:31:30.382
  I1026 12:31:30.382637 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6959 PodName:pod-sharedvolume-02c49cfd-49a9-4a50-924c-cca8bff16169 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:31:30.382656 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:31:30.383165 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:31:30.383224 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-6959/pods/pod-sharedvolume-02c49cfd-49a9-4a50-924c-cca8bff16169/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  I1026 12:31:30.419941 19 exec_util.go:111] Exec stderr: ""
  I1026 12:31:30.420246 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6959" for this suite. @ 10/26/24 12:31:30.424
• [2.096 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 10/26/24 12:31:30.434
  I1026 12:31:30.434042 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename var-expansion @ 10/26/24 12:31:30.434
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:31:30.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:31:30.453
  STEP: creating the pod with failed condition @ 10/26/24 12:31:30.456
  E1026 12:31:30.884081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:31.884898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:32.885906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:33.886881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:34.887885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:35.887981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:36.888109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:37.888201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:38.888960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:39.889080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:40.889225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:41.889440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:42.890256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:43.890521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:44.890840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:45.891043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:46.891141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:47.891266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:48.891529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:49.891662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:50.891912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:51.892126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:52.892285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:53.892718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:54.892886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:55.893007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:56.893061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:57.893260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:58.893908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:31:59.894009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:00.894090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:01.894193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:02.894884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:03.895894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:04.896612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:05.896918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:06.897149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:07.897229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:08.897372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:09.897484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:10.897896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:11.898086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:12.898906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:13.899224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:14.899902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:15.900029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:16.900127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:17.900329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:18.900444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:19.901227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:20.901340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:21.901434      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:22.901751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:23.901813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:24.902406      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:25.903171      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:26.903885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:27.904914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:28.905776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:29.905853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:30.906551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:31.906698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:32.907579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:33.907766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:34.908752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:35.908837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:36.909384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:37.909490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:38.909618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:39.909739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:40.909860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:41.909949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:42.910065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:43.911011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:44.911754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:45.911956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:46.912554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:47.912651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:48.912979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:49.913023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:50.913509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:51.913806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:52.914625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:53.914801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:54.915352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:55.915453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:56.915870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:57.916002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:58.916871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:32:59.917113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:00.917784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:01.918766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:02.919858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:03.920120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:04.921078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:05.921193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:06.921270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:07.921468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:08.922340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:09.922528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:10.923212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:11.924042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:12.924869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:13.925863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:14.926585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:15.926796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:16.927188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:17.927437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:18.927695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:19.927940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:20.928030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:21.928218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:22.928442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:23.928562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:24.928712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:25.928910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:26.929878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:27.930095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:28.930528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:29.930772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating the pod @ 10/26/24 12:33:30.464
  E1026 12:33:30.931801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:33:30.979619 19 pod_client.go:173] Successfully updated pod "var-expansion-1a395b66-5e7b-4a8e-981f-1cc9bb1837fd"
  STEP: waiting for pod running @ 10/26/24 12:33:30.979
  E1026 12:33:31.931959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:32.932273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 10/26/24 12:33:32.99
  I1026 12:33:32.990808 19 delete.go:62] Deleting pod "var-expansion-1a395b66-5e7b-4a8e-981f-1cc9bb1837fd" in namespace "var-expansion-6527"
  I1026 12:33:32.999214 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-1a395b66-5e7b-4a8e-981f-1cc9bb1837fd" to be fully deleted
  E1026 12:33:33.933249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:34.933455      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:35.933829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:36.933931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:37.934022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:38.934878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:39.934996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:40.935092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:41.935183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:42.935289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:43.935398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:44.935460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:45.935634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:46.935863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:47.935977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:48.936912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:49.937012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:50.937147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:51.937255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:52.937943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:53.938879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:54.939028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:55.939135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:56.939261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:57.939837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:58.940023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:33:59.940138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:00.940246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:01.940844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:02.941195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:03.942149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:04.942254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:34:05.097053 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6527" for this suite. @ 10/26/24 12:34:05.102
• [154.676 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1365
  STEP: Creating a kubernetes client @ 10/26/24 12:34:05.11
  I1026 12:34:05.110542 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:34:05.111
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:34:05.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:34:05.135
  STEP: validating cluster-info @ 10/26/24 12:34:05.139
  I1026 12:34:05.139114 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-5782 cluster-info'
  I1026 12:34:05.183771 19 builder.go:146] stderr: ""
  I1026 12:34:05.183827 19 builder.go:147] stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I1026 12:34:05.183996 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5782" for this suite. @ 10/26/24 12:34:05.188
• [0.084 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:312
  STEP: Creating a kubernetes client @ 10/26/24 12:34:05.194
  I1026 12:34:05.194826 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:34:05.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:34:05.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:34:05.215
  STEP: Setting up server cert @ 10/26/24 12:34:05.243
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:34:05.401
  STEP: Deploying the webhook pod @ 10/26/24 12:34:05.41
  STEP: Wait for the deployment to be ready @ 10/26/24 12:34:05.424
  I1026 12:34:05.431808 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:34:05.942952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:06.943092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:34:07.447
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:34:07.459
  E1026 12:34:07.943906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:34:08.459724 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I1026 12:34:08.470114 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:34:08.944579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5982-crds.webhook.example.com via the AdmissionRegistration API @ 10/26/24 12:34:08.985
  STEP: Creating a custom resource while v1 is storage version @ 10/26/24 12:34:08.999
  E1026 12:34:09.944947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:10.945911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 10/26/24 12:34:11.028
  STEP: Patching the custom resource while v2 is storage version @ 10/26/24 12:34:11.053
  I1026 12:34:11.637750 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5977" for this suite. @ 10/26/24 12:34:11.642
  STEP: Destroying namespace "webhook-markers-1226" for this suite. @ 10/26/24 12:34:11.651
• [6.465 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 10/26/24 12:34:11.66
  I1026 12:34:11.660097 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:34:11.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:34:11.685
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:34:11.688
  STEP: Creating configMap with name cm-test-opt-del-56c46b0e-77d8-4557-8e1a-18aebaffaef1 @ 10/26/24 12:34:11.697
  STEP: Creating configMap with name cm-test-opt-upd-7db14c90-2138-4363-91a9-22342f0e721f @ 10/26/24 12:34:11.702
  STEP: Creating the pod @ 10/26/24 12:34:11.706
  E1026 12:34:11.946103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:12.946330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-56c46b0e-77d8-4557-8e1a-18aebaffaef1 @ 10/26/24 12:34:13.756
  STEP: Updating configmap cm-test-opt-upd-7db14c90-2138-4363-91a9-22342f0e721f @ 10/26/24 12:34:13.765
  STEP: Creating configMap with name cm-test-opt-create-d54f0b06-f90d-4785-9d3e-50ed39d5a6ea @ 10/26/24 12:34:13.77
  STEP: waiting to observe update in volume @ 10/26/24 12:34:13.776
  E1026 12:34:13.946340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:14.946562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:15.946696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:16.946911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:17.947649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:18.947897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:19.948248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:20.948466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:21.948570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:22.948803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:23.949694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:24.949836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:25.950909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:26.951019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:27.952069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:28.952267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:29.953017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:30.953290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:31.953969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:32.954077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:33.954886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:34.954987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:35.955493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:36.955744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:37.956011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:38.956883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:39.957413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:40.957732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:41.958464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:42.959446      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:43.960419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:44.960550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:45.960985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:46.961218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:47.961433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:48.961786      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:49.961761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:50.962633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:51.962928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:52.963071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:53.963310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:54.963439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:55.964431      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:56.964829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:57.964927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:58.965913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:34:59.966022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:00.966170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:01.966281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:02.966602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:03.967659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:04.967802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:05.967848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:06.968221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:07.968802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:08.969076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:09.969204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:10.970258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:11.970509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:12.970757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:13.970930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:14.971775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:15.972008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:16.972096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:17.972245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:18.972528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:19.972623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:20.972818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:21.972963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:22.973584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:23.973842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:24.973961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:25.974876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:26.975890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:27.976014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:28.976904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:29.977030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:30.977998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:31.978329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:32.978400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:33.978627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:34.978767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:35.979007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:35:36.191093 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1503" for this suite. @ 10/26/24 12:35:36.195
• [84.542 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 10/26/24 12:35:36.202
  I1026 12:35:36.202644 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 12:35:36.203
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:35:36.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:35:36.224
  I1026 12:35:36.227208 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:35:36.979230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 10/26/24 12:35:37.517
  I1026 12:35:37.517761 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-170 --namespace=crd-publish-openapi-170 create -f -'
  E1026 12:35:37.979692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:38.979922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:35:39.587500 19 builder.go:146] stderr: ""
  I1026 12:35:39.587543 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2144-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I1026 12:35:39.587644 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-170 --namespace=crd-publish-openapi-170 delete e2e-test-crd-publish-openapi-2144-crds test-cr'
  I1026 12:35:39.649666 19 builder.go:146] stderr: ""
  I1026 12:35:39.649723 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2144-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I1026 12:35:39.649761 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-170 --namespace=crd-publish-openapi-170 apply -f -'
  I1026 12:35:39.713061 19 builder.go:146] stderr: ""
  I1026 12:35:39.713108 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2144-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I1026 12:35:39.713163 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-170 --namespace=crd-publish-openapi-170 delete e2e-test-crd-publish-openapi-2144-crds test-cr'
  I1026 12:35:39.763582 19 builder.go:146] stderr: ""
  I1026 12:35:39.763619 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-2144-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 10/26/24 12:35:39.763
  I1026 12:35:39.763715 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-170 explain e2e-test-crd-publish-openapi-2144-crds'
  I1026 12:35:39.804529 19 builder.go:146] stderr: ""
  I1026 12:35:39.804569 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-2144-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E1026 12:35:39.980421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:40.980586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:35:41.007178 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-170" for this suite. @ 10/26/24 12:35:41.014
• [4.821 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 10/26/24 12:35:41.023
  I1026 12:35:41.023598 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:35:41.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:35:41.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:35:41.049
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 10/26/24 12:35:41.059
  E1026 12:35:41.980819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:42.980965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:35:43.09
  I1026 12:35:43.094892 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-dde6323c-8c33-49dc-87f0-dd80c7dd3319 container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:35:43.111
  I1026 12:35:43.132123 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5919" for this suite. @ 10/26/24 12:35:43.136
• [2.119 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 10/26/24 12:35:43.143
  I1026 12:35:43.143525 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename var-expansion @ 10/26/24 12:35:43.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:35:43.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:35:43.164
  STEP: Creating a pod to test substitution in volume subpath @ 10/26/24 12:35:43.168
  E1026 12:35:43.981101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:44.981301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:45.982268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:46.982379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:35:47.194
  I1026 12:35:47.200404 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod var-expansion-3fcc2c9b-6789-4b5c-97b4-c49bf4101574 container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 12:35:47.207
  I1026 12:35:47.227460 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8026" for this suite. @ 10/26/24 12:35:47.233
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:335
  STEP: Creating a kubernetes client @ 10/26/24 12:35:47.243
  I1026 12:35:47.243136 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename statefulset @ 10/26/24 12:35:47.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:35:47.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:35:47.267
  STEP: Creating service test in namespace statefulset-4842 @ 10/26/24 12:35:47.272
  STEP: Creating a new StatefulSet @ 10/26/24 12:35:47.28
  I1026 12:35:47.293817 19 wait.go:40] Found 0 stateful pods, waiting for 3
  E1026 12:35:47.982647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:48.983019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:49.983583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:50.983916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:51.983971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:52.984904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:53.985204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:54.985936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:55.986144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:56.986349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:35:57.292323 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:35:57.292357 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:35:57.292364 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 10/26/24 12:35:57.306
  I1026 12:35:57.316559 19 statefulset.go:2507] Updating stateful set ss2
  STEP: Creating a new revision @ 10/26/24 12:35:57.316
  E1026 12:35:57.986474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:58.986560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:35:59.986898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:00.987104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:01.987292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:02.987601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:03.987831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:04.987977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:05.988068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:06.988172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 10/26/24 12:36:07.326
  STEP: Performing a canary update @ 10/26/24 12:36:07.326
  I1026 12:36:07.340511 19 statefulset.go:2507] Updating stateful set ss2
  I1026 12:36:07.350337 19 wait.go:74] Waiting for Pod statefulset-4842/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1026 12:36:07.988698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:08.989061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:09.989143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:10.989150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:11.989798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:12.989921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:13.990014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:14.990197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:15.990395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:16.991301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 10/26/24 12:36:17.349
  I1026 12:36:17.384110 19 wait.go:40] Found 1 stateful pods, waiting for 3
  E1026 12:36:17.991415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:18.991490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:19.991606      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:20.991710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:21.991807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:22.991921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:23.992913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:24.993871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:25.993961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:26.994870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:36:27.383335 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:36:27.383376 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:36:27.383381 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 10/26/24 12:36:27.392
  I1026 12:36:27.400738 19 statefulset.go:2507] Updating stateful set ss2
  I1026 12:36:27.412492 19 wait.go:74] Waiting for Pod statefulset-4842/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1026 12:36:27.995889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:28.995988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:29.996071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:30.996883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:31.997061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:32.997284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:33.997403      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:34.997638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:35.997806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:36.998004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:36:37.422480 19 statefulset.go:2507] Updating stateful set ss2
  I1026 12:36:37.431137 19 wait.go:56] Waiting for StatefulSet statefulset-4842/ss2 to complete update
  I1026 12:36:37.431165 19 wait.go:63] Waiting for Pod statefulset-4842/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1026 12:36:37.998883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:38.999909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:40.000010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:41.000072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:42.000170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:43.000408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:44.000428      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:45.000885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:46.001029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:47.001119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:36:47.439337 19 statefulset.go:138] Deleting all statefulset in ns statefulset-4842
  I1026 12:36:47.442938 19 rest.go:150] Scaling statefulset ss2 to 0
  E1026 12:36:48.001240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:49.002181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:50.002291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:51.002928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:52.002994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:53.003065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:54.003185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:55.003269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:56.003376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:57.003447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:36:57.462037 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1026 12:36:57.465948 19 rest.go:88] Deleting statefulset ss2
  I1026 12:36:57.482154 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4842" for this suite. @ 10/26/24 12:36:57.486
• [70.251 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 10/26/24 12:36:57.494
  I1026 12:36:57.494349 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:36:57.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:36:57.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:36:57.514
  STEP: Creating configMap with name projected-configmap-test-volume-58501509-5453-410e-8dd7-96ebc302edfa @ 10/26/24 12:36:57.518
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:36:57.522
  E1026 12:36:58.003900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:36:59.004911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:00.005746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:01.006020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:37:01.548
  I1026 12:37:01.552076 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-configmaps-c527b2b0-0754-40aa-9049-b2f5297caa38 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:37:01.564
  I1026 12:37:01.584559 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3089" for this suite. @ 10/26/24 12:37:01.589
• [4.105 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2216
  STEP: Creating a kubernetes client @ 10/26/24 12:37:01.599
  I1026 12:37:01.599337 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 12:37:01.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:01.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:01.62
  STEP: creating service in namespace services-3660 @ 10/26/24 12:37:01.624
  STEP: creating service affinity-nodeport-transition in namespace services-3660 @ 10/26/24 12:37:01.624
  STEP: creating replication controller affinity-nodeport-transition in namespace services-3660 @ 10/26/24 12:37:01.639
  I1026 12:37:01.650187      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-3660, replica count: 3
  E1026 12:37:02.006906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:03.007082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:04.007298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:04.701014      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 12:37:04.714791 19 resource.go:361] Creating new exec pod
  E1026 12:37:05.007538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:06.007653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:07.007726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:07.734974 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3660 exec execpod-affinityb4qgm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I1026 12:37:07.829271 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  I1026 12:37:07.829316 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:37:07.829492 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3660 exec execpod-affinityb4qgm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.177 80'
  I1026 12:37:07.913994 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.177 80\nConnection to 10.152.183.177 80 port [tcp/http] succeeded!\n"
  I1026 12:37:07.914036 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:37:07.914137 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3660 exec execpod-affinityb4qgm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.30.144 30988'
  E1026 12:37:08.007840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:08.010305 19 builder.go:146] stderr: "+ + nc -v -t -w 2 172.31.30.144 30988\necho hostName\nConnection to 172.31.30.144 30988 port [tcp/*] succeeded!\n"
  I1026 12:37:08.010345 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:37:08.010416 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3660 exec execpod-affinityb4qgm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.8.187 30988'
  I1026 12:37:08.093443 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.8.187 30988\nConnection to 172.31.8.187 30988 port [tcp/*] succeeded!\n"
  I1026 12:37:08.093497 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:37:08.104309 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3660 exec execpod-affinityb4qgm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.30.144:30988/ ; done'
  I1026 12:37:08.245901 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n"
  I1026 12:37:08.245948 19 builder.go:147] stdout: "\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-4m4k4\naffinity-nodeport-transition-4m4k4\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-p54jq\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-p54jq\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-p54jq\naffinity-nodeport-transition-p54jq\naffinity-nodeport-transition-p54jq\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-4m4k4\naffinity-nodeport-transition-hqcfd"
  I1026 12:37:08.245960 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.245968 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.245976 19 service.go:242] Received response from host: affinity-nodeport-transition-4m4k4
  I1026 12:37:08.245982 19 service.go:242] Received response from host: affinity-nodeport-transition-4m4k4
  I1026 12:37:08.245994 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.246001 19 service.go:242] Received response from host: affinity-nodeport-transition-p54jq
  I1026 12:37:08.246008 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.246019 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.246025 19 service.go:242] Received response from host: affinity-nodeport-transition-p54jq
  I1026 12:37:08.246056 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.246063 19 service.go:242] Received response from host: affinity-nodeport-transition-p54jq
  I1026 12:37:08.246069 19 service.go:242] Received response from host: affinity-nodeport-transition-p54jq
  I1026 12:37:08.246075 19 service.go:242] Received response from host: affinity-nodeport-transition-p54jq
  I1026 12:37:08.246081 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.246088 19 service.go:242] Received response from host: affinity-nodeport-transition-4m4k4
  I1026 12:37:08.246096 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.256330 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3660 exec execpod-affinityb4qgm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.30.144:30988/ ; done'
  I1026 12:37:08.388669 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30988/\n"
  I1026 12:37:08.388736 19 builder.go:147] stdout: "\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd\naffinity-nodeport-transition-hqcfd"
  I1026 12:37:08.388767 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388776 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388784 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388797 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388804 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388811 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388821 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388835 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388842 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388849 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388880 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388887 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388892 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388898 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388905 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.388913 19 service.go:242] Received response from host: affinity-nodeport-transition-hqcfd
  I1026 12:37:08.389035 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3660, will wait for the garbage collector to delete the pods @ 10/26/24 12:37:08.405
  I1026 12:37:08.468647 19 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 9.183885ms
  I1026 12:37:08.569327 19 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 100.664951ms
  E1026 12:37:09.008812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:10.009393      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:11.010112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:11.192377 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3660" for this suite. @ 10/26/24 12:37:11.197
• [9.605 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:341
  STEP: Creating a kubernetes client @ 10/26/24 12:37:11.204
  I1026 12:37:11.204827 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename cronjob @ 10/26/24 12:37:11.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:11.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:11.23
  STEP: Creating a cronjob @ 10/26/24 12:37:11.233
  STEP: creating @ 10/26/24 12:37:11.233
  STEP: getting @ 10/26/24 12:37:11.239
  STEP: listing @ 10/26/24 12:37:11.242
  STEP: watching @ 10/26/24 12:37:11.245
  I1026 12:37:11.245917 19 cronjob.go:370] starting watch
  STEP: cluster-wide listing @ 10/26/24 12:37:11.247
  STEP: cluster-wide watching @ 10/26/24 12:37:11.252
  I1026 12:37:11.252392 19 cronjob.go:382] starting watch
  STEP: patching @ 10/26/24 12:37:11.253
  STEP: updating @ 10/26/24 12:37:11.26
  I1026 12:37:11.269105 19 cronjob.go:406] waiting for watch events with expected annotations
  I1026 12:37:11.269133 19 cronjob.go:420] saw patched and updated annotations
  STEP: patching /status @ 10/26/24 12:37:11.269
  STEP: updating /status @ 10/26/24 12:37:11.275
  STEP: get /status @ 10/26/24 12:37:11.285
  STEP: deleting @ 10/26/24 12:37:11.289
  STEP: deleting a collection @ 10/26/24 12:37:11.305
  I1026 12:37:11.319848 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4640" for this suite. @ 10/26/24 12:37:11.323
• [0.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 10/26/24 12:37:11.329
  I1026 12:37:11.329991 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename daemonsets @ 10/26/24 12:37:11.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:11.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:11.349
  I1026 12:37:11.377363 19 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I1026 12:37:11.383770 19 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I1026 12:37:11.387521 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:11.387554 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:11.391290 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:37:11.391311 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 12:37:12.011123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:12.388941 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:12.389023 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:12.393901 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1026 12:37:12.393921 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 12:37:13.011590      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:13.390408 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:13.390448 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:13.395555 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 12:37:13.395579 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  I1026 12:37:13.395592 19 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I1026 12:37:13.404957 19 daemon_set.go:102] Updating DaemonSet daemon-set
  E1026 12:37:14.011934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:14.418136 19 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I1026 12:37:14.428176 19 daemon_set.go:102] Updating DaemonSet daemon-set
  I1026 12:37:14.428199 19 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I1026 12:37:14.431469 19 daemon_set.go:1193] Wrong image for pod: daemon-set-qjkqn. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I1026 12:37:14.431489 19 daemon_set.go:1198] Pod daemon-set-qjkqn is not available
  I1026 12:37:14.434526 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:14.434556 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1026 12:37:15.012023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:15.437932 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:15.437974 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1026 12:37:16.012118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:16.433394 19 daemon_set.go:1198] Pod daemon-set-lxwxv is not available
  I1026 12:37:16.436744 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:37:16.436781 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 10/26/24 12:37:16.443
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2392, will wait for the garbage collector to delete the pods @ 10/26/24 12:37:16.443
  I1026 12:37:16.505069 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 6.458534ms
  I1026 12:37:16.605816 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.738995ms
  E1026 12:37:17.012140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:18.010448 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:37:18.010484 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  E1026 12:37:18.012541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:18.015595 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19916"},"items":null}

  I1026 12:37:18.020500 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19916"},"items":null}

  I1026 12:37:18.035782 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2392" for this suite. @ 10/26/24 12:37:18.041
• [6.719 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:166
  STEP: Creating a kubernetes client @ 10/26/24 12:37:18.049
  I1026 12:37:18.049056 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename field-validation @ 10/26/24 12:37:18.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:18.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:18.069
  I1026 12:37:18.072733 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:37:19.012914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:20.013019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W1026 12:37:20.617312      19 warnings.go:70] unknown field "alpha"
  W1026 12:37:20.617332      19 warnings.go:70] unknown field "beta"
  W1026 12:37:20.617335      19 warnings.go:70] unknown field "delta"
  W1026 12:37:20.617338      19 warnings.go:70] unknown field "epsilon"
  W1026 12:37:20.617341      19 warnings.go:70] unknown field "gamma"
  E1026 12:37:21.013145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:21.171260 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1637" for this suite. @ 10/26/24 12:37:21.175
• [3.134 seconds]
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 10/26/24 12:37:21.183
  I1026 12:37:21.183245 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:37:21.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:21.207
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:21.21
  STEP: Creating configMap that has name configmap-test-emptyKey-9a2937b1-c47b-4cce-a8ed-2cf16bc27248 @ 10/26/24 12:37:21.213
  I1026 12:37:21.215791 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6467" for this suite. @ 10/26/24 12:37:21.219
• [0.042 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 10/26/24 12:37:21.225
  I1026 12:37:21.225062 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename podtemplate @ 10/26/24 12:37:21.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:21.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:21.247
  I1026 12:37:21.284837 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8798" for this suite. @ 10/26/24 12:37:21.289
• [0.071 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 10/26/24 12:37:21.296
  I1026 12:37:21.296636 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename init-container @ 10/26/24 12:37:21.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:21.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:21.318
  STEP: creating the pod @ 10/26/24 12:37:21.321
  I1026 12:37:21.321984 19 init_container.go:213] PodSpec: initContainers in spec.initContainers
  E1026 12:37:22.013225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:23.013719      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:24.014297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:25.014364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:25.949172 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9698" for this suite. @ 10/26/24 12:37:25.952
• [4.663 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1054
  STEP: Creating a kubernetes client @ 10/26/24 12:37:25.959
  I1026 12:37:25.959853 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename job @ 10/26/24 12:37:25.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:25.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:25.982
  STEP: Creating a job @ 10/26/24 12:37:25.985
  STEP: Ensure pods equal to parallelism count is attached to the job @ 10/26/24 12:37:25.991
  E1026 12:37:26.014751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:27.014841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching /status @ 10/26/24 12:37:27.996
  STEP: updating /status @ 10/26/24 12:37:28.004
  E1026 12:37:28.014834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get /status @ 10/26/24 12:37:28.016
  I1026 12:37:28.021003 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2377" for this suite. @ 10/26/24 12:37:28.025
• [2.073 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1034
  STEP: Creating a kubernetes client @ 10/26/24 12:37:28.033
  I1026 12:37:28.033024 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename statefulset @ 10/26/24 12:37:28.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:28.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:28.055
  STEP: Creating service test in namespace statefulset-97 @ 10/26/24 12:37:28.059
  STEP: Creating statefulset ss in namespace statefulset-97 @ 10/26/24 12:37:28.073
  I1026 12:37:28.085727 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E1026 12:37:29.015892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:30.015994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:31.016104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:32.016198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:33.016330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:34.016461      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:35.016652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:36.016903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:37.017877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:38.018064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:38.084831 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 10/26/24 12:37:38.094
  STEP: Getting /status @ 10/26/24 12:37:38.104
  I1026 12:37:38.108846 19 statefulset.go:1070] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 10/26/24 12:37:38.108
  I1026 12:37:38.119264 19 statefulset.go:1090] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 10/26/24 12:37:38.119
  I1026 12:37:38.121044 19 statefulset.go:1118] Observed &StatefulSet event: ADDED
  I1026 12:37:38.121068 19 statefulset.go:1111] Found Statefulset ss in namespace statefulset-97 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1026 12:37:38.121077 19 statefulset.go:1122] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 10/26/24 12:37:38.121
  I1026 12:37:38.121104 19 statefulset.go:1126] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I1026 12:37:38.128481 19 statefulset.go:1130] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 10/26/24 12:37:38.128
  I1026 12:37:38.130403 19 statefulset.go:1155] Observed &StatefulSet event: ADDED
  I1026 12:37:38.130432 19 statefulset.go:1151] Observed Statefulset ss in namespace statefulset-97 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1026 12:37:38.130540 19 statefulset.go:1155] Observed &StatefulSet event: MODIFIED
  I1026 12:37:38.130639 19 statefulset.go:138] Deleting all statefulset in ns statefulset-97
  I1026 12:37:38.135781 19 rest.go:150] Scaling statefulset ss to 0
  E1026 12:37:39.018274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:40.018376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:41.018661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:42.018902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:43.019870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:44.020286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:45.020502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:46.020804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:47.020988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:48.021167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:48.150313 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1026 12:37:48.154541 19 rest.go:88] Deleting statefulset ss
  I1026 12:37:48.170157 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-97" for this suite. @ 10/26/24 12:37:48.174
• [20.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 10/26/24 12:37:48.182
  I1026 12:37:48.182356 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename containers @ 10/26/24 12:37:48.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:48.202
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:48.205
  STEP: Creating a pod to test override command @ 10/26/24 12:37:48.208
  E1026 12:37:49.021409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:50.021670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:37:50.227
  I1026 12:37:50.230780 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod client-containers-daeae349-b816-48a1-981c-a6f2110cceb4 container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:37:50.239
  I1026 12:37:50.257211 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9626" for this suite. @ 10/26/24 12:37:50.261
• [2.087 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 10/26/24 12:37:50.269
  I1026 12:37:50.269163 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename runtimeclass @ 10/26/24 12:37:50.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:50.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:50.29
  E1026 12:37:51.021940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:52.022054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:37:52.326501 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2091" for this suite. @ 10/26/24 12:37:52.331
• [2.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 10/26/24 12:37:52.34
  I1026 12:37:52.340164 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 12:37:52.34
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:52.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:52.367
  STEP: Creating secret with name secret-test-753e9c8c-1dc4-4bca-be39-47fadefeb4f4 @ 10/26/24 12:37:52.395
  STEP: Creating a pod to test consume secrets @ 10/26/24 12:37:52.401
  E1026 12:37:53.022131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:54.022289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:55.023161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:56.023245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:37:56.428
  I1026 12:37:56.433296 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-secrets-28005829-6d79-4f80-9014-255d5eb65f25 container secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:37:56.445
  I1026 12:37:56.460400 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6516" for this suite. @ 10/26/24 12:37:56.463
  STEP: Destroying namespace "secret-namespace-9545" for this suite. @ 10/26/24 12:37:56.472
• [4.140 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:111
  STEP: Creating a kubernetes client @ 10/26/24 12:37:56.479
  I1026 12:37:56.479909 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename disruption @ 10/26/24 12:37:56.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:37:56.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:37:56.501
  STEP: creating the pdb @ 10/26/24 12:37:56.504
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:37:56.511
  E1026 12:37:57.024077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:37:58.024182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 10/26/24 12:37:58.516
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:37:58.527
  E1026 12:37:59.024914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:00.025100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 10/26/24 12:38:00.533
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:38:00.544
  E1026 12:38:01.025210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:02.025411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 10/26/24 12:38:02.557
  I1026 12:38:02.560699 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-485" for this suite. @ 10/26/24 12:38:02.565
• [6.093 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:863
  STEP: Creating a kubernetes client @ 10/26/24 12:38:02.572
  I1026 12:38:02.572716 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:38:02.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:02.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:02.592
  STEP: Setting up server cert @ 10/26/24 12:38:02.618
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:38:02.863
  STEP: Deploying the webhook pod @ 10/26/24 12:38:02.874
  STEP: Wait for the deployment to be ready @ 10/26/24 12:38:02.89
  I1026 12:38:02.901124 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:38:03.026355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:04.026540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:38:04.915
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:38:04.926
  E1026 12:38:05.026610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:38:05.926582 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 10/26/24 12:38:05.936
  STEP: create the configmap with a random name @ 10/26/24 12:38:05.953
  STEP: verify the configmap is mutated @ 10/26/24 12:38:05.965
  STEP: create the configmap with 'skip-me' name @ 10/26/24 12:38:05.966
  I1026 12:38:06.024598 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E1026 12:38:06.026793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-7882" for this suite. @ 10/26/24 12:38:06.028
  STEP: Destroying namespace "webhook-markers-5274" for this suite. @ 10/26/24 12:38:06.034
• [3.471 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 10/26/24 12:38:06.043
  I1026 12:38:06.043253 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename runtimeclass @ 10/26/24 12:38:06.043
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:06.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:06.064
  STEP: getting /apis @ 10/26/24 12:38:06.07
  STEP: getting /apis/node.k8s.io @ 10/26/24 12:38:06.074
  STEP: getting /apis/node.k8s.io/v1 @ 10/26/24 12:38:06.075
  STEP: creating @ 10/26/24 12:38:06.077
  STEP: watching @ 10/26/24 12:38:06.094
  I1026 12:38:06.094364 19 runtimeclass.go:275] starting watch
  STEP: getting @ 10/26/24 12:38:06.102
  STEP: listing @ 10/26/24 12:38:06.105
  STEP: patching @ 10/26/24 12:38:06.111
  STEP: updating @ 10/26/24 12:38:06.117
  I1026 12:38:06.124057 19 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 10/26/24 12:38:06.124
  STEP: deleting a collection @ 10/26/24 12:38:06.141
  I1026 12:38:06.159879 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1367" for this suite. @ 10/26/24 12:38:06.163
• [0.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 10/26/24 12:38:06.172
  I1026 12:38:06.172223 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename apf @ 10/26/24 12:38:06.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:06.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:06.192
  STEP: getting /apis @ 10/26/24 12:38:06.195
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 10/26/24 12:38:06.199
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 10/26/24 12:38:06.2
  STEP: creating @ 10/26/24 12:38:06.202
  STEP: getting @ 10/26/24 12:38:06.221
  STEP: listing @ 10/26/24 12:38:06.226
  STEP: watching @ 10/26/24 12:38:06.229
  I1026 12:38:06.229849 19 flowcontrol.go:620] starting watch
  STEP: patching @ 10/26/24 12:38:06.231
  STEP: updating @ 10/26/24 12:38:06.237
  I1026 12:38:06.251388 19 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 10/26/24 12:38:06.251
  STEP: patching /status @ 10/26/24 12:38:06.257
  STEP: updating /status @ 10/26/24 12:38:06.264
  STEP: deleting @ 10/26/24 12:38:06.279
  STEP: deleting a collection @ 10/26/24 12:38:06.301
  I1026 12:38:06.324791 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-597" for this suite. @ 10/26/24 12:38:06.33
• [0.167 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 10/26/24 12:38:06.338
  I1026 12:38:06.338851 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename gc @ 10/26/24 12:38:06.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:06.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:06.36
  STEP: create the rc @ 10/26/24 12:38:06.363
  W1026 12:38:06.370610      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1026 12:38:07.026962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:08.027130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:09.027238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:10.027496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:11.027763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the rc @ 10/26/24 12:38:11.374
  STEP: wait for all pods to be garbage collected @ 10/26/24 12:38:11.383
  E1026 12:38:12.028753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:13.029014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:14.029941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:15.029997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:16.030721      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 10/26/24 12:38:16.392
  W1026 12:38:16.398523      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1026 12:38:16.398560 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1026 12:38:16.398709 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9172" for this suite. @ 10/26/24 12:38:16.402
• [10.070 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 10/26/24 12:38:16.408
  I1026 12:38:16.408634 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:38:16.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:16.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:16.43
  STEP: Creating a pod to test emptydir volume type on node default medium @ 10/26/24 12:38:16.433
  E1026 12:38:17.031762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:18.031869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:19.031999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:20.032918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:38:20.462
  I1026 12:38:20.466174 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-71cb5b7b-5c76-4071-b874-d05ffd93ed31 container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:38:20.472
  I1026 12:38:20.491201 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8320" for this suite. @ 10/26/24 12:38:20.495
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1075
  STEP: Creating a kubernetes client @ 10/26/24 12:38:20.503
  I1026 12:38:20.503280 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:38:20.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:20.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:20.525
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 10/26/24 12:38:20.528
  I1026 12:38:20.528210 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-7345 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I1026 12:38:20.577098 19 builder.go:146] stderr: ""
  I1026 12:38:20.577154 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 10/26/24 12:38:20.577
  I1026 12:38:20.577230 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-7345 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I1026 12:38:20.622020 19 builder.go:146] stderr: ""
  I1026 12:38:20.622048 19 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 10/26/24 12:38:20.622
  I1026 12:38:20.626202 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-7345 delete pods e2e-test-httpd-pod'
  E1026 12:38:21.033341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:38:21.955424 19 builder.go:146] stderr: ""
  I1026 12:38:21.955477 19 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I1026 12:38:21.955582 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7345" for this suite. @ 10/26/24 12:38:21.96
• [1.466 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:712
  STEP: Creating a kubernetes client @ 10/26/24 12:38:21.969
  I1026 12:38:21.969332 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:38:21.969
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:21.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:21.991
  STEP: Setting up server cert @ 10/26/24 12:38:22.022
  E1026 12:38:22.033752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:38:22.143
  STEP: Deploying the webhook pod @ 10/26/24 12:38:22.151
  STEP: Wait for the deployment to be ready @ 10/26/24 12:38:22.166
  I1026 12:38:22.175471 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:38:23.033898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:24.034172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:38:24.191
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:38:24.2
  E1026 12:38:25.035061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:38:25.200972 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 10/26/24 12:38:25.21
  STEP: verifying the validating webhook match conditions @ 10/26/24 12:38:25.218
  STEP: updating the validating webhook match conditions @ 10/26/24 12:38:25.222
  STEP: verifying the validating webhook match conditions @ 10/26/24 12:38:25.231
  I1026 12:38:25.279763 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5806" for this suite. @ 10/26/24 12:38:25.284
  STEP: Destroying namespace "webhook-markers-4001" for this suite. @ 10/26/24 12:38:25.29
• [3.329 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 10/26/24 12:38:25.298
  I1026 12:38:25.298416 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:38:25.298
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:25.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:25.32
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 10/26/24 12:38:25.324
  E1026 12:38:26.035162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:27.035341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:38:27.344
  I1026 12:38:27.349112 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-6198fa82-cbc2-45df-b1dc-2c036fd40f2e container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:38:27.357
  I1026 12:38:27.372912 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2769" for this suite. @ 10/26/24 12:38:27.376
• [2.086 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 10/26/24 12:38:27.384
  I1026 12:38:27.384540 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 12:38:27.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:38:27.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:38:27.407
  E1026 12:38:28.035523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:29.035633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:30.036503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:31.036583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:32.037570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:33.038589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:34.038634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:35.038973      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:36.039019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:37.039745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:38.040569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:39.040753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:40.040904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:41.041010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:42.041118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:43.042128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:44.043145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:45.044161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:46.044896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:47.044994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:48.045109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:49.045198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:50.045891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:51.046043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:52.046911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:53.047025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:54.047827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:55.047929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:56.048926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:57.049977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:58.050912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:38:59.051029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:00.051123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:01.051214      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:02.051992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:03.052966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:04.053067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:05.053690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:06.053837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:07.053937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:08.054904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:09.055753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:10.055890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:11.056003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:12.056053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:13.056762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:14.057639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:15.057746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:16.058732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:17.059187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:18.060138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:19.060302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:20.061139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:21.061265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:22.061499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:23.061591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:24.061830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:25.062621      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:26.063139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:27.063776      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:27.423991 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1116" for this suite. @ 10/26/24 12:39:27.429
• [60.053 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 10/26/24 12:39:27.437
  I1026 12:39:27.437742 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename watch @ 10/26/24 12:39:27.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:39:27.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:39:27.46
  STEP: getting a starting resourceVersion @ 10/26/24 12:39:27.463
  STEP: starting a background goroutine to produce watch events @ 10/26/24 12:39:27.467
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 10/26/24 12:39:27.467
  E1026 12:39:28.064414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:29.065269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:30.066201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:30.248299 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9603" for this suite. @ 10/26/24 12:39:30.295
• [2.912 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1260
  STEP: Creating a kubernetes client @ 10/26/24 12:39:30.349
  I1026 12:39:30.349933 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 12:39:30.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:39:30.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:39:30.374
  STEP: creating service nodeport-test with type=NodePort in namespace services-3434 @ 10/26/24 12:39:30.377
  STEP: creating replication controller nodeport-test in namespace services-3434 @ 10/26/24 12:39:30.392
  I1026 12:39:30.400838      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-3434, replica count: 2
  E1026 12:39:31.066274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:32.066836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:33.066932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:33.452540      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 12:39:33.452575 19 resource.go:361] Creating new exec pod
  E1026 12:39:34.067153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:35.067347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:36.067857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:36.478746 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3434 exec execpodjkqs2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I1026 12:39:36.564357 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  I1026 12:39:36.564395 19 builder.go:147] stdout: "nodeport-test-k6dzn"
  I1026 12:39:36.564457 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3434 exec execpodjkqs2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.222 80'
  I1026 12:39:36.656603 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.222 80\nConnection to 10.152.183.222 80 port [tcp/http] succeeded!\n"
  I1026 12:39:36.656646 19 builder.go:147] stdout: "nodeport-test-k6dzn"
  I1026 12:39:36.656781 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3434 exec execpodjkqs2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.8.187 32093'
  I1026 12:39:36.738108 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.8.187 32093\nConnection to 172.31.8.187 32093 port [tcp/*] succeeded!\n"
  I1026 12:39:36.738193 19 builder.go:147] stdout: "nodeport-test-7r4gs"
  I1026 12:39:36.738311 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3434 exec execpodjkqs2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.30.144 32093'
  I1026 12:39:36.815381 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.30.144 32093\nConnection to 172.31.30.144 32093 port [tcp/*] succeeded!\n"
  I1026 12:39:36.815420 19 builder.go:147] stdout: "nodeport-test-7r4gs"
  I1026 12:39:36.815618 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3434" for this suite. @ 10/26/24 12:39:36.821
• [6.480 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 10/26/24 12:39:36.83
  I1026 12:39:36.830503 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename deployment @ 10/26/24 12:39:36.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:39:36.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:39:36.849
  I1026 12:39:36.852629 19 deployment.go:1196] Creating deployment "webserver-deployment"
  I1026 12:39:36.859484 19 deployment.go:1200] Waiting for observed generation 1
  E1026 12:39:37.067968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:38.068972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:38.869481 19 deployment.go:1205] Waiting for all required pods to come up
  I1026 12:39:38.873780 19 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 10/26/24 12:39:38.873
  I1026 12:39:38.873850 19 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I1026 12:39:38.881283 19 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I1026 12:39:38.891827 19 deployment.go:313] Updating deployment webserver-deployment
  I1026 12:39:38.891853 19 deployment.go:1224] Waiting for observed generation 2
  E1026 12:39:39.069746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:40.070584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:40.904022 19 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I1026 12:39:40.908370 19 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I1026 12:39:40.911865 19 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I1026 12:39:40.924620 19 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I1026 12:39:40.924644 19 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I1026 12:39:40.927827 19 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I1026 12:39:40.935814 19 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I1026 12:39:40.935833 19 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I1026 12:39:40.945874 19 deployment.go:313] Updating deployment webserver-deployment
  I1026 12:39:40.945899 19 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I1026 12:39:40.953103 19 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I1026 12:39:40.959914 19 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  I1026 12:39:40.976649 19 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "538f8eef-7b07-43a5-b920-3c9b4f7e062b",
      ResourceVersion: (string) (len=5) "21427",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-786f49d774\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1026 12:39:40.982592 19 deployment.go:39] New ReplicaSet "webserver-deployment-786f49d774" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-786f49d774",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "28e66e14-4f56-454c-a1a3-6e4bb281dbaf",
      ResourceVersion: (string) (len=5) "21424",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "538f8eef-7b07-43a5-b920-3c9b4f7e062b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 33 38 66 38 65  65 66 2d 37 62 30 37 2d  |\"538f8eef-7b07-|
              00000120  34 33 61 35 2d 62 39 32  30 2d 33 63 39 62 34 66  |43a5-b920-3c9b4f|
              00000130  37 65 30 36 32 62 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |7e062b\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:39:40.983049 19 deployment.go:44] All old ReplicaSets of Deployment "webserver-deployment":
  I1026 12:39:40.983248 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-64bcfc6446",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
      ResourceVersion: (string) (len=5) "21421",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "538f8eef-7b07-43a5-b920-3c9b4f7e062b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 35 33 38 66 38 65  65 66 2d 37 62 30 37 2d  |\"538f8eef-7b07-|
              00000120  34 33 61 35 2d 62 39 32  30 2d 33 63 39 62 34 66  |43a5-b920-3c9b4f|
              00000130  37 65 30 36 32 62 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |7e062b\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:39:40.994317 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-6nnq6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-6nnq6",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fc274db3-9970-47ed-b889-2ecc69db97f5",
      ResourceVersion: (string) (len=5) "21290",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 39  2e 31 38 36 5c 22 7d 22  |2.168.29.186\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-x9kqp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-x9kqp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.186",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.186"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543177,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d93671233f4f8c24f63484839fce16a83e76ead60e440060dc9949ec6a53c7b2",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-x9kqp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:40.995685 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-7gn2w" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-7gn2w",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ae0ea2c5-18e6-4975-8495-5ee48aa0ffef",
      ResourceVersion: (string) (len=5) "21293",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 39  2e 31 37 36 5c 22 7d 22  |2.168.29.176\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tglsp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tglsp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.176",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.176"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543177,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://40f688402459feec381bf364cd3359d4d30c1fecaf21bbbaba66cbdad7adc938",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-tglsp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:40.998634 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-9sqpc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-9sqpc",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "daa5e17e-84e4-43c1-812e-8bc95f673f2a",
      ResourceVersion: (string) (len=5) "21432",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543180,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bdcsl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bdcsl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:40.999870 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-ff7m5" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-ff7m5",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5bccd78f-3921-49ea-aba7-005b901117aa",
      ResourceVersion: (string) (len=5) "21284",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 39  2e 31 38 33 5c 22 7d 22  |2.168.29.183\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s84dk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s84dk",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.183",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.183"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543177,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0e5bdaad7455207099610b869f63e8de9ba65889a2ac117f06efc943f00ff585",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-s84dk",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.001130 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-fzn2h" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-fzn2h",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c5146e64-3c88-44e9-90b8-9809f4f6c82a",
      ResourceVersion: (string) (len=5) "21309",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 33  32 2e 39 36 5c 22 7d 22  |2.168.232.96\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ppqmt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ppqmt",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-8-187",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.8.187",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.8.187"
        }
      },
      PodIP: (string) (len=14) "192.168.232.96",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.232.96"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543177,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://8b7223650dec04b35578d48d6d09c5adef335dcbafb2b1dbdaeb9d12b1f67f38",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-ppqmt",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.002691 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-hxnjw" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-hxnjw",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "549547b4-5cfe-4e93-a276-19dada69e6aa",
      ResourceVersion: (string) (len=5) "21306",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 33  32 2e 38 32 5c 22 7d 22  |2.168.232.82\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6254v",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6254v",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-8-187",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.8.187",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.8.187"
        }
      },
      PodIP: (string) (len=14) "192.168.232.82",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.232.82"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543177,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://e4183620e28ced9a09e9d705c3305596a16e95cb3534d434df62720b536a0ece",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-6254v",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.004736 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-js2n5" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-js2n5",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "641befb5-25e3-47f3-81ba-6bc927e3af0c",
      ResourceVersion: (string) (len=5) "21433",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543180,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-78fwd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-78fwd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.005587 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-lr85p" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-lr85p",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8ae6d44a-5f0a-49e4-b5c1-eef90710b24b",
      ResourceVersion: (string) (len=5) "21302",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 33  32 2e 31 30 33 5c 22 7d  |2.168.232.103\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zggsf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zggsf",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-8-187",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.8.187",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.8.187"
        }
      },
      PodIP: (string) (len=15) "192.168.232.103",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.232.103"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543177,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://3e5641154b85b27b55be0558b27abf383c193a3356a01a885db3a8bfe967386e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-zggsf",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.006819 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-lt85x" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-lt85x",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d6ba5e5c-fc69-4205-9e97-9d04fd4e3578",
      ResourceVersion: (string) (len=5) "21299",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 36  2e 31 32 30 5c 22 7d 22  |2.168.46.120\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8gfh6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8gfh6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.104",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.104"
        }
      },
      PodIP: (string) (len=14) "192.168.46.120",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.46.120"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543177,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://5592199f921ae7d2e0c2eae2a3056b213c255d280ef2665729534617552cfdbd",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-8gfh6",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.007942 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-vzmqz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-vzmqz",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "29010675-6a0a-4a6d-b7bd-795633004724",
      ResourceVersion: (string) (len=5) "21435",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543180,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fkwrl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fkwrl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.008700 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-xhrxq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-xhrxq",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "322cfaaf-209b-4c22-a723-85c498228493",
      ResourceVersion: (string) (len=5) "21431",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543180,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nnh9k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nnh9k",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.009574 19 deployment.go:67] Pod "webserver-deployment-64bcfc6446-z4jfm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-64bcfc6446-z4jfm",
      GenerateName: (string) (len=32) "webserver-deployment-64bcfc6446-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3785519b-3b28-4fa3-869f-f1cd6861fbda",
      ResourceVersion: (string) (len=5) "21303",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "64bcfc6446"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-64bcfc6446",
          UID: (types.UID) (len=36) "12ad8973-61da-4874-8915-0c63fd84e240",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 32  61 64 38 39 37 33 2d 36  |d\":\"12ad8973-6|
              00000090  31 64 61 2d 34 38 37 34  2d 38 39 31 35 2d 30 63  |1da-4874-8915-0c|
              000000a0  36 33 66 64 38 34 65 32  34 30 5c 22 7d 22 3a 7b  |63fd84e240\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 36  2e 31 31 39 5c 22 7d 22  |2.168.46.119\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-px7jj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-px7jj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543176,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.104",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.104"
        }
      },
      PodIP: (string) (len=14) "192.168.46.119",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.46.119"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543176,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543177,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a40ec1b9ab31739a253662d4835e23863f4497f0b258ddd0756fab958a7a3699",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-px7jj",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.011185 19 deployment.go:67] Pod "webserver-deployment-786f49d774-2qs6v" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-2qs6v",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6641e1d4-760a-4c77-ab34-68741a9ecd63",
      ResourceVersion: (string) (len=5) "21409",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "28e66e14-4f56-454c-a1a3-6e4bb281dbaf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 38  65 36 36 65 31 34 2d 34  |d\":\"28e66e14-4|
              00000090  66 35 36 2d 34 35 34 63  2d 61 31 61 33 2d 36 65  |f56-454c-a1a3-6e|
              000000a0  34 62 62 32 38 31 64 62  61 66 5c 22 7d 22 3a 7b  |4bb281dbaf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 39 2e 31 37  31 5c 22 7d 22 3a 7b 22  |68.29.171\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wzj9m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wzj9m",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.171",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.171"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-wzj9m",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.012446 19 deployment.go:67] Pod "webserver-deployment-786f49d774-dsclg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-dsclg",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c3012292-d20d-4997-81f6-bd23155469e9",
      ResourceVersion: (string) (len=5) "21417",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "28e66e14-4f56-454c-a1a3-6e4bb281dbaf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 38  65 36 36 65 31 34 2d 34  |d\":\"28e66e14-4|
              00000090  66 35 36 2d 34 35 34 63  2d 61 31 61 33 2d 36 65  |f56-454c-a1a3-6e|
              000000a0  34 62 62 32 38 31 64 62  61 66 5c 22 7d 22 3a 7b  |4bb281dbaf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 33 32 2e 31  30 38 5c 22 7d 22 3a 7b  |68.232.108\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2f8x7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2f8x7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-8-187",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.8.187",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=12) "172.31.8.187"
        }
      },
      PodIP: (string) (len=15) "192.168.232.108",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.232.108"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-2f8x7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.013709 19 deployment.go:67] Pod "webserver-deployment-786f49d774-frqc7" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-frqc7",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0cc0b7bb-af46-458f-9071-9b6124faead1",
      ResourceVersion: (string) (len=5) "21416",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "28e66e14-4f56-454c-a1a3-6e4bb281dbaf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 38  65 36 36 65 31 34 2d 34  |d\":\"28e66e14-4|
              00000090  66 35 36 2d 34 35 34 63  2d 61 31 61 33 2d 36 65  |f56-454c-a1a3-6e|
              000000a0  34 62 62 32 38 31 64 62  61 66 5c 22 7d 22 3a 7b  |4bb281dbaf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 34 36 2e 31 32  31 5c 22 7d 22 3a 7b 22  |68.46.121\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qldzl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qldzl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.104",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.104"
        }
      },
      PodIP: (string) (len=14) "192.168.46.121",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.46.121"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-qldzl",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.014882 19 deployment.go:67] Pod "webserver-deployment-786f49d774-lmr4c" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-lmr4c",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4f71ea1b-ca24-4b46-9a87-afcc4065898a",
      ResourceVersion: (string) (len=5) "21406",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "28e66e14-4f56-454c-a1a3-6e4bb281dbaf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 38  65 36 36 65 31 34 2d 34  |d\":\"28e66e14-4|
              00000090  66 35 36 2d 34 35 34 63  2d 61 31 61 33 2d 36 65  |f56-454c-a1a3-6e|
              000000a0  34 62 62 32 38 31 64 62  61 66 5c 22 7d 22 3a 7b  |4bb281dbaf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 32 39 2e 31 33  33 5c 22 7d 22 3a 7b 22  |68.29.133\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ln72z",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ln72z",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.133",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.133"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-ln72z",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.016080 19 deployment.go:67] Pod "webserver-deployment-786f49d774-vj2nt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-vj2nt",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "46f9569f-0a80-4ef9-b382-3fde8fca12d7",
      ResourceVersion: (string) (len=5) "21412",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "28e66e14-4f56-454c-a1a3-6e4bb281dbaf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 38  65 36 36 65 31 34 2d 34  |d\":\"28e66e14-4|
              00000090  66 35 36 2d 34 35 34 63  2d 61 31 61 33 2d 36 65  |f56-454c-a1a3-6e|
              000000a0  34 62 62 32 38 31 64 62  61 66 5c 22 7d 22 3a 7b  |4bb281dbaf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 34 36 2e 31 32  32 5c 22 7d 22 3a 7b 22  |68.46.122\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4kj57",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4kj57",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543178,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.104",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.104"
        }
      },
      PodIP: (string) (len=14) "192.168.46.122",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.46.122"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543178,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-4kj57",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.017203 19 deployment.go:67] Pod "webserver-deployment-786f49d774-wb9r5" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-786f49d774-wb9r5",
      GenerateName: (string) (len=32) "webserver-deployment-786f49d774-",
      Namespace: (string) (len=15) "deployment-6534",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6a9d6596-05a3-4246-ac38-7b86061f4996",
      ResourceVersion: (string) (len=5) "21430",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543180,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "786f49d774",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-786f49d774",
          UID: (types.UID) (len=36) "28e66e14-4f56-454c-a1a3-6e4bb281dbaf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543180,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 38  65 36 36 65 31 34 2d 34  |d\":\"28e66e14-4|
              00000090  66 35 36 2d 34 35 34 63  2d 61 31 61 33 2d 36 65  |f56-454c-a1a3-6e|
              000000a0  34 62 62 32 38 31 64 62  61 66 5c 22 7d 22 3a 7b  |4bb281dbaf\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sds64",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sds64",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:41.017855 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6534" for this suite. @ 10/26/24 12:39:41.033
• [4.219 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 10/26/24 12:39:41.05
  I1026 12:39:41.050596 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename deployment @ 10/26/24 12:39:41.051
  E1026 12:39:41.071055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:39:41.087
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:39:41.091
  I1026 12:39:41.094518 19 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I1026 12:39:41.110090 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E1026 12:39:42.071280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:43.071495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:44.071605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:45.071835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:46.071990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:46.114989 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 10/26/24 12:39:46.115
  I1026 12:39:46.115058 19 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I1026 12:39:46.123186 19 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I1026 12:39:46.134595 19 deployment.go:222] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E1026 12:39:47.072940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:48.073131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:48.145209 19 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I1026 12:39:48.148258 19 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I1026 12:39:48.159639 19 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1267",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7708678a-6270-4f1d-b604-5ace13a8c7bf",
      ResourceVersion: (string) (len=5) "21862",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543186,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543186,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543186,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543186,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543186,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-56bb5bb765\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1026 12:39:48.163533 19 deployment.go:39] New ReplicaSet "test-rolling-update-deployment-56bb5bb765" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-56bb5bb765",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1267",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "eb6140fe-f2aa-481b-9ef2-5f8db2cd0c03",
      ResourceVersion: (string) (len=5) "21850",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543186,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "7708678a-6270-4f1d-b604-5ace13a8c7bf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543186,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 37 30 38 36 37  38 61 2d 36 32 37 30 2d  |\"7708678a-6270-|
              00000120  34 66 31 64 2d 62 36 30  34 2d 35 61 63 65 31 33  |4f1d-b604-5ace13|
              00000130  61 38 63 37 62 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a8c7bf\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:39:48.164014 19 deployment.go:44] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I1026 12:39:48.164204 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1267",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e42a76a5-0824-4128-b662-2392671222b6",
      ResourceVersion: (string) (len=5) "21859",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543181,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "7708678a-6270-4f1d-b604-5ace13a8c7bf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543181,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 37 37 30 38 36 37 38  |"uid\":\"7708678|
              000000b0  61 2d 36 32 37 30 2d 34  66 31 64 2d 62 36 30 34  |a-6270-4f1d-b604|
              000000c0  2d 35 61 63 65 31 33 61  38 63 37 62 66 5c 22 7d  |-5ace13a8c7bf\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:39:48.169329 19 deployment.go:67] Pod "test-rolling-update-deployment-56bb5bb765-pm5hv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-56bb5bb765-pm5hv",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-56bb5bb765-",
      Namespace: (string) (len=15) "deployment-1267",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b90b0ac0-c491-4424-aab0-24c986233b10",
      ResourceVersion: (string) (len=5) "21849",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543186,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "56bb5bb765"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-56bb5bb765",
          UID: (types.UID) (len=36) "eb6140fe-f2aa-481b-9ef2-5f8db2cd0c03",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543186,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 62  36 31 34 30 66 65 2d 66  |d\":\"eb6140fe-f|
              00000090  32 61 61 2d 34 38 31 62  2d 39 65 66 32 2d 35 66  |2aa-481b-9ef2-5f|
              000000a0  38 64 62 32 63 64 30 63  30 33 5c 22 7d 22 3a 7b  |8db2cd0c03\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 32 39  2e 31 33 38 5c 22 7d 22  |2.168.29.138\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gc8vz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gc8vz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543186,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543187,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865543186,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) (len=14) "192.168.29.138",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.29.138"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865543186,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865543186,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6",
          ContainerID: (string) (len=77) "containerd://4df8002945aa2c803dc7cdce830691b60016936e080537147553aa9571d2dee2",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-gc8vz",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:39:48.170406 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1267" for this suite. @ 10/26/24 12:39:48.173
• [7.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 10/26/24 12:39:48.181
  I1026 12:39:48.181760 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename svcaccounts @ 10/26/24 12:39:48.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:39:48.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:39:48.203
  STEP: Creating a pod to test service account token:  @ 10/26/24 12:39:48.208
  E1026 12:39:49.074078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:50.074885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:51.075888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:52.076110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:39:52.232
  I1026 12:39:52.237732 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod test-pod-1277be18-a292-4eb5-8c8b-019967540814 container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:39:52.246
  I1026 12:39:52.262216 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8120" for this suite. @ 10/26/24 12:39:52.266
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1473
  STEP: Creating a kubernetes client @ 10/26/24 12:39:52.275
  I1026 12:39:52.275248 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 12:39:52.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:39:52.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:39:52.297
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2595 @ 10/26/24 12:39:52.302
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 10/26/24 12:39:52.313
  STEP: creating service externalsvc in namespace services-2595 @ 10/26/24 12:39:52.313
  STEP: creating replication controller externalsvc in namespace services-2595 @ 10/26/24 12:39:52.326
  I1026 12:39:52.334665      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2595, replica count: 2
  E1026 12:39:53.076790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:54.077245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:55.077337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:55.385814      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 10/26/24 12:39:55.391
  I1026 12:39:55.406819 19 resource.go:361] Creating new exec pod
  E1026 12:39:56.077929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:57.078069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:39:57.423693 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2595 exec execpodvncbf -- /bin/sh -x -c nslookup clusterip-service.services-2595.svc.cluster.local'
  I1026 12:39:57.520303 19 builder.go:146] stderr: "+ nslookup clusterip-service.services-2595.svc.cluster.local\n"
  I1026 12:39:57.520347 19 builder.go:147] stdout: "Server:\t\t10.152.183.57\nAddress:\t10.152.183.57#53\n\nclusterip-service.services-2595.svc.cluster.local\tcanonical name = externalsvc.services-2595.svc.cluster.local.\nName:\texternalsvc.services-2595.svc.cluster.local\nAddress: 10.152.183.45\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-2595, will wait for the garbage collector to delete the pods @ 10/26/24 12:39:57.52
  I1026 12:39:57.585765 19 resources.go:139] Deleting ReplicationController externalsvc took: 10.092109ms
  I1026 12:39:57.686815 19 resources.go:163] Terminating ReplicationController externalsvc pods took: 101.045288ms
  E1026 12:39:58.078801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:39:59.078849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:00.079716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:00.306313 19 service.go:1482] Cleaning up the ClusterIP to ExternalName test service
  I1026 12:40:00.319477 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2595" for this suite. @ 10/26/24 12:40:00.326
• [8.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 10/26/24 12:40:00.334
  I1026 12:40:00.334444 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replication-controller @ 10/26/24 12:40:00.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:00.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:00.366
  STEP: Creating replication controller my-hostname-basic-ad7d8ba5-b9a9-43ba-9c1e-a90a6a24c376 @ 10/26/24 12:40:00.37
  I1026 12:40:00.383133 19 resource.go:87] Pod name my-hostname-basic-ad7d8ba5-b9a9-43ba-9c1e-a90a6a24c376: Found 0 pods out of 1
  E1026 12:40:01.079864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:02.080190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:03.080387      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:04.080749      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:05.080959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:05.387810 19 resource.go:87] Pod name my-hostname-basic-ad7d8ba5-b9a9-43ba-9c1e-a90a6a24c376: Found 1 pods out of 1
  I1026 12:40:05.387843 19 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-ad7d8ba5-b9a9-43ba-9c1e-a90a6a24c376" are running
  I1026 12:40:05.392377 19 rc.go:523] Pod "my-hostname-basic-ad7d8ba5-b9a9-43ba-9c1e-a90a6a24c376-v9f9k" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:40:01 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:40:00 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:40:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:40:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:40:00 +0000 UTC Reason: Message:}])
  I1026 12:40:05.392397 19 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 10/26/24 12:40:05.392
  I1026 12:40:05.405988 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2787" for this suite. @ 10/26/24 12:40:05.411
• [5.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 10/26/24 12:40:05.42
  I1026 12:40:05.420556 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replication-controller @ 10/26/24 12:40:05.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:05.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:05.443
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 10/26/24 12:40:05.446
  E1026 12:40:06.081947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:07.082077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 10/26/24 12:40:07.469
  STEP: Then the orphan pod is adopted @ 10/26/24 12:40:07.476
  E1026 12:40:08.082170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:08.487783 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7400" for this suite. @ 10/26/24 12:40:08.492
• [3.080 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 10/26/24 12:40:08.5
  I1026 12:40:08.500502 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 12:40:08.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:08.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:08.521
  STEP: Creating pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043 @ 10/26/24 12:40:08.524
  E1026 12:40:09.083116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:10.083960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 10/26/24 12:40:10.544
  I1026 12:40:10.548297 19 container_probe.go:1749] Initial restart count of pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca is 0
  I1026 12:40:10.553546 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:11.084901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:12.085019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:12.560254 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:13.085905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:14.086876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:14.565788 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:15.087347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:16.087454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:16.571131 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:17.087710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:18.087929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:18.576873 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:19.088017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:20.088169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:20.583885 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:21.088296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:22.088515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:22.590221 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:23.088762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:24.088851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:24.596819 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:25.088977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:26.089081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:26.602762 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:27.089197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:28.089426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:28.607037 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  E1026 12:40:29.089709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:30.089895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:40:30.612449 19 container_probe.go:1759] Get pod liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca in namespace container-probe-8043
  I1026 12:40:30.612485 19 container_probe.go:1763] Restart count of pod container-probe-8043/liveness-9eb80a6c-938a-4aa6-8132-c893a41374ca is now 1 (20.064166224s elapsed)
  STEP: deleting the pod @ 10/26/24 12:40:30.612
  I1026 12:40:30.624525 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8043" for this suite. @ 10/26/24 12:40:30.628
• [22.135 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 10/26/24 12:40:30.635
  I1026 12:40:30.635240 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:40:30.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:30.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:30.661
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 10/26/24 12:40:30.664
  E1026 12:40:31.089988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:32.090089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:33.090302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:34.090654      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:40:34.692
  I1026 12:40:34.698099 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-6c10fb5d-4644-442f-b1fb-8dd214fa8e1b container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:40:34.706
  I1026 12:40:34.720740 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2037" for this suite. @ 10/26/24 12:40:34.725
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 10/26/24 12:40:34.733
  I1026 12:40:34.733508 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename discovery @ 10/26/24 12:40:34.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:34.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:34.756
  STEP: Setting up server cert @ 10/26/24 12:40:34.761
  I1026 12:40:34.941426 19 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I1026 12:40:34.942964 19 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I1026 12:40:34.942982 19 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I1026 12:40:34.942992 19 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I1026 12:40:34.942998 19 discovery.go:139] Checking APIGroup: apps
  I1026 12:40:34.944646 19 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I1026 12:40:34.944663 19 discovery.go:148] Versions found [{apps/v1 v1}]
  I1026 12:40:34.944669 19 discovery.go:154] apps/v1 matches apps/v1
  I1026 12:40:34.944689 19 discovery.go:139] Checking APIGroup: events.k8s.io
  I1026 12:40:34.946018 19 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I1026 12:40:34.946031 19 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I1026 12:40:34.946037 19 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I1026 12:40:34.946044 19 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I1026 12:40:34.947315 19 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I1026 12:40:34.947349 19 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I1026 12:40:34.947355 19 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I1026 12:40:34.947361 19 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I1026 12:40:34.948657 19 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I1026 12:40:34.948702 19 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I1026 12:40:34.948710 19 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I1026 12:40:34.948716 19 discovery.go:139] Checking APIGroup: autoscaling
  I1026 12:40:34.950057 19 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I1026 12:40:34.950091 19 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I1026 12:40:34.950098 19 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I1026 12:40:34.950104 19 discovery.go:139] Checking APIGroup: batch
  I1026 12:40:34.951347 19 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I1026 12:40:34.951360 19 discovery.go:148] Versions found [{batch/v1 v1}]
  I1026 12:40:34.951365 19 discovery.go:154] batch/v1 matches batch/v1
  I1026 12:40:34.951371 19 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I1026 12:40:34.952630 19 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I1026 12:40:34.952641 19 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I1026 12:40:34.952646 19 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I1026 12:40:34.952652 19 discovery.go:139] Checking APIGroup: networking.k8s.io
  I1026 12:40:34.953975 19 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I1026 12:40:34.953995 19 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I1026 12:40:34.954000 19 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I1026 12:40:34.954031 19 discovery.go:139] Checking APIGroup: policy
  I1026 12:40:34.955254 19 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I1026 12:40:34.955275 19 discovery.go:148] Versions found [{policy/v1 v1}]
  I1026 12:40:34.955280 19 discovery.go:154] policy/v1 matches policy/v1
  I1026 12:40:34.955286 19 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I1026 12:40:34.956772 19 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I1026 12:40:34.956791 19 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I1026 12:40:34.956797 19 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I1026 12:40:34.956839 19 discovery.go:139] Checking APIGroup: storage.k8s.io
  I1026 12:40:34.958374 19 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I1026 12:40:34.958396 19 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I1026 12:40:34.958403 19 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I1026 12:40:34.958409 19 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I1026 12:40:34.959646 19 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I1026 12:40:34.959670 19 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I1026 12:40:34.959692 19 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I1026 12:40:34.959697 19 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I1026 12:40:34.960956 19 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I1026 12:40:34.960981 19 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I1026 12:40:34.960987 19 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I1026 12:40:34.960993 19 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I1026 12:40:34.962231 19 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I1026 12:40:34.962250 19 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I1026 12:40:34.962255 19 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I1026 12:40:34.962261 19 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I1026 12:40:34.963506 19 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I1026 12:40:34.963515 19 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I1026 12:40:34.963520 19 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I1026 12:40:34.963526 19 discovery.go:139] Checking APIGroup: node.k8s.io
  I1026 12:40:34.964994 19 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I1026 12:40:34.965016 19 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I1026 12:40:34.965023 19 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I1026 12:40:34.965029 19 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I1026 12:40:34.966516 19 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I1026 12:40:34.966537 19 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I1026 12:40:34.966544 19 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I1026 12:40:34.966550 19 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I1026 12:40:34.967832 19 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I1026 12:40:34.967857 19 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  I1026 12:40:34.967862 19 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I1026 12:40:34.967868 19 discovery.go:139] Checking APIGroup: metrics.k8s.io
  I1026 12:40:34.969107 19 discovery.go:147] PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  I1026 12:40:34.969122 19 discovery.go:148] Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  I1026 12:40:34.969128 19 discovery.go:154] metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  I1026 12:40:34.969218 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-9716" for this suite. @ 10/26/24 12:40:34.973
• [0.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:52
  STEP: Creating a kubernetes client @ 10/26/24 12:40:34.982
  I1026 12:40:34.982741 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename dns @ 10/26/24 12:40:34.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:35.003
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 10/26/24 12:40:35.007
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 10/26/24 12:40:35.007
  STEP: creating a pod to probe DNS @ 10/26/24 12:40:35.007
  STEP: submitting the pod to kubernetes @ 10/26/24 12:40:35.007
  E1026 12:40:35.091064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:36.091902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 12:40:37.03
  STEP: looking for the results for each expected name from probers @ 10/26/24 12:40:37.034
  I1026 12:40:37.054718 19 dns_common.go:527] DNS probes using dns-2816/dns-test-207167ec-3c3c-41c8-acf1-006af8675379 succeeded

  STEP: deleting the pod @ 10/26/24 12:40:37.054
  I1026 12:40:37.073076 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2816" for this suite. @ 10/26/24 12:40:37.078
• [2.104 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 10/26/24 12:40:37.086
  I1026 12:40:37.086694 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename validating-admission-policy @ 10/26/24 12:40:37.087
  E1026 12:40:37.092661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:37.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:37.112
  STEP: creating a policy with variables @ 10/26/24 12:40:37.122
  STEP: waiting until the marker is denied @ 10/26/24 12:40:37.142
  STEP: testing a replicated Deployment to be allowed @ 10/26/24 12:40:37.45
  STEP: testing a non-replicated ReplicaSet not to be denied @ 10/26/24 12:40:37.465
  I1026 12:40:37.511546 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-1802" for this suite. @ 10/26/24 12:40:37.521
• [0.445 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 10/26/24 12:40:37.531
  I1026 12:40:37.531654 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename subpath @ 10/26/24 12:40:37.532
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:37.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:37.557
  STEP: Setting up data @ 10/26/24 12:40:37.56
  STEP: Creating pod pod-subpath-test-configmap-qccw @ 10/26/24 12:40:37.57
  STEP: Creating a pod to test atomic-volume-subpath @ 10/26/24 12:40:37.57
  E1026 12:40:38.093348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:39.093199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:40.093896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:41.093935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:42.094031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:43.094128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:44.094218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:45.094316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:46.094489      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:47.094898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:48.095754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:49.095837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:50.095937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:51.096206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:52.096893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:53.097021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:54.097127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:55.097222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:56.097306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:57.097960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:58.098074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:40:59.098301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:40:59.649
  I1026 12:40:59.655381 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-subpath-test-configmap-qccw container test-container-subpath-configmap-qccw: <nil>
  STEP: delete the pod @ 10/26/24 12:40:59.674
  STEP: Deleting pod pod-subpath-test-configmap-qccw @ 10/26/24 12:40:59.691
  I1026 12:40:59.691269 19 delete.go:62] Deleting pod "pod-subpath-test-configmap-qccw" in namespace "subpath-511"
  I1026 12:40:59.696911 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-511" for this suite. @ 10/26/24 12:40:59.701
• [22.179 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 10/26/24 12:40:59.71
  I1026 12:40:59.710918 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename gc @ 10/26/24 12:40:59.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:40:59.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:40:59.734
  I1026 12:40:59.768717 19 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ceec51cc-1ad5-40f5-a482-9898a3d9ccd4", Controller:(*bool)(0xc003f0b1be), BlockOwnerDeletion:(*bool)(0xc003f0b1bf)}}
  I1026 12:40:59.776182 19 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"efa27f4d-16a5-4729-881a-fad425f65c78", Controller:(*bool)(0xc003c20576), BlockOwnerDeletion:(*bool)(0xc003c20577)}}
  I1026 12:40:59.781447 19 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a3e20466-3a59-4a69-b2d1-0f3a0914ee42", Controller:(*bool)(0xc003c20866), BlockOwnerDeletion:(*bool)(0xc003c20867)}}
  E1026 12:41:00.098441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:01.099293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:02.099531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:03.099593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:04.099761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:04.796670 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9800" for this suite. @ 10/26/24 12:41:04.801
• [5.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 10/26/24 12:41:04.815
  I1026 12:41:04.815047 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 12:41:04.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:04.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:04.844
  STEP: creating the pod @ 10/26/24 12:41:04.848
  STEP: submitting the pod to kubernetes @ 10/26/24 12:41:04.848
  W1026 12:41:04.857485      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E1026 12:41:05.099846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:06.100075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 10/26/24 12:41:06.87
  STEP: updating the pod @ 10/26/24 12:41:06.875
  E1026 12:41:07.100110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:07.387766 19 pod_client.go:173] Successfully updated pod "pod-update-activedeadlineseconds-0b43a8bb-5d50-458e-b06f-42bc0b15b096"
  E1026 12:41:08.100899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:09.101006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:10.101093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:11.101308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:11.404907 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3750" for this suite. @ 10/26/24 12:41:11.409
• [6.601 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 10/26/24 12:41:11.416
  I1026 12:41:11.416621 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename csiinlinevolumes @ 10/26/24 12:41:11.417
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:11.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:11.442
  STEP: Creating two CSIDrivers @ 10/26/24 12:41:11.445
  STEP: Getting "inline-driver-61280194-6788-4429-87cf-d80af10a4094" & "inline-driver-62f4c030-11ad-4509-9966-511982b335c5" @ 10/26/24 12:41:11.464
  STEP: Patching the CSIDriver "inline-driver-62f4c030-11ad-4509-9966-511982b335c5" @ 10/26/24 12:41:11.471
  STEP: Updating the CSIDriver "inline-driver-62f4c030-11ad-4509-9966-511982b335c5" @ 10/26/24 12:41:11.478
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-8610" @ 10/26/24 12:41:11.487
  STEP: Deleting CSIDriver "inline-driver-61280194-6788-4429-87cf-d80af10a4094" @ 10/26/24 12:41:11.492
  STEP: Confirm deletion of CSIDriver "inline-driver-61280194-6788-4429-87cf-d80af10a4094" @ 10/26/24 12:41:11.5
  STEP: Deleting CSIDriver "inline-driver-62f4c030-11ad-4509-9966-511982b335c5" via DeleteCollection @ 10/26/24 12:41:11.504
  STEP: Confirm deletion of CSIDriver "inline-driver-62f4c030-11ad-4509-9966-511982b335c5" @ 10/26/24 12:41:11.512
  I1026 12:41:11.515954 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-8610" for this suite. @ 10/26/24 12:41:11.52
• [0.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:351
  STEP: Creating a kubernetes client @ 10/26/24 12:41:11.527
  I1026 12:41:11.527139 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename disruption @ 10/26/24 12:41:11.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:11.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:11.55
  STEP: Creating a pdb that targets all three pods in a test replica set @ 10/26/24 12:41:11.553
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:41:11.559
  E1026 12:41:12.102067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:13.102331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 10/26/24 12:41:13.574
  STEP: Waiting for all pods to be running @ 10/26/24 12:41:13.574
  I1026 12:41:13.578967 19 disruption.go:680] pods: 0 < 3
  E1026 12:41:14.102425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:15.102531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 10/26/24 12:41:15.58
  STEP: Updating the pdb to allow a pod to be evicted @ 10/26/24 12:41:15.592
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:41:15.602
  E1026 12:41:16.103216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:17.103313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 10/26/24 12:41:17.607
  STEP: Waiting for all pods to be running @ 10/26/24 12:41:17.607
  STEP: Waiting for the pdb to observed all healthy pods @ 10/26/24 12:41:17.612
  STEP: Patching the pdb to disallow a pod to be evicted @ 10/26/24 12:41:17.638
  STEP: Waiting for the pdb to be processed @ 10/26/24 12:41:17.653
  E1026 12:41:18.103380      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:19.104060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 10/26/24 12:41:19.659
  STEP: locating a running pod @ 10/26/24 12:41:19.664
  STEP: Deleting the pdb to allow a pod to be evicted @ 10/26/24 12:41:19.675
  STEP: Waiting for the pdb to be deleted @ 10/26/24 12:41:19.682
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 10/26/24 12:41:19.686
  STEP: Waiting for all pods to be running @ 10/26/24 12:41:19.686
  I1026 12:41:19.707702 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7355" for this suite. @ 10/26/24 12:41:19.714
• [8.197 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 10/26/24 12:41:19.724
  I1026 12:41:19.724589 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replicaset @ 10/26/24 12:41:19.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:19.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:19.749
  I1026 12:41:19.752340 19 replica_set.go:191] Creating ReplicaSet my-hostname-basic-2e390b8f-0cda-4a3a-98f8-e1bfdef8845c
  I1026 12:41:19.760597 19 resource.go:87] Pod name my-hostname-basic-2e390b8f-0cda-4a3a-98f8-e1bfdef8845c: Found 0 pods out of 1
  E1026 12:41:20.104913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:21.105903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:22.106022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:23.106123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:24.106411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:24.768197 19 resource.go:87] Pod name my-hostname-basic-2e390b8f-0cda-4a3a-98f8-e1bfdef8845c: Found 1 pods out of 1
  I1026 12:41:24.768262 19 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-2e390b8f-0cda-4a3a-98f8-e1bfdef8845c" is running
  I1026 12:41:24.772881 19 replica_set.go:220] Pod "my-hostname-basic-2e390b8f-0cda-4a3a-98f8-e1bfdef8845c-6m97k" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:41:21 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:41:19 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:41:21 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:41:21 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-10-26 12:41:19 +0000 UTC Reason: Message:}])
  I1026 12:41:24.772914 19 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 10/26/24 12:41:24.772
  I1026 12:41:24.787215 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-301" for this suite. @ 10/26/24 12:41:24.79
• [5.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 10/26/24 12:41:24.798
  I1026 12:41:24.798949 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 12:41:24.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:24.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:24.821
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 10/26/24 12:41:24.825
  I1026 12:41:24.825657 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:41:25.106907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:26.052719 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:41:26.107888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:27.108242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:28.108351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:29.109071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:30.109667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:31.105640 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  E1026 12:41:31.109757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-publish-openapi-2311" for this suite. @ 10/26/24 12:41:31.113
• [6.324 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 10/26/24 12:41:31.123
  I1026 12:41:31.123331 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:41:31.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:31.142
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:31.145
  STEP: Creating a pod to test downward api env vars @ 10/26/24 12:41:31.148
  E1026 12:41:32.109910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:33.110122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:34.110697      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:35.110924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:41:35.176
  I1026 12:41:35.179894 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downward-api-60f456a8-eb0b-4677-973c-5d82266f3f99 container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 12:41:35.19
  I1026 12:41:35.209325 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5604" for this suite. @ 10/26/24 12:41:35.213
• [4.098 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:79
  STEP: Creating a kubernetes client @ 10/26/24 12:41:35.221
  I1026 12:41:35.221614 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 12:41:35.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:35.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:35.243
  STEP: Counting existing ResourceQuota @ 10/26/24 12:41:35.246
  E1026 12:41:36.111359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:37.111450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:38.111616      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:39.112216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:40.112835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 10/26/24 12:41:40.252
  STEP: Ensuring resource quota status is calculated @ 10/26/24 12:41:40.257
  E1026 12:41:41.113343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:42.113907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:42.263049 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7450" for this suite. @ 10/26/24 12:41:42.269
• [7.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 10/26/24 12:41:42.278
  I1026 12:41:42.278303 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:41:42.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:42.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:42.3
  STEP: Creating a pod to test downward api env vars @ 10/26/24 12:41:42.303
  E1026 12:41:43.114008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:44.114883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:45.115020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:46.115892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:41:46.332
  I1026 12:41:46.336404 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downward-api-7b4fa1e0-32bb-4554-8344-a27b8639edff container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 12:41:46.346
  I1026 12:41:46.365236 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7946" for this suite. @ 10/26/24 12:41:46.369
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 10/26/24 12:41:46.378
  I1026 12:41:46.378108 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubelet-test @ 10/26/24 12:41:46.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:46.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:46.4
  I1026 12:41:46.427150 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6843" for this suite. @ 10/26/24 12:41:46.432
• [0.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 10/26/24 12:41:46.441
  I1026 12:41:46.441118 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:41:46.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:46.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:46.464
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 12:41:46.468
  E1026 12:41:47.115957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:48.116919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:49.117920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:50.118139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:41:50.496
  I1026 12:41:50.499765 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-df5b8ed5-ab0d-4686-9f33-3e881bcdbf8e container client-container: <nil>
  STEP: delete the pod @ 10/26/24 12:41:50.509
  I1026 12:41:50.528313 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3752" for this suite. @ 10/26/24 12:41:50.531
• [4.099 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 10/26/24 12:41:50.54
  I1026 12:41:50.540292 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 12:41:50.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:50.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:50.561
  I1026 12:41:50.612291 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7461" for this suite. @ 10/26/24 12:41:50.617
• [0.086 seconds]
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 10/26/24 12:41:50.626
  I1026 12:41:50.626442 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 12:41:50.626
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:50.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:50.647
  STEP: creating a secret @ 10/26/24 12:41:50.651
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 10/26/24 12:41:50.656
  STEP: patching the secret @ 10/26/24 12:41:50.659
  STEP: deleting the secret using a LabelSelector @ 10/26/24 12:41:50.675
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 10/26/24 12:41:50.69
  I1026 12:41:50.694510 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8081" for this suite. @ 10/26/24 12:41:50.701
• [0.085 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:167
  STEP: Creating a kubernetes client @ 10/26/24 12:41:50.711
  I1026 12:41:50.711902 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl-logs @ 10/26/24 12:41:50.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:50.73
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:50.733
  STEP: creating a pod @ 10/26/24 12:41:50.738
  I1026 12:41:50.738467 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-logs-4904 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.52 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  I1026 12:41:50.792384 19 builder.go:146] stderr: ""
  I1026 12:41:50.792413 19 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 10/26/24 12:41:50.792
  I1026 12:41:50.792477 19 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E1026 12:41:51.118439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:52.118499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:52.802417 19 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 10/26/24 12:41:52.802
  I1026 12:41:52.802515 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-logs-4904 logs logs-generator logs-generator'
  I1026 12:41:52.857381 19 builder.go:146] stderr: ""
  I1026 12:41:52.857422 19 builder.go:147] stdout: "I1026 12:41:51.337473       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/r4c 323\nI1026 12:41:51.537883       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/wc9 388\nI1026 12:41:51.738259       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/bcph 393\nI1026 12:41:51.937526       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/8r75 295\nI1026 12:41:52.137846       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/9nn 473\nI1026 12:41:52.338211       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/hrn 475\nI1026 12:41:52.537543       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/jhwn 296\nI1026 12:41:52.738011       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/pg9 587\n"
  STEP: limiting log lines @ 10/26/24 12:41:52.857
  I1026 12:41:52.857493 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-logs-4904 logs logs-generator logs-generator --tail=1'
  I1026 12:41:52.907713 19 builder.go:146] stderr: ""
  I1026 12:41:52.907752 19 builder.go:147] stdout: "I1026 12:41:52.738011       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/pg9 587\n"
  I1026 12:41:52.907764 19 logs.go:180] got output "I1026 12:41:52.738011       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/pg9 587\n"
  STEP: limiting log bytes @ 10/26/24 12:41:52.907
  I1026 12:41:52.907834 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-logs-4904 logs logs-generator logs-generator --limit-bytes=1'
  I1026 12:41:52.959261 19 builder.go:146] stderr: ""
  I1026 12:41:52.959293 19 builder.go:147] stdout: "I"
  I1026 12:41:52.959301 19 logs.go:186] got output "I"
  STEP: exposing timestamps @ 10/26/24 12:41:52.959
  I1026 12:41:52.959369 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-logs-4904 logs logs-generator logs-generator --tail=1 --timestamps'
  I1026 12:41:53.011401 19 builder.go:146] stderr: ""
  I1026 12:41:53.011433 19 builder.go:147] stdout: "2024-10-26T12:41:52.938423075Z I1026 12:41:52.938335       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/4mv9 376\n"
  I1026 12:41:53.011446 19 logs.go:192] got output "2024-10-26T12:41:52.938423075Z I1026 12:41:52.938335       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/4mv9 376\n"
  STEP: restricting to a time range @ 10/26/24 12:41:53.011
  E1026 12:41:53.118817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:54.119118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:55.119411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:55.511650 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-logs-4904 logs logs-generator logs-generator --since=1s'
  I1026 12:41:55.561284 19 builder.go:146] stderr: ""
  I1026 12:41:55.561328 19 builder.go:147] stdout: "I1026 12:41:54.738235       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/dvt9 462\nI1026 12:41:54.938582       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/78l 552\nI1026 12:41:55.137836       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/76hm 357\nI1026 12:41:55.338017       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/7c42 422\nI1026 12:41:55.538354       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/qmj 571\n"
  I1026 12:41:55.561369 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-logs-4904 logs logs-generator logs-generator --since=24h'
  I1026 12:41:55.609507 19 builder.go:146] stderr: ""
  I1026 12:41:55.609610 19 builder.go:147] stdout: "I1026 12:41:51.337473       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/r4c 323\nI1026 12:41:51.537883       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/wc9 388\nI1026 12:41:51.738259       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/bcph 393\nI1026 12:41:51.937526       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/8r75 295\nI1026 12:41:52.137846       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/9nn 473\nI1026 12:41:52.338211       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/hrn 475\nI1026 12:41:52.537543       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/jhwn 296\nI1026 12:41:52.738011       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/pg9 587\nI1026 12:41:52.938335       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/4mv9 376\nI1026 12:41:53.137646       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/ds24 383\nI1026 12:41:53.338115       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/8dwq 315\nI1026 12:41:53.538295       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/kzgd 398\nI1026 12:41:53.737659       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/nkv 530\nI1026 12:41:53.937976       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/j9g7 277\nI1026 12:41:54.138391       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/ncbl 224\nI1026 12:41:54.337611       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/hl9 578\nI1026 12:41:54.537929       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/vm7 560\nI1026 12:41:54.738235       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/dvt9 462\nI1026 12:41:54.938582       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/78l 552\nI1026 12:41:55.137836       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/76hm 357\nI1026 12:41:55.338017       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/7c42 422\nI1026 12:41:55.538354       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/qmj 571\n"
  I1026 12:41:55.609777 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-logs-4904 delete pod logs-generator'
  E1026 12:41:56.120167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:56.408854 19 builder.go:146] stderr: ""
  I1026 12:41:56.408893 19 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I1026 12:41:56.409013 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-4904" for this suite. @ 10/26/24 12:41:56.413
• [5.710 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:196
  STEP: Creating a kubernetes client @ 10/26/24 12:41:56.421
  I1026 12:41:56.421738 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:41:56.422
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:41:56.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:41:56.446
  STEP: Setting up server cert @ 10/26/24 12:41:56.476
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:41:56.614
  STEP: Deploying the webhook pod @ 10/26/24 12:41:56.626
  STEP: Wait for the deployment to be ready @ 10/26/24 12:41:56.641
  I1026 12:41:56.650205 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:41:57.120662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:41:58.121236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:41:58.664
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:41:58.677
  E1026 12:41:59.121358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:41:59.677867 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 10/26/24 12:41:59.686
  STEP: create a pod that should be denied by the webhook @ 10/26/24 12:41:59.701
  STEP: create a pod that causes the webhook to hang @ 10/26/24 12:41:59.714
  E1026 12:42:00.122241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:01.122520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:02.122671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:03.122881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:04.123871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:05.124233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:06.124468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:07.124564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:08.124804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:09.124935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 10/26/24 12:42:09.724
  STEP: create a configmap that should be admitted by the webhook @ 10/26/24 12:42:09.758
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 10/26/24 12:42:09.768
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 10/26/24 12:42:09.778
  STEP: create a namespace that bypass the webhook @ 10/26/24 12:42:09.784
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 10/26/24 12:42:09.805
  I1026 12:42:09.862155 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9614" for this suite. @ 10/26/24 12:42:09.866
  STEP: Destroying namespace "webhook-markers-577" for this suite. @ 10/26/24 12:42:09.877
  STEP: Destroying namespace "exempted-namespace-3416" for this suite. @ 10/26/24 12:42:09.882
• [13.470 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1396
  STEP: Creating a kubernetes client @ 10/26/24 12:42:09.891
  I1026 12:42:09.891631 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 12:42:09.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:42:09.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:42:09.914
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-9361 @ 10/26/24 12:42:09.917
  STEP: changing the ExternalName service to type=ClusterIP @ 10/26/24 12:42:09.924
  STEP: creating replication controller externalname-service in namespace services-9361 @ 10/26/24 12:42:09.938
  I1026 12:42:09.947419      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9361, replica count: 2
  E1026 12:42:10.125878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:11.126920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:12.127180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:42:12.998174      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 12:42:12.998223 19 resource.go:361] Creating new exec pod
  E1026 12:42:13.128192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:14.128290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:15.129044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:42:16.021108 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-9361 exec execpodxqtn8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I1026 12:42:16.111910 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I1026 12:42:16.111955 19 builder.go:147] stdout: "externalname-service-tmf58"
  I1026 12:42:16.112025 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-9361 exec execpodxqtn8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.168 80'
  E1026 12:42:16.129359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:42:16.200561 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.168 80\nConnection to 10.152.183.168 80 port [tcp/http] succeeded!\n"
  I1026 12:42:16.200606 19 builder.go:147] stdout: "externalname-service-vptnb"
  I1026 12:42:16.200711 19 service.go:1405] Cleaning up the ExternalName to ClusterIP test service
  I1026 12:42:16.218927 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9361" for this suite. @ 10/26/24 12:42:16.222
• [6.341 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 10/26/24 12:42:16.233
  I1026 12:42:16.233206 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:42:16.234
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:42:16.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:42:16.254
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-b00fe158-f7f9-4ffd-8205-2059168eb4d7 @ 10/26/24 12:42:16.262
  STEP: Creating the pod @ 10/26/24 12:42:16.267
  E1026 12:42:17.129841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:18.130026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-b00fe158-f7f9-4ffd-8205-2059168eb4d7 @ 10/26/24 12:42:18.302
  STEP: waiting to observe update in volume @ 10/26/24 12:42:18.308
  E1026 12:42:19.130415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:20.130634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:21.130836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:22.131900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:23.132624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:24.133517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:25.133809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:26.133922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:27.134012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:28.134120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:29.134903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:30.134982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:31.135081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:32.135188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:33.135276      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:34.135354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:35.135442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:36.135530      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:37.135620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:38.135737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:39.135883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:40.135952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:41.136968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:42.138021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:43.138187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:44.138289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:45.139068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:46.139273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:47.139389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:48.139788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:49.140377      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:50.140572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:51.140782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:52.141018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:53.141120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:54.141371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:55.141463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:56.141584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:57.141838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:58.141962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:42:59.142071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:00.142205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:01.142400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:02.143014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:03.143112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:04.143137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:05.143942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:06.144912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:07.145009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:08.145899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:09.146487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:10.147095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:11.147902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:12.148045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:13.148289      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:14.148402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:15.148528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:16.148818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:17.149778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:18.150283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:19.151035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:20.151907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:21.152462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:22.152620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:23.152736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:24.152808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:43:24.639633 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2646" for this suite. @ 10/26/24 12:43:24.644
• [68.419 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 10/26/24 12:43:24.652
  I1026 12:43:24.652208 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename gc @ 10/26/24 12:43:24.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:43:24.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:43:24.676
  STEP: create the rc1 @ 10/26/24 12:43:24.683
  STEP: create the rc2 @ 10/26/24 12:43:24.689
  E1026 12:43:25.153911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:26.157381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:27.157702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:28.157823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:29.157956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:30.161853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 10/26/24 12:43:30.699
  STEP: delete the rc simpletest-rc-to-be-deleted @ 10/26/24 12:43:31.157
  E1026 12:43:31.161957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: wait for the rc to be deleted @ 10/26/24 12:43:31.163
  E1026 12:43:32.162305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:33.162447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:34.162830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:35.162948      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:36.163226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:43:36.189994 19 garbage_collector.go:762] 69 pods remaining
  I1026 12:43:36.190476 19 garbage_collector.go:769] 69 pods has nil DeletionTimestamp
  I1026 12:43:36.190491 19 garbage_collector.go:770] 
  E1026 12:43:37.163336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:38.163433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:39.166168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:40.164952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:41.165909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 10/26/24 12:43:41.173
  W1026 12:43:41.179637      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1026 12:43:41.179665 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1026 12:43:41.179732 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-26mc6" in namespace "gc-149"
  I1026 12:43:41.193301 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-2vcn5" in namespace "gc-149"
  I1026 12:43:41.207098 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-48s6l" in namespace "gc-149"
  I1026 12:43:41.224571 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4f9rh" in namespace "gc-149"
  I1026 12:43:41.249876 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4gbx6" in namespace "gc-149"
  I1026 12:43:41.261798 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4j5bp" in namespace "gc-149"
  I1026 12:43:41.272890 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4mfq7" in namespace "gc-149"
  I1026 12:43:41.284562 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4mwm9" in namespace "gc-149"
  I1026 12:43:41.299499 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4vnj7" in namespace "gc-149"
  I1026 12:43:41.309395 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-52zd2" in namespace "gc-149"
  I1026 12:43:41.322958 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5m6p2" in namespace "gc-149"
  I1026 12:43:41.334702 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5nwbr" in namespace "gc-149"
  I1026 12:43:41.344082 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-65xvf" in namespace "gc-149"
  I1026 12:43:41.358202 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6bbmt" in namespace "gc-149"
  I1026 12:43:41.375085 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6h5t5" in namespace "gc-149"
  I1026 12:43:41.386031 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7cqgp" in namespace "gc-149"
  I1026 12:43:41.415737 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7dlrv" in namespace "gc-149"
  I1026 12:43:41.433366 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7s2zr" in namespace "gc-149"
  I1026 12:43:41.446044 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7swhl" in namespace "gc-149"
  I1026 12:43:41.462934 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7wdsm" in namespace "gc-149"
  I1026 12:43:41.477867 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-82zgm" in namespace "gc-149"
  I1026 12:43:41.489375 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-87cxl" in namespace "gc-149"
  I1026 12:43:41.502996 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8hkv6" in namespace "gc-149"
  I1026 12:43:41.517807 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9gnnk" in namespace "gc-149"
  I1026 12:43:41.529755 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9gwx4" in namespace "gc-149"
  I1026 12:43:41.543661 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9pw5v" in namespace "gc-149"
  I1026 12:43:41.559517 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9rjc5" in namespace "gc-149"
  I1026 12:43:41.574507 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b5jw8" in namespace "gc-149"
  I1026 12:43:41.586837 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bdbhq" in namespace "gc-149"
  I1026 12:43:41.601248 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bf4wn" in namespace "gc-149"
  I1026 12:43:41.614541 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bfrfr" in namespace "gc-149"
  I1026 12:43:41.626019 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bzbpn" in namespace "gc-149"
  I1026 12:43:41.639731 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-c2sg4" in namespace "gc-149"
  I1026 12:43:41.652823 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cdf5p" in namespace "gc-149"
  I1026 12:43:41.663279 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cdpjn" in namespace "gc-149"
  I1026 12:43:41.673435 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cdzc8" in namespace "gc-149"
  I1026 12:43:41.684897 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cm46d" in namespace "gc-149"
  I1026 12:43:41.703836 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ctqmk" in namespace "gc-149"
  I1026 12:43:41.715088 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cvg6r" in namespace "gc-149"
  I1026 12:43:41.727471 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cz98w" in namespace "gc-149"
  I1026 12:43:41.743401 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ddn69" in namespace "gc-149"
  I1026 12:43:41.754463 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dh24j" in namespace "gc-149"
  I1026 12:43:41.768961 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dkd6j" in namespace "gc-149"
  I1026 12:43:41.781457 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fdsdr" in namespace "gc-149"
  I1026 12:43:41.792920 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gdn8r" in namespace "gc-149"
  I1026 12:43:41.807224 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gdrlt" in namespace "gc-149"
  I1026 12:43:41.818152 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gfm8b" in namespace "gc-149"
  I1026 12:43:41.828388 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-ghv6l" in namespace "gc-149"
  I1026 12:43:41.843353 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gpdmp" in namespace "gc-149"
  I1026 12:43:41.852816 19 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gv624" in namespace "gc-149"
  I1026 12:43:41.867482 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-149" for this suite. @ 10/26/24 12:43:41.872
• [17.227 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:221
  STEP: Creating a kubernetes client @ 10/26/24 12:43:41.879
  I1026 12:43:41.879667 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-preemption @ 10/26/24 12:43:41.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:43:41.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:43:41.903
  I1026 12:43:41.926664 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1026 12:43:42.166379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:43.166461      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:44.166818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:45.166907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:46.167584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:47.167948      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:48.168769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:49.168931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:50.169723      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:51.169821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:52.169959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:53.170211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:54.171059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:55.171272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:56.171402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:57.171538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:58.171950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:43:59.172119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:00.172885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:01.172913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:02.173298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:03.173375      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:04.174324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:05.174874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:06.175824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:07.175827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:08.175925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:09.177296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:10.177869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:11.178059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:12.178938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:13.179054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:14.179091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:15.179291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:16.179939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:17.180054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:18.180985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:19.181311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:20.181374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:21.181557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:22.182610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:23.182739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:24.183270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:25.184016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:26.184875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:27.185876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:28.186868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:29.186984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:30.187806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:31.187994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:32.188278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:33.188422      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:34.189387      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:35.189814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:36.190077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:37.190359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:38.190495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:39.190836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:40.190936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:41.191144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:44:41.932076 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 10/26/24 12:44:41.938
  I1026 12:44:41.959067 19 preemption.go:266] Created pod: pod0-0-sched-preemption-low-priority
  I1026 12:44:41.966155 19 preemption.go:266] Created pod: pod0-1-sched-preemption-medium-priority
  I1026 12:44:41.981445 19 preemption.go:266] Created pod: pod1-0-sched-preemption-medium-priority
  I1026 12:44:41.988079 19 preemption.go:266] Created pod: pod1-1-sched-preemption-medium-priority
  I1026 12:44:42.001496 19 preemption.go:266] Created pod: pod2-0-sched-preemption-medium-priority
  I1026 12:44:42.012270 19 preemption.go:266] Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 10/26/24 12:44:42.012
  E1026 12:44:42.191897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:43.192113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 10/26/24 12:44:44.039
  E1026 12:44:44.192361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:45.193357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:46.194161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:47.194268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:44:48.163435 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3655" for this suite. @ 10/26/24 12:44:48.169
• [66.298 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 10/26/24 12:44:48.178
  I1026 12:44:48.178025 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename subpath @ 10/26/24 12:44:48.178
  E1026 12:44:48.194795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:44:48.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:44:48.203
  STEP: Setting up data @ 10/26/24 12:44:48.21
  STEP: Creating pod pod-subpath-test-secret-wjjz @ 10/26/24 12:44:48.22
  STEP: Creating a pod to test atomic-volume-subpath @ 10/26/24 12:44:48.22
  E1026 12:44:49.195711      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:50.195837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:51.195872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:52.195977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:53.196089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:54.196881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:55.197027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:56.197405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:57.197550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:58.197666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:44:59.201913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:00.198141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:01.198273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:02.198482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:03.198857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:04.198941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:05.199097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:06.199532      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:07.199762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:08.199980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:09.200892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:10.201011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:11.201130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:12.201247      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:45:12.314
  I1026 12:45:12.319954 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-subpath-test-secret-wjjz container test-container-subpath-secret-wjjz: <nil>
  STEP: delete the pod @ 10/26/24 12:45:12.33
  STEP: Deleting pod pod-subpath-test-secret-wjjz @ 10/26/24 12:45:12.346
  I1026 12:45:12.346629 19 delete.go:62] Deleting pod "pod-subpath-test-secret-wjjz" in namespace "subpath-9864"
  I1026 12:45:12.351345 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9864" for this suite. @ 10/26/24 12:45:12.356
• [24.187 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:643
  STEP: Creating a kubernetes client @ 10/26/24 12:45:12.365
  I1026 12:45:12.365636 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:45:12.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:12.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:12.387
  STEP: Setting up server cert @ 10/26/24 12:45:12.416
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:45:12.528
  STEP: Deploying the webhook pod @ 10/26/24 12:45:12.534
  STEP: Wait for the deployment to be ready @ 10/26/24 12:45:12.551
  I1026 12:45:12.560345 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:45:13.202119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:14.202238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:45:14.574
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:45:14.589
  E1026 12:45:15.203146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:45:15.589553 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 10/26/24 12:45:15.672
  STEP: Creating a configMap that should be mutated @ 10/26/24 12:45:15.684
  STEP: Deleting the collection of validation webhooks @ 10/26/24 12:45:15.707
  STEP: Creating a configMap that should not be mutated @ 10/26/24 12:45:15.771
  I1026 12:45:15.832934 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4481" for this suite. @ 10/26/24 12:45:15.837
  STEP: Destroying namespace "webhook-markers-529" for this suite. @ 10/26/24 12:45:15.844
• [3.486 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 10/26/24 12:45:15.851
  I1026 12:45:15.851450 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename namespaces @ 10/26/24 12:45:15.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:15.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:15.871
  STEP: creating a Namespace @ 10/26/24 12:45:15.874
  STEP: patching the Namespace @ 10/26/24 12:45:15.896
  STEP: get the Namespace and ensuring it has the label @ 10/26/24 12:45:15.901
  I1026 12:45:15.905042 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6161" for this suite. @ 10/26/24 12:45:15.908
  STEP: Destroying namespace "nspatchtest-c2fdcfee-f49a-4e16-9aed-ff57f7829325-9072" for this suite. @ 10/26/24 12:45:15.915
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 10/26/24 12:45:15.923
  I1026 12:45:15.923847 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replication-controller @ 10/26/24 12:45:15.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:15.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:15.948
  I1026 12:45:15.951294 19 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 10/26/24 12:45:15.961
  STEP: Checking rc "condition-test" has the desired failure condition set @ 10/26/24 12:45:15.969
  E1026 12:45:16.203951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 10/26/24 12:45:16.977
  I1026 12:45:16.989058 19 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 10/26/24 12:45:16.989
  E1026 12:45:17.204023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:45:18.000951 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7908" for this suite. @ 10/26/24 12:45:18.005
• [2.090 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 10/26/24 12:45:18.014
  I1026 12:45:18.014120 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 10/26/24 12:45:18.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:18.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:18.036
  STEP: create the container to handle the HTTPGet hook request. @ 10/26/24 12:45:18.044
  E1026 12:45:18.204142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:19.204901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 10/26/24 12:45:20.069
  E1026 12:45:20.205877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:21.205986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 10/26/24 12:45:22.09
  STEP: delete the pod with lifecycle hook @ 10/26/24 12:45:22.101
  E1026 12:45:22.206421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:23.206735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:45:24.119749 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4547" for this suite. @ 10/26/24 12:45:24.124
• [6.119 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:235
  STEP: Creating a kubernetes client @ 10/26/24 12:45:24.132
  I1026 12:45:24.132994 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 12:45:24.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:24.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:24.155
  STEP: Counting existing ResourceQuota @ 10/26/24 12:45:24.159
  E1026 12:45:24.207196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:25.207741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:26.208734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:27.209123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:28.209596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 10/26/24 12:45:29.165
  STEP: Ensuring resource quota status is calculated @ 10/26/24 12:45:29.175
  E1026 12:45:29.209719      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:30.209913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 10/26/24 12:45:31.181
  STEP: Ensuring ResourceQuota status captures the pod usage @ 10/26/24 12:45:31.197
  E1026 12:45:31.210560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:32.210814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 10/26/24 12:45:33.203
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 10/26/24 12:45:33.206
  STEP: Ensuring a pod cannot update its resource requirements @ 10/26/24 12:45:33.208
  E1026 12:45:33.211334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 10/26/24 12:45:33.213
  E1026 12:45:34.211461      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:35.211574      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 10/26/24 12:45:35.219
  STEP: Ensuring resource quota status released the pod usage @ 10/26/24 12:45:35.236
  E1026 12:45:36.211756      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:37.211972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:45:37.241848 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7119" for this suite. @ 10/26/24 12:45:37.246
• [13.122 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 10/26/24 12:45:37.254
  I1026 12:45:37.254983 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:45:37.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:37.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:37.276
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 12:45:37.279
  E1026 12:45:38.212391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:39.212484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:40.212566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:41.212706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:45:41.305
  I1026 12:45:41.310894 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-d102e12f-5709-42db-849a-32d8ce5e55fa container client-container: <nil>
  STEP: delete the pod @ 10/26/24 12:45:41.318
  I1026 12:45:41.334227 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7367" for this suite. @ 10/26/24 12:45:41.339
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1858
  STEP: Creating a kubernetes client @ 10/26/24 12:45:41.346
  I1026 12:45:41.346118 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:45:41.346
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:41.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:41.368
  STEP: Starting the proxy @ 10/26/24 12:45:41.371
  I1026 12:45:41.371909 19 util.go:585] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-7377 proxy --unix-socket=/tmp/kubectl-proxy-unix4156061689/test'
  STEP: retrieving proxy /api/ output @ 10/26/24 12:45:41.403
  I1026 12:45:41.403530 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7377" for this suite. @ 10/26/24 12:45:41.408
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:302
  STEP: Creating a kubernetes client @ 10/26/24 12:45:41.415
  I1026 12:45:41.415722 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename security-context @ 10/26/24 12:45:41.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:41.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:41.437
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 10/26/24 12:45:41.441
  E1026 12:45:42.212802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:43.212941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:44.213911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:45.214021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:45:45.469
  I1026 12:45:45.473980 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod security-context-cfb64194-5cfc-40ca-8258-98c0d54f198d container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:45:45.48
  I1026 12:45:45.496326 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-4037" for this suite. @ 10/26/24 12:45:45.501
• [4.091 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 10/26/24 12:45:45.506
  I1026 12:45:45.506664 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename custom-resource-definition @ 10/26/24 12:45:45.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:45.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:45.533
  STEP: fetching the /apis discovery document @ 10/26/24 12:45:45.536
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 10/26/24 12:45:45.538
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 10/26/24 12:45:45.538
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 10/26/24 12:45:45.538
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 10/26/24 12:45:45.539
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 10/26/24 12:45:45.539
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 10/26/24 12:45:45.541
  I1026 12:45:45.541341 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-745" for this suite. @ 10/26/24 12:45:45.545
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:164
  STEP: Creating a kubernetes client @ 10/26/24 12:45:45.552
  I1026 12:45:45.552500 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 12:45:45.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:45:45.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:45:45.574
  STEP: Discovering how many secrets are in namespace by default @ 10/26/24 12:45:45.577
  E1026 12:45:46.214874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:47.215871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:48.216946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:49.217902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:50.218085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 10/26/24 12:45:50.582
  E1026 12:45:51.218286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:52.218352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:53.218504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:54.219368      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:55.220141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 10/26/24 12:45:55.595
  STEP: Ensuring resource quota status is calculated @ 10/26/24 12:45:55.6
  E1026 12:45:56.220310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:57.220371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 10/26/24 12:45:57.605
  STEP: Ensuring resource quota status captures secret creation @ 10/26/24 12:45:57.617
  E1026 12:45:58.221375      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:45:59.221823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 10/26/24 12:45:59.623
  STEP: Ensuring resource quota status released usage @ 10/26/24 12:45:59.63
  E1026 12:46:00.222715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:01.222855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:46:01.636743 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5288" for this suite. @ 10/26/24 12:46:01.64
• [16.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 10/26/24 12:46:01.649
  I1026 12:46:01.649421 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename certificates @ 10/26/24 12:46:01.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:46:01.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:46:01.673
  STEP: getting /apis @ 10/26/24 12:46:01.93
  STEP: getting /apis/certificates.k8s.io @ 10/26/24 12:46:01.934
  STEP: getting /apis/certificates.k8s.io/v1 @ 10/26/24 12:46:01.936
  STEP: creating @ 10/26/24 12:46:01.937
  STEP: getting @ 10/26/24 12:46:01.959
  STEP: listing @ 10/26/24 12:46:01.963
  STEP: watching @ 10/26/24 12:46:01.967
  I1026 12:46:01.967339 19 certificates.go:316] starting watch
  STEP: patching @ 10/26/24 12:46:01.968
  STEP: updating @ 10/26/24 12:46:01.974
  I1026 12:46:01.982543 19 certificates.go:332] waiting for watch events with expected annotations
  I1026 12:46:01.982573 19 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 10/26/24 12:46:01.982
  STEP: patching /approval @ 10/26/24 12:46:01.986
  STEP: updating /approval @ 10/26/24 12:46:01.991
  STEP: getting /status @ 10/26/24 12:46:01.999
  STEP: patching /status @ 10/26/24 12:46:02.002
  STEP: updating /status @ 10/26/24 12:46:02.009
  STEP: deleting @ 10/26/24 12:46:02.017
  STEP: deleting a collection @ 10/26/24 12:46:02.031
  I1026 12:46:02.049717 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-2716" for this suite. @ 10/26/24 12:46:02.055
• [0.413 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 10/26/24 12:46:02.062
  I1026 12:46:02.063007 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename conformance-tests @ 10/26/24 12:46:02.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:46:02.079
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:46:02.082
  STEP: Getting node addresses @ 10/26/24 12:46:02.086
  I1026 12:46:02.086027 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I1026 12:46:02.092182 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-8598" for this suite. @ 10/26/24 12:46:02.096
• [0.042 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:859
  STEP: Creating a kubernetes client @ 10/26/24 12:46:02.104
  I1026 12:46:02.104821 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 12:46:02.105
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:46:02.122
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:46:02.125
  STEP: Creating a ResourceQuota with best effort scope @ 10/26/24 12:46:02.128
  STEP: Ensuring ResourceQuota status is calculated @ 10/26/24 12:46:02.133
  E1026 12:46:02.223249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:03.223355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 10/26/24 12:46:04.138
  STEP: Ensuring ResourceQuota status is calculated @ 10/26/24 12:46:04.143
  E1026 12:46:04.223730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:05.223844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 10/26/24 12:46:06.15
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 10/26/24 12:46:06.2
  E1026 12:46:06.224740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:07.224838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 10/26/24 12:46:08.204
  E1026 12:46:08.225763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:09.225841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 10/26/24 12:46:10.209
  STEP: Ensuring resource quota status released the pod usage @ 10/26/24 12:46:10.22
  E1026 12:46:10.225892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:11.226019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:12.226464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 10/26/24 12:46:12.226
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 10/26/24 12:46:12.238
  E1026 12:46:13.226647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:14.227246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 10/26/24 12:46:14.244
  E1026 12:46:15.227694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:16.227933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 10/26/24 12:46:16.249
  STEP: Ensuring resource quota status released the pod usage @ 10/26/24 12:46:16.261
  E1026 12:46:17.228075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:18.228319      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:46:18.267819 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6149" for this suite. @ 10/26/24 12:46:18.272
• [16.175 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:116
  STEP: Creating a kubernetes client @ 10/26/24 12:46:18.279
  I1026 12:46:18.279914 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:46:18.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:46:18.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:46:18.304
  STEP: Setting up server cert @ 10/26/24 12:46:18.338
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:46:18.493
  STEP: Deploying the webhook pod @ 10/26/24 12:46:18.503
  STEP: Wait for the deployment to be ready @ 10/26/24 12:46:18.516
  I1026 12:46:18.532731 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:46:19.228465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:20.228741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:46:20.546
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:46:20.558
  E1026 12:46:21.228903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:46:21.558368 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 10/26/24 12:46:21.566
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 10/26/24 12:46:21.568
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 10/26/24 12:46:21.568
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 10/26/24 12:46:21.568
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 10/26/24 12:46:21.569
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 10/26/24 12:46:21.569
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 10/26/24 12:46:21.571
  I1026 12:46:21.609462 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6155" for this suite. @ 10/26/24 12:46:21.614
  STEP: Destroying namespace "webhook-markers-4788" for this suite. @ 10/26/24 12:46:21.621
• [3.349 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 10/26/24 12:46:21.629
  I1026 12:46:21.629241 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename hostport @ 10/26/24 12:46:21.629
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:46:21.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:46:21.648
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 10/26/24 12:46:21.654
  E1026 12:46:22.229063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:23.229277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:24.229514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:25.230002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:26.230127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:27.230284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:28.230907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:29.231219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:30.232128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:31.232423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:32.232635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:33.232936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.30.144 on the node which pod1 resides and expect scheduled @ 10/26/24 12:46:33.704
  E1026 12:46:34.233037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:35.234052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.30.144 but use UDP protocol on the node which pod2 resides @ 10/26/24 12:46:35.722
  E1026 12:46:36.234928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:37.235022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:38.235114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:39.235209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 10/26/24 12:46:39.758
  I1026 12:46:39.759000 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.30.144 http://127.0.0.1:54323/hostname] Namespace:hostport-3530 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:46:39.759016 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:46:39.759458 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:46:39.759500 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-3530/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.30.144+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.30.144, port: 54323 @ 10/26/24 12:46:39.799
  I1026 12:46:39.799566 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.30.144:54323/hostname] Namespace:hostport-3530 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:46:39.799579 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:46:39.799965 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:46:39.800008 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-3530/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.30.144%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.30.144, port: 54323 UDP @ 10/26/24 12:46:39.842
  I1026 12:46:39.842265 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.30.144 54323] Namespace:hostport-3530 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:46:39.842278 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:46:39.842670 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:46:39.842744 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-3530/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.30.144+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E1026 12:46:40.235417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:41.235529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:42.235607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:43.235846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:44.236201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:46:44.884701 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-3530" for this suite. @ 10/26/24 12:46:44.889
• [23.268 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:490
  STEP: Creating a kubernetes client @ 10/26/24 12:46:44.897
  I1026 12:46:44.897791 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename job @ 10/26/24 12:46:44.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:46:44.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:46:44.918
  STEP: Creating Indexed job @ 10/26/24 12:46:44.921
  STEP: Ensuring job reaches completions @ 10/26/24 12:46:44.929
  E1026 12:46:45.236905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:46.237107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:47.237925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:48.238074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:49.238873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:50.239037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:51.239138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:52.239290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:53.239898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:54.240213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 10/26/24 12:46:54.939
  I1026 12:46:54.943126 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1161" for this suite. @ 10/26/24 12:46:54.948
• [10.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 10/26/24 12:46:54.957
  I1026 12:46:54.957238 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:46:54.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:46:54.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:46:54.981
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 10/26/24 12:46:54.985
  E1026 12:46:55.240829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:56.240937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:46:57.006
  I1026 12:46:57.011760 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-b786f20e-0d46-418a-8a0d-40f7a5af1f43 container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:46:57.018
  I1026 12:46:57.032522 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2490" for this suite. @ 10/26/24 12:46:57.036
• [2.089 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 10/26/24 12:46:57.046
  I1026 12:46:57.046293 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:46:57.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:46:57.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:46:57.068
  STEP: Creating the pod @ 10/26/24 12:46:57.071
  E1026 12:46:57.241048      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:58.241166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:46:59.241830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:46:59.621625 19 pod_client.go:173] Successfully updated pod "labelsupdate65e78252-f9a0-4f20-806f-33e4d3df3b34"
  E1026 12:47:00.242822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:01.243029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:01.637178 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8377" for this suite. @ 10/26/24 12:47:01.642
• [4.606 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 10/26/24 12:47:01.652
  I1026 12:47:01.652950 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename endpointslice @ 10/26/24 12:47:01.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:47:01.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:47:01.674
  E1026 12:47:02.243857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:03.244912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 10/26/24 12:47:03.747
  STEP: referencing matching pods with named port @ 10/26/24 12:47:03.758
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 10/26/24 12:47:03.765
  STEP: recreating EndpointSlices after they've been deleted @ 10/26/24 12:47:03.771
  I1026 12:47:03.793535 19 endpointslice.go:938] EndpointSlice for Service endpointslice-393/example-named-port not found
  E1026 12:47:04.245906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:05.246006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:05.801814 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-393" for this suite. @ 10/26/24 12:47:05.806
• [4.165 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 10/26/24 12:47:05.818
  I1026 12:47:05.818180 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename init-container @ 10/26/24 12:47:05.818
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:47:05.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:47:05.849
  STEP: creating the pod @ 10/26/24 12:47:05.853
  I1026 12:47:05.853721 19 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E1026 12:47:06.247058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:07.247579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:08.247962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:09.254937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:09.336304 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-652" for this suite. @ 10/26/24 12:47:09.34
• [3.532 seconds]
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 10/26/24 12:47:09.349
  I1026 12:47:09.349860 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 12:47:09.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:47:09.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:47:09.371
  STEP: Creating pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822 @ 10/26/24 12:47:09.375
  E1026 12:47:10.250173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:11.250382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 10/26/24 12:47:11.398
  I1026 12:47:11.402375 19 container_probe.go:1749] Initial restart count of pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b is 0
  I1026 12:47:11.405547 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:12.250581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:13.250800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:13.411039 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:14.250959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:15.251080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:15.416364 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:16.251199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:17.251483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:17.422967 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:18.251882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:19.252082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:19.428460 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:20.252207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:21.252455      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:21.435508 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:22.253462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:23.254062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:23.441032 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:24.254836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:25.255875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:25.447237 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:26.256907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:27.257925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:27.453087 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:28.258030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:29.258346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:29.459760 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:30.258642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:31.258763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:31.465001 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:32.258969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:33.259068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:33.470151 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:34.259125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:35.259352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:35.475578 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:36.259514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:37.259843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:37.482552 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:38.259972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:39.260087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:39.488038 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:40.260216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:41.260343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:41.495287 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:42.260448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:43.260586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:43.501139 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:44.260951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:45.261182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:45.507141 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:46.261881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:47.262045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:47.512426 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:48.262265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:49.262587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:49.518778 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:50.263625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:51.263734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:51.523665 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:52.263851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:53.264902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:53.528259 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:54.264985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:55.265071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:55.533559 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:56.265910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:57.266164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:57.540832 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:47:58.266254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:47:59.266361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:47:59.548720 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:00.266442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:01.266666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:01.553634 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:02.267418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:03.267661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:03.558971 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:04.267801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:05.268063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:05.564837 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:06.268562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:07.268830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:07.570632 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:08.269372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:09.269735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:09.577232 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:10.269849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:11.270050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:11.582288 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:12.270467      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:13.270738      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:13.588296 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:14.270843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:15.271055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:15.594833 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:16.271178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:17.271390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:17.600750 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:18.271526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:19.271777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:19.606546 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:20.272309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:21.272529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:21.611037 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:22.272655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:23.272808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:23.617131 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:24.273871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:25.273967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:25.622088 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:26.274871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:27.275864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:27.628728 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:28.275961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:29.276866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:29.634421 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:30.276971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:31.277866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:31.641615 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:32.277953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:33.278886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:33.647449 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:34.278995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:35.279888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:35.655087 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:36.280809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:37.281014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:37.660225 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:38.281965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:39.282056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:39.665894 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:40.282156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:41.282998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:41.671646 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:42.283154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:43.284055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:43.678948 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:44.284585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:45.284706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:45.683793 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:46.284916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:47.284996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:47.690775 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:48.285089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:49.285862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:49.696330 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:50.285998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:51.286253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:51.702923 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:52.286578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:53.286784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:53.708184 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:54.287869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:55.287983      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:55.715044 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:56.288660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:57.288857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:57.720133 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:48:58.289895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:48:59.290014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:48:59.725758 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:00.290195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:01.290384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:01.730807 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:02.290496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:03.290742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:03.737812 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:04.291502      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:05.291710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:05.743048 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:06.292754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:07.292841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:07.749802 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:08.292986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:09.293644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:09.754837 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:10.294504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:11.294875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:11.761486 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:12.294970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:13.295085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:13.766424 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:14.295990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:15.296869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:15.772936 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:16.297571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:17.297783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:17.777806 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:18.297870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:19.298228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:19.782624 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:20.298266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:21.298583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:21.787323 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:22.298866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:23.298920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:23.794377 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:24.299860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:25.300012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:25.800096 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:26.300905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:27.301879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:27.804623 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:28.302883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:29.302976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:29.810319 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:30.303669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:31.303811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:31.816111 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:32.304751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:33.304859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:33.821708 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:34.305037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:35.305872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:35.828922 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:36.306460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:37.306661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:37.833936 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:38.306739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:39.307065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:39.839924 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:40.307257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:41.307558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:41.845081 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:42.307749      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:43.307952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:43.851931 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:44.308228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:45.308459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:45.856807 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:46.309352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:47.309573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:47.864368 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:48.310644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:49.311017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:49.869771 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:50.311115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:51.311309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:51.876218 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:52.311537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:53.311771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:53.881364 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:54.311820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:55.311999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:55.887925 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:56.312107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:57.312181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:57.892904 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:49:58.312394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:49:59.313118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:49:59.899161 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:00.313641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:01.314060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:01.904371 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:02.314876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:03.314976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:03.910962 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:04.315064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:05.315874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:05.916010 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:06.316466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:07.316714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:07.922307 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:08.316836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:09.317197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:09.927536 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:10.318053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:11.318172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:11.933881 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:12.318321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:13.318588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:13.937864 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:14.319362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:15.319504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:15.943964 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:16.320441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:17.320536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:17.949562 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:18.321180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:19.321627      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:19.955554 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:20.322492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:21.322717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:21.962332 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:22.322781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:23.323017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:23.968081 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:24.323387      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:25.323486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:25.974813 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:26.324290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:27.324880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:27.980761 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:28.324977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:29.325871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:29.988276 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:30.326790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:31.326899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:31.993831 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:32.327255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:33.328017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:33.999456 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:34.329052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:35.329156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:36.005020 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:36.329871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:37.330857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:38.011637 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:38.331037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:39.331231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:40.017163 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:40.331477      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:41.331667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:42.024323 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:42.332736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:43.333022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:44.029468 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:44.333910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:45.334004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:46.034986 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:46.334299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:47.334871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:48.040479 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:48.335042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:49.335870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:50.045788 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:50.335989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:51.336181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:52.050296 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:52.336628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:53.336968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:54.057030 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:54.337473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:55.337666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:56.061979 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:56.338381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:57.338487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:50:58.067396 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:50:58.338744      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:50:59.338954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:51:00.073821 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:51:00.339044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:01.339220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:51:02.079822 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:51:02.340269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:03.341081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:51:04.083770 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:51:04.342159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:05.342357      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:51:06.089705 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:51:06.343009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:07.343114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:51:08.095280 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:51:08.343601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:09.344539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:51:10.100489 19 container_probe.go:1759] Get pod liveness-277d4dc5-2eb7-441c-80ed-bf5f3eac581b in namespace container-probe-8822
  E1026 12:51:10.344622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:11.344878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 10/26/24 12:51:12.1
  I1026 12:51:12.112996 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8822" for this suite. @ 10/26/24 12:51:12.116
• [242.775 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 10/26/24 12:51:12.125
  I1026 12:51:12.125108 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:51:12.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:51:12.143
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:51:12.147
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 10/26/24 12:51:12.15
  E1026 12:51:12.345878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:13.346251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:14.346569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:15.346761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:51:16.175
  I1026 12:51:16.180642 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-b1d69d8d-2af0-45f1-a6b7-1abec1f1f0eb container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:51:16.197
  I1026 12:51:16.213226 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8819" for this suite. @ 10/26/24 12:51:16.218
• [4.102 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 10/26/24 12:51:16.227
  I1026 12:51:16.227486 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:51:16.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:51:16.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:51:16.251
  STEP: Creating configMap with name configmap-test-volume-aaa673e5-1507-45f7-828a-add30ab17ad7 @ 10/26/24 12:51:16.255
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:51:16.26
  E1026 12:51:16.347066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:17.347205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:18.347742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:19.347846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:51:20.286
  I1026 12:51:20.290513 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-configmaps-728d8ff5-c395-41ca-abf9-505787ce5397 container configmap-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 12:51:20.299
  I1026 12:51:20.316186 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5580" for this suite. @ 10/26/24 12:51:20.319
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 10/26/24 12:51:20.33
  I1026 12:51:20.330438 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 12:51:20.33
  E1026 12:51:20.348615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:51:20.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:51:20.355
  STEP: Creating configMap configmap-193/configmap-test-77b43eff-75f0-4da8-95c0-dc0028c0762c @ 10/26/24 12:51:20.358
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:51:20.363
  E1026 12:51:21.349300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:22.349359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:51:22.382
  I1026 12:51:22.387402 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-configmaps-e73466a1-09e4-43f9-8b60-1cbf9ea91a98 container env-test: <nil>
  STEP: delete the pod @ 10/26/24 12:51:22.395
  I1026 12:51:22.410891 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-193" for this suite. @ 10/26/24 12:51:22.415
• [2.094 seconds]
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 10/26/24 12:51:22.424
  I1026 12:51:22.424448 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-runtime @ 10/26/24 12:51:22.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:51:22.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:51:22.445
  STEP: create the container @ 10/26/24 12:51:22.449
  W1026 12:51:22.459132      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 10/26/24 12:51:22.459
  E1026 12:51:23.349814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:24.349939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 10/26/24 12:51:24.474
  STEP: the container should be terminated @ 10/26/24 12:51:24.48
  STEP: the termination message should be set @ 10/26/24 12:51:24.48
  I1026 12:51:24.480570 19 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 10/26/24 12:51:24.48
  I1026 12:51:24.499532 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-766" for this suite. @ 10/26/24 12:51:24.502
• [2.085 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 10/26/24 12:51:24.509
  I1026 12:51:24.509870 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename svcaccounts @ 10/26/24 12:51:24.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:51:24.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:51:24.53
  STEP: creating a ServiceAccount @ 10/26/24 12:51:24.533
  STEP: watching for the ServiceAccount to be added @ 10/26/24 12:51:24.543
  STEP: patching the ServiceAccount @ 10/26/24 12:51:24.545
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 10/26/24 12:51:24.55
  STEP: deleting the ServiceAccount @ 10/26/24 12:51:24.555
  I1026 12:51:24.570753 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1273" for this suite. @ 10/26/24 12:51:24.575
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:673
  STEP: Creating a kubernetes client @ 10/26/24 12:51:24.581
  I1026 12:51:24.581724 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename validating-admission-policy @ 10/26/24 12:51:24.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:51:24.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:51:24.601
  STEP: getting /apis @ 10/26/24 12:51:24.611
  STEP: getting /apis/admissionregistration.k8s.io @ 10/26/24 12:51:24.615
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 10/26/24 12:51:24.616
  STEP: creating @ 10/26/24 12:51:24.618
  STEP: getting @ 10/26/24 12:51:24.634
  STEP: listing @ 10/26/24 12:51:24.637
  STEP: watching @ 10/26/24 12:51:24.641
  I1026 12:51:24.641787 19 validatingadmissionpolicy.go:768] starting watch
  STEP: patching @ 10/26/24 12:51:24.643
  STEP: updating @ 10/26/24 12:51:24.649
  I1026 12:51:24.657804 19 validatingadmissionpolicy.go:796] waiting for watch events with expected annotations
  STEP: deleting @ 10/26/24 12:51:24.657
  STEP: deleting a collection @ 10/26/24 12:51:24.671
  I1026 12:51:24.692659 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-1804" for this suite. @ 10/26/24 12:51:24.696
• [0.123 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 10/26/24 12:51:24.705
  I1026 12:51:24.705347 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename containers @ 10/26/24 12:51:24.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:51:24.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:51:24.732
  E1026 12:51:25.350716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:26.350946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:51:26.760913 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8252" for this suite. @ 10/26/24 12:51:26.766
• [2.069 seconds]
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:444
  STEP: Creating a kubernetes client @ 10/26/24 12:51:26.773
  I1026 12:51:26.773879 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename taint-multiple-pods @ 10/26/24 12:51:26.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:51:26.794
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:51:26.798
  I1026 12:51:26.801129 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1026 12:51:27.351056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:28.352088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:29.352280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:30.352354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:31.352482      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:32.352564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:33.353220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:34.353308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:35.354102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:36.354875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:37.355840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:38.356031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:39.356898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:40.356985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:41.357907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:42.358098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:43.358692      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:44.358875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:45.359835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:46.359983      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:47.360029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:48.360451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:49.360579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:50.360709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:51.360852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:52.361071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:53.362004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:54.362186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:55.362344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:56.362707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:57.363690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:58.364015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:51:59.364911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:00.364998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:01.365089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:02.365891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:03.366632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:04.366772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:05.367706      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:06.367854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:07.368870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:08.369012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:09.369385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:10.369630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:11.369775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:12.370029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:13.371049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:14.371242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:15.372291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:16.372883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:17.373871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:18.374227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:19.374523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:20.374869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:21.375793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:22.376863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:23.376913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:24.377102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:25.377220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:26.377419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:52:26.802168 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1026 12:52:26.807308 19 taints.go:144] Starting informer...
  STEP: Starting pods... @ 10/26/24 12:52:26.807
  I1026 12:52:27.029328 19 taints.go:463] Pod1 is running on ip-172-31-30-144. Tainting Node
  E1026 12:52:27.377617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:28.378187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:52:29.256044 19 taints.go:471] Pod2 is running on ip-172-31-30-144. Tainting Node
  STEP: Trying to apply a taint on the Node @ 10/26/24 12:52:29.256
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 10/26/24 12:52:29.266
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 10/26/24 12:52:29.27
  E1026 12:52:29.378544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:30.378781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:31.379002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:32.379219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:33.379695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:34.379782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:52:35.296395 19 taints.go:492] Noticed Pod "taint-eviction-b1" gets evicted.
  E1026 12:52:35.380739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:36.380863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:37.380865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:38.381831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:39.381945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:40.382132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:41.382294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:42.382394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:43.382722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:44.382818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:45.383877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:46.384869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:47.384927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:48.385975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:49.386082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:50.386880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:51.387069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:52.388000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:53.388943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:54.389444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:52:55.336878 19 taints.go:492] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 10/26/24 12:52:55.347
  I1026 12:52:55.351584 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-6259" for this suite. @ 10/26/24 12:52:55.356
• [88.592 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:644
  STEP: Creating a kubernetes client @ 10/26/24 12:52:55.365
  I1026 12:52:55.365987 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename statefulset @ 10/26/24 12:52:55.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:52:55.386
  E1026 12:52:55.389397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:52:55.389
  STEP: Creating service test in namespace statefulset-2816 @ 10/26/24 12:52:55.392
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 10/26/24 12:52:55.399
  STEP: Creating stateful set ss in namespace statefulset-2816 @ 10/26/24 12:52:55.403
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2816 @ 10/26/24 12:52:55.411
  I1026 12:52:55.416732 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E1026 12:52:56.389794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:57.389966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:58.390041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:52:59.390234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:00.390897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:01.391103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:02.391311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:03.392229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:04.392424      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:05.392720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:05.416706 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 10/26/24 12:53:05.416
  I1026 12:53:05.421799 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-2816 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 12:53:05.507935 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 12:53:05.507989 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 12:53:05.507999 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1026 12:53:05.511916 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1026 12:53:06.393044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:07.393071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:08.394085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:09.394979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:10.395063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:11.395133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:12.395242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:13.396076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:14.396185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:15.396376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:15.515661 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I1026 12:53:15.515724 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I1026 12:53:15.537390 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 9.999999799s
  E1026 12:53:16.397444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:16.542712 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 8.992968358s
  E1026 12:53:17.397669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:17.547825 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 7.98789794s
  E1026 12:53:18.397720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:18.555028 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 6.982807709s
  E1026 12:53:19.397885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:19.560892 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 5.975665366s
  E1026 12:53:20.398809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:20.566840 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 4.969739264s
  E1026 12:53:21.398910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:21.572430 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 3.963610298s
  E1026 12:53:22.399099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:22.578800 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 2.957383514s
  E1026 12:53:23.399198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:23.586297 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 1.951141253s
  E1026 12:53:24.399234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:24.590972 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 1 for another 944.384004ms
  E1026 12:53:25.399799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2816 @ 10/26/24 12:53:25.591
  I1026 12:53:25.597493 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-2816 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1026 12:53:25.677077 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1026 12:53:25.677120 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 12:53:25.677129 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1026 12:53:25.681280 19 wait.go:40] Found 1 stateful pods, waiting for 3
  E1026 12:53:26.400152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:27.400362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:28.401294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:29.401426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:30.401718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:31.401986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:32.402111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:33.402825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:34.402923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:35.403955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:35.683201 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:53:35.683226 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:53:35.683233 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 10/26/24 12:53:35.683
  STEP: Scale down will halt with unhealthy stateful pod @ 10/26/24 12:53:35.683
  I1026 12:53:35.692769 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-2816 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 12:53:35.775664 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 12:53:35.775721 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 12:53:35.775732 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1026 12:53:35.775777 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-2816 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 12:53:35.861739 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 12:53:35.861775 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 12:53:35.861785 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1026 12:53:35.861860 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-2816 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 12:53:35.948651 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 12:53:35.948709 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 12:53:35.948732 19 rest.go:241] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I1026 12:53:35.948746 19 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I1026 12:53:35.953103 19 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  E1026 12:53:36.404893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:37.404982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:38.406023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:39.406177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:40.406274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:41.406542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:42.406812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:43.407296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:44.407592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:45.407728      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:45.959998 19 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I1026 12:53:45.960023 19 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I1026 12:53:45.960030 19 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I1026 12:53:45.975753 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 9.99999976s
  E1026 12:53:46.408207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:46.982334 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 8.993554104s
  E1026 12:53:47.408896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:47.987358 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 7.987643059s
  E1026 12:53:48.408950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:48.994129 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 6.982710178s
  E1026 12:53:49.409778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:49.999127 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 5.976095569s
  E1026 12:53:50.410736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:51.008176 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 4.971097647s
  E1026 12:53:51.410952      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:52.013470 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 3.961987285s
  E1026 12:53:52.411863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:53.018505 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 2.956800654s
  E1026 12:53:53.412088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:54.025145 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 1.951559892s
  E1026 12:53:54.412800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:53:55.030274 19 statefulset.go:2418] Verifying statefulset ss doesn't scale past 3 for another 944.832872ms
  E1026 12:53:55.413792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2816 @ 10/26/24 12:53:56.03
  I1026 12:53:56.037060 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-2816 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1026 12:53:56.118304 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1026 12:53:56.118345 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 12:53:56.118357 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1026 12:53:56.118426 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-2816 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1026 12:53:56.195185 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1026 12:53:56.195219 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 12:53:56.195228 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1026 12:53:56.195265 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-2816 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1026 12:53:56.280144 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1026 12:53:56.280184 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 12:53:56.280193 19 rest.go:241] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I1026 12:53:56.280211 19 rest.go:150] Scaling statefulset ss to 0
  E1026 12:53:56.414554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:57.415379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:58.416142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:53:59.416339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:00.416451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:01.416850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:02.417076      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:03.417430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:04.417649      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:05.417868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 10/26/24 12:54:06.291
  I1026 12:54:06.291246 19 statefulset.go:138] Deleting all statefulset in ns statefulset-2816
  I1026 12:54:06.295885 19 rest.go:150] Scaling statefulset ss to 0
  I1026 12:54:06.303135 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1026 12:54:06.308619 19 rest.go:88] Deleting statefulset ss
  I1026 12:54:06.324744 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2816" for this suite. @ 10/26/24 12:54:06.329
• [70.971 seconds]
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 10/26/24 12:54:06.337
  I1026 12:54:06.337243 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 12:54:06.337
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:06.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:06.359
  STEP: Create a pod @ 10/26/24 12:54:06.362
  E1026 12:54:06.418553      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:07.418725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: patching /status @ 10/26/24 12:54:08.38
  I1026 12:54:08.388901 19 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I1026 12:54:08.389003 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8679" for this suite. @ 10/26/24 12:54:08.392
• [2.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:406
  STEP: Creating a kubernetes client @ 10/26/24 12:54:08.401
  I1026 12:54:08.401509 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename validating-admission-policy @ 10/26/24 12:54:08.402
  E1026 12:54:08.419162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:08.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:08.425
  STEP: getting /apis @ 10/26/24 12:54:08.436
  STEP: getting /apis/admissionregistration.k8s.io @ 10/26/24 12:54:08.44
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 10/26/24 12:54:08.441
  STEP: creating @ 10/26/24 12:54:08.443
  STEP: getting @ 10/26/24 12:54:08.461
  STEP: listing @ 10/26/24 12:54:08.465
  STEP: watching @ 10/26/24 12:54:08.468
  I1026 12:54:08.468431 19 validatingadmissionpolicy.go:523] starting watch
  STEP: patching @ 10/26/24 12:54:08.469
  STEP: updating @ 10/26/24 12:54:08.482
  I1026 12:54:08.492071 19 validatingadmissionpolicy.go:552] waiting for watch events with expected annotations
  I1026 12:54:08.492102 19 validatingadmissionpolicy.go:568] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 10/26/24 12:54:08.492
  STEP: patching /status @ 10/26/24 12:54:08.495
  STEP: updating /status @ 10/26/24 12:54:08.5
  STEP: deleting @ 10/26/24 12:54:08.535
  STEP: deleting a collection @ 10/26/24 12:54:08.55
  I1026 12:54:08.570400 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6466" for this suite. @ 10/26/24 12:54:08.575
• [0.182 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:472
  STEP: Creating a kubernetes client @ 10/26/24 12:54:08.583
  I1026 12:54:08.583270 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename field-validation @ 10/26/24 12:54:08.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:08.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:08.606
  I1026 12:54:08.611931 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:54:09.419440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:10.419656      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W1026 12:54:11.151185      19 warnings.go:70] unknown field "alpha"
  W1026 12:54:11.151205      19 warnings.go:70] unknown field "beta"
  W1026 12:54:11.151208      19 warnings.go:70] unknown field "delta"
  W1026 12:54:11.151211      19 warnings.go:70] unknown field "epsilon"
  W1026 12:54:11.151214      19 warnings.go:70] unknown field "gamma"
  E1026 12:54:11.419745      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:11.701563 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-171" for this suite. @ 10/26/24 12:54:11.705
• [3.128 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 10/26/24 12:54:11.712
  I1026 12:54:11.712016 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 12:54:11.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:11.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:11.732
  STEP: creating pod @ 10/26/24 12:54:11.736
  E1026 12:54:12.419946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:13.420190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:13.763166 19 pods.go:83] Pod pod-hostip-d5e3aa63-7afb-4e54-8c16-a0b620a82119 has hostIP: 172.31.30.144
  I1026 12:54:13.763277 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-337" for this suite. @ 10/26/24 12:54:13.766
• [2.060 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 10/26/24 12:54:13.771
  I1026 12:54:13.771993 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename custom-resource-definition @ 10/26/24 12:54:13.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:13.794
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:13.797
  I1026 12:54:13.800351 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:54:14.420509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:15.420760      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:16.421390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:16.885943 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-106" for this suite. @ 10/26/24 12:54:16.89
• [3.126 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 10/26/24 12:54:16.897
  I1026 12:54:16.897742 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 12:54:16.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:16.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:16.921
  I1026 12:54:16.924864 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: creating the pod @ 10/26/24 12:54:16.925
  STEP: submitting the pod to kubernetes @ 10/26/24 12:54:16.925
  E1026 12:54:17.421539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:18.422180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:18.966969 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1551" for this suite. @ 10/26/24 12:54:18.97
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 10/26/24 12:54:18.977
  I1026 12:54:18.977104 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 10/26/24 12:54:18.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:18.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:18.998
  STEP: create the container to handle the HTTPGet hook request. @ 10/26/24 12:54:19.005
  E1026 12:54:19.423199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:20.423262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 10/26/24 12:54:21.029
  E1026 12:54:21.423350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:22.424298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 10/26/24 12:54:23.05
  E1026 12:54:23.425164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:24.425903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 10/26/24 12:54:25.067
  I1026 12:54:25.083765 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-432" for this suite. @ 10/26/24 12:54:25.087
• [6.118 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 10/26/24 12:54:25.095
  I1026 12:54:25.095368 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename daemonsets @ 10/26/24 12:54:25.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:25.113
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:25.116
  STEP: Creating a simple DaemonSet "daemon-set" @ 10/26/24 12:54:25.141
  STEP: Check that daemon pods launch on every node of the cluster. @ 10/26/24 12:54:25.148
  I1026 12:54:25.154295 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:54:25.154323 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:54:25.157597 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:54:25.157618 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 12:54:25.426095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:26.153571 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:54:26.153617 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:54:26.157415 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1026 12:54:26.157435 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 12:54:26.426807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:27.154980 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:54:27.155021 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:54:27.160295 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 12:54:27.160317 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 10/26/24 12:54:27.164
  I1026 12:54:27.180407 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:54:27.180438 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:54:27.185126 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 12:54:27.185147 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 10/26/24 12:54:27.185
  E1026 12:54:27.427819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting DaemonSet "daemon-set" @ 10/26/24 12:54:28.192
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1546, will wait for the garbage collector to delete the pods @ 10/26/24 12:54:28.192
  I1026 12:54:28.255799 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.492959ms
  I1026 12:54:28.356559 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.756536ms
  E1026 12:54:28.428795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:29.429759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:29.962495 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:54:29.962531 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1026 12:54:29.967775 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29440"},"items":null}

  I1026 12:54:29.971889 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29440"},"items":null}

  I1026 12:54:29.988456 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1546" for this suite. @ 10/26/24 12:54:29.993
• [4.907 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 10/26/24 12:54:30.002
  I1026 12:54:30.002357 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename events @ 10/26/24 12:54:30.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:30.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:30.025
  STEP: Create set of events @ 10/26/24 12:54:30.028
  STEP: get a list of Events with a label in the current namespace @ 10/26/24 12:54:30.048
  STEP: delete a list of events @ 10/26/24 12:54:30.052
  I1026 12:54:30.052473 19 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 10/26/24 12:54:30.078
  I1026 12:54:30.082248 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6332" for this suite. @ 10/26/24 12:54:30.086
• [0.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 10/26/24 12:54:30.093
  I1026 12:54:30.093585 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 12:54:30.094
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:30.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:30.118
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 10/26/24 12:54:30.121
  E1026 12:54:30.429872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:31.430092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:32.430896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:33.431014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:54:34.146
  I1026 12:54:34.149636 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-67f4b3ee-22da-4fb5-9b78-bb528d8d2641 container test-container: <nil>
  STEP: delete the pod @ 10/26/24 12:54:34.157
  I1026 12:54:34.174581 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3473" for this suite. @ 10/26/24 12:54:34.178
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 10/26/24 12:54:34.186
  I1026 12:54:34.186858 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubelet-test @ 10/26/24 12:54:34.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:34.206
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:34.209
  E1026 12:54:34.431554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:35.431704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:36.255293 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1795" for this suite. @ 10/26/24 12:54:36.26
• [2.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:393
  STEP: Creating a kubernetes client @ 10/26/24 12:54:36.269
  I1026 12:54:36.269433 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:54:36.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:36.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:36.29
  STEP: creating all guestbook components @ 10/26/24 12:54:36.293
  I1026 12:54:36.293588 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I1026 12:54:36.293695 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 create -f -'
  I1026 12:54:36.378017 19 builder.go:146] stderr: ""
  I1026 12:54:36.378053 19 builder.go:147] stdout: "service/agnhost-replica created\n"
  I1026 12:54:36.378112 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I1026 12:54:36.378169 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 create -f -'
  E1026 12:54:36.431823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:36.472948 19 builder.go:146] stderr: ""
  I1026 12:54:36.473001 19 builder.go:147] stdout: "service/agnhost-primary created\n"
  I1026 12:54:36.473050 19 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I1026 12:54:36.473112 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 create -f -'
  I1026 12:54:36.562786 19 builder.go:146] stderr: ""
  I1026 12:54:36.562830 19 builder.go:147] stdout: "service/frontend created\n"
  I1026 12:54:36.562926 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I1026 12:54:36.563038 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 create -f -'
  I1026 12:54:36.627180 19 builder.go:146] stderr: ""
  I1026 12:54:36.627237 19 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I1026 12:54:36.627299 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I1026 12:54:36.627364 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 create -f -'
  I1026 12:54:36.696645 19 builder.go:146] stderr: ""
  I1026 12:54:36.696703 19 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I1026 12:54:36.696761 19 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.52
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I1026 12:54:36.696828 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 create -f -'
  I1026 12:54:36.758025 19 builder.go:146] stderr: ""
  I1026 12:54:36.758062 19 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 10/26/24 12:54:36.758
  I1026 12:54:36.758108 19 kubectl.go:2272] Waiting for all frontend pods to be Running.
  E1026 12:54:37.431797      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:38.432650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:39.432878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:40.433556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:41.433668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:54:41.809177 19 kubectl.go:2276] Waiting for frontend to serve content.
  I1026 12:54:41.820833 19 kubectl.go:2281] Trying to add a new entry to the guestbook.
  I1026 12:54:41.829345 19 kubectl.go:2286] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 10/26/24 12:54:41.842
  I1026 12:54:41.842536 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 delete --grace-period=0 --force -f -'
  I1026 12:54:41.904072 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 12:54:41.904097 19 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 10/26/24 12:54:41.904
  I1026 12:54:41.904194 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 delete --grace-period=0 --force -f -'
  I1026 12:54:41.964989 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 12:54:41.965013 19 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 10/26/24 12:54:41.965
  I1026 12:54:41.965237 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 delete --grace-period=0 --force -f -'
  I1026 12:54:42.022431 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 12:54:42.022465 19 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 10/26/24 12:54:42.022
  I1026 12:54:42.022581 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 delete --grace-period=0 --force -f -'
  I1026 12:54:42.072202 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 12:54:42.072232 19 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 10/26/24 12:54:42.072
  I1026 12:54:42.072407 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 delete --grace-period=0 --force -f -'
  I1026 12:54:42.127582 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 12:54:42.127616 19 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 10/26/24 12:54:42.127
  I1026 12:54:42.127746 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3246 delete --grace-period=0 --force -f -'
  I1026 12:54:42.184960 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 12:54:42.185002 19 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I1026 12:54:42.185193 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3246" for this suite. @ 10/26/24 12:54:42.189
• [5.926 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 10/26/24 12:54:42.195
  I1026 12:54:42.196003 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename svcaccounts @ 10/26/24 12:54:42.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:42.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:42.22
  I1026 12:54:42.228881 19 service_accounts.go:754] Got root ca configmap in namespace "svcaccounts-6624"
  I1026 12:54:42.235635 19 service_accounts.go:757] Deleted root ca configmap in namespace "svcaccounts-6624"
  E1026 12:54:42.433896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 10/26/24 12:54:42.736
  I1026 12:54:42.743092 19 service_accounts.go:771] Recreated root ca configmap in namespace "svcaccounts-6624"
  I1026 12:54:42.748751 19 service_accounts.go:782] Updated root ca configmap in namespace "svcaccounts-6624"
  STEP: waiting for the root ca configmap reconciled @ 10/26/24 12:54:43.249
  I1026 12:54:43.254035 19 service_accounts.go:800] Reconciled root ca configmap in namespace "svcaccounts-6624"
  I1026 12:54:43.254163 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6624" for this suite. @ 10/26/24 12:54:43.257
• [1.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 10/26/24 12:54:43.265
  I1026 12:54:43.265199 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename validating-admission-policy @ 10/26/24 12:54:43.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:43.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:43.288
  STEP: creating the policy @ 10/26/24 12:54:43.298
  STEP: waiting until the marker is denied @ 10/26/24 12:54:43.31
  E1026 12:54:43.434426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 10/26/24 12:54:43.918
  STEP: testing a non-replicated ReplicaSet not to be denied @ 10/26/24 12:54:43.933
  I1026 12:54:43.979590 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6260" for this suite. @ 10/26/24 12:54:43.989
• [0.732 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 10/26/24 12:54:43.998
  I1026 12:54:43.998024 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename csi-storageclass @ 10/26/24 12:54:43.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:44.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:44.021
  STEP: Creating a StorageClass @ 10/26/24 12:54:44.025
  STEP: Get StorageClass "e2e-prtwr" @ 10/26/24 12:54:44.03
  STEP: Patching the StorageClass "e2e-prtwr" @ 10/26/24 12:54:44.034
  STEP: Delete StorageClass "e2e-prtwr" @ 10/26/24 12:54:44.041
  STEP: Confirm deletion of StorageClass "e2e-prtwr" @ 10/26/24 12:54:44.048
  STEP: Create a replacement StorageClass @ 10/26/24 12:54:44.053
  STEP: Updating StorageClass "e2e-v2-n788z" @ 10/26/24 12:54:44.058
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-n788z=updated" @ 10/26/24 12:54:44.068
  STEP: Deleting StorageClass "e2e-v2-n788z" via DeleteCollection @ 10/26/24 12:54:44.072
  STEP: Confirm deletion of StorageClass "e2e-v2-n788z" @ 10/26/24 12:54:44.082
  I1026 12:54:44.086246 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-5796" for this suite. @ 10/26/24 12:54:44.09
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 10/26/24 12:54:44.097
  I1026 12:54:44.097490 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:54:44.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:44.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:44.118
  STEP: Creating configMap with name projected-configmap-test-volume-7134289b-8853-44be-8065-3313c98086f4 @ 10/26/24 12:54:44.121
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:54:44.127
  E1026 12:54:44.434641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:45.434899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:46.434978      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:47.435085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:54:48.155
  I1026 12:54:48.159754 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-configmaps-eb8e9dac-dcdf-4d40-94d9-cec74f27615b container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:54:48.166
  I1026 12:54:48.183593 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7272" for this suite. @ 10/26/24 12:54:48.188
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:284
  STEP: Creating a kubernetes client @ 10/26/24 12:54:48.198
  I1026 12:54:48.198247 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename taint-single-pod @ 10/26/24 12:54:48.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:54:48.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:54:48.221
  I1026 12:54:48.224736 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1026 12:54:48.436065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:49.436152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:50.436518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:51.436557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:52.436695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:53.437075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:54.437829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:55.438245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:56.439057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:57.439258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:58.439774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:54:59.439964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:00.440081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:01.440205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:02.440612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:03.441137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:04.441216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:05.441993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:06.443013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:07.444061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:08.444994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:09.445083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:10.445246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:11.445341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:12.445866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:13.445982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:14.447032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:15.447884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:16.448798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:17.448994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:18.449969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:19.450099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:20.451148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:21.451339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:22.451857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:23.452198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:24.452895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:25.453004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:26.453539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:27.453742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:28.454513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:29.454877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:30.455916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:31.456882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:32.456998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:33.458069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:34.458795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:35.459833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:36.460842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:37.461123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:38.462042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:39.462150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:40.463149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:41.463243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:42.463797      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:43.464061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:44.464793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:45.464927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:46.465077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:47.465845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:55:48.225902 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1026 12:55:48.230897 19 taints.go:144] Starting informer...
  STEP: Starting pod... @ 10/26/24 12:55:48.23
  I1026 12:55:48.446882 19 taints.go:294] Pod is running on ip-172-31-30-144. Tainting Node
  STEP: Trying to apply a taint on the Node @ 10/26/24 12:55:48.446
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 10/26/24 12:55:48.457
  STEP: Waiting short time to make sure Pod is queued for deletion @ 10/26/24 12:55:48.461
  I1026 12:55:48.461047 19 taints.go:313] Pod wasn't evicted. Proceeding
  I1026 12:55:48.461058 19 taints.go:320] Removing taint from Node
  E1026 12:55:48.466717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 10/26/24 12:55:48.472
  STEP: Waiting some time to make sure that toleration time passed. @ 10/26/24 12:55:48.476
  E1026 12:55:49.466840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:50.466973      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:51.467074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:52.467145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:53.468109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:54.468179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:55.468310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:56.468452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:57.468582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:58.468746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:55:59.468938      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:00.469162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:01.469279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:02.469354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:03.470239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:04.470536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:05.470667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:06.470971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:07.471070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:08.472108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:09.472295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:10.472873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:11.473875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:12.474869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:13.475301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:14.475862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:15.476880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:16.477221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:17.477414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:18.477624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:19.477858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:20.478396      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:21.478591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:22.478789      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:23.479164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:24.479293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:25.479602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:26.479821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:27.480024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:28.480312      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:29.480400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:30.480592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:31.480880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:32.481065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:33.481807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:34.481997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:35.482068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:36.482198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:37.483067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:38.484086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:39.484894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:40.485173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:41.485899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:42.486150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:43.486491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:44.486720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:45.486818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:46.487063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:47.487261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:48.487638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:49.487802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:50.488016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:51.488226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:52.488370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:53.489182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:54.489896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:55.489981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:56.490120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:57.490367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:58.491174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:56:59.491374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:00.491476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:01.491873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:02.491979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:03.476988 19 taints.go:329] Pod wasn't evicted. Test successful
  I1026 12:57:03.477172 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-2109" for this suite. @ 10/26/24 12:57:03.482
• [135.294 seconds]
------------------------------
  E1026 12:57:03.492027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 10/26/24 12:57:03.492
  I1026 12:57:03.492167 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-runtime @ 10/26/24 12:57:03.492
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:57:03.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:57:03.515
  STEP: create the container @ 10/26/24 12:57:03.518
  W1026 12:57:03.527724      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 10/26/24 12:57:03.527
  E1026 12:57:04.492906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:05.493008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:06.493840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: get the container status @ 10/26/24 12:57:06.55
  STEP: the container should be terminated @ 10/26/24 12:57:06.553
  STEP: the termination message should be set @ 10/26/24 12:57:06.553
  I1026 12:57:06.553898 19 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 10/26/24 12:57:06.553
  I1026 12:57:06.574060 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9109" for this suite. @ 10/26/24 12:57:06.579
• [3.093 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:569
  STEP: Creating a kubernetes client @ 10/26/24 12:57:06.585
  I1026 12:57:06.585470 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:57:06.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:57:06.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:57:06.607
  STEP: Setting up server cert @ 10/26/24 12:57:06.635
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:57:06.799
  STEP: Deploying the webhook pod @ 10/26/24 12:57:06.808
  STEP: Wait for the deployment to be ready @ 10/26/24 12:57:06.826
  I1026 12:57:06.835104 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:57:07.494893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:08.495034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:57:08.848
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:57:08.859
  E1026 12:57:09.495173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:09.859594 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 10/26/24 12:57:09.942
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 10/26/24 12:57:09.974
  STEP: Deleting the collection of validation webhooks @ 10/26/24 12:57:10
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 10/26/24 12:57:10.058
  I1026 12:57:10.110670 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1682" for this suite. @ 10/26/24 12:57:10.114
  STEP: Destroying namespace "webhook-markers-6010" for this suite. @ 10/26/24 12:57:10.124
• [3.547 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 10/26/24 12:57:10.132
  I1026 12:57:10.132388 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:57:10.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:57:10.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:57:10.154
  STEP: Creating configMap with name projected-configmap-test-volume-map-5458f80c-e1e8-4b5c-8020-05ad790922c9 @ 10/26/24 12:57:10.157
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:57:10.162
  E1026 12:57:10.495337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:11.496339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:12.497321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:13.498169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:57:14.189
  I1026 12:57:14.192917 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-configmaps-10172d6e-5419-4a17-8a1c-d79620b9373d container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:57:14.217
  I1026 12:57:14.235103 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3179" for this suite. @ 10/26/24 12:57:14.24
• [4.116 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 10/26/24 12:57:14.248
  I1026 12:57:14.248708 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 12:57:14.249
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:57:14.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:57:14.273
  E1026 12:57:14.498311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:15.499303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:16.499917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:17.500887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:18.501507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:19.501609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:20.502205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:21.502298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:22.502396      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:23.502865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:24.503819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:25.504891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:26.505442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:27.506421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:28.506824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:29.507121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:30.507720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:31.507910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:32.508609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:33.508896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:34.509516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:35.509747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:36.360503 19 container_probe.go:92] Container started at 2024-10-26 12:57:14 +0000 UTC, pod became ready at 2024-10-26 12:57:34 +0000 UTC
  I1026 12:57:36.360615 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3858" for this suite. @ 10/26/24 12:57:36.364
• [22.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3703
  STEP: Creating a kubernetes client @ 10/26/24 12:57:36.372
  I1026 12:57:36.372661 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 12:57:36.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:57:36.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:57:36.397
  STEP: creating service multiprotocol-test in namespace services-7992 @ 10/26/24 12:57:36.4
  STEP: creating pod pod1 in namespace services-7992 @ 10/26/24 12:57:36.412
  STEP: Creating pod pod1 in namespace services-7992 @ 10/26/24 12:57:36.412
  E1026 12:57:36.509748      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:37.509899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-7992 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 10/26/24 12:57:38.438
  I1026 12:57:38.451761 19 service.go:4392] successfully validated that service multiprotocol-test in namespace services-7992 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 10/26/24 12:57:38.451
  I1026 12:57:38.451824 19 resource.go:361] Creating new exec pod
  E1026 12:57:38.510475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:39.510601      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:40.469431 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.228 80'
  E1026 12:57:40.510780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:40.549587 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.228 80\nConnection to 10.152.183.228 80 port [tcp/http] succeeded!\n"
  I1026 12:57:40.549618 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:57:40.549774 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.228 80'
  E1026 12:57:41.510891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:42.511875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:43.512579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:44.512705      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:44.644111 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.228 80\nConnection to 10.152.183.228 80 port [udp/*] succeeded!\n"
  I1026 12:57:44.644157 19 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 10/26/24 12:57:44.644
  I1026 12:57:44.655334 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.228 80'
  I1026 12:57:44.740932 19 builder.go:146] stderr: "+ + nc -v -t -w 2 10.152.183.228 80\necho hostName\nConnection to 10.152.183.228 80 port [tcp/http] succeeded!\n"
  I1026 12:57:44.740968 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 12:57:44.741057 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.228 80'
  E1026 12:57:45.513755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:46.514024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:47.514931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:48.515445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:48.815025 19 builder.go:146] stderr: "+ + nc -v -u -w 2 10.152.183.228 80\necho hostName\nConnection to 10.152.183.228 80 port [udp/*] succeeded!\n"
  I1026 12:57:48.815120 19 builder.go:147] stdout: ""
  I1026 12:57:48.815177 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.228 80'
  E1026 12:57:49.515895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:50.516150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:51.516359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:52.516582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:52.899953 19 builder.go:146] stderr: "+ + echo hostName\nnc -v -u -w 2 10.152.183.228 80\nConnection to 10.152.183.228 80 port [udp/*] succeeded!\n"
  I1026 12:57:52.899999 19 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 10/26/24 12:57:52.9
  I1026 12:57:52.909771 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.228 80'
  E1026 12:57:53.517186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:54.517382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:55.518407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:56.518668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:56.995885 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.228 80\nConnection to 10.152.183.228 80 port [udp/*] succeeded!\n"
  I1026 12:57:56.995926 19 builder.go:147] stdout: "pod1"
  I1026 12:57:56.996019 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.228 80'
  E1026 12:57:57.519507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:57:58.520008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:57:59.078730 19 builder.go:135] rc: 1
  I1026 12:57:59.078808 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.228 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.152.183.228 80
  nc: connect to 10.152.183.228 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I1026 12:57:59.078875 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.228 80'
  E1026 12:57:59.520538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:00.520779      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:01.201360 19 builder.go:135] rc: 1
  I1026 12:58:01.201448 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.228 80:
  Command stdout:

  stderr:
  + + nc -v -techo hostName -w 2
   10.152.183.228 80
  nc: connect to 10.152.183.228 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I1026 12:58:01.201543 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.228 80'
  E1026 12:58:01.521395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:02.521425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:03.280589 19 builder.go:135] rc: 1
  I1026 12:58:03.280660 19 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7992 exec execpodbqsh6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.228 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.152.183.228 80
  nc: connect to 10.152.183.228 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I1026 12:58:03.280870 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7992" for this suite. @ 10/26/24 12:58:03.285
• [26.921 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1530
  STEP: Creating a kubernetes client @ 10/26/24 12:58:03.293
  I1026 12:58:03.293941 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 12:58:03.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:03.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:03.323
  STEP: creating Agnhost RC @ 10/26/24 12:58:03.327
  I1026 12:58:03.327442 19 kubectl.go:1537] namespace kubectl-7940
  I1026 12:58:03.327501 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-7940 create -f -'
  I1026 12:58:03.407970 19 builder.go:146] stderr: ""
  I1026 12:58:03.408006 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 10/26/24 12:58:03.408
  E1026 12:58:03.522097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:04.413024 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 12:58:04.413052 19 framework.go:733] Found 0 / 1
  E1026 12:58:04.522175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:05.414972 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 12:58:05.415006 19 framework.go:733] Found 1 / 1
  I1026 12:58:05.415019 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I1026 12:58:05.419662 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 12:58:05.419701 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I1026 12:58:05.419709 19 kubectl.go:1544] wait on agnhost-primary startup in kubectl-7940 
  I1026 12:58:05.419751 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-7940 logs agnhost-primary-zwslw agnhost-primary'
  I1026 12:58:05.474878 19 builder.go:146] stderr: ""
  I1026 12:58:05.474905 19 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 10/26/24 12:58:05.474
  I1026 12:58:05.474975 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-7940 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  E1026 12:58:05.522321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:05.530868 19 builder.go:146] stderr: ""
  I1026 12:58:05.530897 19 builder.go:147] stdout: "service/rm2 exposed\n"
  I1026 12:58:05.537018 19 utils.go:1203] Service rm2 in namespace kubectl-7940 found.
  E1026 12:58:06.523092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:07.523163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: exposing service @ 10/26/24 12:58:07.547
  I1026 12:58:07.547820 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-7940 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I1026 12:58:07.607214 19 builder.go:146] stderr: ""
  I1026 12:58:07.607245 19 builder.go:147] stdout: "service/rm3 exposed\n"
  I1026 12:58:07.613119 19 utils.go:1203] Service rm3 in namespace kubectl-7940 found.
  E1026 12:58:08.524162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:09.524894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:09.623106 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7940" for this suite. @ 10/26/24 12:58:09.626
• [6.340 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:890
  STEP: Creating a kubernetes client @ 10/26/24 12:58:09.634
  I1026 12:58:09.634562 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename daemonsets @ 10/26/24 12:58:09.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:09.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:09.655
  STEP: Creating simple DaemonSet "daemon-set" @ 10/26/24 12:58:09.683
  STEP: Check that daemon pods launch on every node of the cluster. @ 10/26/24 12:58:09.69
  I1026 12:58:09.695006 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:58:09.695040 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:58:09.698936 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:58:09.698959 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 12:58:10.524992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:10.695992 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:58:10.696036 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:58:10.699521 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:58:10.699542 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 12:58:11.525130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:11.697655 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:58:11.697719 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 12:58:11.702572 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 12:58:11.702595 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 10/26/24 12:58:11.706
  I1026 12:58:11.710387 19 daemon_set.go:927] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 10/26/24 12:58:11.71
  I1026 12:58:11.722322 19 daemon_set.go:947] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 10/26/24 12:58:11.722
  I1026 12:58:11.724350 19 daemon_set.go:972] Observed &DaemonSet event: ADDED
  I1026 12:58:11.724453 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.724547 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.724743 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.724829 19 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.724868 19 daemon_set.go:965] Found daemon set daemon-set in namespace daemonsets-8641 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I1026 12:58:11.724891 19 daemon_set.go:976] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 10/26/24 12:58:11.724
  STEP: watching for the daemon set status to be patched @ 10/26/24 12:58:11.731
  I1026 12:58:11.733477 19 daemon_set.go:1016] Observed &DaemonSet event: ADDED
  I1026 12:58:11.733562 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.733662 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.733796 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.733936 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.733974 19 daemon_set.go:1012] Observed daemon set daemon-set in namespace daemonsets-8641 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I1026 12:58:11.734050 19 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I1026 12:58:11.734065 19 daemon_set.go:1009] Found daemon set daemon-set in namespace daemonsets-8641 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I1026 12:58:11.734076 19 daemon_set.go:1020] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 10/26/24 12:58:11.739
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8641, will wait for the garbage collector to delete the pods @ 10/26/24 12:58:11.739
  I1026 12:58:11.801806 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 8.535421ms
  I1026 12:58:11.902732 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.920015ms
  E1026 12:58:12.525341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:13.308766 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 12:58:13.308800 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1026 12:58:13.312471 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30963"},"items":null}

  I1026 12:58:13.316503 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30963"},"items":null}

  I1026 12:58:13.331928 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8641" for this suite. @ 10/26/24 12:58:13.335
• [3.709 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:965
  STEP: Creating a kubernetes client @ 10/26/24 12:58:13.343
  I1026 12:58:13.343860 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename statefulset @ 10/26/24 12:58:13.344
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:13.363
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:13.366
  STEP: Creating service test in namespace statefulset-2524 @ 10/26/24 12:58:13.369
  I1026 12:58:13.387298 19 wait.go:40] Found 0 stateful pods, waiting for 1
  E1026 12:58:13.525645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:14.525844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:15.526156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:16.526233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:17.526333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:18.527176      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:19.527365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:20.527458      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:21.527563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:22.527739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:23.389361 19 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 10/26/24 12:58:23.397
  I1026 12:58:23.412492 19 wait.go:40] Found 1 stateful pods, waiting for 2
  E1026 12:58:23.527788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:24.527892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:25.528199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:26.528269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:27.528613      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:28.528839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:29.528941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:30.529015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:31.529226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:32.529365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:33.416521 19 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I1026 12:58:33.416558 19 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 10/26/24 12:58:33.424
  STEP: Delete all of the StatefulSets @ 10/26/24 12:58:33.428
  STEP: Verify that StatefulSets have been deleted @ 10/26/24 12:58:33.439
  I1026 12:58:33.444465 19 statefulset.go:138] Deleting all statefulset in ns statefulset-2524
  I1026 12:58:33.457897 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2524" for this suite. @ 10/26/24 12:58:33.463
• [20.129 seconds]
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 10/26/24 12:58:33.472
  I1026 12:58:33.472769 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename runtimeclass @ 10/26/24 12:58:33.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:33.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:33.496
  STEP: Deleting RuntimeClass runtimeclass-7432-delete-me @ 10/26/24 12:58:33.506
  STEP: Waiting for the RuntimeClass to disappear @ 10/26/24 12:58:33.512
  I1026 12:58:33.523421 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7432" for this suite. @ 10/26/24 12:58:33.527
  E1026 12:58:33.530273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
• [0.061 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 10/26/24 12:58:33.533
  I1026 12:58:33.533834 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 12:58:33.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:33.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:33.554
  STEP: Creating configMap with name projected-configmap-test-volume-map-175c7e1f-eb12-4731-a155-f86ed3e5bd11 @ 10/26/24 12:58:33.558
  STEP: Creating a pod to test consume configMaps @ 10/26/24 12:58:33.565
  E1026 12:58:34.530408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:35.530653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:36.530806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:37.531376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:58:37.592
  I1026 12:58:37.597820 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-configmaps-68253b0c-f054-416d-8d99-4438452e3b6b container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 12:58:37.604
  I1026 12:58:37.620559 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1188" for this suite. @ 10/26/24 12:58:37.626
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:788
  STEP: Creating a kubernetes client @ 10/26/24 12:58:37.633
  I1026 12:58:37.633215 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename job @ 10/26/24 12:58:37.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:37.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:37.659
  STEP: Creating a job @ 10/26/24 12:58:37.662
  STEP: Ensuring job reaches completions @ 10/26/24 12:58:37.667
  E1026 12:58:38.531964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:39.532059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:40.532155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:41.532880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:42.533894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:43.534160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:44.534883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:45.534985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:46.535911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:47.536901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:48.537005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:49.537112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:49.680743 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9260" for this suite. @ 10/26/24 12:58:49.685
• [12.060 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 10/26/24 12:58:49.693
  I1026 12:58:49.693137 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename deployment @ 10/26/24 12:58:49.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:49.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:49.715
  I1026 12:58:49.718460 19 deployment.go:792] Creating deployment "test-recreate-deployment"
  I1026 12:58:49.724576 19 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I1026 12:58:49.731775 19 deployment.go:222] deployment "test-recreate-deployment" doesn't have the required revision set
  E1026 12:58:50.537199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:51.537320      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:58:51.742581 19 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I1026 12:58:51.746537 19 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I1026 12:58:51.756230 19 deployment.go:313] Updating deployment test-recreate-deployment
  I1026 12:58:51.756255 19 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I1026 12:58:51.844520 19 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "912107d6-d99d-44ea-a0f6-2d45dea61529",
      ResourceVersion: (string) (len=5) "31426",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865544329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544329,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-88d47c55d\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1026 12:58:51.850893 19 deployment.go:39] New ReplicaSet "test-recreate-deployment-88d47c55d" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-88d47c55d",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5064bbf4-1cb8-46a4-9cfe-554de359cb57",
      ResourceVersion: (string) (len=5) "31425",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865544331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d",
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "912107d6-d99d-44ea-a0f6-2d45dea61529",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 31 32 31 30 37  64 36 2d 64 39 39 64 2d  |\"912107d6-d99d-|
              00000120  34 34 65 61 2d 61 30 66  36 2d 32 64 34 35 64 65  |44ea-a0f6-2d45de|
              00000130  61 36 31 35 32 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a61529\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:58:51.851369 19 deployment.go:44] All old ReplicaSets of Deployment "test-recreate-deployment":
  I1026 12:58:51.851550 19 deployment.go:47] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-7549bcf47c",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "415e32b4-4b8f-41f1-b629-0de8bcac2c4f",
      ResourceVersion: (string) (len=5) "31415",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865544329,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "912107d6-d99d-44ea-a0f6-2d45dea61529",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 31 32 31 30 37  64 36 2d 64 39 39 64 2d  |\"912107d6-d99d-|
              00000120  34 34 65 61 2d 61 30 66  36 2d 32 64 34 35 64 65  |44ea-a0f6-2d45de|
              00000130  61 36 31 35 32 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a61529\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7549bcf47c"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.52",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 12:58:51.856415 19 deployment.go:67] Pod "test-recreate-deployment-88d47c55d-p8vkx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-88d47c55d-p8vkx",
      GenerateName: (string) (len=35) "test-recreate-deployment-88d47c55d-",
      Namespace: (string) (len=14) "deployment-158",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1a4021c5-5a7f-4967-b859-e03c1f509ac1",
      ResourceVersion: (string) (len=5) "31427",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865544331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "88d47c55d"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-88d47c55d",
          UID: (types.UID) (len=36) "5064bbf4-1cb8-46a4-9cfe-554de359cb57",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 30  36 34 62 62 66 34 2d 31  |d\":\"5064bbf4-1|
              00000090  63 62 38 2d 34 36 61 34  2d 39 63 66 65 2d 35 35  |cb8-46a4-9cfe-55|
              000000a0  34 64 65 33 35 39 63 62  35 37 5c 22 7d 22 3a 7b  |4de359cb57\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vcxtp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vcxtp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-30-144",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865544331,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.30.144",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.30.144"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865544331,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-vcxtp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 12:58:51.857429 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-158" for this suite. @ 10/26/24 12:58:51.861
• [2.174 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:999
  STEP: Creating a kubernetes client @ 10/26/24 12:58:51.867
  I1026 12:58:51.867840 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 12:58:51.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:51.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:51.889
  STEP: Creating a ResourceQuota @ 10/26/24 12:58:51.893
  STEP: Getting a ResourceQuota @ 10/26/24 12:58:51.897
  STEP: Listing all ResourceQuotas with LabelSelector @ 10/26/24 12:58:51.902
  STEP: Patching the ResourceQuota @ 10/26/24 12:58:51.905
  STEP: Deleting a Collection of ResourceQuotas @ 10/26/24 12:58:51.911
  STEP: Verifying the deleted ResourceQuota @ 10/26/24 12:58:51.922
  I1026 12:58:51.926614 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5935" for this suite. @ 10/26/24 12:58:51.931
• [0.071 seconds]
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 10/26/24 12:58:51.939
  I1026 12:58:51.939272 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename subpath @ 10/26/24 12:58:51.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:58:51.956
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:58:51.959
  STEP: Setting up data @ 10/26/24 12:58:51.962
  STEP: Creating pod pod-subpath-test-projected-rqh8 @ 10/26/24 12:58:51.972
  STEP: Creating a pod to test atomic-volume-subpath @ 10/26/24 12:58:51.972
  E1026 12:58:52.537896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:53.538096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:54.538239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:55.538367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:56.538715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:57.538922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:58.539905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:58:59.540213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:00.540425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:01.540546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:02.540749      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:03.540832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:04.541025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:05.541315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:06.541827      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:07.541954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:08.542435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:09.542531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:10.543526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:11.543652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:12.543746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:13.543780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:14.543847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:15.543932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:59:16.055
  I1026 12:59:16.059924 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-subpath-test-projected-rqh8 container test-container-subpath-projected-rqh8: <nil>
  STEP: delete the pod @ 10/26/24 12:59:16.067
  STEP: Deleting pod pod-subpath-test-projected-rqh8 @ 10/26/24 12:59:16.083
  I1026 12:59:16.083388 19 delete.go:62] Deleting pod "pod-subpath-test-projected-rqh8" in namespace "subpath-5557"
  I1026 12:59:16.087700 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5557" for this suite. @ 10/26/24 12:59:16.092
• [24.161 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 10/26/24 12:59:16.1
  I1026 12:59:16.100166 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename security-context-test @ 10/26/24 12:59:16.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:59:16.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:59:16.124
  E1026 12:59:16.544045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:17.544982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:18.545825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:19.545901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:20.160476 19 security_context.go:538] Got logs for pod "busybox-privileged-false-e4b4ae2c-8074-469b-be9f-024268290a93": "ip: RTNETLINK answers: Operation not permitted\n"
  I1026 12:59:20.160602 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4023" for this suite. @ 10/26/24 12:59:20.164
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:282
  STEP: Creating a kubernetes client @ 10/26/24 12:59:20.171
  I1026 12:59:20.171450 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 12:59:20.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:59:20.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:59:20.196
  STEP: Setting up server cert @ 10/26/24 12:59:20.225
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 12:59:20.52
  STEP: Deploying the webhook pod @ 10/26/24 12:59:20.529
  STEP: Wait for the deployment to be ready @ 10/26/24 12:59:20.542
  E1026 12:59:20.545962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:20.554703 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 12:59:21.546508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:22.547053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 12:59:22.567
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 12:59:22.58
  E1026 12:59:23.547806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:23.580990 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I1026 12:59:23.589987 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1779-crds.webhook.example.com via the AdmissionRegistration API @ 10/26/24 12:59:24.102
  STEP: Creating a custom resource that should be mutated by the webhook @ 10/26/24 12:59:24.117
  E1026 12:59:24.547905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:25.548212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:26.548313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:26.704866 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8886" for this suite. @ 10/26/24 12:59:26.71
  STEP: Destroying namespace "webhook-markers-40" for this suite. @ 10/26/24 12:59:26.717
• [6.554 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 10/26/24 12:59:26.725
  I1026 12:59:26.725926 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 12:59:26.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:59:26.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:59:26.753
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 12:59:26.756
  E1026 12:59:27.548368      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:28.549332      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:29.549839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:30.550062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 12:59:30.784
  I1026 12:59:30.789096 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-575a3b31-0501-4506-88c0-fcb1426ee67f container client-container: <nil>
  STEP: delete the pod @ 10/26/24 12:59:30.796
  I1026 12:59:30.812407 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4869" for this suite. @ 10/26/24 12:59:30.818
• [4.100 seconds]
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 10/26/24 12:59:30.825
  I1026 12:59:30.825972 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-pred @ 10/26/24 12:59:30.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:59:30.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:59:30.846
  I1026 12:59:30.850978 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I1026 12:59:30.860272 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1026 12:59:30.865406 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-30-144 before test
  I1026 12:59:30.871142 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-7dwlf from ingress-nginx-kubernetes-worker started at 2024-10-26 12:55:59 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.871157 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 12:59:30.871164 19 predicates.go:957] calico-node-mh8sl from kube-system started at 2024-10-26 12:05:37 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.871172 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 12:59:30.871178 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-10-26 12:09:56 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.871187 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I1026 12:59:30.871193 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-cj9w2 from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 12:59:30.871202 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 12:59:30.871207 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1026 12:59:30.871212 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-35-104 before test
  I1026 12:59:30.876141 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-j79fd from ingress-nginx-kubernetes-worker started at 2024-10-26 12:00:11 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.876159 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 12:59:30.876166 19 predicates.go:957] calico-node-7mt8z from kube-system started at 2024-10-26 12:06:48 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.876172 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 12:59:30.876179 19 predicates.go:957] sonobuoy-e2e-job-f2d0e8def796404a from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 12:59:30.876186 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I1026 12:59:30.876192 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 12:59:30.876198 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-x5lp5 from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 12:59:30.876203 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 12:59:30.876208 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1026 12:59:30.876214 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-8-187 before test
  I1026 12:59:30.882965 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-bkqfk from ingress-nginx-kubernetes-worker started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.882981 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 12:59:30.882988 19 predicates.go:957] calico-node-gctkm from kube-system started at 2024-10-26 12:07:09 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.882993 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 12:59:30.882999 19 predicates.go:957] coredns-5b4857d7c8-l5pcc from kube-system started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.883004 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I1026 12:59:30.883010 19 predicates.go:957] kube-state-metrics-5d7bdccd49-nxf5p from kube-system started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.883014 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 2
  I1026 12:59:30.883020 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-cbtf8 from kube-system started at 2024-10-26 11:50:52 +0000 UTC (2 container statuses recorded)
  I1026 12:59:30.883025 19 predicates.go:959] 	Container metrics-server ready: true, restart count 1
  I1026 12:59:30.883034 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I1026 12:59:30.883039 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-6lj85 from kubernetes-dashboard started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.883043 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I1026 12:59:30.883049 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-ntk95 from kubernetes-dashboard started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 12:59:30.883052 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 4
  I1026 12:59:30.883058 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-wv9nc from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 12:59:30.883091 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 12:59:30.883097 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 10/26/24 12:59:30.883
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.180202266bcb64f3], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] @ 10/26/24 12:59:30.911
  E1026 12:59:31.550976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:31.912830 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3310" for this suite. @ 10/26/24 12:59:31.916
• [1.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 10/26/24 12:59:31.922
  I1026 12:59:31.922325 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename var-expansion @ 10/26/24 12:59:31.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:59:31.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:59:31.943
  E1026 12:59:32.551088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:33.551288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:33.965379 19 delete.go:62] Deleting pod "var-expansion-51b1aecc-3afd-4363-8ba6-e441526d2595" in namespace "var-expansion-1960"
  I1026 12:59:33.975000 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-51b1aecc-3afd-4363-8ba6-e441526d2595" to be fully deleted
  E1026 12:59:34.551895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:35.552120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:35.984820 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1960" for this suite. @ 10/26/24 12:59:35.989
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 10/26/24 12:59:35.997
  I1026 12:59:35.997308 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename aggregateddiscovery @ 10/26/24 12:59:35.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:59:36.014
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:59:36.018
  I1026 12:59:36.021359 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 12:59:36.552301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:37.552390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:38.553139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:39.076772 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-2435" for this suite. @ 10/26/24 12:59:39.082
• [3.093 seconds]
------------------------------
SS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 10/26/24 12:59:39.09
  I1026 12:59:39.090960 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 10/26/24 12:59:39.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:59:39.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:59:39.111
  STEP: creating a target pod @ 10/26/24 12:59:39.114
  E1026 12:59:39.553925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:40.554895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 10/26/24 12:59:41.137
  E1026 12:59:41.555016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:42.555917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 10/26/24 12:59:43.156
  I1026 12:59:43.156809 19 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3775 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:59:43.156825 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:59:43.157319 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:59:43.157363 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-3775/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I1026 12:59:43.204722 19 exec_util.go:111] Exec stderr: ""
  I1026 12:59:43.213952 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-3775" for this suite. @ 10/26/24 12:59:43.218
• [4.134 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 10/26/24 12:59:43.224
  I1026 12:59:43.224625 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pod-network-test @ 10/26/24 12:59:43.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 12:59:43.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 12:59:43.248
  STEP: Performing setup for networking test in namespace pod-network-test-1445 @ 10/26/24 12:59:43.251
  STEP: creating a selector @ 10/26/24 12:59:43.251
  STEP: Creating the service pods in kubernetes @ 10/26/24 12:59:43.251
  I1026 12:59:43.251425 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1026 12:59:43.556751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:44.557085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:45.557179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:46.557302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:47.558347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:48.559335      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:49.560394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:50.560492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:51.560718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:52.560990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:53.561566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:54.561714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 10/26/24 12:59:55.341
  E1026 12:59:55.561843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 12:59:56.562052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:57.377541 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I1026 12:59:57.377577 19 utils.go:496] Going to poll 192.168.29.181 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I1026 12:59:57.382256 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.29.181 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1445 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:59:57.382277 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:59:57.382746 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:59:57.382815 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1445/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.29.181+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1026 12:59:57.562140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:58.431754 19 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I1026 12:59:58.431803 19 utils.go:496] Going to poll 192.168.46.123 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I1026 12:59:58.436160 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.46.123 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1445 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:59:58.436182 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:59:58.436587 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:59:58.436630 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1445/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.46.123+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1026 12:59:58.562704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 12:59:59.472046 19 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I1026 12:59:59.472083 19 utils.go:496] Going to poll 192.168.232.121 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  I1026 12:59:59.477153 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.232.121 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1445 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 12:59:59.477175 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 12:59:59.477583 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 12:59:59.477641 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1445/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.232.121+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1026 12:59:59.563632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:00:00.511904 19 utils.go:513] Found all 1 expected endpoints: [netserver-2]
  I1026 13:00:00.512045 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1445" for this suite. @ 10/26/24 13:00:00.517
• [17.303 seconds]
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 10/26/24 13:00:00.527
  I1026 13:00:00.527281 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replicaset @ 10/26/24 13:00:00.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:00.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:00.549
  STEP: Create a ReplicaSet @ 10/26/24 13:00:00.552
  STEP: Verify that the required pods have come up @ 10/26/24 13:00:00.558
  I1026 13:00:00.561952 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 3
  E1026 13:00:00.564083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:01.564903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:02.564997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:03.565080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:04.565182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:05.565462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:00:05.566659 19 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 10/26/24 13:00:05.566
  I1026 13:00:05.569973 19 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 10/26/24 13:00:05.569
  STEP: DeleteCollection of the ReplicaSets @ 10/26/24 13:00:05.574
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 10/26/24 13:00:05.583
  I1026 13:00:05.587396 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6521" for this suite. @ 10/26/24 13:00:05.591
• [5.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:331
  STEP: Creating a kubernetes client @ 10/26/24 13:00:05.603
  I1026 13:00:05.603125 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename dns @ 10/26/24 13:00:05.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:05.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:05.627
  STEP: Creating a test externalName service @ 10/26/24 13:00:05.63
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9679.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9679.svc.cluster.local; sleep 1; done
   @ 10/26/24 13:00:05.638
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9679.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9679.svc.cluster.local; sleep 1; done
   @ 10/26/24 13:00:05.638
  STEP: creating a pod to probe DNS @ 10/26/24 13:00:05.638
  STEP: submitting the pod to kubernetes @ 10/26/24 13:00:05.638
  E1026 13:00:06.565611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:07.565834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 13:00:07.658
  STEP: looking for the results for each expected name from probers @ 10/26/24 13:00:07.661
  I1026 13:00:07.673331 19 dns_common.go:552] DNS probes using dns-test-b296e27b-f0ac-43ee-8bae-fbe5832c1950 succeeded

  STEP: changing the externalName to bar.example.com @ 10/26/24 13:00:07.673
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9679.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9679.svc.cluster.local; sleep 1; done
   @ 10/26/24 13:00:07.681
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9679.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9679.svc.cluster.local; sleep 1; done
   @ 10/26/24 13:00:07.681
  STEP: creating a second pod to probe DNS @ 10/26/24 13:00:07.681
  STEP: submitting the pod to kubernetes @ 10/26/24 13:00:07.681
  E1026 13:00:08.566244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:09.566356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:10.566452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:11.566916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:12.567314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:13.567814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 13:00:13.71
  STEP: looking for the results for each expected name from probers @ 10/26/24 13:00:13.715
  I1026 13:00:13.727394 19 dns_common.go:552] DNS probes using dns-test-17eb3f91-35c9-4484-970f-055327c9ca62 succeeded

  STEP: changing the service to type=ClusterIP @ 10/26/24 13:00:13.727
  W1026 13:00:13.742436      19 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9679.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9679.svc.cluster.local; sleep 1; done
   @ 10/26/24 13:00:13.742
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9679.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9679.svc.cluster.local; sleep 1; done
   @ 10/26/24 13:00:13.742
  STEP: creating a third pod to probe DNS @ 10/26/24 13:00:13.742
  STEP: submitting the pod to kubernetes @ 10/26/24 13:00:13.747
  E1026 13:00:14.568563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:15.568775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 13:00:15.765
  STEP: looking for the results for each expected name from probers @ 10/26/24 13:00:15.769
  I1026 13:00:15.780440 19 dns_common.go:552] DNS probes using dns-test-92c37421-386f-4760-a53e-7910a95d35e4 succeeded

  STEP: deleting the pod @ 10/26/24 13:00:15.78
  STEP: deleting the pod @ 10/26/24 13:00:15.797
  STEP: deleting the pod @ 10/26/24 13:00:15.809
  STEP: deleting the test externalName service @ 10/26/24 13:00:15.823
  I1026 13:00:15.839037 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9679" for this suite. @ 10/26/24 13:00:15.843
• [10.250 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 10/26/24 13:00:15.853
  I1026 13:00:15.853856 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replicaset @ 10/26/24 13:00:15.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:15.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:15.874
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 10/26/24 13:00:15.878
  I1026 13:00:15.887173 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E1026 13:00:16.568861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:17.569910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:18.570100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:19.571179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:20.571902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:00:20.891499 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 10/26/24 13:00:20.891
  STEP: getting scale subresource @ 10/26/24 13:00:20.891
  STEP: updating a scale subresource @ 10/26/24 13:00:20.895
  STEP: verifying the replicaset Spec.Replicas was modified @ 10/26/24 13:00:20.903
  STEP: Patch a scale subresource @ 10/26/24 13:00:20.905
  I1026 13:00:20.918818 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8457" for this suite. @ 10/26/24 13:00:20.923
• [5.081 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 10/26/24 13:00:20.934
  I1026 13:00:20.934643 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:00:20.935
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:20.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:20.962
  STEP: Creating projection with secret that has name projected-secret-test-map-1d87f57d-3fbb-45a6-ba4e-2516d4c7f80b @ 10/26/24 13:00:20.965
  STEP: Creating a pod to test consume secrets @ 10/26/24 13:00:20.971
  E1026 13:00:21.572043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:22.572214      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:23.572316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:24.572428      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:00:24.998
  I1026 13:00:25.003320 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-projected-secrets-370f030f-da80-4104-978d-7b4fb9b05a56 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 13:00:25.009
  I1026 13:00:25.025130 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4008" for this suite. @ 10/26/24 13:00:25.03
• [4.102 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 10/26/24 13:00:25.037
  I1026 13:00:25.037056 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename server-version @ 10/26/24 13:00:25.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:25.056
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:25.059
  STEP: Request ServerVersion @ 10/26/24 13:00:25.062
  STEP: Confirm major version @ 10/26/24 13:00:25.064
  I1026 13:00:25.064269 19 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 10/26/24 13:00:25.064
  I1026 13:00:25.064292 19 server_version.go:58] cleanMinorVersion: 31
  I1026 13:00:25.064301 19 server_version.go:62] Minor version: 31
  I1026 13:00:25.064355 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-2832" for this suite. @ 10/26/24 13:00:25.068
• [0.037 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 10/26/24 13:00:25.074
  I1026 13:00:25.074642 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 13:00:25.075
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:25.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:25.095
  STEP: Creating projection with secret that has name secret-emptykey-test-4c50b6ed-bf7a-4695-95f6-805abe1219e7 @ 10/26/24 13:00:25.098
  I1026 13:00:25.100478 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6440" for this suite. @ 10/26/24 13:00:25.103
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 10/26/24 13:00:25.111
  I1026 13:00:25.111597 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 13:00:25.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:25.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:25.13
  E1026 13:00:25.573295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:26.573391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:27.574123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:28.574607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:29.575354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:30.575463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:00:31.195
  I1026 13:00:31.199962 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod client-envvars-bf3bd082-1237-4b59-9ba7-9ae9c5b4e4ff container env3cont: <nil>
  STEP: delete the pod @ 10/26/24 13:00:31.221
  I1026 13:00:31.239255 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5374" for this suite. @ 10/26/24 13:00:31.243
• [6.139 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:298
  STEP: Creating a kubernetes client @ 10/26/24 13:00:31.25
  I1026 13:00:31.250951 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:00:31.251
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:31.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:31.278
  STEP: Setting up server cert @ 10/26/24 13:00:31.308
  E1026 13:00:31.576288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:00:31.639
  STEP: Deploying the webhook pod @ 10/26/24 13:00:31.648
  STEP: Wait for the deployment to be ready @ 10/26/24 13:00:31.665
  I1026 13:00:31.677572 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:00:32.576416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:33.577379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:00:33.693
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:00:33.705
  E1026 13:00:34.577432      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:00:34.705715 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 10/26/24 13:00:34.714
  STEP: Creating a custom resource definition that should be denied by the webhook @ 10/26/24 13:00:34.73
  I1026 13:00:34.730463 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:00:34.783992 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7369" for this suite. @ 10/26/24 13:00:34.787
  STEP: Destroying namespace "webhook-markers-2626" for this suite. @ 10/26/24 13:00:34.794
• [3.550 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 10/26/24 13:00:34.801
  I1026 13:00:34.801127 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replicaset @ 10/26/24 13:00:34.801
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:34.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:34.822
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 10/26/24 13:00:34.826
  E1026 13:00:35.577547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:36.579783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 10/26/24 13:00:36.85
  STEP: Then the orphan pod is adopted @ 10/26/24 13:00:36.857
  E1026 13:00:37.578451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 10/26/24 13:00:37.867
  I1026 13:00:37.871326 19 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 10/26/24 13:00:37.884
  E1026 13:00:38.579395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:00:38.893892 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1067" for this suite. @ 10/26/24 13:00:38.899
• [4.108 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 10/26/24 13:00:38.909
  I1026 13:00:38.909025 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 13:00:38.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:38.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:38.932
  I1026 13:00:38.936212 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: creating the pod @ 10/26/24 13:00:38.936
  STEP: submitting the pod to kubernetes @ 10/26/24 13:00:38.936
  E1026 13:00:39.579514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:40.579759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:00:41.006324 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8992" for this suite. @ 10/26/24 13:00:41.01
• [2.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 10/26/24 13:00:41.018
  I1026 13:00:41.018692 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename watch @ 10/26/24 13:00:41.019
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:41.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:41.039
  STEP: creating a new configmap @ 10/26/24 13:00:41.042
  STEP: modifying the configmap once @ 10/26/24 13:00:41.047
  STEP: modifying the configmap a second time @ 10/26/24 13:00:41.058
  STEP: deleting the configmap @ 10/26/24 13:00:41.069
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 10/26/24 13:00:41.074
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 10/26/24 13:00:41.075
  I1026 13:00:41.076108 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7480  41dc51ea-07c1-4172-a9df-317b2512d3b9 32687 0 2024-10-26 13:00:41 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-10-26 13:00:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:00:41.076211 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7480  41dc51ea-07c1-4172-a9df-317b2512d3b9 32688 0 2024-10-26 13:00:41 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-10-26 13:00:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:00:41.076292 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7480" for this suite. @ 10/26/24 13:00:41.081
• [0.070 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 10/26/24 13:00:41.089
  I1026 13:00:41.089035 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-runtime @ 10/26/24 13:00:41.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:00:41.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:00:41.11
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 10/26/24 13:00:41.122
  E1026 13:00:41.579833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:42.580603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:43.581463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:44.582213      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:45.582925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:46.583208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:47.583302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:48.583977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:49.584070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:50.584245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:51.584878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:52.585894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:53.586375      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:54.586908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:55.587007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:56.587893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:57.588447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 10/26/24 13:00:58.227
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 10/26/24 13:00:58.23
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 10/26/24 13:00:58.239
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 10/26/24 13:00:58.239
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 10/26/24 13:00:58.262
  E1026 13:00:58.588584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:00:59.589270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:00.589450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 10/26/24 13:01:01.284
  E1026 13:01:01.589999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 10/26/24 13:01:02.296
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 10/26/24 13:01:02.303
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 10/26/24 13:01:02.303
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 10/26/24 13:01:02.326
  E1026 13:01:02.590547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 10/26/24 13:01:03.336
  E1026 13:01:03.591181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:04.591585      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 10/26/24 13:01:05.353
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 10/26/24 13:01:05.36
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 10/26/24 13:01:05.36
  I1026 13:01:05.391822 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3643" for this suite. @ 10/26/24 13:01:05.395
• [24.312 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 10/26/24 13:01:05.401
  I1026 13:01:05.401650 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename daemonsets @ 10/26/24 13:01:05.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:01:05.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:01:05.423
  I1026 13:01:05.449363 19 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 10/26/24 13:01:05.455
  I1026 13:01:05.459126 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:01:05.459150 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 10/26/24 13:01:05.459
  I1026 13:01:05.482597 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:01:05.482809 19 fixtures.go:130] Node ip-172-31-35-104 is running 0 daemon pod, expected 1
  E1026 13:01:05.592209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:01:06.483568 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:01:06.483603 19 fixtures.go:130] Node ip-172-31-35-104 is running 0 daemon pod, expected 1
  E1026 13:01:06.592824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:01:07.482587 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1026 13:01:07.482644 19 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 10/26/24 13:01:07.486
  I1026 13:01:07.502460 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1026 13:01:07.502491 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E1026 13:01:07.593790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:01:08.505422 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:01:08.505449 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 10/26/24 13:01:08.505
  I1026 13:01:08.518099 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:01:08.518124 19 fixtures.go:130] Node ip-172-31-35-104 is running 0 daemon pod, expected 1
  E1026 13:01:08.594330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:01:09.521788 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:01:09.521822 19 fixtures.go:130] Node ip-172-31-35-104 is running 0 daemon pod, expected 1
  E1026 13:01:09.594883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:01:10.518892 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I1026 13:01:10.518925 19 fixtures.go:135] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 10/26/24 13:01:10.524
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4565, will wait for the garbage collector to delete the pods @ 10/26/24 13:01:10.524
  I1026 13:01:10.587025 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 6.979974ms
  E1026 13:01:10.595210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:01:10.688144 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.11097ms
  I1026 13:01:11.592619 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:01:11.592651 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  E1026 13:01:11.595753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:01:11.597753 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32956"},"items":null}

  I1026 13:01:11.602113 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32956"},"items":null}

  I1026 13:01:11.627179 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4565" for this suite. @ 10/26/24 13:01:11.63
• [6.236 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 10/26/24 13:01:11.637
  I1026 13:01:11.638413 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename var-expansion @ 10/26/24 13:01:11.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:01:11.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:01:11.659
  STEP: Creating a pod to test substitution in container's command @ 10/26/24 13:01:11.663
  E1026 13:01:12.595951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:13.596196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:01:13.682
  I1026 13:01:13.686145 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod var-expansion-9d48c914-b16f-4fed-b5d8-8698eec133e8 container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 13:01:13.695
  I1026 13:01:13.715296 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3936" for this suite. @ 10/26/24 13:01:13.718
• [2.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 10/26/24 13:01:13.727
  I1026 13:01:13.727351 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-watch @ 10/26/24 13:01:13.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:01:13.746
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:01:13.749
  I1026 13:01:13.752954 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:01:14.596350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:15.596465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 10/26/24 13:01:16.295
  I1026 13:01:16.300659 19 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-10-26T13:01:16Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-10-26T13:01:16Z]] name:name1 resourceVersion:33002 uid:a87b2341-a470-443f-9140-58f058276265] num:map[num1:9223372036854775807 num2:1000000]]}
  E1026 13:01:16.597202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:17.597418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:18.598304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:19.598479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:20.598737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:21.598969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:22.599158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:23.599884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:24.600065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:25.600193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 10/26/24 13:01:26.301
  I1026 13:01:26.308213 19 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-10-26T13:01:26Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-10-26T13:01:26Z]] name:name2 resourceVersion:33061 uid:64e73983-f056-46b1-ba26-298305cd2826] num:map[num1:9223372036854775807 num2:1000000]]}
  E1026 13:01:26.600435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:27.600517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:28.601315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:29.601897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:30.602017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:31.602093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:32.602879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:33.602918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:34.603082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:35.603178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 10/26/24 13:01:36.308
  I1026 13:01:36.317437 19 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-10-26T13:01:16Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-10-26T13:01:36Z]] name:name1 resourceVersion:33082 uid:a87b2341-a470-443f-9140-58f058276265] num:map[num1:9223372036854775807 num2:1000000]]}
  E1026 13:01:36.603883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:37.604869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:38.605183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:39.605373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:40.605866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:41.606384      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:42.606718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:43.606970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:44.607170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:45.607863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 10/26/24 13:01:46.317
  I1026 13:01:46.324735 19 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-10-26T13:01:26Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-10-26T13:01:46Z]] name:name2 resourceVersion:33103 uid:64e73983-f056-46b1-ba26-298305cd2826] num:map[num1:9223372036854775807 num2:1000000]]}
  E1026 13:01:46.608227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:47.608362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:48.609287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:49.609484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:50.609663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:51.610824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:52.611859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:53.612126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:54.613047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:55.613140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 10/26/24 13:01:56.325
  I1026 13:01:56.334925 19 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-10-26T13:01:16Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-10-26T13:01:36Z]] name:name1 resourceVersion:33125 uid:a87b2341-a470-443f-9140-58f058276265] num:map[num1:9223372036854775807 num2:1000000]]}
  E1026 13:01:56.614217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:57.614867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:58.615152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:01:59.615865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:00.616863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:01.617867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:02.618864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:03.619314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:04.619878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:05.620899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 10/26/24 13:02:06.335
  I1026 13:02:06.344543 19 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-10-26T13:01:26Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-10-26T13:01:46Z]] name:name2 resourceVersion:33146 uid:64e73983-f056-46b1-ba26-298305cd2826] num:map[num1:9223372036854775807 num2:1000000]]}
  E1026 13:02:06.622022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:07.622245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:08.623295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:09.623491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:10.623782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:11.623846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:12.624869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:13.625295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:14.625643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:15.625832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:16.626783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:02:16.862298 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-8358" for this suite. @ 10/26/24 13:02:16.868
• [63.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 10/26/24 13:02:16.881
  I1026 13:02:16.881558 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 13:02:16.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:02:16.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:02:16.903
  STEP: Creating secret with name secret-test-e4181317-0182-48b5-84dc-e4882239d7e5 @ 10/26/24 13:02:16.906
  STEP: Creating a pod to test consume secrets @ 10/26/24 13:02:16.911
  E1026 13:02:17.626865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:18.627910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:19.628923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:20.629090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:02:20.936
  I1026 13:02:20.941988 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-secrets-76ff9dd0-3716-40d7-ad43-940daa6545e6 container secret-env-test: <nil>
  STEP: delete the pod @ 10/26/24 13:02:20.956
  I1026 13:02:20.972872 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2742" for this suite. @ 10/26/24 13:02:20.976
• [4.104 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:104
  STEP: Creating a kubernetes client @ 10/26/24 13:02:20.985
  I1026 13:02:20.985297 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 13:02:20.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:02:21.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:02:21.008
  STEP: Counting existing ResourceQuota @ 10/26/24 13:02:21.011
  E1026 13:02:21.629108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:22.629321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:23.629951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:24.630729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:25.630831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 10/26/24 13:02:26.016
  STEP: Ensuring resource quota status is calculated @ 10/26/24 13:02:26.022
  E1026 13:02:26.631464      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:27.631644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 10/26/24 13:02:28.027
  STEP: Creating a NodePort Service @ 10/26/24 13:02:28.045
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 10/26/24 13:02:28.07
  STEP: Ensuring resource quota status captures service creation @ 10/26/24 13:02:28.094
  E1026 13:02:28.632414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:29.632659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 10/26/24 13:02:30.1
  STEP: Ensuring resource quota status released usage @ 10/26/24 13:02:30.14
  E1026 13:02:30.633015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:31.633326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:02:32.145354 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8140" for this suite. @ 10/26/24 13:02:32.149
• [11.174 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 10/26/24 13:02:32.159
  I1026 13:02:32.159771 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 13:02:32.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:02:32.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:02:32.182
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 10/26/24 13:02:32.185
  I1026 13:02:32.186310 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:02:32.633419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:33.633750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:34.633912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:35.634661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:36.635408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 10/26/24 13:02:37.23
  I1026 13:02:37.231218 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:02:37.635899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:02:38.542777 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:02:38.636688      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:39.636925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:40.637032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:41.637229      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:42.637922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:02:43.529195 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7107" for this suite. @ 10/26/24 13:02:43.536
• [11.383 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 10/26/24 13:02:43.542
  I1026 13:02:43.542830 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pod-network-test @ 10/26/24 13:02:43.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:02:43.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:02:43.564
  STEP: Performing setup for networking test in namespace pod-network-test-8853 @ 10/26/24 13:02:43.567
  STEP: creating a selector @ 10/26/24 13:02:43.567
  STEP: Creating the service pods in kubernetes @ 10/26/24 13:02:43.567
  I1026 13:02:43.567343 19 helper.go:48] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1026 13:02:43.637979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:44.638197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:45.638497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:46.638802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:47.639811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:48.639891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:49.640557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:50.640813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:51.641763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:52.641972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:53.642874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:54.643209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:55.643339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:56.643488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:57.644348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:58.645340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:02:59.645703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:00.645890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:01.646902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:02.647027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:03.647722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:04.648411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:05.649045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 10/26/24 13:03:05.686
  E1026 13:03:06.649082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:07.650080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:03:07.705200 19 utils.go:803] Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  I1026 13:03:07.705228 19 networking.go:42] Breadth first check of 192.168.29.143 on host 172.31.30.144...
  I1026 13:03:07.710050 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.29.131:9080/dial?request=hostname&protocol=http&host=192.168.29.143&port=8083&tries=1'] Namespace:pod-network-test-8853 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 13:03:07.710070 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:03:07.710523 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 13:03:07.710565 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8853/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.29.131%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.29.143%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1026 13:03:07.755115 19 utils.go:356] Waiting for responses: map[]
  I1026 13:03:07.755141 19 utils.go:360] reached 192.168.29.143 after 0/1 tries
  I1026 13:03:07.755151 19 networking.go:42] Breadth first check of 192.168.46.73 on host 172.31.35.104...
  I1026 13:03:07.758955 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.29.131:9080/dial?request=hostname&protocol=http&host=192.168.46.73&port=8083&tries=1'] Namespace:pod-network-test-8853 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 13:03:07.758972 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:03:07.759333 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 13:03:07.759372 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8853/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.29.131%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.46.73%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1026 13:03:07.805936 19 utils.go:356] Waiting for responses: map[]
  I1026 13:03:07.805958 19 utils.go:360] reached 192.168.46.73 after 0/1 tries
  I1026 13:03:07.805966 19 networking.go:42] Breadth first check of 192.168.232.104 on host 172.31.8.187...
  I1026 13:03:07.809929 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.29.131:9080/dial?request=hostname&protocol=http&host=192.168.232.104&port=8083&tries=1'] Namespace:pod-network-test-8853 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 13:03:07.809946 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:03:07.810301 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 13:03:07.810339 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8853/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.29.131%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.232.104%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  I1026 13:03:07.851470 19 utils.go:356] Waiting for responses: map[]
  I1026 13:03:07.851506 19 utils.go:360] reached 192.168.232.104 after 0/1 tries
  I1026 13:03:07.851515 19 networking.go:53] Going to retry 0 out of 3 pods....
  I1026 13:03:07.851619 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8853" for this suite. @ 10/26/24 13:03:07.856
• [24.320 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 10/26/24 13:03:07.862
  I1026 13:03:07.862602 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename watch @ 10/26/24 13:03:07.863
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:03:07.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:03:07.887
  STEP: creating a watch on configmaps with label A @ 10/26/24 13:03:07.89
  STEP: creating a watch on configmaps with label B @ 10/26/24 13:03:07.892
  STEP: creating a watch on configmaps with label A or B @ 10/26/24 13:03:07.893
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 10/26/24 13:03:07.894
  I1026 13:03:07.901364 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3226  0638a6ff-625e-4494-b7b2-aa815e2cfdf4 33443 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:03:07.901474 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3226  0638a6ff-625e-4494-b7b2-aa815e2cfdf4 33443 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 10/26/24 13:03:07.901
  I1026 13:03:07.908898 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3226  0638a6ff-625e-4494-b7b2-aa815e2cfdf4 33444 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:03:07.909002 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3226  0638a6ff-625e-4494-b7b2-aa815e2cfdf4 33444 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 10/26/24 13:03:07.909
  I1026 13:03:07.918130 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3226  0638a6ff-625e-4494-b7b2-aa815e2cfdf4 33445 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:03:07.918228 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3226  0638a6ff-625e-4494-b7b2-aa815e2cfdf4 33445 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 10/26/24 13:03:07.918
  I1026 13:03:07.924699 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3226  0638a6ff-625e-4494-b7b2-aa815e2cfdf4 33447 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:03:07.924739 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3226  0638a6ff-625e-4494-b7b2-aa815e2cfdf4 33447 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 10/26/24 13:03:07.924
  I1026 13:03:07.928990 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3226  cbf714f0-461d-4191-bd6a-5200d7e2aba9 33448 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:03:07.929058 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3226  cbf714f0-461d-4191-bd6a-5200d7e2aba9 33448 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1026 13:03:08.650667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:09.650817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:10.651001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:11.651907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:12.652160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:13.652751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:14.652847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:15.653249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:16.653361      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:17.654029      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 10/26/24 13:03:17.929
  I1026 13:03:17.936519 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3226  cbf714f0-461d-4191-bd6a-5200d7e2aba9 33516 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:03:17.936555 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3226  cbf714f0-461d-4191-bd6a-5200d7e2aba9 33516 0 2024-10-26 13:03:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-10-26 13:03:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1026 13:03:18.654129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:19.654877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:20.655872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:21.655997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:22.656885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:23.657377      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:24.657577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:25.658632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:26.658784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:27.658970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:03:27.937560 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3226" for this suite. @ 10/26/24 13:03:27.942
• [20.087 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 10/26/24 13:03:27.949
  I1026 13:03:27.949997 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename chunking @ 10/26/24 13:03:27.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:03:27.967
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:03:27.971
  STEP: creating a large number of resources @ 10/26/24 13:03:27.974
  E1026 13:03:28.659436      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:29.659497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:30.660071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:31.660950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:32.661772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:33.662304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:34.662416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:35.662756      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:36.663186      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:37.664117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:38.664916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:39.665588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:40.665718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:41.665792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:42.666761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:43.667245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:44.668026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 10/26/24 13:03:45.659
  E1026 13:03:45.668481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:03:45.705129 19 chunking.go:163] Retrieved 40/40 results with rv 33982 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 10/26/24 13:03:45.705
  E1026 13:03:46.668918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:47.669035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:48.670008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:49.670297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:50.670518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:51.670618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:52.670977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:53.671144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:54.671874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:55.672064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:56.672156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:57.672293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:58.672595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:03:59.672711      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:00.672806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:01.672882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:02.673056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:03.673135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:04.673328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:05.673632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:04:05.710950 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:04:06.673806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:07.674872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:08.675877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:09.675990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:10.676097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:11.676344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:12.676527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:13.677370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:14.677484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:15.677740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:16.678164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:17.678364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:18.679339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:19.679520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:20.679811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:21.680870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:22.681987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:23.682142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:24.682395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:25.683298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:04:25.711950 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:04:26.683803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:27.683900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:28.684205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:29.684866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:30.685110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:31.685875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:32.686884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:33.687874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:34.688112      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:35.688246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:36.688433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:37.688631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:38.688913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:39.689134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:40.689323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:41.689915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:42.689982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:43.690319      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:44.690321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:45.690811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:04:45.711134 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:04:46.691301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:47.691816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:48.692073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:49.692261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:50.692992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:51.694027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:52.694871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:53.695872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:54.695976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:55.696604      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:56.696835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:57.697157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:58.697516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:04:59.697731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:00.697811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:01.697999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:02.698129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:03.698281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:04.698529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:05.698783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:05:05.711138 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:05:06.698961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:07.699067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:08.699246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:09.699432      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:10.699702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:11.699824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:12.699976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:13.700283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:14.700527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:15.700746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:16.700928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:17.701913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:18.702916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:19.703001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:20.703126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:21.703525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:22.703587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:23.704369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:24.704882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:25.705880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:05:25.712410 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:05:26.705984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:27.706876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:28.707279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:29.707578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:30.707911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:31.708098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:32.708339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:33.708425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:34.708619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:35.708812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:36.709067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:37.709244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:38.709552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:39.709696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:40.709878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:41.709946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:42.710149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:43.710367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:44.710589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:45.710626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:05:45.710942 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:05:46.711172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:47.711369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:48.712434      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:49.713065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:50.713206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:51.713303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:52.714062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:53.714888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:54.715002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:55.715869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:56.716879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:57.717878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:58.718717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:05:59.718879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:00.719860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:01.720874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:02.721231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:03.721337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:04.721557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:06:05.712516 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:06:05.722514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:06.722659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:07.722845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:08.723407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:09.723501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:10.723732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:11.723936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:12.724035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:13.724265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:14.725218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:15.725964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:16.726875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:17.727101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:18.727292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:19.728001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:20.728188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:21.728369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:22.728556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:23.729396      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:24.729924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:06:25.710845 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:06:25.730761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:26.730977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:27.731193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:28.731304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:29.731518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:30.731750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:31.731936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:32.732090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:33.732282      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:34.732533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:35.733350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:36.734107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:37.734898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:38.735867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:39.735968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:40.736873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:41.737021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:42.737209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:43.737510      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:44.737539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:06:45.711971 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:06:45.738067      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:46.738334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:47.738538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:48.739406      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:49.739612      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:50.739746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:51.740002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:52.740204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:53.740306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:54.740427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:55.740660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:56.740894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:57.741081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:58.741966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:06:59.742086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:00.742870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:01.743900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:02.743990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:03.744251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:04.744875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:07:05.711096 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:07:05.745105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:06.745870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:07.746879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:08.747132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:09.747298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:10.747391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:11.748284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:12.748405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:13.748438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:14.748629      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:15.748847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:16.749032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:17.749343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:18.749391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:19.749618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:20.749807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:21.750877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:22.751124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:23.751351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:24.751534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:07:25.710428 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:07:25.752410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:26.752549      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:27.752871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:28.752977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:29.753884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:30.754865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:31.755869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:32.756058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:33.756351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:34.756559      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:35.756900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:36.757878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:37.758066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:38.758299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:39.758479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:40.758869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:41.759940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:42.760135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:43.760561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:44.760767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:07:45.712505 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:07:45.761470      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:46.761595      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:47.761808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:48.762886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:49.763119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:50.763205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:51.764194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:52.764883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:53.765870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:54.766128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:55.766884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:56.767128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:57.767381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:58.767570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:07:59.767811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:00.767862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:01.768042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:02.768248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:03.768382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:04.768573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:08:05.710790 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:08:05.768759      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:06.768812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:07.769016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:08.769276      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:09.769417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:10.769539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:11.769658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:12.769936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:13.770879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:14.771126      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:15.771880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:16.772920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:17.773020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:18.773781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:19.773823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:20.774873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:21.774969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:22.775871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:23.776130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:24.776232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:08:25.712315 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:08:25.776301      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:26.776497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:27.776940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:28.777951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:29.778199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:30.778411      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:31.778872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:32.779069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:33.779342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:34.779438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:35.779698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:36.779886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:37.780069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:38.780418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:39.780633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:40.780860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:41.781069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:42.781251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:43.781713      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:44.781724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:08:45.711106 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:08:45.782170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:46.782310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:47.782501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:48.782602      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:49.782838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:50.783004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:51.783101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:52.783196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:53.783291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:54.784052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:55.784132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:56.784874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:57.785869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:58.786874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:08:59.787069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:00.787869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:01.788109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:02.788314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:03.788425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:04.788644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:09:05.710853 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:09:05.788908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:06.789163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:07.789344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:08.789519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:09.789851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:10.790083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:11.790305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:12.790490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:13.791513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:14.791740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:15.791950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:16.792139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:17.792260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:18.793223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:19.793320      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:20.794388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:21.794483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:22.794875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:23.795872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:24.796872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:09:25.712251 19 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzM5ODIsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E1026 13:09:25.797408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:26.797576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:27.797784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:28.797815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:29.798088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:30.798369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:31.798623      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:32.798829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:33.798944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:34.799879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:35.800121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:36.800215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:37.800408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:38.801478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:39.801660      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:40.801869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:41.802097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:42.802329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:43.802496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:44.802582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:09:45.710853 19 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I1026 13:09:45.710889 19 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 10/26/24 13:09:45.71
  STEP: retrieving all remaining pages @ 10/26/24 13:09:45.715
  I1026 13:09:45.721061 19 chunking.go:221] Retrieved 40/40 results with rv 34688 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ2ODgsInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  I1026 13:09:45.726160 19 chunking.go:221] Retrieved 40/40 results with rv 34688 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ2ODgsInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  I1026 13:09:45.730163 19 chunking.go:221] Retrieved 40/40 results with rv 34688 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ2ODgsInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  I1026 13:09:45.735472 19 chunking.go:221] Retrieved 40/40 results with rv 34688 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ2ODgsInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  I1026 13:09:45.739739 19 chunking.go:221] Retrieved 40/40 results with rv 34688 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ2ODgsInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  I1026 13:09:45.743795 19 chunking.go:221] Retrieved 40/40 results with rv 34688 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ2ODgsInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  I1026 13:09:45.749521 19 chunking.go:221] Retrieved 40/40 results with rv 34688 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzQ2ODgsInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  I1026 13:09:45.753951 19 chunking.go:221] Retrieved 40/40 results with rv 34688 and continue 
  I1026 13:09:45.754154 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-1442" for this suite. @ 10/26/24 13:09:45.758
• [377.815 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 10/26/24 13:09:45.765
  I1026 13:09:45.765538 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 13:09:45.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:09:45.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:09:45.786
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:09:45.789
  E1026 13:09:45.803118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:46.803265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:47.804125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:48.804140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:49.804895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:09:49.817
  I1026 13:09:49.822990 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-7fd24a0f-74cd-497c-ba33-bd3507cf342c container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:09:49.838
  I1026 13:09:49.852753 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7489" for this suite. @ 10/26/24 13:09:49.858
• [4.099 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 10/26/24 13:09:49.864
  I1026 13:09:49.864465 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename podtemplate @ 10/26/24 13:09:49.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:09:49.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:09:49.885
  STEP: Create set of pod templates @ 10/26/24 13:09:49.888
  I1026 13:09:49.894180 19 podtemplates.go:143] created test-podtemplate-1
  I1026 13:09:49.899909 19 podtemplates.go:143] created test-podtemplate-2
  I1026 13:09:49.904426 19 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 10/26/24 13:09:49.904
  STEP: delete collection of pod templates @ 10/26/24 13:09:49.907
  I1026 13:09:49.907362 19 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 10/26/24 13:09:49.925
  I1026 13:09:49.925843 19 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I1026 13:09:49.929606 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-414" for this suite. @ 10/26/24 13:09:49.933
• [0.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:626
  STEP: Creating a kubernetes client @ 10/26/24 13:09:49.939
  I1026 13:09:49.939650 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-preemption @ 10/26/24 13:09:49.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:09:49.958
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:09:49.961
  I1026 13:09:49.981515 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1026 13:09:50.804993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:51.805079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:52.805272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:53.805344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:54.805587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:55.805704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:56.805910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:57.805977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:58.806873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:09:59.807010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:00.807134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:01.807352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:02.808369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:03.808583      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:04.808838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:05.808937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:06.809042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:07.809882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:08.810113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:09.810198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:10.810414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:11.810516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:12.810910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:13.811016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:14.811152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:15.811374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:16.812157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:17.812880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:18.813537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:19.813635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:20.813803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:21.814874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:22.814966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:23.815865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:24.816863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:25.817937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:26.818140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:27.818321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:28.819233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:29.819421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:30.820153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:31.820257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:32.821300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:33.821385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:34.822438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:35.822539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:36.823611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:37.823814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:38.824876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:39.825875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:40.826950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:41.827107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:42.827337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:43.827726      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:44.827823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:45.828015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:46.828039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:47.828155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:48.829139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:49.829409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:10:49.987262 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 10/26/24 13:10:49.992
  I1026 13:10:49.992442 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-preemption-path @ 10/26/24 13:10:49.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:10:50.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:10:50.016
  STEP: Finding an available node @ 10/26/24 13:10:50.019
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 10/26/24 13:10:50.019
  E1026 13:10:50.830138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:51.830346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 10/26/24 13:10:52.045
  I1026 13:10:52.059810 19 preemption.go:585] found a healthy node: ip-172-31-30-144
  E1026 13:10:52.830576      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:53.830824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:54.831888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:55.832201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:56.832299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:57.832944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:10:58.130345 19 preemption.go:708] pods created so far: [1 1 1]
  I1026 13:10:58.130373 19 preemption.go:709] length of pods created so far: 3
  E1026 13:10:58.833743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:10:59.834801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:00.142999 19 preemption.go:726] pods created so far: [2 2 1]
  E1026 13:11:00.834915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:01.835008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:02.835089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:03.835899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:04.835987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:05.836177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:06.836415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:07.218971 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-6601" for this suite. @ 10/26/24 13:11:07.222
  I1026 13:11:07.231845 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-9272" for this suite. @ 10/26/24 13:11:07.236
• [77.305 seconds]
------------------------------
SS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:668
  STEP: Creating a kubernetes client @ 10/26/24 13:11:07.244
  I1026 13:11:07.244641 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pv @ 10/26/24 13:11:07.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:07.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:07.267
  STEP: Creating initial PV and PVC @ 10/26/24 13:11:07.27
  I1026 13:11:07.270137 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-7777" @ 10/26/24 13:11:07.283
  STEP: Listing PVCs in namespace "pv-7777" @ 10/26/24 13:11:07.286
  STEP: Reading "pvc-qltft" Status @ 10/26/24 13:11:07.291
  STEP: Reading "pv-7777-fslrs" Status @ 10/26/24 13:11:07.294
  STEP: Patching "pvc-qltft" Status @ 10/26/24 13:11:07.3
  STEP: Patching "pv-7777-fslrs" Status @ 10/26/24 13:11:07.307
  STEP: Updating "pvc-qltft" Status @ 10/26/24 13:11:07.33
  STEP: Updating "pv-7777-fslrs" Status @ 10/26/24 13:11:07.36
  I1026 13:11:07.370190 19 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I1026 13:11:07.370237 19 pv.go:205] Deleting PersistentVolumeClaim "pvc-qltft"
  I1026 13:11:07.378265 19 pv.go:193] Deleting PersistentVolume "pv-7777-fslrs"
  I1026 13:11:07.386917 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-7777" for this suite. @ 10/26/24 13:11:07.39
• [0.155 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 10/26/24 13:11:07.4
  I1026 13:11:07.400058 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename csiinlinevolumes @ 10/26/24 13:11:07.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:07.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:07.422
  STEP: creating @ 10/26/24 13:11:07.425
  STEP: getting @ 10/26/24 13:11:07.444
  STEP: listing in namespace @ 10/26/24 13:11:07.449
  STEP: patching @ 10/26/24 13:11:07.453
  STEP: deleting @ 10/26/24 13:11:07.46
  I1026 13:11:07.473750 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-7152" for this suite. @ 10/26/24 13:11:07.479
• [0.087 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
  STEP: Creating a kubernetes client @ 10/26/24 13:11:07.487
  I1026 13:11:07.487390 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 13:11:07.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:07.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:07.506
  STEP: creating Agnhost RC @ 10/26/24 13:11:07.51
  I1026 13:11:07.510193 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3600 create -f -'
  I1026 13:11:07.590601 19 builder.go:146] stderr: ""
  I1026 13:11:07.590720 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 10/26/24 13:11:07.59
  E1026 13:11:07.836905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:08.597844 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 13:11:08.597873 19 framework.go:733] Found 0 / 1
  E1026 13:11:08.837092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:09.595989 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 13:11:09.596025 19 framework.go:733] Found 1 / 1
  I1026 13:11:09.596039 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 10/26/24 13:11:09.596
  I1026 13:11:09.601744 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 13:11:09.601768 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I1026 13:11:09.601808 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-3600 patch pod agnhost-primary-fjw8p -p {"metadata":{"annotations":{"x":"y"}}}'
  I1026 13:11:09.653266 19 builder.go:146] stderr: ""
  I1026 13:11:09.653296 19 builder.go:147] stdout: "pod/agnhost-primary-fjw8p patched\n"
  STEP: checking annotations @ 10/26/24 13:11:09.653
  I1026 13:11:09.658239 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 13:11:09.658257 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I1026 13:11:09.658352 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3600" for this suite. @ 10/26/24 13:11:09.663
• [2.185 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 10/26/24 13:11:09.672
  I1026 13:11:09.672775 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:11:09.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:09.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:09.692
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:11:09.695
  E1026 13:11:09.837608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:10.837774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:11:11.711
  I1026 13:11:11.716559 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod downwardapi-volume-efc9b08b-7454-4238-89e1-a01e961bea90 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:11:11.733
  I1026 13:11:11.749417 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-452" for this suite. @ 10/26/24 13:11:11.752
• [2.089 seconds]
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 10/26/24 13:11:11.762
  I1026 13:11:11.762062 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename runtimeclass @ 10/26/24 13:11:11.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:11.781
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:11.784
  E1026 13:11:11.838509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:12.838737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:13.816396 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5733" for this suite. @ 10/26/24 13:11:13.821
• [2.068 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 10/26/24 13:11:13.83
  I1026 13:11:13.830205 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename aggregator @ 10/26/24 13:11:13.83
  E1026 13:11:13.838670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:13.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:13.851
  I1026 13:11:13.854080 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Registering the sample API server. @ 10/26/24 13:11:13.854
  I1026 13:11:14.095863 19 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I1026 13:11:14.127336 19 deployment.go:222] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E1026 13:11:14.838949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:15.839180      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:16.181172 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:16.839888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:17.840026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:18.187884 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:18.840758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:19.840970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:20.185665 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:20.841085      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:21.841270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:22.188660 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:22.841932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:23.842992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:24.185413 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:24.843974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:25.844868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:26.185697 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:26.845917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:27.845996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:28.188010 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:28.846902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:29.847143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:30.186489 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:30.847218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:31.847314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:32.188762 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:32.847458      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:33.847536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:34.188653 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:34.848485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:35.848717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:36.187636 19 deployment.go:103] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-c4bc74fb5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1026 13:11:36.849303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:37.850000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:38.307694 19 aggregator.go:755] Waited 114.519968ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 10/26/24 13:11:38.347
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 10/26/24 13:11:38.35
  STEP: List APIServices @ 10/26/24 13:11:38.358
  I1026 13:11:38.364919 19 aggregator.go:556] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 10/26/24 13:11:38.364
  I1026 13:11:38.387454 19 aggregator.go:581] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 10/26/24 13:11:38.387
  I1026 13:11:38.400799 19 aggregator.go:607] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.October, 26, 13, 11, 38, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 10/26/24 13:11:38.4
  I1026 13:11:38.406309 19 aggregator.go:625] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-10-26 13:11:38 +0000 UTC Passed all checks passed}
  I1026 13:11:38.406337 19 aggregator.go:621] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1026 13:11:38.406349 19 aggregator.go:631] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 10/26/24 13:11:38.406
  I1026 13:11:38.419830 19 aggregator.go:647] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-322541679" @ 10/26/24 13:11:38.419
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 10/26/24 13:11:38.436
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 10/26/24 13:11:38.445
  STEP: Patch APIService Status @ 10/26/24 13:11:38.45
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 10/26/24 13:11:38.459
  I1026 13:11:38.462667 19 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-10-26 13:11:38 +0000 UTC Passed all checks passed}
  I1026 13:11:38.462713 19 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1026 13:11:38.462727 19 aggregator.go:721] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I1026 13:11:38.462737 19 aggregator.go:731] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 10/26/24 13:11:38.462
  STEP: Confirm that the generated APIService has been deleted @ 10/26/24 13:11:38.473
  I1026 13:11:38.473481 19 aggregator.go:792] Requesting list of APIServices to confirm quantity
  I1026 13:11:38.479022 19 aggregator.go:802] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I1026 13:11:38.479040 19 aggregator.go:744] APIService v1alpha1.wardle.example.com has been deleted.
  I1026 13:11:38.590958 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-126" for this suite. @ 10/26/24 13:11:38.594
• [24.772 seconds]
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 10/26/24 13:11:38.602
  I1026 13:11:38.602563 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 10/26/24 13:11:38.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:38.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:38.624
  STEP: creating a target pod @ 10/26/24 13:11:38.627
  E1026 13:11:38.850160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:39.850362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 10/26/24 13:11:40.653
  E1026 13:11:40.850833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:41.851031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 10/26/24 13:11:42.673
  I1026 13:11:42.673782 19 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2107 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 13:11:42.673799 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:11:42.674285 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 13:11:42.674324 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-2107/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  I1026 13:11:42.718611 19 exec_util.go:111] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 10/26/24 13:11:42.729
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 10/26/24 13:11:42.733
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 10/26/24 13:11:42.747
  I1026 13:11:42.751560 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-2107" for this suite. @ 10/26/24 13:11:42.755
• [4.160 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 10/26/24 13:11:42.762
  I1026 13:11:42.762900 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename controllerrevisions @ 10/26/24 13:11:42.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:42.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:42.787
  STEP: Creating DaemonSet "e2e-gfw9h-daemon-set" @ 10/26/24 13:11:42.812
  STEP: Check that daemon pods launch on every node of the cluster. @ 10/26/24 13:11:42.817
  I1026 13:11:42.821480 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:11:42.821506 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:11:42.825509 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-gfw9h-daemon-set: 0
  I1026 13:11:42.825540 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 13:11:42.851735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:43.821989 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:11:43.822070 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:11:43.825138 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-gfw9h-daemon-set: 1
  I1026 13:11:43.825165 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 13:11:43.852241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:44.824494 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:11:44.824552 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:11:44.828396 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-gfw9h-daemon-set: 3
  I1026 13:11:44.828415 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset e2e-gfw9h-daemon-set
  STEP: Confirm DaemonSet "e2e-gfw9h-daemon-set" successfully created with "daemonset-name=e2e-gfw9h-daemon-set" label @ 10/26/24 13:11:44.833
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-gfw9h-daemon-set" @ 10/26/24 13:11:44.84
  I1026 13:11:44.844368 19 controller_revision.go:162] Located ControllerRevision: "e2e-gfw9h-daemon-set-6d54cbcff7"
  STEP: Patching ControllerRevision "e2e-gfw9h-daemon-set-6d54cbcff7" @ 10/26/24 13:11:44.847
  E1026 13:11:44.852580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:44.854482 19 controller_revision.go:173] e2e-gfw9h-daemon-set-6d54cbcff7 has been patched
  STEP: Create a new ControllerRevision @ 10/26/24 13:11:44.854
  I1026 13:11:44.861256 19 controller_revision.go:191] Created ControllerRevision: e2e-gfw9h-daemon-set-869d4685cc
  STEP: Confirm that there are two ControllerRevisions @ 10/26/24 13:11:44.861
  I1026 13:11:44.861305 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I1026 13:11:44.864475 19 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-gfw9h-daemon-set-6d54cbcff7" @ 10/26/24 13:11:44.864
  STEP: Confirm that there is only one ControllerRevision @ 10/26/24 13:11:44.871
  I1026 13:11:44.871915 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I1026 13:11:44.874811 19 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-gfw9h-daemon-set-869d4685cc" @ 10/26/24 13:11:44.879
  I1026 13:11:44.887918 19 controller_revision.go:220] e2e-gfw9h-daemon-set-869d4685cc has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 10/26/24 13:11:44.887
  W1026 13:11:44.895430      19 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 10/26/24 13:11:44.895
  I1026 13:11:44.895536 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  E1026 13:11:45.852837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:45.895996 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I1026 13:11:45.901386 19 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-gfw9h-daemon-set-869d4685cc=updated" @ 10/26/24 13:11:45.901
  STEP: Confirm that there is only one ControllerRevision @ 10/26/24 13:11:45.912
  I1026 13:11:45.912283 19 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I1026 13:11:45.915497 19 controller_revision.go:265] Found 1 ControllerRevisions
  I1026 13:11:45.920378 19 controller_revision.go:246] ControllerRevision "e2e-gfw9h-daemon-set-8c5564556" has revision 3
  STEP: Deleting DaemonSet "e2e-gfw9h-daemon-set" @ 10/26/24 13:11:45.924
  STEP: deleting DaemonSet.extensions e2e-gfw9h-daemon-set in namespace controllerrevisions-4962, will wait for the garbage collector to delete the pods @ 10/26/24 13:11:45.924
  I1026 13:11:45.987792 19 resources.go:139] Deleting DaemonSet.extensions e2e-gfw9h-daemon-set took: 10.530606ms
  I1026 13:11:46.087942 19 resources.go:163] Terminating DaemonSet.extensions e2e-gfw9h-daemon-set pods took: 100.136916ms
  E1026 13:11:46.853751      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:11:47.494945 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset e2e-gfw9h-daemon-set: 0
  I1026 13:11:47.494980 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-gfw9h-daemon-set
  I1026 13:11:47.497968 19 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35976"},"items":null}

  I1026 13:11:47.501229 19 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35976"},"items":null}

  I1026 13:11:47.515979 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-4962" for this suite. @ 10/26/24 13:11:47.519
• [4.765 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:329
  STEP: Creating a kubernetes client @ 10/26/24 13:11:47.527
  I1026 13:11:47.527849 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-preemption @ 10/26/24 13:11:47.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:11:47.544
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:11:47.547
  I1026 13:11:47.566165 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1026 13:11:47.854102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:48.854191      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:49.854728      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:50.854810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:51.854945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:52.854999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:53.855088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:54.855173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:55.855923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:56.856933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:57.857447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:58.857471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:11:59.857735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:00.857958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:01.858249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:02.858545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:03.858761      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:04.858953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:05.859166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:06.859870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:07.860453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:08.860493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:09.860538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:10.860762      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:11.860809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:12.861378      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:13.862079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:14.862279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:15.862418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:16.863492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:17.864264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:18.864465      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:19.864881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:20.864987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:21.865266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:22.865365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:23.865603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:24.866039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:25.866147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:26.866983      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:27.867597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:28.868425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:29.869225      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:30.869326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:31.869891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:32.870041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:33.870166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:34.870344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:35.870736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:36.870953      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:37.871123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:38.872196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:39.872754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:40.873372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:41.874141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:42.874220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:43.874325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:44.874402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:45.874909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:46.874981      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:12:47.571466 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Select a node to run the lower and higher priority pods @ 10/26/24 13:12:47.576
  STEP: Create a low priority pod that consumes 1/1 of node resources @ 10/26/24 13:12:47.586
  I1026 13:12:47.599194 19 preemption.go:367] Created pod: victim-pod
  STEP: Wait for the victim pod to be scheduled @ 10/26/24 13:12:47.599
  E1026 13:12:47.875914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:48.876007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create a high priority pod to trigger preemption of the lower priority pod @ 10/26/24 13:12:49.609
  I1026 13:12:49.616813 19 preemption.go:385] Created pod: preemptor-pod
  STEP: Waiting for the victim pod to be terminating @ 10/26/24 13:12:49.616
  E1026 13:12:49.876081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:50.876519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying the pod has the pod disruption condition @ 10/26/24 13:12:51.625
  I1026 13:12:51.631488 19 pod_client.go:378] Removing pod's "victim-pod" finalizer: "example.com/test-finalizer"
  E1026 13:12:51.876830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:12:52.148000 19 pod_client.go:173] Successfully updated pod "victim-pod"
  I1026 13:12:52.188628 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6501" for this suite. @ 10/26/24 13:12:52.192
• [64.671 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 10/26/24 13:12:52.199
  I1026 13:12:52.199479 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename var-expansion @ 10/26/24 13:12:52.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:12:52.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:12:52.221
  STEP: creating the pod @ 10/26/24 13:12:52.226
  STEP: waiting for pod running @ 10/26/24 13:12:52.239
  E1026 13:12:52.876927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:53.877009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 10/26/24 13:12:54.248
  I1026 13:12:54.253636 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4560 PodName:var-expansion-e18bc799-06c9-42e9-82c2-72d84b847ae2 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 13:12:54.253661 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:12:54.254089 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 13:12:54.254139 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-4560/pods/var-expansion-e18bc799-06c9-42e9-82c2-72d84b847ae2/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 10/26/24 13:12:54.294
  I1026 13:12:54.299648 19 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4560 PodName:var-expansion-e18bc799-06c9-42e9-82c2-72d84b847ae2 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 13:12:54.299666 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:12:54.300031 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 13:12:54.300079 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-4560/pods/var-expansion-e18bc799-06c9-42e9-82c2-72d84b847ae2/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 10/26/24 13:12:54.332
  I1026 13:12:54.847081 19 pod_client.go:173] Successfully updated pod "var-expansion-e18bc799-06c9-42e9-82c2-72d84b847ae2"
  STEP: waiting for annotated pod running @ 10/26/24 13:12:54.847
  STEP: deleting the pod gracefully @ 10/26/24 13:12:54.851
  I1026 13:12:54.851624 19 delete.go:62] Deleting pod "var-expansion-e18bc799-06c9-42e9-82c2-72d84b847ae2" in namespace "var-expansion-4560"
  I1026 13:12:54.860285 19 delete.go:70] Wait up to 5m0s for pod "var-expansion-e18bc799-06c9-42e9-82c2-72d84b847ae2" to be fully deleted
  E1026 13:12:54.878008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:55.878217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:56.879104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:57.879283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:58.879236      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:12:59.879433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:00.879557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:01.879817      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:02.879843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:03.880563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:04.880863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:05.881026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:06.881262      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:07.881355      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:08.881470      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:09.881709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:10.881931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:11.882838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:12.882947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:13.883908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:14.884015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:15.884111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:16.884902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:17.884994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:18.885098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:19.885207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:20.885274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:21.885425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:22.885526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:23.886567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:24.886908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:25.887059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:26.887184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:13:26.957340 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4560" for this suite. @ 10/26/24 13:13:26.961
• [34.770 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 10/26/24 13:13:26.97
  I1026 13:13:26.970085 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 13:13:26.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:13:26.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:13:26.992
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:13:26.996
  E1026 13:13:27.887312      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:28.887538      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:29.887722      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:30.887830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:13:31.023
  I1026 13:13:31.026652 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-4ae86d64-17f2-4b2c-af9a-57eda2f650c7 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:13:31.039
  I1026 13:13:31.058284 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2746" for this suite. @ 10/26/24 13:13:31.062
• [4.101 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 10/26/24 13:13:31.07
  I1026 13:13:31.070825 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubelet-test @ 10/26/24 13:13:31.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:13:31.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:13:31.093
  STEP: Waiting for pod completion @ 10/26/24 13:13:31.107
  E1026 13:13:31.887929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:32.888062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:33.888898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:34.889102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:13:35.129854 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9790" for this suite. @ 10/26/24 13:13:35.135
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 10/26/24 13:13:35.144
  I1026 13:13:35.144023 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 13:13:35.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:13:35.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:13:35.168
  STEP: Creating configMap with name configmap-test-volume-69b21ee5-ea20-452a-9846-c66e39db1274 @ 10/26/24 13:13:35.171
  STEP: Creating a pod to test consume configMaps @ 10/26/24 13:13:35.176
  E1026 13:13:35.889348      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:36.889567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:37.890524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:38.890525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:13:39.2
  I1026 13:13:39.205204 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-configmaps-371765c9-6971-4aac-94e3-af10516289be container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 13:13:39.212
  I1026 13:13:39.228548 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4577" for this suite. @ 10/26/24 13:13:39.232
• [4.096 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 10/26/24 13:13:39.24
  I1026 13:13:39.240051 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sysctl @ 10/26/24 13:13:39.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:13:39.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:13:39.261
  STEP: Creating a pod with one valid and two invalid sysctls @ 10/26/24 13:13:39.264
  I1026 13:13:39.269530 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-3306" for this suite. @ 10/26/24 13:13:39.274
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 10/26/24 13:13:39.283
  I1026 13:13:39.283341 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 13:13:39.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:13:39.302
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:13:39.305
  I1026 13:13:39.355127 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-599" for this suite. @ 10/26/24 13:13:39.36
• [0.085 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2179
  STEP: Creating a kubernetes client @ 10/26/24 13:13:39.368
  I1026 13:13:39.368619 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:13:39.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:13:39.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:13:39.389
  STEP: creating service in namespace services-2395 @ 10/26/24 13:13:39.392
  STEP: creating service affinity-clusterip-transition in namespace services-2395 @ 10/26/24 13:13:39.392
  STEP: creating replication controller affinity-clusterip-transition in namespace services-2395 @ 10/26/24 13:13:39.404
  I1026 13:13:39.415909      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2395, replica count: 3
  E1026 13:13:39.891277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:40.891717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:41.891838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:13:42.467045      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 13:13:42.476254 19 resource.go:361] Creating new exec pod
  E1026 13:13:42.891993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:43.892101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:44.892453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:13:45.494866 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2395 exec execpod-affinityz2pz9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I1026 13:13:45.578717 19 builder.go:146] stderr: "+ + echo hostName\nnc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  I1026 13:13:45.578758 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:13:45.578827 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2395 exec execpod-affinityz2pz9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.100 80'
  I1026 13:13:45.660172 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.100 80\nConnection to 10.152.183.100 80 port [tcp/http] succeeded!\n"
  I1026 13:13:45.660212 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:13:45.671553 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2395 exec execpod-affinityz2pz9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.100:80/ ; done'
  I1026 13:13:45.820209 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n"
  I1026 13:13:45.820265 19 builder.go:147] stdout: "\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-dr5b5\naffinity-clusterip-transition-dr5b5\naffinity-clusterip-transition-k7b2c\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-k7b2c\naffinity-clusterip-transition-dr5b5\naffinity-clusterip-transition-k7b2c\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-dr5b5\naffinity-clusterip-transition-dr5b5\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-k7b2c"
  I1026 13:13:45.820288 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.820297 19 service.go:242] Received response from host: affinity-clusterip-transition-dr5b5
  I1026 13:13:45.820303 19 service.go:242] Received response from host: affinity-clusterip-transition-dr5b5
  I1026 13:13:45.820309 19 service.go:242] Received response from host: affinity-clusterip-transition-k7b2c
  I1026 13:13:45.820314 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.820320 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.820325 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.820331 19 service.go:242] Received response from host: affinity-clusterip-transition-k7b2c
  I1026 13:13:45.820337 19 service.go:242] Received response from host: affinity-clusterip-transition-dr5b5
  I1026 13:13:45.820343 19 service.go:242] Received response from host: affinity-clusterip-transition-k7b2c
  I1026 13:13:45.820349 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.820354 19 service.go:242] Received response from host: affinity-clusterip-transition-dr5b5
  I1026 13:13:45.820360 19 service.go:242] Received response from host: affinity-clusterip-transition-dr5b5
  I1026 13:13:45.820365 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.820370 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.820376 19 service.go:242] Received response from host: affinity-clusterip-transition-k7b2c
  I1026 13:13:45.833081 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2395 exec execpod-affinityz2pz9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.100:80/ ; done'
  E1026 13:13:45.892505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:13:45.972332 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.100:80/\n"
  I1026 13:13:45.972378 19 builder.go:147] stdout: "\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt\naffinity-clusterip-transition-ssqgt"
  I1026 13:13:45.972392 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972402 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972409 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972414 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972420 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972425 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972430 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972435 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972441 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972447 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972453 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972464 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972470 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972476 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972481 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972487 19 service.go:242] Received response from host: affinity-clusterip-transition-ssqgt
  I1026 13:13:45.972635 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2395, will wait for the garbage collector to delete the pods @ 10/26/24 13:13:45.986
  I1026 13:13:46.048877 19 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 8.37657ms
  I1026 13:13:46.149511 19 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 100.627608ms
  E1026 13:13:46.893524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:47.894096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:13:48.772464 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2395" for this suite. @ 10/26/24 13:13:48.777
• [9.416 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 10/26/24 13:13:48.785
  I1026 13:13:48.785266 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename containers @ 10/26/24 13:13:48.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:13:48.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:13:48.804
  STEP: Creating a pod to test override arguments @ 10/26/24 13:13:48.807
  E1026 13:13:48.895160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:49.895281      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:50.896249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:51.896371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:13:52.831
  I1026 13:13:52.835980 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod client-containers-d807e37f-9551-4b53-a099-88dc8cd5243a container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 13:13:52.843
  I1026 13:13:52.861345 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-43" for this suite. @ 10/26/24 13:13:52.868
• [4.091 seconds]
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2157
  STEP: Creating a kubernetes client @ 10/26/24 13:13:52.876
  I1026 13:13:52.876581 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:13:52.877
  E1026 13:13:52.896396      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:13:52.896
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:13:52.9
  STEP: creating service in namespace services-5289 @ 10/26/24 13:13:52.904
  STEP: creating service affinity-clusterip in namespace services-5289 @ 10/26/24 13:13:52.904
  STEP: creating replication controller affinity-clusterip in namespace services-5289 @ 10/26/24 13:13:52.915
  I1026 13:13:52.925039      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-5289, replica count: 3
  E1026 13:13:53.896575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:54.897345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:55.897556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:13:55.975751      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 13:13:55.984116 19 resource.go:361] Creating new exec pod
  E1026 13:13:56.897701      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:57.897955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:13:58.898069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:13:59.002348 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-5289 exec execpod-affinityw96vk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I1026 13:13:59.084033 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  I1026 13:13:59.084092 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:13:59.084185 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-5289 exec execpod-affinityw96vk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.169 80'
  I1026 13:13:59.174092 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.169 80\nConnection to 10.152.183.169 80 port [tcp/http] succeeded!\n"
  I1026 13:13:59.174156 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:13:59.174224 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-5289 exec execpod-affinityw96vk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.169:80/ ; done'
  I1026 13:13:59.352368 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.169:80/\n"
  I1026 13:13:59.352431 19 builder.go:147] stdout: "\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz\naffinity-clusterip-pllvz"
  I1026 13:13:59.352443 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352505 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352511 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352517 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352574 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352582 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352589 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352599 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352608 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352615 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352624 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352631 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352645 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352652 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352659 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352668 19 service.go:242] Received response from host: affinity-clusterip-pllvz
  I1026 13:13:59.352805 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-5289, will wait for the garbage collector to delete the pods @ 10/26/24 13:13:59.366
  I1026 13:13:59.431783 19 resources.go:139] Deleting ReplicationController affinity-clusterip took: 9.118484ms
  I1026 13:13:59.532455 19 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 100.668872ms
  E1026 13:13:59.898390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:00.898992      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:01.899626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:14:02.756346 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5289" for this suite. @ 10/26/24 13:14:02.76
• [9.891 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:57
  STEP: Creating a kubernetes client @ 10/26/24 13:14:02.767
  I1026 13:14:02.767575 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename volumeattachment @ 10/26/24 13:14:02.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:14:02.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:14:02.789
  STEP: Create VolumeAttachment "va-e2e-w7s2d" on node "ip-172-31-34-127" @ 10/26/24 13:14:02.796
  STEP: Get VolumeAttachment "va-e2e-w7s2d" on node "ip-172-31-34-127" @ 10/26/24 13:14:02.801
  STEP: Patch VolumeAttachment "va-e2e-w7s2d" on node "ip-172-31-34-127" @ 10/26/24 13:14:02.805
  STEP: List VolumeAttachments with "va-e2e-w7s2d=patched" label @ 10/26/24 13:14:02.812
  STEP: Delete VolumeAttachment "va-e2e-w7s2d" on node "ip-172-31-34-127" @ 10/26/24 13:14:02.815
  STEP: Confirm deletion of VolumeAttachment "va-e2e-w7s2d" on node "ip-172-31-34-127" @ 10/26/24 13:14:02.823
  STEP: Create VolumeAttachment "va-e2e-cpd2l" on node "ip-172-31-30-144" @ 10/26/24 13:14:02.829
  STEP: Update the VolumeAttachment "va-e2e-cpd2l" on node "ip-172-31-30-144" with label "va-e2e=updated" @ 10/26/24 13:14:02.835
  STEP: Create VolumeAttachment "va-e2e-sbmnk" on node "ip-172-31-70-148" @ 10/26/24 13:14:02.848
  STEP: Update the VolumeAttachment "va-e2e-sbmnk" on node "ip-172-31-70-148" with label "va-e2e=updated" @ 10/26/24 13:14:02.854
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 10/26/24 13:14:02.863
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 10/26/24 13:14:02.879
  I1026 13:14:02.883138 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-9414" for this suite. @ 10/26/24 13:14:02.887
• [0.128 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 10/26/24 13:14:02.895
  I1026 13:14:02.895607 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-pred @ 10/26/24 13:14:02.896
  E1026 13:14:02.900488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:14:02.917
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:14:02.921
  I1026 13:14:02.924396 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I1026 13:14:02.932907 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1026 13:14:02.936404 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-30-144 before test
  I1026 13:14:02.941180 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-7dwlf from ingress-nginx-kubernetes-worker started at 2024-10-26 12:55:59 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.941198 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:14:02.941204 19 predicates.go:957] calico-node-mh8sl from kube-system started at 2024-10-26 12:05:37 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.941209 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:14:02.941215 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-10-26 12:09:56 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.941220 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I1026 13:14:02.941225 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-cj9w2 from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:14:02.941230 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:14:02.941235 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1026 13:14:02.941240 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-35-104 before test
  I1026 13:14:02.948211 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-j79fd from ingress-nginx-kubernetes-worker started at 2024-10-26 12:00:11 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.948229 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:14:02.948236 19 predicates.go:957] calico-node-7mt8z from kube-system started at 2024-10-26 12:06:48 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.948241 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:14:02.948308 19 predicates.go:957] sonobuoy-e2e-job-f2d0e8def796404a from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:14:02.948320 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I1026 13:14:02.948326 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:14:02.948333 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-x5lp5 from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:14:02.948338 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:14:02.948343 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1026 13:14:02.948349 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-8-187 before test
  I1026 13:14:02.953762 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-bkqfk from ingress-nginx-kubernetes-worker started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.953779 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:14:02.953785 19 predicates.go:957] calico-node-gctkm from kube-system started at 2024-10-26 12:07:09 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.953790 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:14:02.953796 19 predicates.go:957] coredns-5b4857d7c8-l5pcc from kube-system started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.953801 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I1026 13:14:02.953808 19 predicates.go:957] kube-state-metrics-5d7bdccd49-nxf5p from kube-system started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.953817 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 2
  I1026 13:14:02.953822 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-cbtf8 from kube-system started at 2024-10-26 11:50:52 +0000 UTC (2 container statuses recorded)
  I1026 13:14:02.953826 19 predicates.go:959] 	Container metrics-server ready: true, restart count 1
  I1026 13:14:02.953831 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I1026 13:14:02.953836 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-6lj85 from kubernetes-dashboard started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.953841 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I1026 13:14:02.953846 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-ntk95 from kubernetes-dashboard started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:02.953851 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 4
  I1026 13:14:02.953856 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-wv9nc from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:14:02.953860 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:14:02.953865 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 10/26/24 13:14:02.953
  E1026 13:14:03.901154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:04.901266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 10/26/24 13:14:04.975
  STEP: Trying to apply a random label on the found node. @ 10/26/24 13:14:04.992
  STEP: verifying the node has the label kubernetes.io/e2e-f3efe5c3-0459-4f56-a3e8-5dc7c02e3004 42 @ 10/26/24 13:14:05
  STEP: Trying to relaunch the pod, now with labels. @ 10/26/24 13:14:05.003
  E1026 13:14:05.901360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:06.901498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-f3efe5c3-0459-4f56-a3e8-5dc7c02e3004 off the node ip-172-31-30-144 @ 10/26/24 13:14:07.027
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-f3efe5c3-0459-4f56-a3e8-5dc7c02e3004 @ 10/26/24 13:14:07.041
  I1026 13:14:07.044477 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2371" for this suite. @ 10/26/24 13:14:07.051
• [4.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
  STEP: Creating a kubernetes client @ 10/26/24 13:14:07.06
  I1026 13:14:07.060055 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 13:14:07.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:14:07.079
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:14:07.082
  STEP: creating the pod @ 10/26/24 13:14:07.085
  I1026 13:14:07.086032 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4876 create -f -'
  I1026 13:14:07.172343 19 builder.go:146] stderr: ""
  I1026 13:14:07.172376 19 builder.go:147] stdout: "pod/pause created\n"
  E1026 13:14:07.901847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:08.901985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 10/26/24 13:14:09.182
  I1026 13:14:09.182768 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4876 label pods pause testing-label=testing-label-value'
  I1026 13:14:09.257450 19 builder.go:146] stderr: ""
  I1026 13:14:09.257525 19 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 10/26/24 13:14:09.257
  I1026 13:14:09.257617 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4876 get pod pause -L testing-label'
  I1026 13:14:09.325714 19 builder.go:146] stderr: ""
  I1026 13:14:09.325782 19 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 10/26/24 13:14:09.325
  I1026 13:14:09.326222 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4876 label pods pause testing-label-'
  I1026 13:14:09.401831 19 builder.go:146] stderr: ""
  I1026 13:14:09.402284 19 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 10/26/24 13:14:09.402
  I1026 13:14:09.402651 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4876 get pod pause -L testing-label'
  I1026 13:14:09.473466 19 builder.go:146] stderr: ""
  I1026 13:14:09.473721 19 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 10/26/24 13:14:09.473
  I1026 13:14:09.474120 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4876 delete --grace-period=0 --force -f -'
  I1026 13:14:09.554878 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 13:14:09.555039 19 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I1026 13:14:09.555084 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4876 get rc,svc -l name=pause --no-headers'
  I1026 13:14:09.632157 19 builder.go:146] stderr: "No resources found in kubectl-4876 namespace.\n"
  I1026 13:14:09.632267 19 builder.go:147] stdout: ""
  I1026 13:14:09.632311 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-4876 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I1026 13:14:09.693381 19 builder.go:146] stderr: ""
  I1026 13:14:09.693418 19 builder.go:147] stdout: ""
  I1026 13:14:09.693533 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4876" for this suite. @ 10/26/24 13:14:09.698
• [2.645 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 10/26/24 13:14:09.705
  I1026 13:14:09.705629 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-pred @ 10/26/24 13:14:09.706
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:14:09.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:14:09.728
  I1026 13:14:09.731795 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I1026 13:14:09.739972 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1026 13:14:09.743347 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-30-144 before test
  I1026 13:14:09.749783 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-7dwlf from ingress-nginx-kubernetes-worker started at 2024-10-26 12:55:59 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.749801 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:14:09.749809 19 predicates.go:957] calico-node-mh8sl from kube-system started at 2024-10-26 12:05:37 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.749815 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:14:09.749821 19 predicates.go:957] with-labels from sched-pred-2371 started at 2024-10-26 13:14:05 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.749827 19 predicates.go:959] 	Container with-labels ready: true, restart count 0
  I1026 13:14:09.749832 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-10-26 12:09:56 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.749839 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I1026 13:14:09.749845 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-cj9w2 from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:14:09.749850 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:14:09.749855 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1026 13:14:09.749866 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-35-104 before test
  I1026 13:14:09.755134 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-j79fd from ingress-nginx-kubernetes-worker started at 2024-10-26 12:00:11 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.755148 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:14:09.755154 19 predicates.go:957] calico-node-7mt8z from kube-system started at 2024-10-26 12:06:48 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.755175 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:14:09.755180 19 predicates.go:957] sonobuoy-e2e-job-f2d0e8def796404a from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:14:09.755185 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I1026 13:14:09.755190 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:14:09.755196 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-x5lp5 from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:14:09.755205 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:14:09.755209 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1026 13:14:09.755215 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-8-187 before test
  I1026 13:14:09.760310 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-bkqfk from ingress-nginx-kubernetes-worker started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.760327 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:14:09.760334 19 predicates.go:957] calico-node-gctkm from kube-system started at 2024-10-26 12:07:09 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.760339 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:14:09.760344 19 predicates.go:957] coredns-5b4857d7c8-l5pcc from kube-system started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.760349 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I1026 13:14:09.760356 19 predicates.go:957] kube-state-metrics-5d7bdccd49-nxf5p from kube-system started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.760364 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 2
  I1026 13:14:09.760370 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-cbtf8 from kube-system started at 2024-10-26 11:50:52 +0000 UTC (2 container statuses recorded)
  I1026 13:14:09.760374 19 predicates.go:959] 	Container metrics-server ready: true, restart count 1
  I1026 13:14:09.760379 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I1026 13:14:09.760384 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-6lj85 from kubernetes-dashboard started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.760389 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I1026 13:14:09.760394 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-ntk95 from kubernetes-dashboard started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:14:09.760398 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 4
  I1026 13:14:09.760403 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-wv9nc from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:14:09.760408 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:14:09.760413 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 10/26/24 13:14:09.76
  E1026 13:14:09.902785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:10.902856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 10/26/24 13:14:11.783
  STEP: Trying to apply a random label on the found node. @ 10/26/24 13:14:11.8
  STEP: verifying the node has the label kubernetes.io/e2e-869bebe6-ae8a-42d2-b937-3d5f6eaf1b6a 95 @ 10/26/24 13:14:11.808
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 10/26/24 13:14:11.817
  E1026 13:14:11.903635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:12.903768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.35.104 on the node which pod4 resides and expect not scheduled @ 10/26/24 13:14:13.835
  E1026 13:14:13.904479      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:14.904910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:15.905211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:16.905323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:17.905430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:18.905552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:19.906106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:20.906921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:21.907423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:22.907582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:23.908199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:24.908308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:25.908783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:26.909022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:27.909038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:28.909258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:29.910066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:30.910280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:31.910299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:32.910844      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:33.911552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:34.911860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:35.912725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:36.912850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:37.913755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:38.913838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:39.914089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:40.914224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:41.914324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:42.914826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:43.914934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:44.915025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:45.916009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:46.916136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:47.916363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:48.917224      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:49.917343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:50.917442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:51.917742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:52.917999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:53.917962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:54.918795      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:55.918979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:56.919132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:57.919253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:58.919307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:14:59.919507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:00.920115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:01.920341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:02.920481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:03.920609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:04.920758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:05.921243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:06.921310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:07.921555      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:08.921709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:09.921928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:10.922752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:11.922832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:12.922930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:13.923035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:14.923138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:15.923331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:16.923798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:17.924874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:18.925874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:19.925984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:20.926794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:21.926982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:22.927102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:23.927358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:24.928215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:25.928347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:26.928438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:27.928625      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:28.928930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:29.929178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:30.929329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:31.929934      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:32.930054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:33.930885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:34.931042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:35.931217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:36.931887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:37.932009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:38.932080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:39.933044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:40.933170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:41.933264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:42.933798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:43.934880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:44.935888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:45.935994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:46.936837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:47.936968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:48.937077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:49.937288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:50.937804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:51.937928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:52.938737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:53.939125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:54.939315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:55.939535      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:56.939868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:57.940077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:58.940956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:15:59.941092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:00.942081      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:01.942246      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:02.942736      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:03.943161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:04.943798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:05.944875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:06.944965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:07.945870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:08.946046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:09.946174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:10.946775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:11.946841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:12.946925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:13.947161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:14.947287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:15.947892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:16.947985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:17.948866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:18.949082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:19.950098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:20.951159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:21.951283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:22.951354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:23.951437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:24.951879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:25.952870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:26.953870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:27.953968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:28.954094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:29.954897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:30.955920      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:31.956248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:32.956395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:33.956562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:34.956777      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:35.957027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:36.957197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:37.957455      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:38.957812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:39.958113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:40.958234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:41.958454      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:42.958764      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:43.959104      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:44.959215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:45.959419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:46.959529      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:47.959811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:48.960012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:49.960198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:50.960316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:51.960572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:52.961476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:53.961567      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:54.962346      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:55.963326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:56.963517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:57.964165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:58.964265      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:16:59.964356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:00.964873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:01.964973      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:02.965129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:03.965921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:04.966873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:05.967002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:06.967887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:07.968012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:08.968151      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:09.968344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:10.968548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:11.968754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:12.968855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:13.969123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:14.970035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:15.970156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:16.970274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:17.970475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:18.970898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:19.971015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:20.971129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:21.971325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:22.971416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:23.971575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:24.971741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:25.971997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:26.972788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:27.972976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:28.973369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:29.973475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:30.973809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:31.974877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:32.974974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:33.975870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:34.976707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:35.976841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:36.977878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:37.978070      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:38.978770      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:39.978810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:40.979005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:41.979869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:42.980845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:43.981073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:44.981418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:45.981596      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:46.981651      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:47.981940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:48.982424      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:49.982695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:50.982919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:51.983288      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:52.983900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:53.983993      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:54.984869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:55.985871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:56.986637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:57.986893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:58.987645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:17:59.987805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:00.987908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:01.988638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:02.989415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:03.989501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:04.990401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:05.990877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:06.991170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:07.991874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:08.992283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:09.992381      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:10.992871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:11.993102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:12.993885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:13.994874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:14.995875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:15.996072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:16.996184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:17.996369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:18.997254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:19.997437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:20.998228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:21.998388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:22.999317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:23.999416      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:24.999520      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:25.999709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:27.000373      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:28.000514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:29.001537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:30.001632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:31.001746      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:32.001812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:33.002632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:34.002802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:35.003913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:36.004012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:37.004109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:38.004871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:39.005866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:40.006050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:41.006198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:42.006423      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:43.007145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:44.007300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:45.007921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:46.008043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:47.008193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:48.008389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:49.008896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:50.009055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:51.009175      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:52.009367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:53.009499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:54.009900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:55.010871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:56.010969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:57.011079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:58.011266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:18:59.011362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:00.012310      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:01.012401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:02.012515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:03.013390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:04.013492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:05.013584      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:06.014284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:07.014440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:08.014805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:09.015866      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:10.015991      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:11.016092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:12.017122      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:13.017488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-869bebe6-ae8a-42d2-b937-3d5f6eaf1b6a off the node ip-172-31-35-104 @ 10/26/24 13:19:13.843
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-869bebe6-ae8a-42d2-b937-3d5f6eaf1b6a @ 10/26/24 13:19:13.857
  I1026 13:19:13.861005 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2463" for this suite. @ 10/26/24 13:19:13.868
• [304.172 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 10/26/24 13:19:13.879
  I1026 13:19:13.879140 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replication-controller @ 10/26/24 13:19:13.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:19:13.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:19:13.901
  STEP: Given a ReplicationController is created @ 10/26/24 13:19:13.909
  STEP: When the matched label of one of its pods change @ 10/26/24 13:19:13.915
  I1026 13:19:13.920140 19 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  E1026 13:19:14.017741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:15.017987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:16.018882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:17.018990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:18.019169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:18.926372 19 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 10/26/24 13:19:18.938
  E1026 13:19:19.019204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:19.950477 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1251" for this suite. @ 10/26/24 13:19:19.954
• [6.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 10/26/24 13:19:19.961
  I1026 13:19:19.961692 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 13:19:19.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:19:19.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:19:19.982
  STEP: Creating pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245 @ 10/26/24 13:19:19.985
  E1026 13:19:20.019471      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:21.019614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 10/26/24 13:19:22.004
  I1026 13:19:22.008060 19 container_probe.go:1749] Initial restart count of pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 is 0
  I1026 13:19:22.012756 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:22.019846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:23.020008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:24.018058 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:24.020129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:25.020294      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:26.020400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:26.022569 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:27.020639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:28.020856      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:28.028941 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:29.021096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:30.021308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:30.034400 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:31.021448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:32.021669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:32.041027 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:33.021804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:34.021921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:34.048097 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:35.022039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:36.022178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:36.054759 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:37.022937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:38.023107      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:38.060419 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:39.023513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:40.023611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:40.066119 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:41.023830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:42.023918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:42.072034 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:43.024903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:44.025001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:44.078899 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:45.025879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:46.026900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:46.083766 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:47.027024      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:48.027157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:48.090491 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:49.027428      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:50.027611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:50.095934 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:51.027864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:52.028032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:52.102503 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:53.028157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:54.028885      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:54.107732 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:55.028984      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:56.029118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:56.114669 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:57.029611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:19:58.029743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:19:58.121140 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:19:59.029839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:00.029945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:00.125935 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:01.030911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:02.031005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:02.132878 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:03.031853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:04.032074      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:04.138033 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:05.032120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:06.032200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:06.144832 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:07.032305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:08.032919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:08.150003 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:09.033037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:10.033155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:10.157048 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:11.033834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:12.034902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:12.162196 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:13.035015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:14.035870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:14.169356 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:15.036911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:16.037030      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:16.175106 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:17.038066      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:18.038193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:18.181051 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:19.038790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:20.039011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:20.186135 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:21.039060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:22.039299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:22.192879 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:23.039829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:24.039994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:24.197875 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:25.040092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:26.040305      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:26.204539 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:27.040418      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:28.040927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:28.209965 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:29.041058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:30.041165      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:30.216821 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:31.041274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:32.041393      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:32.223996 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:33.041468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:34.041662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:34.230039 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:35.041851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:36.041962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:36.235385 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:37.042065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:38.042928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:38.241449 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:39.043325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:40.043397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:40.247856 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:41.043533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:42.043900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:42.253135 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:43.044010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:44.044875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:44.259112 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:45.045909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:46.046137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:46.264637 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:47.046445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:48.046543      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:48.269786 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:49.046707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:50.047003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:50.275640 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:51.047123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:52.047267      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:52.281436 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:53.047522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:54.047490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:54.287040 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:55.047597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:56.047833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:56.291955 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:57.048900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:20:58.049003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:20:58.297718 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:20:59.049640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:00.049867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:00.304585 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:01.050487      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:02.050739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:02.309941 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:03.050791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:04.051098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:04.316896 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:05.051727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:06.051910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:06.322202 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:07.053023      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:08.053139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:08.329240 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:09.053968      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:10.054875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:10.335362 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:11.054979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:12.055972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:12.342038 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:13.056962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:14.057270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:14.347533 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:15.057328      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:16.057427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:16.354185 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:17.057541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:18.057815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:18.358920 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:19.058880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:20.059002      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:20.374003 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:21.059758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:22.059972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:22.378933 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:23.060086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:24.060162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:24.385503 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:25.060273      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:26.060407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:26.389872 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:27.060631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:28.060832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:28.396736 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:29.060954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:30.061141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:30.402770 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:31.061304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:32.061494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:32.409728 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:33.062481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:34.063128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:34.415317 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:35.064059      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:36.064903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:36.422622 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:37.065903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:38.066018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:38.427514 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:39.066184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:40.066336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:40.432930 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:41.066581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:42.066715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:42.438154 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:43.066849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:44.066931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:44.443482 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:45.067137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:46.067354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:46.448637 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:47.068345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:48.068497      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:48.455265 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:49.068792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:50.068980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:50.460995 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:51.069130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:52.069249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:52.468942 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:53.069419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:54.069527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:54.474624 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:55.070358      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:56.070537      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:56.480930 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:57.070724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:21:58.070859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:21:58.486601 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:21:59.070964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:00.071082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:00.493083 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:01.071279      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:02.071500      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:02.498449 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:03.071641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:04.071970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:04.503554 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:05.072167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:06.072274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:06.508397 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:07.073177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:08.073382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:08.515729 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:09.073940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:10.074899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:10.521068 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:11.075661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:12.075886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:12.527933 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:13.076594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:14.076916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:14.532669 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:15.077149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:16.077376      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:16.538656 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:17.077916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:18.078903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:18.544497 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:19.079103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:20.079272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:20.550392 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:21.080047      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:22.080258      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:22.555633 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:23.080360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:24.080462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:24.560143 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:25.080753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:26.080971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:26.567003 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:27.081766      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:28.081963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:28.572026 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:29.082630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:30.082768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:30.578632 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:31.083188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:32.083949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:32.583990 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:33.084593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:34.084730      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:34.590354 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:35.084826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:36.085926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:36.595829 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:37.086015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:38.086144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:38.602419 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:39.087063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:40.087169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:40.606803 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:41.087382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:42.087554      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:42.612622 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:43.088317      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:44.088402      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:44.617545 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:45.089109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:46.089293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:46.623652 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:47.090309      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:48.090409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:48.628945 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:49.090580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:50.090733      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:50.635424 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:51.090848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:52.091068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:52.641739 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:53.091428      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:54.091724      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:54.649070 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:55.092615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:56.092840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:56.654508 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:57.092907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:22:58.093876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:22:58.661399 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:22:59.094912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:00.095003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:00.666709 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:01.095099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:02.095882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:02.674197 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:03.096703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:04.096850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:04.679120 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:05.097772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:06.097893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:06.686166 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:07.098796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:08.098935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:08.691950 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:09.099536      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:10.099773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:10.699051 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:11.100547      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:12.100773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:12.704398 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:13.100848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:14.101159      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:14.710856 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:15.101252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:16.101488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:16.716066 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:17.101527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:18.101752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:18.721775 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:19.102263      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:20.103277      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:20.727634 19 container_probe.go:1759] Get pod test-webserver-f5a451da-85ff-4b16-86fc-00ab6e1feea9 in namespace container-probe-3245
  E1026 13:23:21.104042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:22.104871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 10/26/24 13:23:22.727
  I1026 13:23:22.744834 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3245" for this suite. @ 10/26/24 13:23:22.751
• [242.798 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 10/26/24 13:23:22.759
  I1026 13:23:22.759722 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 13:23:22.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:22.781
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:22.785
  STEP: Creating configMap configmap-1898/configmap-test-fdac4d8c-863b-4e2b-808f-86be05dbcf95 @ 10/26/24 13:23:22.796
  STEP: Creating a pod to test consume configMaps @ 10/26/24 13:23:22.804
  E1026 13:23:23.105849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:24.106207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:23:24.827
  I1026 13:23:24.832135 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-configmaps-76bfa80d-e318-44dd-a445-40bad0367362 container env-test: <nil>
  STEP: delete the pod @ 10/26/24 13:23:24.847
  I1026 13:23:24.864007 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1898" for this suite. @ 10/26/24 13:23:24.868
• [2.117 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:760
  STEP: Creating a kubernetes client @ 10/26/24 13:23:24.876
  I1026 13:23:24.876727 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:23:24.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:24.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:24.897
  STEP: creating service endpoint-test2 in namespace services-7977 @ 10/26/24 13:23:24.9
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7977 to expose endpoints map[] @ 10/26/24 13:23:24.913
  I1026 13:23:24.917211 19 service.go:4267] Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E1026 13:23:25.106586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:25.927404 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-7977 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-7977 @ 10/26/24 13:23:25.927
  E1026 13:23:26.107051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:27.107164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7977 to expose endpoints map[pod1:[80]] @ 10/26/24 13:23:27.949
  I1026 13:23:27.963122 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-7977 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 10/26/24 13:23:27.963
  I1026 13:23:27.963173 19 resource.go:361] Creating new exec pod
  E1026 13:23:28.108183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:29.108297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:30.108905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:30.976969 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7977 exec execpodgslsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I1026 13:23:31.066415 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I1026 13:23:31.066458 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:23:31.066520 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7977 exec execpodgslsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.139 80'
  E1026 13:23:31.109909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:31.148643 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.139 80\nConnection to 10.152.183.139 80 port [tcp/http] succeeded!\n"
  I1026 13:23:31.148704 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-7977 @ 10/26/24 13:23:31.148
  E1026 13:23:32.110796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:33.111016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7977 to expose endpoints map[pod1:[80] pod2:[80]] @ 10/26/24 13:23:33.167
  I1026 13:23:33.184541 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-7977 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 10/26/24 13:23:33.184
  E1026 13:23:34.111407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:34.184743 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7977 exec execpodgslsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I1026 13:23:34.270354 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I1026 13:23:34.270392 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:23:34.270461 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7977 exec execpodgslsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.139 80'
  I1026 13:23:34.350499 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.139 80\nConnection to 10.152.183.139 80 port [tcp/http] succeeded!\n"
  I1026 13:23:34.350589 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-7977 @ 10/26/24 13:23:34.35
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7977 to expose endpoints map[pod2:[80]] @ 10/26/24 13:23:34.412
  I1026 13:23:34.427733 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-7977 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 10/26/24 13:23:34.427
  E1026 13:23:35.111518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:35.428028 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7977 exec execpodgslsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I1026 13:23:35.510535 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  I1026 13:23:35.510596 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:23:35.510736 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-7977 exec execpodgslsf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.139 80'
  I1026 13:23:35.595910 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.139 80\nConnection to 10.152.183.139 80 port [tcp/http] succeeded!\n"
  I1026 13:23:35.595966 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-7977 @ 10/26/24 13:23:35.595
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7977 to expose endpoints map[] @ 10/26/24 13:23:35.611
  I1026 13:23:35.622350 19 service.go:4299] successfully validated that service endpoint-test2 in namespace services-7977 exposes endpoints map[]
  I1026 13:23:35.636188 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7977" for this suite. @ 10/26/24 13:23:35.64
• [10.773 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 10/26/24 13:23:35.649
  I1026 13:23:35.649739 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename subjectreview @ 10/26/24 13:23:35.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:35.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:35.67
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-6062" @ 10/26/24 13:23:35.673
  I1026 13:23:35.677853 19 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-6062:e2e"
  I1026 13:23:35.678080 19 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-6062"}
  I1026 13:23:35.678178 19 subjectreviews.go:71] saUID: "8a53cdfc-6461-46d6-903b-10c4c83e1a4c"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-6062:e2e" @ 10/26/24 13:23:35.678
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-6062:e2e" @ 10/26/24 13:23:35.678
  I1026 13:23:35.680524 19 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-6062:e2e" api 'list' configmaps in "subjectreview-6062" namespace @ 10/26/24 13:23:35.68
  I1026 13:23:35.682147 19 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-6062:e2e" @ 10/26/24 13:23:35.682
  I1026 13:23:35.684232 19 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I1026 13:23:35.684253 19 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I1026 13:23:35.684319 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-6062" for this suite. @ 10/26/24 13:23:35.688
• [0.045 seconds]
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 10/26/24 13:23:35.694
  I1026 13:23:35.694935 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubelet-test @ 10/26/24 13:23:35.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:35.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:35.714
  E1026 13:23:36.112478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:37.112725      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:38.112865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:39.113119      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:39.738804 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1467" for this suite. @ 10/26/24 13:23:39.742
• [4.053 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:429
  STEP: Creating a kubernetes client @ 10/26/24 13:23:39.748
  I1026 13:23:39.748347 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pv @ 10/26/24 13:23:39.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:39.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:39.772
  STEP: Creating initial PV and PVC @ 10/26/24 13:23:39.775
  I1026 13:23:39.775343 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-6541" @ 10/26/24 13:23:39.79
  STEP: Listing PVCs in namespace "pv-6541" @ 10/26/24 13:23:39.794
  STEP: Patching the PV "pv-6541-lkfpp" @ 10/26/24 13:23:39.799
  STEP: Patching the PVC "pvc-6jmzz" @ 10/26/24 13:23:39.809
  STEP: Getting PV "pv-6541-lkfpp" @ 10/26/24 13:23:39.819
  STEP: Getting PVC "pvc-6jmzz" @ 10/26/24 13:23:39.823
  STEP: Deleting PVC "pvc-6jmzz" @ 10/26/24 13:23:39.826
  STEP: Confirm deletion of PVC "pvc-6jmzz" @ 10/26/24 13:23:39.834
  E1026 13:23:40.113832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:41.113936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-6541-lkfpp" @ 10/26/24 13:23:41.843
  STEP: Confirm deletion of PV "pv-6541-lkfpp" @ 10/26/24 13:23:41.851
  E1026 13:23:42.114475      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:43.114573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 10/26/24 13:23:43.859
  I1026 13:23:43.860028 19 pv.go:394] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-6541-srxp8" @ 10/26/24 13:23:43.887
  STEP: Updating the PVC "pvc-fzcd7" @ 10/26/24 13:23:43.92
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-fzcd7=updated" @ 10/26/24 13:23:43.929
  STEP: Deleting PVC "pvc-fzcd7" via DeleteCollection @ 10/26/24 13:23:43.934
  STEP: Confirm deletion of PVC "pvc-fzcd7" @ 10/26/24 13:23:43.944
  E1026 13:23:44.115184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:45.115287      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-6541-srxp8" via DeleteCollection @ 10/26/24 13:23:45.953
  STEP: Confirm deletion of PV "pv-6541-srxp8" @ 10/26/24 13:23:45.964
  E1026 13:23:46.115664      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:47.115842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:47.974753 19 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I1026 13:23:47.974790 19 pv.go:205] Deleting PersistentVolumeClaim "pvc-fzcd7"
  I1026 13:23:47.979888 19 pv.go:193] Deleting PersistentVolume "pv-6541-srxp8"
  I1026 13:23:47.984049 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-6541" for this suite. @ 10/26/24 13:23:47.991
• [8.249 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 10/26/24 13:23:47.997
  I1026 13:23:47.997725 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 13:23:47.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:48.017
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:48.02
  STEP: Creating secret with name secret-test-map-d900324f-8999-4f9d-b43d-dee3c7206124 @ 10/26/24 13:23:48.023
  STEP: Creating a pod to test consume secrets @ 10/26/24 13:23:48.028
  E1026 13:23:48.115989      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:49.116185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:50.117098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:51.117234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:23:52.049
  I1026 13:23:52.052907 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-secrets-5ed1fe84-e8d5-4f45-8387-52fe5b7ae7be container secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 13:23:52.061
  I1026 13:23:52.079645 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6022" for this suite. @ 10/26/24 13:23:52.083
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 10/26/24 13:23:52.092
  I1026 13:23:52.092032 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename discovery @ 10/26/24 13:23:52.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:52.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:52.114
  E1026 13:23:52.117179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 10/26/24 13:23:52.118
  STEP: Requesting APIResourceList from "/api/v1" @ 10/26/24 13:23:52.353
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 10/26/24 13:23:52.355
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 10/26/24 13:23:52.356
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 10/26/24 13:23:52.358
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 10/26/24 13:23:52.359
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 10/26/24 13:23:52.36
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 10/26/24 13:23:52.362
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 10/26/24 13:23:52.364
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 10/26/24 13:23:52.367
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 10/26/24 13:23:52.368
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 10/26/24 13:23:52.37
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 10/26/24 13:23:52.372
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 10/26/24 13:23:52.373
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 10/26/24 13:23:52.375
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 10/26/24 13:23:52.376
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 10/26/24 13:23:52.377
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 10/26/24 13:23:52.378
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 10/26/24 13:23:52.38
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 10/26/24 13:23:52.381
  I1026 13:23:52.383060 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-3175" for this suite. @ 10/26/24 13:23:52.388
• [0.305 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 10/26/24 13:23:52.397
  I1026 13:23:52.397793 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replicaset @ 10/26/24 13:23:52.398
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:52.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:52.421
  STEP: Create a Replicaset @ 10/26/24 13:23:52.427
  STEP: Verify that the required pods have come up. @ 10/26/24 13:23:52.435
  I1026 13:23:52.439451 19 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E1026 13:23:53.118333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:54.118715      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:55.118923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:56.119134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:23:57.119352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:57.445219 19 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 10/26/24 13:23:57.445
  STEP: Getting /status @ 10/26/24 13:23:57.445
  I1026 13:23:57.450145 19 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 10/26/24 13:23:57.45
  I1026 13:23:57.460457 19 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 10/26/24 13:23:57.46
  I1026 13:23:57.462351 19 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I1026 13:23:57.462431 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I1026 13:23:57.462482 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I1026 13:23:57.462585 19 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I1026 13:23:57.462604 19 replica_set.go:682] Found replicaset test-rs in namespace replicaset-6387 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I1026 13:23:57.462614 19 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 10/26/24 13:23:57.462
  I1026 13:23:57.462637 19 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I1026 13:23:57.469066 19 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 10/26/24 13:23:57.469
  I1026 13:23:57.471304 19 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I1026 13:23:57.471403 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I1026 13:23:57.471533 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I1026 13:23:57.471599 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I1026 13:23:57.471615 19 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-6387 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1026 13:23:57.471737 19 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I1026 13:23:57.471769 19 replica_set.go:718] Found replicaset test-rs in namespace replicaset-6387 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I1026 13:23:57.471779 19 replica_set.go:729] Replicaset test-rs has a patched status
  I1026 13:23:57.471907 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6387" for this suite. @ 10/26/24 13:23:57.475
• [5.085 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 10/26/24 13:23:57.483
  I1026 13:23:57.483258 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename custom-resource-definition @ 10/26/24 13:23:57.483
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:57.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:57.501
  I1026 13:23:57.504434 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:23:58.119961      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:23:58.528867 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2710" for this suite. @ 10/26/24 13:23:58.533
• [1.058 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 10/26/24 13:23:58.541
  I1026 13:23:58.541808 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 13:23:58.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:23:58.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:23:58.563
  STEP: Creating pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160 @ 10/26/24 13:23:58.566
  E1026 13:23:59.120072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:00.120263      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 10/26/24 13:24:00.585
  I1026 13:24:00.589084 19 container_probe.go:1749] Initial restart count of pod busybox-b20f141b-e987-4422-963d-9e9598d79527 is 0
  I1026 13:24:00.594519 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:01.121200      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:02.121407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:02.598713 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:03.121954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:04.122028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:04.605239 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:05.122840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:06.122950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:06.610292 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:07.123902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:08.123988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:08.614805 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:09.124943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:10.125220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:10.621172 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:11.125700      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:12.125853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:12.626088 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:13.126666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:14.127313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:14.631941 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:15.127441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:16.128522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:16.636990 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:17.128717      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:18.128829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:18.642007 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:19.129220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:20.129501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:20.647358 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:21.129653      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:22.129791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:22.652203 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:23.130815      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:24.130944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:24.658356 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:25.131916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:26.132017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:26.663584 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:27.132141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:28.132270      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:28.670454 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:29.133075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:30.133113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:30.675265 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:31.133895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:32.134006      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:32.681788 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:33.134095      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:34.134152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:34.686778 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:35.134891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:36.135001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:36.694285 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:37.135813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:38.135898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:38.699162 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:39.136794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:40.136915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:40.704278 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:41.137898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:42.138012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:42.709087 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:43.138710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:44.139077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:44.714935 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:45.139194      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:46.139405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:46.719615 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:47.140133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:48.140266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:48.726066 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:49.140496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:50.140807      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:50.731068 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:51.141716      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:52.141939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:52.738192 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:53.142245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:54.142195      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:54.743572 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:55.143218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:56.143302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:56.748458 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:57.143949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:24:58.144045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:24:58.753289 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:24:59.144995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:00.145043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:00.758770 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:01.145140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:02.145891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:02.764486 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:03.145985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:04.146589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:04.770151 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:05.147657      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:06.147785      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:06.775408 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:07.148970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:08.149120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:08.781908 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:09.150087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:10.150372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:10.787952 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:11.150495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:12.150747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:12.794924 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:13.151337      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:14.151544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:14.800615 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:15.152133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:16.152245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:16.805180 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:17.152356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:18.152900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:18.810483 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:19.153928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:20.154017      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:20.815882 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:21.154830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:22.155881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:22.821526 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:23.156888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:24.157058      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:24.826963 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:25.157162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:26.157347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:26.832221 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:27.157541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:28.157835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:28.838996 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:29.158638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:30.158794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:30.843971 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:31.159356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:32.159476      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:32.850931 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:33.160433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:34.160799      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:34.855847 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:35.161247      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:36.161349      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:36.862013 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:37.161496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:38.161734      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:38.867390 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:39.162161      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:40.162882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:40.872241 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:41.163430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:42.164364      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:42.877568 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:43.164922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:44.165897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:44.882354 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:45.166767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:46.166996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:46.887692 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:47.167037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:48.167268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:48.893418 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:49.167950      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:50.168908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:50.898566 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:51.169124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:52.169218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:52.904595 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:53.170053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:54.170371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:54.909468 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:55.170899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:56.171086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:56.914429 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:57.171911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:25:58.172031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:25:58.919212 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:25:59.172833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:00.172947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:00.924862 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:01.173120      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:02.174046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:02.930703 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:03.174903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:04.175903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:04.935248 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:05.176597      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:06.176935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:06.942086 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:07.177419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:08.177551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:08.947695 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:09.178548      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:10.179138      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:10.952723 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:11.180054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:12.180174      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:12.957775 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:13.181065      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:14.181353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:14.963035 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:15.181400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:16.181626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:16.969209 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:17.182549      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:18.183468      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:18.974700 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:19.184125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:20.184118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:20.982081 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:21.184458      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:22.184533      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:22.987431 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:23.184636      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:24.184852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:24.995152 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:25.185429      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:26.185560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:27.000824 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:27.186148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:28.186909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:29.006465 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:29.187671      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:30.187842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:31.011609 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:31.188829      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:32.189040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:33.016271 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:33.189611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:34.189735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:35.021946 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:35.190192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:36.190394      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:37.028418 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:37.190594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:38.190837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:39.034015 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:39.191517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:40.191643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:41.040541 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:41.191755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:42.191903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:43.046478 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:43.192843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:44.193156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:45.053028 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:45.193252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:46.193351      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:47.058319 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:47.193566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:48.193632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:49.062983 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:49.194211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:50.194314      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:51.068264 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:51.194398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:52.194666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:53.075175 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:53.197818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:54.198178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:55.080398 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:55.198609      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:56.198861      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:57.086897 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:57.199158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:26:58.199371      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:26:59.092041 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:26:59.200179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:00.200298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:01.098772 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:01.200948      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:02.201054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:03.103825 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:03.202090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:04.202344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:05.111044 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:05.203230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:06.203321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:07.116195 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:07.204344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:08.204889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:09.121391 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:09.205714      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:10.205816      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:11.126694 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:11.206917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:12.207926      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:13.131600 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:13.208805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:14.208924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:15.136314 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:15.209512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:16.209633      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:17.142887 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:17.210103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:18.210303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:19.151066 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:19.211322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:20.211543      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:21.157559 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:21.211735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:22.212142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:23.163890 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:23.213073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:24.214054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:25.170273 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:25.214360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:26.214473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:27.175696 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:27.214769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:28.214879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:29.184095 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:29.215425      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:30.215620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:31.189800 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:31.215902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:32.216027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:33.195226 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:33.216341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:34.216451      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:35.201272 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:35.217372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:36.217503      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:37.206908 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:37.217996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:38.218330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:39.212463 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:39.218619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:40.219022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:41.218871 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:41.219867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:42.220050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:43.220283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:43.224056 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:44.221367      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:45.221498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:45.229947 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:46.221707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:47.221893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:47.234603 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:48.222645      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:49.222940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:49.240111 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:50.223147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:51.223239      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:51.245423 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:52.223469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:53.223570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:53.252252 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:54.223837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:55.223917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:55.257989 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:56.224011      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:57.224884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:57.262741 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:27:58.225003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:27:59.225523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:27:59.270049 19 container_probe.go:1759] Get pod busybox-b20f141b-e987-4422-963d-9e9598d79527 in namespace container-probe-160
  E1026 13:28:00.225831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:01.225940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 10/26/24 13:28:01.27
  I1026 13:28:01.288060 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-160" for this suite. @ 10/26/24 13:28:01.292
• [242.760 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:287
  STEP: Creating a kubernetes client @ 10/26/24 13:28:01.301
  I1026 13:28:01.301718 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename field-validation @ 10/26/24 13:28:01.302
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:01.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:01.369
  I1026 13:28:01.372484 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:28:02.226637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:03.226790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:04.227524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:28:04.467219 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-498" for this suite. @ 10/26/24 13:28:04.471
• [3.178 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 10/26/24 13:28:04.479
  I1026 13:28:04.479430 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename containers @ 10/26/24 13:28:04.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:04.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:04.498
  STEP: Creating a pod to test override all @ 10/26/24 13:28:04.501
  E1026 13:28:05.227640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:06.227944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:07.228019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:08.228231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:28:08.52
  I1026 13:28:08.524132 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod client-containers-71cac7a0-3de8-4ace-9a41-e9b9beacd09e container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 13:28:08.537
  I1026 13:28:08.553607 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-789" for this suite. @ 10/26/24 13:28:08.557
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 10/26/24 13:28:08.563
  I1026 13:28:08.563026 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename namespaces @ 10/26/24 13:28:08.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:08.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:08.586
  STEP: Creating namespace "e2e-ns-qj8sr" @ 10/26/24 13:28:08.589
  I1026 13:28:08.604629 19 namespace.go:411] Namespace "e2e-ns-qj8sr-9827" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-qj8sr-9827" @ 10/26/24 13:28:08.604
  I1026 13:28:08.614407 19 namespace.go:434] Namespace "e2e-ns-qj8sr-9827" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-qj8sr-9827" @ 10/26/24 13:28:08.614
  I1026 13:28:08.621377 19 namespace.go:463] Namespace "e2e-ns-qj8sr-9827" has []v1.FinalizerName{"kubernetes"}
  I1026 13:28:08.621453 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2284" for this suite. @ 10/26/24 13:28:08.624
  STEP: Destroying namespace "e2e-ns-qj8sr-9827" for this suite. @ 10/26/24 13:28:08.632
• [0.076 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 10/26/24 13:28:08.639
  I1026 13:28:08.639480 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename watch @ 10/26/24 13:28:08.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:08.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:08.658
  STEP: creating a watch on configmaps @ 10/26/24 13:28:08.662
  STEP: creating a new configmap @ 10/26/24 13:28:08.663
  STEP: modifying the configmap once @ 10/26/24 13:28:08.668
  STEP: closing the watch once it receives two notifications @ 10/26/24 13:28:08.675
  I1026 13:28:08.675848 19 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4755  af861a4c-898a-4aea-8f63-54fd2279242c 39164 0 2024-10-26 13:28:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-10-26 13:28:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:28:08.675954 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4755  af861a4c-898a-4aea-8f63-54fd2279242c 39165 0 2024-10-26 13:28:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-10-26 13:28:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 10/26/24 13:28:08.675
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 10/26/24 13:28:08.685
  STEP: deleting the configmap @ 10/26/24 13:28:08.687
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 10/26/24 13:28:08.693
  I1026 13:28:08.693634 19 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4755  af861a4c-898a-4aea-8f63-54fd2279242c 39166 0 2024-10-26 13:28:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-10-26 13:28:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:28:08.693753 19 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4755  af861a4c-898a-4aea-8f63-54fd2279242c 39167 0 2024-10-26 13:28:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-10-26 13:28:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I1026 13:28:08.693828 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4755" for this suite. @ 10/26/24 13:28:08.7
• [0.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 10/26/24 13:28:08.707
  I1026 13:28:08.707022 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sysctl @ 10/26/24 13:28:08.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:08.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:08.729
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 10/26/24 13:28:08.732
  STEP: Watching for error events or started pod @ 10/26/24 13:28:08.741
  E1026 13:28:09.229033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:10.229291      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 10/26/24 13:28:10.746
  E1026 13:28:11.229433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:12.229610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 10/26/24 13:28:12.76
  STEP: Getting logs from the pod @ 10/26/24 13:28:12.76
  STEP: Checking that the sysctl is actually updated @ 10/26/24 13:28:12.769
  I1026 13:28:12.769154 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-1543" for this suite. @ 10/26/24 13:28:12.774
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:940
  STEP: Creating a kubernetes client @ 10/26/24 13:28:12.782
  I1026 13:28:12.782234 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 13:28:12.782
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:12.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:12.807
  STEP: Creating a ResourceQuota @ 10/26/24 13:28:12.811
  STEP: Getting a ResourceQuota @ 10/26/24 13:28:12.815
  STEP: Updating a ResourceQuota @ 10/26/24 13:28:12.822
  STEP: Verifying a ResourceQuota was modified @ 10/26/24 13:28:12.827
  STEP: Deleting a ResourceQuota @ 10/26/24 13:28:12.831
  STEP: Verifying the deleted ResourceQuota @ 10/26/24 13:28:12.838
  I1026 13:28:12.841294 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6463" for this suite. @ 10/26/24 13:28:12.844
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:620
  STEP: Creating a kubernetes client @ 10/26/24 13:28:12.851
  I1026 13:28:12.851697 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename field-validation @ 10/26/24 13:28:12.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:12.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:12.872
  I1026 13:28:12.876059 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:28:13.230593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:14.231611      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:15.231841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  W1026 13:28:15.414962      19 warnings.go:70] unknown field "alpha"
  W1026 13:28:15.414982      19 warnings.go:70] unknown field "beta"
  W1026 13:28:15.414986      19 warnings.go:70] unknown field "delta"
  W1026 13:28:15.414989      19 warnings.go:70] unknown field "epsilon"
  W1026 13:28:15.414992      19 warnings.go:70] unknown field "gamma"
  I1026 13:28:15.965135 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3529" for this suite. @ 10/26/24 13:28:15.968
• [3.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1148
  STEP: Creating a kubernetes client @ 10/26/24 13:28:15.977
  I1026 13:28:15.977657 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename job @ 10/26/24 13:28:15.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:15.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:16.002
  STEP: Creating a suspended job @ 10/26/24 13:28:16.008
  STEP: Patching the Job @ 10/26/24 13:28:16.015
  STEP: Watching for Job to be patched @ 10/26/24 13:28:16.029
  I1026 13:28:16.030926 19 job.go:1330] Event ADDED observed for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-job-label:e2e-8fzxv] and annotations: map[]
  I1026 13:28:16.030948 19 job.go:1333] Event MODIFIED found for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv] and annotations: map[]
  STEP: Updating the job @ 10/26/24 13:28:16.03
  STEP: Watching for Job to be updated @ 10/26/24 13:28:16.041
  I1026 13:28:16.043060 19 job.go:1333] Event MODIFIED found for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv] and annotations: map[updated:true]
  I1026 13:28:16.043092 19 job.go:1226] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 10/26/24 13:28:16.043
  I1026 13:28:16.046450 19 job.go:1233] Job: e2e-8fzxv as labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv]
  STEP: Waiting for job to complete @ 10/26/24 13:28:16.046
  E1026 13:28:16.232825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:17.233082      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:18.233642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:19.233825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:20.234589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:21.234806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:22.235354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:23.235445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:24.236439      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:25.236540      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 10/26/24 13:28:26.058
  STEP: Watching for Job to be deleted @ 10/26/24 13:28:26.069
  I1026 13:28:26.070865 19 job.go:1330] Event MODIFIED observed for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv] and annotations: map[updated:true]
  I1026 13:28:26.070899 19 job.go:1330] Event MODIFIED observed for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv] and annotations: map[updated:true]
  I1026 13:28:26.070919 19 job.go:1330] Event MODIFIED observed for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv] and annotations: map[updated:true]
  I1026 13:28:26.071027 19 job.go:1330] Event MODIFIED observed for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv] and annotations: map[updated:true]
  I1026 13:28:26.071042 19 job.go:1330] Event MODIFIED observed for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv] and annotations: map[updated:true]
  I1026 13:28:26.071052 19 job.go:1333] Event DELETED found for Job e2e-8fzxv in namespace job-9787 with labels: map[e2e-8fzxv:patched e2e-job-label:e2e-8fzxv] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 10/26/24 13:28:26.071
  I1026 13:28:26.074880 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9787" for this suite. @ 10/26/24 13:28:26.08
• [10.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1833
  STEP: Creating a kubernetes client @ 10/26/24 13:28:26.098
  I1026 13:28:26.099005 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 13:28:26.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:26.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:26.123
  STEP: starting the proxy server @ 10/26/24 13:28:26.128
  I1026 13:28:26.128712 19 util.go:585] Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-6056 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 10/26/24 13:28:26.161
  I1026 13:28:26.166416 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  I1026 13:28:26.167624 19 kubectl.go:2224] kubectl proxy stdout: Starting to serve on 127.0.0.1:34271

  I1026 13:28:26.167640 19 kubectl.go:2229] kubectl proxy stderr: W1026 13:28:26.161600     621 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-6056" for this suite. @ 10/26/24 13:28:26.171
• [0.082 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:329
  STEP: Creating a kubernetes client @ 10/26/24 13:28:26.181
  I1026 13:28:26.181019 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:28:26.181
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:26.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:26.204
  STEP: Setting up server cert @ 10/26/24 13:28:26.232
  E1026 13:28:26.236550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:28:26.467
  STEP: Deploying the webhook pod @ 10/26/24 13:28:26.475
  STEP: Wait for the deployment to be ready @ 10/26/24 13:28:26.49
  I1026 13:28:26.500796 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:28:27.237603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:28.238333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:28:28.514
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:28:28.524
  E1026 13:28:29.238525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:28:29.524819 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I1026 13:28:29.533615 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1789-crds.webhook.example.com via the AdmissionRegistration API @ 10/26/24 13:28:30.047
  STEP: Creating a custom resource that should be mutated by the webhook @ 10/26/24 13:28:30.062
  E1026 13:28:30.238708      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:31.238988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:32.239199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:28:32.659625 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7824" for this suite. @ 10/26/24 13:28:32.664
  STEP: Destroying namespace "webhook-markers-9696" for this suite. @ 10/26/24 13:28:32.671
• [6.500 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 10/26/24 13:28:32.681
  I1026 13:28:32.681336 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 13:28:32.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:32.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:32.704
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:28:32.708
  E1026 13:28:33.239283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:34.239412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:35.240149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:36.240517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:28:36.733
  I1026 13:28:36.737589 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-b2cf6d1f-2c40-49e8-9334-3ba6ef71250b container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:28:36.755
  I1026 13:28:36.774097 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7824" for this suite. @ 10/26/24 13:28:36.778
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 10/26/24 13:28:36.787
  I1026 13:28:36.787104 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 13:28:36.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:36.805
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:36.808
  STEP: Creating secret with name secret-test-15dd8912-f2a4-40bb-a8f7-6483235ecb9f @ 10/26/24 13:28:36.811
  STEP: Creating a pod to test consume secrets @ 10/26/24 13:28:36.818
  E1026 13:28:37.240568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:38.240838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:39.241360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:40.241510      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:28:40.847
  I1026 13:28:40.851300 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-secrets-99b3bf1f-1f24-4a17-b4aa-358694167a8e container secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 13:28:40.857
  I1026 13:28:40.879154 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1025" for this suite. @ 10/26/24 13:28:40.884
• [4.105 seconds]
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:144
  STEP: Creating a kubernetes client @ 10/26/24 13:28:40.892
  I1026 13:28:40.892231 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename disruption @ 10/26/24 13:28:40.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:40.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:40.914
  STEP: Waiting for the pdb to be processed @ 10/26/24 13:28:40.922
  E1026 13:28:41.242513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:42.242709      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 10/26/24 13:28:42.951
  I1026 13:28:42.956711 19 disruption.go:691] running pods: 0 < 3
  E1026 13:28:43.242857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:44.243136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:28:44.961962 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6155" for this suite. @ 10/26/24 13:28:44.965
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 10/26/24 13:28:44.974
  I1026 13:28:44.974871 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename deployment @ 10/26/24 13:28:44.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:44.996
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:44.999
  STEP: creating a Deployment @ 10/26/24 13:28:45.006
  I1026 13:28:45.006025 19 deployment.go:507] Creating simple deployment test-deployment-8lhwv
  I1026 13:28:45.020539 19 deployment.go:222] deployment "test-deployment-8lhwv" doesn't have the required revision set
  E1026 13:28:45.243891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:46.244001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Getting /status @ 10/26/24 13:28:47.037
  I1026 13:28:47.041242 19 deployment.go:532] Deployment test-deployment-8lhwv has Conditions: [{Available True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8lhwv-f4dbbbf74" has successfully progressed.}]
  STEP: updating Deployment Status @ 10/26/24 13:28:47.041
  I1026 13:28:47.052473 19 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 28, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 28, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.October, 26, 13, 28, 46, 0, time.Local), LastTransitionTime:time.Date(2024, time.October, 26, 13, 28, 45, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-8lhwv-f4dbbbf74\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 10/26/24 13:28:47.052
  I1026 13:28:47.054492 19 deployment.go:579] Observed &Deployment event: ADDED
  I1026 13:28:47.054516 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-8lhwv-f4dbbbf74"}
  I1026 13:28:47.054584 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I1026 13:28:47.054601 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-8lhwv-f4dbbbf74"}
  I1026 13:28:47.054611 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I1026 13:28:47.054702 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I1026 13:28:47.054717 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I1026 13:28:47.054725 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-8lhwv-f4dbbbf74" is progressing.}
  I1026 13:28:47.054805 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I1026 13:28:47.054818 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I1026 13:28:47.054827 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8lhwv-f4dbbbf74" has successfully progressed.}
  I1026 13:28:47.054909 19 deployment.go:579] Observed &Deployment event: MODIFIED
  I1026 13:28:47.054925 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I1026 13:28:47.054938 19 deployment.go:575] Observed Deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8lhwv-f4dbbbf74" has successfully progressed.}
  I1026 13:28:47.054947 19 deployment.go:572] Found Deployment test-deployment-8lhwv in namespace deployment-4586 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1026 13:28:47.054988 19 deployment.go:583] Deployment test-deployment-8lhwv has an updated status
  STEP: patching the Statefulset Status @ 10/26/24 13:28:47.055
  I1026 13:28:47.055012 19 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I1026 13:28:47.062885 19 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 10/26/24 13:28:47.062
  I1026 13:28:47.064759 19 deployment.go:616] Observed &Deployment event: ADDED
  I1026 13:28:47.064779 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-8lhwv-f4dbbbf74"}
  I1026 13:28:47.064860 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1026 13:28:47.064889 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-8lhwv-f4dbbbf74"}
  I1026 13:28:47.064969 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I1026 13:28:47.065065 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1026 13:28:47.065081 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I1026 13:28:47.065094 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:45 +0000 UTC 2024-10-26 13:28:45 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-8lhwv-f4dbbbf74" is progressing.}
  I1026 13:28:47.065176 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1026 13:28:47.065192 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I1026 13:28:47.065202 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8lhwv-f4dbbbf74" has successfully progressed.}
  I1026 13:28:47.065271 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1026 13:28:47.065285 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I1026 13:28:47.065295 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-10-26 13:28:46 +0000 UTC 2024-10-26 13:28:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-8lhwv-f4dbbbf74" has successfully progressed.}
  I1026 13:28:47.065304 19 deployment.go:612] Observed deployment test-deployment-8lhwv in namespace deployment-4586 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I1026 13:28:47.065392 19 deployment.go:616] Observed &Deployment event: MODIFIED
  I1026 13:28:47.065408 19 deployment.go:609] Found deployment test-deployment-8lhwv in namespace deployment-4586 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I1026 13:28:47.065417 19 deployment.go:620] Deployment test-deployment-8lhwv has a patched status
  I1026 13:28:47.069596 19 deployment.go:633] Deployment "test-deployment-8lhwv":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-8lhwv",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4586",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7c1d2687-19ae-4c8e-82f1-929d729d9f59",
      ResourceVersion: (string) (len=5) "39717",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865546125,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546125,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546127,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546127,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546127,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546127,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=55) "Found new replica set \"test-deployment-8lhwv-f4dbbbf74\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I1026 13:28:47.075721 19 deployment.go:39] New ReplicaSet "test-deployment-8lhwv-f4dbbbf74" of Deployment "test-deployment-8lhwv":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-8lhwv-f4dbbbf74",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4586",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c5913383-8cce-42b0-88ff-9ae4abd272a1",
      ResourceVersion: (string) (len=5) "39709",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865546125,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-8lhwv",
          UID: (types.UID) (len=36) "7c1d2687-19ae-4c8e-82f1-929d729d9f59",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546125,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 37 63 31  |k:{\"uid\":\"7c1|
              00000120  64 32 36 38 37 2d 31 39  61 65 2d 34 63 38 65 2d  |d2687-19ae-4c8e-|
              00000130  38 32 66 31 2d 39 32 39  64 37 32 39 64 39 66 35  |82f1-929d729d9f5|
              00000140  39 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |9\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546126,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74",
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I1026 13:28:47.082589 19 deployment.go:67] Pod "test-deployment-8lhwv-f4dbbbf74-6t5jl" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "test-deployment-8lhwv-f4dbbbf74-6t5jl",
      GenerateName: (string) (len=32) "test-deployment-8lhwv-f4dbbbf74-",
      Namespace: (string) (len=15) "deployment-4586",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "11ca47c1-e54c-4aeb-89f2-f56c1cd1d82a",
      ResourceVersion: (string) (len=5) "39708",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865546125,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "f4dbbbf74"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "test-deployment-8lhwv-f4dbbbf74",
          UID: (types.UID) (len=36) "c5913383-8cce-42b0-88ff-9ae4abd272a1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546125,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 63 35 39 31 33 33 38  33 2d 38 63 63 65 2d 34  |"c5913383-8cce-4|
              000000a0  32 62 30 2d 38 38 66 66  2d 39 61 65 34 61 62 64  |2b0-88ff-9ae4abd|
              000000b0  32 37 32 61 31 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |272a1\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546126,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 36  2e 31 30 35 5c 22 7d 22  |2.168.46.105\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4577w",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4577w",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-35-104",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546126,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546125,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546126,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546126,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63865546125,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.35.104",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.35.104"
        }
      },
      PodIP: (string) (len=14) "192.168.46.105",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.46.105"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63865546125,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63865546125,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://cb16935ca2e31d5ad156691621d0e1dfaf7da894328930537eb94379391f16be",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-4577w",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I1026 13:28:47.083891 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4586" for this suite. @ 10/26/24 13:28:47.087
• [2.120 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 10/26/24 13:28:47.095
  I1026 13:28:47.095312 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:28:47.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:47.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:47.115
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:28:47.119
  E1026 13:28:47.244062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:48.244163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:49.245197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:50.245908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:28:51.148
  I1026 13:28:51.152014 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-35ead6ed-9955-45dd-8f24-fb42f6c5bc0e container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:28:51.163
  I1026 13:28:51.181551 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4108" for this suite. @ 10/26/24 13:28:51.185
• [4.097 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 10/26/24 13:28:51.192
  I1026 13:28:51.192241 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 13:28:51.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:51.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:51.216
  STEP: Creating the pod @ 10/26/24 13:28:51.219
  E1026 13:28:51.246448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:52.247521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:53.247916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:28:53.775781 19 pod_client.go:173] Successfully updated pod "annotationupdate1772c29f-5ad2-475c-bbc4-44e950d7a83f"
  E1026 13:28:54.248019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:55.248134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:28:55.794544 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6950" for this suite. @ 10/26/24 13:28:55.798
• [4.613 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:409
  STEP: Creating a kubernetes client @ 10/26/24 13:28:55.805
  I1026 13:28:55.805391 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename dns @ 10/26/24 13:28:55.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:55.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:55.83
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 10/26/24 13:28:55.833
  I1026 13:28:55.842851 19 dns.go:421] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6621  42a13841-1c4a-43da-b45e-dd882b31ee6e 39847 0 2024-10-26 13:28:55 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-10-26 13:28:55 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f8fbz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,Image:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.52,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f8fbz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,SupplementalGroupsPolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E1026 13:28:56.249401      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:28:57.249009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 10/26/24 13:28:57.85
  I1026 13:28:57.850794 19 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6621 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 13:28:57.850811 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:28:57.851291 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 13:28:57.851349 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-6621/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 10/26/24 13:28:57.897
  I1026 13:28:57.897519 19 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6621 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I1026 13:28:57.897552 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:28:57.897968 19 exec_util.go:66] ExecWithOptions: Clientset creation
  I1026 13:28:57.898020 19 exec_util.go:83] ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-6621/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  I1026 13:28:57.953371 19 dns.go:423] Deleting pod test-dns-nameservers...
  I1026 13:28:57.970869 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6621" for this suite. @ 10/26/24 13:28:57.975
• [2.177 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:235
  STEP: Creating a kubernetes client @ 10/26/24 13:28:57.982
  I1026 13:28:57.982801 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:28:57.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:28:58.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:28:58.006
  STEP: Setting up server cert @ 10/26/24 13:28:58.035
  E1026 13:28:58.249592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:28:58.433
  STEP: Deploying the webhook pod @ 10/26/24 13:28:58.445
  STEP: Wait for the deployment to be ready @ 10/26/24 13:28:58.461
  I1026 13:28:58.470713 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:28:59.250663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:00.250839      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:29:00.486
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:29:00.499
  E1026 13:29:01.250966      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:01.499258 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 10/26/24 13:29:01.508
  STEP: create a namespace for the webhook @ 10/26/24 13:29:01.521
  STEP: create a configmap should be unconditionally rejected by the webhook @ 10/26/24 13:29:01.539
  I1026 13:29:01.588114 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8784" for this suite. @ 10/26/24 13:29:01.591
  STEP: Destroying namespace "webhook-markers-3137" for this suite. @ 10/26/24 13:29:01.602
  STEP: Destroying namespace "fail-closed-namespace-3452" for this suite. @ 10/26/24 13:29:01.611
• [3.635 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1391
  STEP: Creating a kubernetes client @ 10/26/24 13:29:01.617
  I1026 13:29:01.618002 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 13:29:01.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:01.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:01.638
  I1026 13:29:01.641390 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9838 create -f -'
  I1026 13:29:01.724661 19 builder.go:146] stderr: ""
  I1026 13:29:01.724714 19 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I1026 13:29:01.724771 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9838 create -f -'
  I1026 13:29:01.812118 19 builder.go:146] stderr: ""
  I1026 13:29:01.812176 19 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 10/26/24 13:29:01.812
  E1026 13:29:02.251849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:02.817873 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 13:29:02.817906 19 framework.go:733] Found 0 / 1
  E1026 13:29:03.252369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:03.819555 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 13:29:03.819590 19 framework.go:733] Found 1 / 1
  I1026 13:29:03.819604 19 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I1026 13:29:03.823562 19 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I1026 13:29:03.823581 19 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I1026 13:29:03.823636 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9838 describe pod agnhost-primary-zq6n5'
  I1026 13:29:03.875693 19 builder.go:146] stderr: ""
  I1026 13:29:03.875822 19 builder.go:147] stdout: "Name:             agnhost-primary-zq6n5\nNamespace:        kubectl-9838\nPriority:         0\nService Account:  default\nNode:             ip-172-31-30-144/172.31.30.144\nStart Time:       Sat, 26 Oct 2024 13:29:01 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.29.167\nIPs:\n  IP:           192.168.29.167\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://0adda2a2ac2a1901289c574d446f62edc256c9e4ba1f226ecc8ade387369ec39\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.52\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:b173c7d0ffe3d805d49f4dfe48375169b7b8d2e1feb81783efd61eb9d08042e6\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 26 Oct 2024 13:29:02 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-2p7sm (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-2p7sm:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-9838/agnhost-primary-zq6n5 to ip-172-31-30-144\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.52\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  I1026 13:29:03.875895 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9838 describe rc agnhost-primary'
  I1026 13:29:03.929272 19 builder.go:146] stderr: ""
  I1026 13:29:03.929328 19 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9838\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.52\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-zq6n5\n"
  I1026 13:29:03.929372 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9838 describe service agnhost-primary'
  I1026 13:29:03.980601 19 builder.go:146] stderr: ""
  I1026 13:29:03.980642 19 builder.go:147] stdout: "Name:                     agnhost-primary\nNamespace:                kubectl-9838\nLabels:                   app=agnhost\n                          role=primary\nAnnotations:              <none>\nSelector:                 app=agnhost,role=primary\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.152.183.46\nIPs:                      10.152.183.46\nPort:                     <unset>  6379/TCP\nTargetPort:               agnhost-server/TCP\nEndpoints:                192.168.29.167:6379\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n"
  I1026 13:29:03.986446 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9838 describe node ip-172-31-30-144'
  I1026 13:29:04.051653 19 builder.go:146] stderr: ""
  I1026 13:29:04.051742 19 builder.go:147] stdout: "Name:               ip-172-31-30-144\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    juju.io/cloud=ec2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-30-144\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 26 Oct 2024 12:05:26 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-30-144\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 26 Oct 2024 13:28:55 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 26 Oct 2024 12:06:05 +0000   Sat, 26 Oct 2024 12:06:05 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 26 Oct 2024 13:26:55 +0000   Sat, 26 Oct 2024 12:05:26 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 26 Oct 2024 13:26:55 +0000   Sat, 26 Oct 2024 12:05:26 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 26 Oct 2024 13:26:55 +0000   Sat, 26 Oct 2024 12:05:26 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 26 Oct 2024 13:26:55 +0000   Sat, 26 Oct 2024 12:05:47 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.31.30.144\n  Hostname:    ip-172-31-30-144\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      16069568Ki\n  example.com/fakecpu:    1k\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7967640Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  1\nAllocatable:\n  cpu:                    2\n  ephemeral-storage:      14809713845\n  example.com/fakecpu:    1k\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7865240Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  1\nSystem Info:\n  Machine ID:                      ec2e8253303400c7cb77128185929d0c\n  System UUID:                     ec2e8253-3034-00c7-cb77-128185929d0c\n  Boot ID:                         b540b3dd-fa81-4087-b88e-235d52f8c449\n  Kernel Version:                  6.8.0-1017-aws\n  OS Image:                        Ubuntu 22.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.6.8\n  Kubelet Version:                 v1.31.2\n  Kube-Proxy Version:              v1.31.2\nNon-terminated Pods:               (5 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-7dwlf           0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                      calico-node-mh8sl                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         83m\n  kubectl-9838                     agnhost-primary-zq6n5                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                         sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         79m\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-cj9w2    0 (0%)        0 (0%)      0 (0%)           0 (0%)         79m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    250m (12%)  0 (0%)\n  memory                 0 (0%)      0 (0%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  example.com/fakecpu    0           0\n  scheduling.k8s.io/foo  0           0\nEvents:                  <none>\n"
  I1026 13:29:04.051793 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9838 describe namespace kubectl-9838'
  I1026 13:29:04.102392 19 builder.go:146] stderr: ""
  I1026 13:29:04.102428 19 builder.go:147] stdout: "Name:         kubectl-9838\nLabels:       e2e-framework=kubectl\n              e2e-run=4f86a21b-dd31-4e45-b53e-bf3ec6810827\n              kubernetes.io/metadata.name=kubectl-9838\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I1026 13:29:04.102549 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9838" for this suite. @ 10/26/24 13:29:04.106
• [2.495 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 10/26/24 13:29:04.113
  I1026 13:29:04.113162 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 13:29:04.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:04.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:04.14
  STEP: Creating secret with name secret-test-0faf8a74-f281-4161-81f6-ab77431e8272 @ 10/26/24 13:29:04.143
  STEP: Creating a pod to test consume secrets @ 10/26/24 13:29:04.15
  E1026 13:29:04.252546      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:05.252956      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:06.253415      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:07.253638      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:29:08.175
  I1026 13:29:08.180846 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-secrets-a8fb7939-27da-43a9-af57-8633f7fefc2c container secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 13:29:08.187
  I1026 13:29:08.202248 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4018" for this suite. @ 10/26/24 13:29:08.207
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 10/26/24 13:29:08.213
  I1026 13:29:08.213142 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 10/26/24 13:29:08.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:08.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:08.236
  STEP: create the container to handle the HTTPGet hook request. @ 10/26/24 13:29:08.243
  E1026 13:29:08.253605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:09.253911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:10.253947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 10/26/24 13:29:10.27
  E1026 13:29:11.254041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:12.254135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 10/26/24 13:29:12.29
  E1026 13:29:13.254841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:14.255900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 10/26/24 13:29:14.308
  I1026 13:29:14.315326 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-3168" for this suite. @ 10/26/24 13:29:14.321
• [6.117 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 10/26/24 13:29:14.33
  I1026 13:29:14.330098 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 13:29:14.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:14.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:14.354
  STEP: Creating configMap with name configmap-test-upd-fdf5f8a3-d48c-4ef4-9d08-62cd6b499bb9 @ 10/26/24 13:29:14.361
  STEP: Creating the pod @ 10/26/24 13:29:14.367
  E1026 13:29:15.255996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:16.256142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 10/26/24 13:29:16.387
  STEP: Waiting for pod with binary data @ 10/26/24 13:29:16.408
  I1026 13:29:16.417013 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8219" for this suite. @ 10/26/24 13:29:16.421
• [2.097 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3393
  STEP: Creating a kubernetes client @ 10/26/24 13:29:16.427
  I1026 13:29:16.427797 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:29:16.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:16.448
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:16.451
  STEP: creating a Service @ 10/26/24 13:29:16.458
  STEP: watching for the Service to be added @ 10/26/24 13:29:16.474
  I1026 13:29:16.476712 19 service.go:3445] Found Service test-service-c6wp4 in namespace services-7160 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 30379}]
  I1026 13:29:16.476739 19 service.go:3452] Service test-service-c6wp4 created
  STEP: Getting /status @ 10/26/24 13:29:16.476
  I1026 13:29:16.482649 19 service.go:3463] Service test-service-c6wp4 has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 10/26/24 13:29:16.482
  STEP: watching for the Service to be patched @ 10/26/24 13:29:16.488
  I1026 13:29:16.490483 19 service.go:3486] observed Service test-service-c6wp4 in namespace services-7160 with annotations: map[] & LoadBalancer: {[]}
  I1026 13:29:16.490520 19 service.go:3489] Found Service test-service-c6wp4 in namespace services-7160 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc0048163b0 []}]}
  I1026 13:29:16.490529 19 service.go:3496] Service test-service-c6wp4 has service status patched
  STEP: updating the ServiceStatus @ 10/26/24 13:29:16.49
  I1026 13:29:16.502483 19 service.go:3516] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 10/26/24 13:29:16.502
  I1026 13:29:16.504421 19 service.go:3527] Observed Service test-service-c6wp4 in namespace services-7160 with annotations: map[] & Conditions: []
  I1026 13:29:16.504446 19 service.go:3538] Observed Service test-service-c6wp4 in namespace services-7160 with annotations: map[patchedstatus:true] & Conditions: []
  I1026 13:29:16.504468 19 service.go:3534] Found Service test-service-c6wp4 in namespace services-7160 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I1026 13:29:16.504487 19 service.go:3545] Service test-service-c6wp4 has service status updated
  STEP: patching the service @ 10/26/24 13:29:16.504
  STEP: watching for the Service to be patched @ 10/26/24 13:29:16.517
  I1026 13:29:16.518932 19 service.go:3568] observed Service test-service-c6wp4 in namespace services-7160 with labels: map[test-service-static:true]
  I1026 13:29:16.518955 19 service.go:3568] observed Service test-service-c6wp4 in namespace services-7160 with labels: map[test-service-static:true]
  I1026 13:29:16.519044 19 service.go:3568] observed Service test-service-c6wp4 in namespace services-7160 with labels: map[test-service-static:true]
  I1026 13:29:16.519116 19 service.go:3571] Found Service test-service-c6wp4 in namespace services-7160 with labels: map[test-service:patched test-service-static:true]
  I1026 13:29:16.519126 19 service.go:3578] Service test-service-c6wp4 patched
  STEP: deleting the service @ 10/26/24 13:29:16.519
  STEP: watching for the Service to be deleted @ 10/26/24 13:29:16.537
  I1026 13:29:16.539480 19 service.go:3602] Observed event: ADDED
  I1026 13:29:16.539499 19 service.go:3602] Observed event: MODIFIED
  I1026 13:29:16.539507 19 service.go:3602] Observed event: MODIFIED
  I1026 13:29:16.539564 19 service.go:3602] Observed event: MODIFIED
  I1026 13:29:16.539589 19 service.go:3598] Found Service test-service-c6wp4 in namespace services-7160 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I1026 13:29:16.539597 19 service.go:3607] Service test-service-c6wp4 deleted
  I1026 13:29:16.539704 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7160" for this suite. @ 10/26/24 13:29:16.543
• [0.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 10/26/24 13:29:16.55
  I1026 13:29:16.550349 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename events @ 10/26/24 13:29:16.55
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:16.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:16.571
  STEP: creating a test event @ 10/26/24 13:29:16.574
  STEP: listing events in all namespaces @ 10/26/24 13:29:16.585
  STEP: listing events in test namespace @ 10/26/24 13:29:16.589
  STEP: listing events with field selection filtering on source @ 10/26/24 13:29:16.594
  STEP: listing events with field selection filtering on reportingController @ 10/26/24 13:29:16.597
  STEP: getting the test event @ 10/26/24 13:29:16.6
  STEP: patching the test event @ 10/26/24 13:29:16.603
  STEP: getting the test event @ 10/26/24 13:29:16.615
  STEP: updating the test event @ 10/26/24 13:29:16.618
  STEP: getting the test event @ 10/26/24 13:29:16.626
  STEP: deleting the test event @ 10/26/24 13:29:16.63
  STEP: listing events in all namespaces @ 10/26/24 13:29:16.64
  STEP: listing events in test namespace @ 10/26/24 13:29:16.645
  I1026 13:29:16.649480 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4704" for this suite. @ 10/26/24 13:29:16.654
• [0.112 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 10/26/24 13:29:16.662
  I1026 13:29:16.662603 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename events @ 10/26/24 13:29:16.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:16.685
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:16.688
  STEP: Create set of events @ 10/26/24 13:29:16.691
  I1026 13:29:16.698835 19 core_events.go:198] created test-event-1
  I1026 13:29:16.703380 19 core_events.go:198] created test-event-2
  I1026 13:29:16.708002 19 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 10/26/24 13:29:16.708
  STEP: delete collection of events @ 10/26/24 13:29:16.712
  I1026 13:29:16.712552 19 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 10/26/24 13:29:16.736
  I1026 13:29:16.736243 19 core_events.go:230] requesting list of events to confirm quantity
  I1026 13:29:16.739471 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1036" for this suite. @ 10/26/24 13:29:16.743
• [0.090 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:139
  STEP: Creating a kubernetes client @ 10/26/24 13:29:16.752
  I1026 13:29:16.752438 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-webhook @ 10/26/24 13:29:16.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:16.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:16.774
  STEP: Setting up server cert @ 10/26/24 13:29:16.777
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 10/26/24 13:29:17.106
  STEP: Deploying the custom resource conversion webhook pod @ 10/26/24 13:29:17.114
  STEP: Wait for the deployment to be ready @ 10/26/24 13:29:17.128
  I1026 13:29:17.143222 19 deployment.go:222] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E1026 13:29:17.256519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:18.256821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:29:19.163
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:29:19.182
  E1026 13:29:19.257690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:20.182359 19 util.go:420] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I1026 13:29:20.191198 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:29:20.258409      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:21.259330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:22.259868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 10/26/24 13:29:22.748
  STEP: v2 custom resource should be converted @ 10/26/24 13:29:22.754
  E1026 13:29:23.260958      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:23.313370 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-7142" for this suite. @ 10/26/24 13:29:23.318
• [6.575 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:814
  STEP: Creating a kubernetes client @ 10/26/24 13:29:23.327
  I1026 13:29:23.327474 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:29:23.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:23.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:23.349
  STEP: Setting up server cert @ 10/26/24 13:29:23.376
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:29:23.634
  STEP: Deploying the webhook pod @ 10/26/24 13:29:23.642
  STEP: Wait for the deployment to be ready @ 10/26/24 13:29:23.659
  I1026 13:29:23.668063 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:29:24.261319      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:25.261427      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:29:25.684
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:29:25.699
  E1026 13:29:26.261524      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:26.700058 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 10/26/24 13:29:26.71
  I1026 13:29:26.755978 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5318" for this suite. @ 10/26/24 13:29:26.763
  STEP: Destroying namespace "webhook-markers-3406" for this suite. @ 10/26/24 13:29:26.77
• [3.451 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 10/26/24 13:29:26.778
  I1026 13:29:26.778340 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename limitrange @ 10/26/24 13:29:26.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:26.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:26.798
  STEP: Creating LimitRange "e2e-limitrange-2wr46" in namespace "limitrange-3977" @ 10/26/24 13:29:26.801
  STEP: Creating another limitRange in another namespace @ 10/26/24 13:29:26.807
  I1026 13:29:26.825478 19 limit_range.go:299] Namespace "e2e-limitrange-2wr46-2205" created
  I1026 13:29:26.825497 19 limit_range.go:300] Creating LimitRange "e2e-limitrange-2wr46" in namespace "e2e-limitrange-2wr46-2205"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-2wr46" @ 10/26/24 13:29:26.833
  I1026 13:29:26.836841 19 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-2wr46" in "limitrange-3977" namespace @ 10/26/24 13:29:26.836
  I1026 13:29:26.861063 19 limit_range.go:335] LimitRange "e2e-limitrange-2wr46" has been patched
  STEP: Delete LimitRange "e2e-limitrange-2wr46" by Collection with labelSelector: "e2e-limitrange-2wr46=patched" @ 10/26/24 13:29:26.861
  STEP: Confirm that the limitRange "e2e-limitrange-2wr46" has been deleted @ 10/26/24 13:29:26.873
  I1026 13:29:26.873083 19 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I1026 13:29:26.880148 19 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-2wr46=patched"
  I1026 13:29:26.880175 19 limit_range.go:344] LimitRange "e2e-limitrange-2wr46" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-2wr46" @ 10/26/24 13:29:26.88
  I1026 13:29:26.891055 19 limit_range.go:350] Found 1 limitRange
  I1026 13:29:26.891154 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-3977" for this suite. @ 10/26/24 13:29:26.9
  STEP: Destroying namespace "e2e-limitrange-2wr46-2205" for this suite. @ 10/26/24 13:29:26.913
• [0.142 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 10/26/24 13:29:26.919
  I1026 13:29:26.919943 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 13:29:26.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:26.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:26.944
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 10/26/24 13:29:26.947
  E1026 13:29:27.261658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:28.262558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:29.263152      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:30.263240      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:29:30.974
  I1026 13:29:30.978527 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-846d06aa-2331-4b5b-bcdd-8d42d7e2083a container test-container: <nil>
  STEP: delete the pod @ 10/26/24 13:29:30.986
  I1026 13:29:31.005506 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5259" for this suite. @ 10/26/24 13:29:31.01
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 10/26/24 13:29:31.018
  I1026 13:29:31.018585 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename podtemplate @ 10/26/24 13:29:31.019
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:31.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:31.04
  STEP: Create a pod template @ 10/26/24 13:29:31.044
  STEP: Replace a pod template @ 10/26/24 13:29:31.049
  I1026 13:29:31.059902 19 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I1026 13:29:31.059990 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3679" for this suite. @ 10/26/24 13:29:31.063
• [0.052 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:218
  STEP: Creating a kubernetes client @ 10/26/24 13:29:31.071
  I1026 13:29:31.071084 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:29:31.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:31.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:31.093
  STEP: Setting up server cert @ 10/26/24 13:29:31.119
  E1026 13:29:31.263848      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:29:31.487
  STEP: Deploying the webhook pod @ 10/26/24 13:29:31.498
  STEP: Wait for the deployment to be ready @ 10/26/24 13:29:31.511
  I1026 13:29:31.522358 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:29:32.263994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:33.264898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:29:33.535
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:29:33.549
  E1026 13:29:34.265344      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:34.549711 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I1026 13:29:34.557971 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 10/26/24 13:29:35.067
  STEP: Creating a custom resource that should be denied by the webhook @ 10/26/24 13:29:35.082
  E1026 13:29:35.265754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:36.265924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 10/26/24 13:29:37.099
  STEP: Updating the custom resource with disallowed data should be denied @ 10/26/24 13:29:37.108
  STEP: Deleting the custom resource should be denied @ 10/26/24 13:29:37.117
  STEP: Remove the offending key and value from the custom resource data @ 10/26/24 13:29:37.124
  STEP: Deleting the updated custom resource should be successful @ 10/26/24 13:29:37.136
  E1026 13:29:37.266883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:37.708785 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2387" for this suite. @ 10/26/24 13:29:37.713
  STEP: Destroying namespace "webhook-markers-230" for this suite. @ 10/26/24 13:29:37.72
• [6.656 seconds]
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 10/26/24 13:29:37.726
  I1026 13:29:37.726806 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename endpointslice @ 10/26/24 13:29:37.727
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:37.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:37.748
  I1026 13:29:37.762728 19 endpointslice.go:1045] Endpoints addresses: [172.31.34.127 172.31.70.148] , ports: [6443]
  I1026 13:29:37.762752 19 endpointslice.go:1075] EndpointSlices addresses: [172.31.34.127 172.31.70.148] , ports: [6443]
  I1026 13:29:37.762822 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-6816" for this suite. @ 10/26/24 13:29:37.767
• [0.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:337
  STEP: Creating a kubernetes client @ 10/26/24 13:29:37.775
  I1026 13:29:37.775036 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 13:29:37.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:37.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:37.799
  STEP: creating a replication controller @ 10/26/24 13:29:37.802
  I1026 13:29:37.802990 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 create -f -'
  I1026 13:29:37.882588 19 builder.go:146] stderr: ""
  I1026 13:29:37.882615 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 10/26/24 13:29:37.882
  I1026 13:29:37.882709 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1026 13:29:37.931180 19 builder.go:146] stderr: ""
  I1026 13:29:37.931214 19 builder.go:147] stdout: "update-demo-nautilus-4ck8k update-demo-nautilus-4khdh "
  I1026 13:29:37.931253 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get pods update-demo-nautilus-4ck8k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:29:37.973903 19 builder.go:146] stderr: ""
  I1026 13:29:37.973937 19 builder.go:147] stdout: ""
  I1026 13:29:37.973946 19 kubectl.go:2502] update-demo-nautilus-4ck8k is created but not running
  E1026 13:29:38.266985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:39.267858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:40.268902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:41.269912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:42.269988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:42.974845 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1026 13:29:43.025969 19 builder.go:146] stderr: ""
  I1026 13:29:43.026004 19 builder.go:147] stdout: "update-demo-nautilus-4ck8k update-demo-nautilus-4khdh "
  I1026 13:29:43.026047 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get pods update-demo-nautilus-4ck8k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:29:43.070331 19 builder.go:146] stderr: ""
  I1026 13:29:43.070363 19 builder.go:147] stdout: "true"
  I1026 13:29:43.070426 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get pods update-demo-nautilus-4ck8k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1026 13:29:43.111799 19 builder.go:146] stderr: ""
  I1026 13:29:43.111837 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1026 13:29:43.111848 19 kubectl.go:2393] validating pod update-demo-nautilus-4ck8k
  I1026 13:29:43.118262 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1026 13:29:43.118329 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1026 13:29:43.118342 19 kubectl.go:2520] update-demo-nautilus-4ck8k is verified up and running
  I1026 13:29:43.118384 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get pods update-demo-nautilus-4khdh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:29:43.161575 19 builder.go:146] stderr: ""
  I1026 13:29:43.161608 19 builder.go:147] stdout: "true"
  I1026 13:29:43.161647 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get pods update-demo-nautilus-4khdh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1026 13:29:43.203238 19 builder.go:146] stderr: ""
  I1026 13:29:43.203331 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1026 13:29:43.203344 19 kubectl.go:2393] validating pod update-demo-nautilus-4khdh
  I1026 13:29:43.211040 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1026 13:29:43.211081 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1026 13:29:43.211094 19 kubectl.go:2520] update-demo-nautilus-4khdh is verified up and running
  STEP: using delete to clean up resources @ 10/26/24 13:29:43.211
  I1026 13:29:43.211154 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 delete --grace-period=0 --force -f -'
  I1026 13:29:43.258414 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 13:29:43.258452 19 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I1026 13:29:43.258494 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get rc,svc -l name=update-demo --no-headers'
  E1026 13:29:43.270867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:43.323922 19 builder.go:146] stderr: "No resources found in kubectl-9100 namespace.\n"
  I1026 13:29:43.324043 19 builder.go:147] stdout: ""
  I1026 13:29:43.324107 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-9100 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I1026 13:29:43.375202 19 builder.go:146] stderr: ""
  I1026 13:29:43.375246 19 builder.go:147] stdout: ""
  I1026 13:29:43.375443 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9100" for this suite. @ 10/26/24 13:29:43.38
• [5.615 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 10/26/24 13:29:43.39
  I1026 13:29:43.390376 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 13:29:43.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:43.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:43.411
  STEP: creating a ConfigMap @ 10/26/24 13:29:43.414
  STEP: fetching the ConfigMap @ 10/26/24 13:29:43.42
  STEP: patching the ConfigMap @ 10/26/24 13:29:43.423
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 10/26/24 13:29:43.428
  STEP: deleting the ConfigMap by collection with a label selector @ 10/26/24 13:29:43.433
  STEP: listing all ConfigMaps in test namespace @ 10/26/24 13:29:43.441
  I1026 13:29:43.444959 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2868" for this suite. @ 10/26/24 13:29:43.448
• [0.066 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 10/26/24 13:29:43.456
  I1026 13:29:43.456958 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 13:29:43.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:29:43.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:29:43.477
  STEP: Creating pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692 @ 10/26/24 13:29:43.48
  E1026 13:29:44.271793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:45.272043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 10/26/24 13:29:45.504
  I1026 13:29:45.508873 19 container_probe.go:1749] Initial restart count of pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf is 0
  I1026 13:29:45.512545 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:29:46.272405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:47.272521      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:47.519408 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:29:48.273128      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:49.273256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:49.523516 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:29:50.273982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:51.274086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:51.530576 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:29:52.274908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:53.274972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:53.536337 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:29:54.275912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:55.276118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:55.542549 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:29:56.276911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:57.277091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:57.548592 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:29:58.277203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:29:59.277474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:29:59.553487 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:00.278336      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:01.278435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:01.558711 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:02.279509      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:03.279648      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:03.566030 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:04.279757      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:05.279864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:05.572346 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  I1026 13:30:05.572386 19 container_probe.go:1763] Restart count of pod container-probe-7692/liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf is now 1 (20.063483696s elapsed)
  E1026 13:30:06.279898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:07.279957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:07.579269 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:08.280026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:09.280325      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:09.586496 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:10.281110      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:11.281219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:11.591750 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:12.281485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:13.281737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:13.597218 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:14.281851      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:15.281972      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:15.602347 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:16.282086      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:17.282340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:17.609744 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:18.282408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:19.282507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:19.613660 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:20.283507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:21.283620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:21.620112 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:22.283838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:23.283931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:23.625520 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:24.284013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:25.284116      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:25.631005 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  I1026 13:30:25.631040 19 container_probe.go:1763] Restart count of pod container-probe-7692/liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf is now 2 (40.122137223s elapsed)
  E1026 13:30:26.284754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:27.284875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:27.636069 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:28.285808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:29.285915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:29.642974 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:30.286814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:31.287005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:31.648792 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:32.287452      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:33.287579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:33.655649 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:34.288441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:35.288658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:35.661247 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:36.288936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:37.289163      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:37.667024 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:38.289372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:39.289729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:39.673630 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:40.289847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:41.289982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:41.679538 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:42.290233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:43.290321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:43.684866 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:44.290504      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:45.290753      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:45.690417 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  I1026 13:30:45.690460 19 container_probe.go:1763] Restart count of pod container-probe-7692/liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf is now 3 (1m0.181556487s elapsed)
  E1026 13:30:46.290843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:47.290971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:47.697152 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:48.291904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:49.292252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:49.702548 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:50.292304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:51.292525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:51.710261 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:52.292636      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:53.292840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:53.715642 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:54.292960      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:55.293053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:55.722375 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:56.294062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:57.294158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:57.727367 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:30:58.294903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:30:59.294997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:30:59.732478 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:00.295902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:01.296146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:01.737441 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:02.296918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:03.297033      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:03.744260 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:04.297923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:05.298136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:05.751264 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  I1026 13:31:05.751300 19 container_probe.go:1763] Restart count of pod container-probe-7692/liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf is now 4 (1m20.242397012s elapsed)
  E1026 13:31:06.299036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:07.300004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:07.756855 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:08.300501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:09.301022      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:09.763935 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:10.301517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:11.301805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:11.769627 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:12.302252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:13.302911      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:13.777059 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:14.303763      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:15.303834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:15.781843 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:16.304395      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:17.304489      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:17.787732 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:18.304910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:19.305008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:19.793893 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:20.305488      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:21.305551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:21.798557 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:22.305825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:23.305943      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:23.804881 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:24.306440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:25.306666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:25.811112 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:26.306835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:27.307131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:27.816787 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:28.307250      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:29.307579      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:29.823159 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:30.307752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:31.307964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:31.830457 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:32.308205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:33.308252      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:33.835558 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:34.309097      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:35.309199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:35.840860 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:36.309438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:37.309788      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:37.847398 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:38.309877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:39.310865      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:39.851914 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:40.311607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:41.312571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:41.858322 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:42.312728      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:43.313329      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:43.864500 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:44.313985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:45.314884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:45.870913 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:46.315372      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:47.315469      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:47.876334 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:48.315575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:49.315805      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:49.882924 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:50.316462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:51.316801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:51.889139 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:52.317652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:53.318514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:53.894259 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:54.318739      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:55.318804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:55.899414 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:56.319063      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:57.319266      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:57.905942 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:31:58.319493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:31:59.319855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:31:59.910799 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:32:00.320249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:01.320443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:01.918035 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:32:02.321501      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:03.321758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:03.923036 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:32:04.322560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:05.322772      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:05.929131 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  E1026 13:32:06.323591      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:07.323718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:07.933888 19 container_probe.go:1759] Get pod liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf in namespace container-probe-7692
  I1026 13:32:07.933927 19 container_probe.go:1763] Restart count of pod container-probe-7692/liveness-16097d34-03ab-40e3-82ec-aee3d6943dcf is now 5 (2m22.425023469s elapsed)
  STEP: deleting the pod @ 10/26/24 13:32:07.934
  I1026 13:32:07.946268 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7692" for this suite. @ 10/26/24 13:32:07.951
• [144.503 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:62
  STEP: Creating a kubernetes client @ 10/26/24 13:32:07.96
  I1026 13:32:07.960182 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename field-validation @ 10/26/24 13:32:07.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:32:07.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:32:07.982
  STEP: apply creating a deployment @ 10/26/24 13:32:07.987
  I1026 13:32:08.003380 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7877" for this suite. @ 10/26/24 13:32:08.006
• [0.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 10/26/24 13:32:08.018
  I1026 13:32:08.018640 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 10/26/24 13:32:08.019
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:32:08.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:32:08.04
  STEP: create the container to handle the HTTPGet hook request. @ 10/26/24 13:32:08.047
  E1026 13:32:08.324435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:09.324531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 10/26/24 13:32:10.069
  E1026 13:32:10.325010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:11.325109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 10/26/24 13:32:12.093
  STEP: delete the pod with lifecycle hook @ 10/26/24 13:32:12.107
  E1026 13:32:12.325292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:13.325400      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:14.123910 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9921" for this suite. @ 10/26/24 13:32:14.128
• [6.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 10/26/24 13:32:14.137
  I1026 13:32:14.137316 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename aggregateddiscovery @ 10/26/24 13:32:14.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:32:14.157
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:32:14.16
  I1026 13:32:14.167176 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-4497" for this suite. @ 10/26/24 13:32:14.17
• [0.041 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 10/26/24 13:32:14.178
  I1026 13:32:14.178123 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 13:32:14.178
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:32:14.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:32:14.199
  STEP: Creating pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416 @ 10/26/24 13:32:14.203
  E1026 13:32:14.326203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:15.326365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 10/26/24 13:32:16.22
  I1026 13:32:16.224940 19 container_probe.go:1749] Initial restart count of pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 is 0
  I1026 13:32:16.228714 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:16.326907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:17.327260      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:18.233563 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:18.327907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:19.330871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:20.238523 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:20.331838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:21.331987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:22.244921 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:22.332098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:23.332979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:24.250420 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:24.333570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:25.333702      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:26.257514 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:26.334741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:27.334836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:28.262911 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:28.335164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:29.335932      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:30.269838 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:30.336004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:31.336131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:32.275196 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:32.336408      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:33.337042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:34.282091 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:34.337268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:35.337473      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:36.287461 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:36.337773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:37.337840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:38.294942 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:38.338219      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:39.338441      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:40.299780 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:40.339167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:41.339379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:42.306106 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:42.340211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:43.341089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:44.311149 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:44.341292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:45.341516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:46.318228 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:46.342403      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:47.342610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:48.323532 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:48.342792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:49.342863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:50.330059 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:50.343312      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:51.343433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:52.335931 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:52.344100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:53.344435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:54.342230 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:54.345316      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:55.345930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:56.346912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:56.347838 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:57.347939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:32:58.348284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:32:58.354960 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:32:59.349333      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:00.349453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:00.360696 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:33:01.349556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:02.349670      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:02.367104 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:33:03.349997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:04.350143      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:04.372250 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  E1026 13:33:05.350374      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:06.350658      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:06.378477 19 container_probe.go:1759] Get pod busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 in namespace container-probe-9416
  I1026 13:33:06.378507 19 container_probe.go:1763] Restart count of pod container-probe-9416/busybox-bcdcdf16-7827-4422-ac01-69d2fbf43415 is now 1 (50.153542049s elapsed)
  STEP: deleting the pod @ 10/26/24 13:33:06.378
  I1026 13:33:06.392025 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-9416" for this suite. @ 10/26/24 13:33:06.396
• [52.225 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:454
  STEP: Creating a kubernetes client @ 10/26/24 13:33:06.403
  I1026 13:33:06.403877 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 13:33:06.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:33:06.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:33:06.426
  STEP: Counting existing ResourceQuota @ 10/26/24 13:33:06.429
  E1026 13:33:07.351039      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:08.351007      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:09.351078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:10.351230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:11.351354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 10/26/24 13:33:11.434
  STEP: Ensuring resource quota status is calculated @ 10/26/24 13:33:11.442
  E1026 13:33:12.352216      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:13.353078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 10/26/24 13:33:13.448
  STEP: Ensuring resource quota status captures replicaset creation @ 10/26/24 13:33:13.462
  E1026 13:33:14.353544      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:15.354042      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 10/26/24 13:33:15.469
  STEP: Ensuring resource quota status released usage @ 10/26/24 13:33:15.476
  E1026 13:33:16.354876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:17.355907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:17.482258 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8614" for this suite. @ 10/26/24 13:33:17.487
• [11.091 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:115
  STEP: Creating a kubernetes client @ 10/26/24 13:33:17.494
  I1026 13:33:17.494738 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename field-validation @ 10/26/24 13:33:17.495
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:33:17.513
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:33:17.516
  STEP: apply creating a deployment @ 10/26/24 13:33:17.519
  I1026 13:33:17.537861 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7820" for this suite. @ 10/26/24 13:33:17.541
• [0.055 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 10/26/24 13:33:17.55
  I1026 13:33:17.550150 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:33:17.55
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:33:17.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:33:17.574
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:33:17.577
  E1026 13:33:18.356522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:19.356740      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:20.356904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:21.357118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:33:21.601
  I1026 13:33:21.605201 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-40347c8f-bbcc-4667-8f51-01eaa15f2486 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:33:21.617
  I1026 13:33:21.638507 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3559" for this suite. @ 10/26/24 13:33:21.643
• [4.101 seconds]
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 10/26/24 13:33:21.651
  I1026 13:33:21.651611 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 13:33:21.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:33:21.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:33:21.674
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:33:21.677
  E1026 13:33:22.357904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:23.357975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:24.358043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:25.358232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:33:25.706
  I1026 13:33:25.710724 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-2692d85f-8a09-499d-9b45-b37029f44b41 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:33:25.717
  I1026 13:33:25.738106 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1866" for this suite. @ 10/26/24 13:33:25.741
• [4.100 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1066
  STEP: Creating a kubernetes client @ 10/26/24 13:33:25.752
  I1026 13:33:25.752036 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename resourcequota @ 10/26/24 13:33:25.752
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:33:25.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:33:25.773
  STEP: Creating resourceQuota "e2e-rq-status-xphvp" @ 10/26/24 13:33:25.781
  I1026 13:33:25.790360 19 resource_quota.go:1102] Resource quota "e2e-rq-status-xphvp" reports spec: hard cpu limit of 500m
  I1026 13:33:25.790383 19 resource_quota.go:1104] Resource quota "e2e-rq-status-xphvp" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-xphvp" /status @ 10/26/24 13:33:25.79
  STEP: Confirm /status for "e2e-rq-status-xphvp" resourceQuota via watch @ 10/26/24 13:33:25.799
  I1026 13:33:25.801351 19 resource_quota.go:1131] observed resourceQuota "e2e-rq-status-xphvp" in namespace "resourcequota-1428" with hard status: v1.ResourceList(nil)
  I1026 13:33:25.801406 19 resource_quota.go:1134] Found resourceQuota "e2e-rq-status-xphvp" in namespace "resourcequota-1428" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I1026 13:33:25.801420 19 resource_quota.go:1141] ResourceQuota "e2e-rq-status-xphvp" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 10/26/24 13:33:25.804
  I1026 13:33:25.811973 19 resource_quota.go:1152] Resource quota "e2e-rq-status-xphvp" reports spec: hard cpu limit of 1
  I1026 13:33:25.811993 19 resource_quota.go:1153] Resource quota "e2e-rq-status-xphvp" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-xphvp" /status @ 10/26/24 13:33:25.812
  STEP: Confirm /status for "e2e-rq-status-xphvp" resourceQuota via watch @ 10/26/24 13:33:25.819
  I1026 13:33:25.821075 19 resource_quota.go:1175] observed resourceQuota "e2e-rq-status-xphvp" in namespace "resourcequota-1428" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I1026 13:33:25.821114 19 resource_quota.go:1178] Found resourceQuota "e2e-rq-status-xphvp" in namespace "resourcequota-1428" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I1026 13:33:25.821123 19 resource_quota.go:1185] ResourceQuota "e2e-rq-status-xphvp" /status was patched
  STEP: Get "e2e-rq-status-xphvp" /status @ 10/26/24 13:33:25.821
  I1026 13:33:25.824814 19 resource_quota.go:1196] Resourcequota "e2e-rq-status-xphvp" reports status: hard cpu of 1
  I1026 13:33:25.824837 19 resource_quota.go:1198] Resourcequota "e2e-rq-status-xphvp" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-xphvp" /status before checking Spec is unchanged @ 10/26/24 13:33:25.829
  I1026 13:33:25.835172 19 resource_quota.go:1218] Resourcequota "e2e-rq-status-xphvp" reports status: hard cpu of 2
  I1026 13:33:25.835195 19 resource_quota.go:1220] Resourcequota "e2e-rq-status-xphvp" reports status: hard memory of 2Gi
  I1026 13:33:25.836822 19 resource_quota.go:1232] Found resourceQuota "e2e-rq-status-xphvp" in namespace "resourcequota-1428" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I1026 13:33:25.839802 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f2c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f2f0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f350), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:33:26.358563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:27.358729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:28.359091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:29.359221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:30.359450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:30.843567 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b320), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b368), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b3e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:33:31.360201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:32.360527      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:33.360909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:34.361916      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:35.362109      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:35.842773 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e090), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e0c0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e0f0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:33:36.362253      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:37.362577      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:38.362575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:39.362888      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:40.363132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:40.842719 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e2b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e348), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e390), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:33:41.363264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:42.363869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:43.364450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:44.364880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:45.364980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:45.843723 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e4f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e5b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e600), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:33:46.365078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:47.366137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:48.366631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:49.366804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:50.366982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:50.842066 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e768), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e798), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487e7e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:33:51.367946      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:52.368873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:53.369230      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:54.369444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:55.369566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:33:55.841917 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3a2e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3a318), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3a3a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:33:56.370626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:57.370909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:58.371255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:33:59.371459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:00.371659      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:00.842832 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487ea68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487eaf8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487eb28), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:01.372410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:02.372523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:03.372905      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:04.373302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:05.374235      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:05.842807 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3a6d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3a750), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3a828), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:06.374870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:07.375870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:08.376179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:09.376388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:10.376808      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:10.843653 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487edf8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487ee28), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487ee58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:11.376945      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:12.377092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:13.378053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:14.378380      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:15.378639      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:15.842198 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f1e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f278), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f2c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:16.378821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:17.379049      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:18.379426      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:19.379634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:20.379849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:20.842348 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f4e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f518), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f548), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:21.379964      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:22.380880      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:23.381322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:24.382084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:25.382183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:25.843934 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3ac18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3ac48), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3aca8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:26.382410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:27.382698      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:28.383020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:29.383898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:30.384254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:30.842916 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f770), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f818), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487f890), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:31.384450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:32.384887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:33.384935      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:34.385868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:35.385977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:35.842340 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b050), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b098), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b0c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:36.386876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:37.386977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:38.387419      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:39.387628      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:40.387837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:40.843997 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487fb60), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487fbc0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00487fc08), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:41.388666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:42.388854      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:43.389339      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:44.389593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:45.389729      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:45.842241 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b3e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b428), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b458), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:46.389899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:47.390581      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:48.390667      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:49.390881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:50.391068      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:50.842588 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b668), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b698), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b6c8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:51.391221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:52.391438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:53.392198      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:54.392474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:55.392619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:34:55.842726 19 resource_quota.go:1263] ResourceQuota "e2e-rq-status-xphvp" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-xphvp", GenerateName:"", Namespace:"resourcequota-1428", SelfLink:"", UID:"a5b6fa7a-73e3-4f3d-9795-34f4a54862a7", ResourceVersion:"41440", Generation:0, CreationTimestamp:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-xphvp"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b8d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b920), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.October, 26, 13, 33, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000b3b950), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E1026 13:34:56.393388      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:57.393566      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:58.393641      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:34:59.393806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:00.394872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:35:00.842322 19 resource_quota.go:1260] ResourceQuota "e2e-rq-status-xphvp" Spec was unchanged and /status reset
  I1026 13:35:00.842457 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1428" for this suite. @ 10/26/24 13:35:00.847
• [95.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 10/26/24 13:35:00.854
  I1026 13:35:00.854266 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename cronjob @ 10/26/24 13:35:00.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:35:00.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:35:00.877
  STEP: Creating a ReplaceConcurrent cronjob @ 10/26/24 13:35:00.88
  STEP: Ensuring a job is scheduled @ 10/26/24 13:35:00.886
  E1026 13:35:01.395894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:02.396924      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:03.397056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:04.397160      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:05.397223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:06.397522      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:07.398188      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:08.399010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:09.400055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:10.400156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:11.400274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:12.401304      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:13.402115      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:14.402330      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:15.402440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:16.402647      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:17.403492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:18.403825      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:19.404703      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:20.404832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:21.404955      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:22.405019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:23.406073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:24.406298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:25.407207      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:26.407320      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:27.407593      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:28.408184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:29.408227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:30.408910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:31.409008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:32.409326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:33.410137      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:34.410215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:35.410832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:36.411867      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:37.412784      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:38.413051      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:39.413148      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:40.413323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:41.414190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:42.414320      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:43.415053      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:44.415223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:45.415526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:46.416181      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:47.416227      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:48.416594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:49.416754      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:50.416818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:51.417523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:52.417656      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:53.418091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:54.418293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:55.418498      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:56.418810      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:57.419472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:58.419804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:35:59.419909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:00.420098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 10/26/24 13:36:00.89
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 10/26/24 13:36:00.895
  STEP: Ensuring the job is replaced with a new one @ 10/26/24 13:36:00.901
  E1026 13:36:01.420303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:02.420515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:03.420812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:04.420986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:05.421831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:06.422696      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:07.423445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:08.423707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:09.423826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:10.423921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:11.424010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:12.424103      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:13.424727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:14.425254      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:15.425366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:16.425438      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:17.425843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:18.426062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:19.427136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:20.427264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:21.427449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:22.427769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:23.428274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:24.428483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:25.428587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:26.429513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:27.430286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:28.431105      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:29.432021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:30.432914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:31.433045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:32.433144      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:33.434145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:34.434249      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:35.434890      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:36.434986      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:37.435778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:38.436064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:39.436831      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:40.436944      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:41.437094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:42.437182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:43.438125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:44.438347      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:45.438458      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:46.438552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:47.439444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:48.440146      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:49.440255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:50.440490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:51.440732      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:52.440967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:53.441056      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:54.441164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:55.441379      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:56.441620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:57.442450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:58.443228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:36:59.443752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:00.443832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 10/26/24 13:37:00.907
  I1026 13:37:00.915558 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8645" for this suite. @ 10/26/24 13:37:00.919
• [120.073 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 10/26/24 13:37:00.927
  I1026 13:37:00.927478 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename pods @ 10/26/24 13:37:00.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:37:00.954
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:37:00.957
  STEP: creating the pod @ 10/26/24 13:37:00.96
  STEP: setting up watch @ 10/26/24 13:37:00.96
  STEP: submitting the pod to kubernetes @ 10/26/24 13:37:01.063
  STEP: verifying the pod is in kubernetes @ 10/26/24 13:37:01.073
  STEP: verifying pod creation was observed @ 10/26/24 13:37:01.08
  E1026 13:37:01.445822      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:02.446020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 10/26/24 13:37:03.093
  STEP: verifying pod deletion was observed @ 10/26/24 13:37:03.104
  E1026 13:37:03.446413      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:37:03.976426 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7632" for this suite. @ 10/26/24 13:37:03.981
• [3.062 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 10/26/24 13:37:03.989
  I1026 13:37:03.989279 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename security-context-test @ 10/26/24 13:37:03.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:37:04.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:37:04.009
  E1026 13:37:04.447556      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:05.447774      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:06.448341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:07.448550      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:37:08.041296 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3583" for this suite. @ 10/26/24 13:37:08.045
• [4.065 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:763
  STEP: Creating a kubernetes client @ 10/26/24 13:37:08.054
  I1026 13:37:08.054496 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:37:08.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:37:08.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:37:08.078
  STEP: Setting up server cert @ 10/26/24 13:37:08.104
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:37:08.375
  STEP: Deploying the webhook pod @ 10/26/24 13:37:08.386
  STEP: Wait for the deployment to be ready @ 10/26/24 13:37:08.4
  I1026 13:37:08.409989 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:37:08.449108      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:09.449307      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:37:10.425
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:37:10.437
  E1026 13:37:10.449545      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:37:11.437636 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 10/26/24 13:37:11.445
  E1026 13:37:11.450046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the mutating webhook match conditions @ 10/26/24 13:37:11.453
  STEP: updating the mutating webhook match conditions @ 10/26/24 13:37:11.456
  STEP: verifying the mutating webhook match conditions @ 10/26/24 13:37:11.465
  I1026 13:37:11.515254 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9039" for this suite. @ 10/26/24 13:37:11.519
  STEP: Destroying namespace "webhook-markers-4620" for this suite. @ 10/26/24 13:37:11.528
• [3.481 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:324
  STEP: Creating a kubernetes client @ 10/26/24 13:37:11.535
  I1026 13:37:11.535158 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename statefulset @ 10/26/24 13:37:11.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:37:11.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:37:11.557
  STEP: Creating service test in namespace statefulset-3087 @ 10/26/24 13:37:11.561
  STEP: Creating a new StatefulSet @ 10/26/24 13:37:11.568
  I1026 13:37:11.582430 19 wait.go:40] Found 0 stateful pods, waiting for 3
  E1026 13:37:12.450223      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:13.450792      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:14.450910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:15.451003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:16.451320      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:17.451447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:18.452245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:19.452360      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:20.452470      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:21.452712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:37:21.585358 19 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I1026 13:37:21.585399 19 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I1026 13:37:21.585407 19 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I1026 13:37:21.598397 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-3087 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 13:37:21.690478 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 13:37:21.690516 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 13:37:21.690527 19 statefulset.go:2450] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E1026 13:37:22.452835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:23.453170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:24.453241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:25.453359      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:26.453587      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:27.454215      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:28.454798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:29.454910      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:30.455005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:31.455069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 10/26/24 13:37:31.701
  I1026 13:37:31.710933 19 statefulset.go:2507] Updating stateful set ss2
  STEP: Creating a new revision @ 10/26/24 13:37:31.71
  E1026 13:37:32.455414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:33.456038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:34.456136      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:35.456238      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:36.456942      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:37.457127      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:38.457542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:39.457806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:40.458099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:41.458302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 10/26/24 13:37:41.719
  I1026 13:37:41.725032 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-3087 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1026 13:37:41.807877 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1026 13:37:41.807923 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 13:37:41.807932 19 statefulset.go:2474] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E1026 13:37:42.458511      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:43.458790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:44.458988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:45.459134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:46.459237      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:47.459324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:48.460164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:49.460377      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:50.460922      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:51.461035      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 10/26/24 13:37:51.825
  I1026 13:37:51.825891 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-3087 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I1026 13:37:51.909908 19 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I1026 13:37:51.909948 19 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I1026 13:37:51.909958 19 statefulset.go:2450] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E1026 13:37:52.461145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:53.462101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:54.462269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:55.462551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:56.462782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:57.463166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:58.463823      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:37:59.464889      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:00.465093      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:01.465282      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:01.932870 19 statefulset.go:2507] Updating stateful set ss2
  E1026 13:38:02.465896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:03.466008      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:04.466192      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:05.466293      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:06.466513      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:07.466750      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:08.467096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:09.467272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:10.467881      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:11.468876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 10/26/24 13:38:11.944
  I1026 13:38:11.948717 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=statefulset-3087 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I1026 13:38:12.033130 19 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I1026 13:38:12.033172 19 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I1026 13:38:12.033183 19 statefulset.go:2474] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E1026 13:38:12.469752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:13.470767      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:14.470904      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:15.471037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:16.471117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:17.471210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:18.471872      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:19.471995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:20.472210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:21.472398      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:22.052456 19 statefulset.go:138] Deleting all statefulset in ns statefulset-3087
  I1026 13:38:22.057081 19 rest.go:150] Scaling statefulset ss2 to 0
  E1026 13:38:22.473125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:23.474124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:24.474899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:25.475869      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:26.476080      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:27.476895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:28.477000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:29.477113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:30.477297      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:31.477947      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:32.072444 19 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I1026 13:38:32.077930 19 rest.go:88] Deleting statefulset ss2
  I1026 13:38:32.090845 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3087" for this suite. @ 10/26/24 13:38:32.094
• [80.568 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:193
  STEP: Creating a kubernetes client @ 10/26/24 13:38:32.103
  I1026 13:38:32.103668 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename dns @ 10/26/24 13:38:32.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:38:32.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:38:32.124
  STEP: Creating a test headless service @ 10/26/24 13:38:32.127
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7245 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7245;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7245 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7245;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7245.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7245.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7245.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7245.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7245.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7245.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7245.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7245.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7245.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7245.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7245.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7245.svc;check="$$(dig +notcp +noall +answer +search 223.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.223_udp@PTR;check="$$(dig +tcp +noall +answer +search 223.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.223_tcp@PTR;sleep 1; done
   @ 10/26/24 13:38:32.146
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7245 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7245;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7245 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7245;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7245.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7245.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7245.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7245.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7245.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7245.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7245.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7245.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7245.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7245.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7245.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7245.svc;check="$$(dig +notcp +noall +answer +search 223.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.223_udp@PTR;check="$$(dig +tcp +noall +answer +search 223.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.223_tcp@PTR;sleep 1; done
   @ 10/26/24 13:38:32.146
  STEP: creating a pod to probe DNS @ 10/26/24 13:38:32.146
  STEP: submitting the pod to kubernetes @ 10/26/24 13:38:32.146
  E1026 13:38:32.478205      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:33.478640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 13:38:34.167
  STEP: looking for the results for each expected name from probers @ 10/26/24 13:38:34.172
  I1026 13:38:34.178342 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.182260 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.188206 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-7245 from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.192194 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-7245 from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.195959 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-7245.svc from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.200991 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-7245.svc from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.204941 19 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7245.svc from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.208894 19 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7245.svc from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.232098 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.236151 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.241551 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-7245 from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.246039 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-7245 from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.249857 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-7245.svc from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.255071 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-7245.svc from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.259207 19 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7245.svc from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.263246 19 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7245.svc from pod dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572: the server could not find the requested resource (get pods dns-test-90c8290f-e308-431b-9045-e737c08e0572)
  I1026 13:38:34.281992 19 dns_common.go:489] Lookups using dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7245 wheezy_tcp@dns-test-service.dns-7245 wheezy_udp@dns-test-service.dns-7245.svc wheezy_tcp@dns-test-service.dns-7245.svc wheezy_udp@_http._tcp.dns-test-service.dns-7245.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7245.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7245 jessie_tcp@dns-test-service.dns-7245 jessie_udp@dns-test-service.dns-7245.svc jessie_tcp@dns-test-service.dns-7245.svc jessie_udp@_http._tcp.dns-test-service.dns-7245.svc jessie_tcp@_http._tcp.dns-test-service.dns-7245.svc]

  I1026 13:38:34.305878 19 dns_common.go:495] Pod client logs for webserver: 
  I1026 13:38:34.313033 19 dns_common.go:495] Pod client logs for querier: 
  I1026 13:38:34.321044 19 dns_common.go:495] Pod client logs for jessie-querier: 
  E1026 13:38:34.479443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:35.479662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:36.479868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:37.479976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:38.480075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:39.281586 19 dns_common.go:527] DNS probes using dns-7245/dns-test-90c8290f-e308-431b-9045-e737c08e0572 succeeded

  STEP: deleting the pod @ 10/26/24 13:38:39.281
  STEP: deleting the test service @ 10/26/24 13:38:39.294
  STEP: deleting the test headless service @ 10/26/24 13:38:39.317
  I1026 13:38:39.334323 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7245" for this suite. @ 10/26/24 13:38:39.337
• [7.241 seconds]
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:750
  STEP: Creating a kubernetes client @ 10/26/24 13:38:39.345
  I1026 13:38:39.345051 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:38:39.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:38:39.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:38:39.367
  I1026 13:38:39.374500 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9152" for this suite. @ 10/26/24 13:38:39.379
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 10/26/24 13:38:39.39
  I1026 13:38:39.390258 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename svc-latency @ 10/26/24 13:38:39.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:38:39.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:38:39.412
  I1026 13:38:39.415208 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-6254 @ 10/26/24 13:38:39.415
  I1026 13:38:39.421127      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6254, replica count: 1
  E1026 13:38:39.480787      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:40.471741      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E1026 13:38:40.481516      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:40.586873 19 service_latency.go:356] Created: latency-svc-mnkfg
  I1026 13:38:40.594538 19 service_latency.go:363] Got endpoints: latency-svc-mnkfg [21.729524ms]
  I1026 13:38:40.606652 19 service_latency.go:356] Created: latency-svc-ll9tr
  I1026 13:38:40.613406 19 service_latency.go:363] Got endpoints: latency-svc-ll9tr [18.523466ms]
  I1026 13:38:40.617084 19 service_latency.go:356] Created: latency-svc-ngc2r
  I1026 13:38:40.623800 19 service_latency.go:363] Got endpoints: latency-svc-ngc2r [28.882275ms]
  I1026 13:38:40.624392 19 service_latency.go:356] Created: latency-svc-pkwsd
  I1026 13:38:40.630960 19 service_latency.go:356] Created: latency-svc-t2pzc
  I1026 13:38:40.631429 19 service_latency.go:363] Got endpoints: latency-svc-pkwsd [36.587586ms]
  I1026 13:38:40.637023 19 service_latency.go:363] Got endpoints: latency-svc-t2pzc [42.288749ms]
  I1026 13:38:40.640587 19 service_latency.go:356] Created: latency-svc-gb7n2
  I1026 13:38:40.645449 19 service_latency.go:363] Got endpoints: latency-svc-gb7n2 [50.43884ms]
  I1026 13:38:40.646526 19 service_latency.go:356] Created: latency-svc-knvp9
  I1026 13:38:40.654479 19 service_latency.go:363] Got endpoints: latency-svc-knvp9 [59.318408ms]
  I1026 13:38:40.654561 19 service_latency.go:356] Created: latency-svc-lrnhs
  I1026 13:38:40.661226 19 service_latency.go:363] Got endpoints: latency-svc-lrnhs [66.093622ms]
  I1026 13:38:40.663617 19 service_latency.go:356] Created: latency-svc-57bkw
  I1026 13:38:40.667661 19 service_latency.go:363] Got endpoints: latency-svc-57bkw [72.68513ms]
  I1026 13:38:40.670637 19 service_latency.go:356] Created: latency-svc-m9sbv
  I1026 13:38:40.676980 19 service_latency.go:356] Created: latency-svc-bzc7r
  I1026 13:38:40.677301 19 service_latency.go:363] Got endpoints: latency-svc-m9sbv [82.355073ms]
  I1026 13:38:40.683406 19 service_latency.go:363] Got endpoints: latency-svc-bzc7r [88.305892ms]
  I1026 13:38:40.685925 19 service_latency.go:356] Created: latency-svc-dwmpv
  I1026 13:38:40.691853 19 service_latency.go:363] Got endpoints: latency-svc-dwmpv [96.795855ms]
  I1026 13:38:40.693058 19 service_latency.go:356] Created: latency-svc-rwg92
  I1026 13:38:40.697417 19 service_latency.go:363] Got endpoints: latency-svc-rwg92 [102.315632ms]
  I1026 13:38:40.698418 19 service_latency.go:356] Created: latency-svc-jz74n
  I1026 13:38:40.704903 19 service_latency.go:363] Got endpoints: latency-svc-jz74n [109.771978ms]
  I1026 13:38:40.708089 19 service_latency.go:356] Created: latency-svc-hgkc6
  I1026 13:38:40.713859 19 service_latency.go:363] Got endpoints: latency-svc-hgkc6 [118.78888ms]
  I1026 13:38:40.713970 19 service_latency.go:356] Created: latency-svc-ltjcg
  I1026 13:38:40.721887 19 service_latency.go:356] Created: latency-svc-b7pdg
  I1026 13:38:40.723051 19 service_latency.go:363] Got endpoints: latency-svc-ltjcg [128.012999ms]
  I1026 13:38:40.727342 19 service_latency.go:363] Got endpoints: latency-svc-b7pdg [113.900805ms]
  I1026 13:38:40.730978 19 service_latency.go:356] Created: latency-svc-wwlrf
  I1026 13:38:40.736990 19 service_latency.go:363] Got endpoints: latency-svc-wwlrf [113.154462ms]
  I1026 13:38:40.739348 19 service_latency.go:356] Created: latency-svc-87lf5
  I1026 13:38:40.745798 19 service_latency.go:363] Got endpoints: latency-svc-87lf5 [114.154195ms]
  I1026 13:38:40.746364 19 service_latency.go:356] Created: latency-svc-d4xxx
  I1026 13:38:40.752940 19 service_latency.go:363] Got endpoints: latency-svc-d4xxx [115.882018ms]
  I1026 13:38:40.754764 19 service_latency.go:356] Created: latency-svc-kkmhd
  I1026 13:38:40.760435 19 service_latency.go:363] Got endpoints: latency-svc-kkmhd [114.952069ms]
  I1026 13:38:40.762325 19 service_latency.go:356] Created: latency-svc-wtkgh
  I1026 13:38:40.766705 19 service_latency.go:356] Created: latency-svc-qh4zz
  I1026 13:38:40.768306 19 service_latency.go:363] Got endpoints: latency-svc-wtkgh [113.800077ms]
  I1026 13:38:40.773533 19 service_latency.go:363] Got endpoints: latency-svc-qh4zz [112.279648ms]
  I1026 13:38:40.778176 19 service_latency.go:356] Created: latency-svc-2gw66
  I1026 13:38:40.782524 19 service_latency.go:363] Got endpoints: latency-svc-2gw66 [114.815012ms]
  I1026 13:38:40.784981 19 service_latency.go:356] Created: latency-svc-vxp6j
  I1026 13:38:40.790830 19 service_latency.go:363] Got endpoints: latency-svc-vxp6j [113.430715ms]
  I1026 13:38:40.791898 19 service_latency.go:356] Created: latency-svc-brblx
  I1026 13:38:40.796471 19 service_latency.go:363] Got endpoints: latency-svc-brblx [113.036575ms]
  I1026 13:38:40.798373 19 service_latency.go:356] Created: latency-svc-pqlp4
  I1026 13:38:40.804378 19 service_latency.go:363] Got endpoints: latency-svc-pqlp4 [112.462651ms]
  I1026 13:38:40.807181 19 service_latency.go:356] Created: latency-svc-lfgxq
  I1026 13:38:40.812696 19 service_latency.go:363] Got endpoints: latency-svc-lfgxq [115.241992ms]
  I1026 13:38:40.813697 19 service_latency.go:356] Created: latency-svc-srj69
  I1026 13:38:40.818558 19 service_latency.go:363] Got endpoints: latency-svc-srj69 [113.629835ms]
  I1026 13:38:40.823961 19 service_latency.go:356] Created: latency-svc-2pbvd
  I1026 13:38:40.828236 19 service_latency.go:363] Got endpoints: latency-svc-2pbvd [114.337127ms]
  I1026 13:38:40.829060 19 service_latency.go:356] Created: latency-svc-ksdrd
  I1026 13:38:40.834334 19 service_latency.go:363] Got endpoints: latency-svc-ksdrd [111.252213ms]
  I1026 13:38:40.836356 19 service_latency.go:356] Created: latency-svc-qklc6
  I1026 13:38:40.842495 19 service_latency.go:363] Got endpoints: latency-svc-qklc6 [115.129024ms]
  I1026 13:38:40.845731 19 service_latency.go:356] Created: latency-svc-jzf4b
  I1026 13:38:40.851172 19 service_latency.go:363] Got endpoints: latency-svc-jzf4b [114.14932ms]
  I1026 13:38:40.852216 19 service_latency.go:356] Created: latency-svc-vbk6x
  I1026 13:38:40.858887 19 service_latency.go:363] Got endpoints: latency-svc-vbk6x [113.034258ms]
  I1026 13:38:40.859382 19 service_latency.go:356] Created: latency-svc-nxzzz
  I1026 13:38:40.864392 19 service_latency.go:363] Got endpoints: latency-svc-nxzzz [111.309148ms]
  I1026 13:38:40.868569 19 service_latency.go:356] Created: latency-svc-qnprd
  I1026 13:38:40.874946 19 service_latency.go:356] Created: latency-svc-gtjmp
  I1026 13:38:40.880103 19 service_latency.go:356] Created: latency-svc-wmrvb
  I1026 13:38:40.885151 19 service_latency.go:356] Created: latency-svc-46n54
  I1026 13:38:40.889251 19 service_latency.go:356] Created: latency-svc-2wldh
  I1026 13:38:40.892876 19 service_latency.go:363] Got endpoints: latency-svc-qnprd [132.407076ms]
  I1026 13:38:40.897357 19 service_latency.go:356] Created: latency-svc-m55mv
  I1026 13:38:40.904156 19 service_latency.go:356] Created: latency-svc-s6n2q
  I1026 13:38:40.911387 19 service_latency.go:356] Created: latency-svc-xbq89
  I1026 13:38:40.916653 19 service_latency.go:356] Created: latency-svc-vkc9r
  I1026 13:38:40.922575 19 service_latency.go:356] Created: latency-svc-fbnrk
  I1026 13:38:40.929732 19 service_latency.go:356] Created: latency-svc-zz8ls
  I1026 13:38:40.935541 19 service_latency.go:356] Created: latency-svc-zswzz
  I1026 13:38:40.942906 19 service_latency.go:363] Got endpoints: latency-svc-gtjmp [174.571242ms]
  I1026 13:38:40.943883 19 service_latency.go:356] Created: latency-svc-wl9mr
  I1026 13:38:40.947334 19 service_latency.go:356] Created: latency-svc-n6wnh
  I1026 13:38:40.952325 19 service_latency.go:356] Created: latency-svc-cxm9r
  I1026 13:38:40.958712 19 service_latency.go:356] Created: latency-svc-wxqcc
  I1026 13:38:40.964533 19 service_latency.go:356] Created: latency-svc-xcnrz
  I1026 13:38:40.991330 19 service_latency.go:363] Got endpoints: latency-svc-wmrvb [217.770283ms]
  I1026 13:38:41.001638 19 service_latency.go:356] Created: latency-svc-5jq6m
  I1026 13:38:41.044701 19 service_latency.go:363] Got endpoints: latency-svc-46n54 [262.155954ms]
  I1026 13:38:41.055809 19 service_latency.go:356] Created: latency-svc-7vjjd
  I1026 13:38:41.093432 19 service_latency.go:363] Got endpoints: latency-svc-2wldh [302.577599ms]
  I1026 13:38:41.104704 19 service_latency.go:356] Created: latency-svc-bvhgl
  I1026 13:38:41.141882 19 service_latency.go:363] Got endpoints: latency-svc-m55mv [345.382243ms]
  I1026 13:38:41.154897 19 service_latency.go:356] Created: latency-svc-svshz
  I1026 13:38:41.192497 19 service_latency.go:363] Got endpoints: latency-svc-s6n2q [388.080249ms]
  I1026 13:38:41.204440 19 service_latency.go:356] Created: latency-svc-tcdvr
  I1026 13:38:41.243076 19 service_latency.go:363] Got endpoints: latency-svc-xbq89 [430.351396ms]
  I1026 13:38:41.255085 19 service_latency.go:356] Created: latency-svc-kvlrv
  I1026 13:38:41.294014 19 service_latency.go:363] Got endpoints: latency-svc-vkc9r [475.43109ms]
  I1026 13:38:41.305485 19 service_latency.go:356] Created: latency-svc-qpfhv
  I1026 13:38:41.343321 19 service_latency.go:363] Got endpoints: latency-svc-fbnrk [515.053612ms]
  I1026 13:38:41.356460 19 service_latency.go:356] Created: latency-svc-bxh5q
  I1026 13:38:41.393420 19 service_latency.go:363] Got endpoints: latency-svc-zz8ls [559.057519ms]
  I1026 13:38:41.404966 19 service_latency.go:356] Created: latency-svc-qvg25
  I1026 13:38:41.443086 19 service_latency.go:363] Got endpoints: latency-svc-zswzz [600.561886ms]
  I1026 13:38:41.453440 19 service_latency.go:356] Created: latency-svc-lzg5l
  E1026 13:38:41.482572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:41.492342 19 service_latency.go:363] Got endpoints: latency-svc-wl9mr [641.141621ms]
  I1026 13:38:41.505223 19 service_latency.go:356] Created: latency-svc-q57vj
  I1026 13:38:41.544321 19 service_latency.go:363] Got endpoints: latency-svc-n6wnh [685.400476ms]
  I1026 13:38:41.557230 19 service_latency.go:356] Created: latency-svc-k8ds6
  I1026 13:38:41.594155 19 service_latency.go:363] Got endpoints: latency-svc-cxm9r [729.546999ms]
  I1026 13:38:41.604455 19 service_latency.go:356] Created: latency-svc-sdz5f
  I1026 13:38:41.642991 19 service_latency.go:363] Got endpoints: latency-svc-wxqcc [750.077625ms]
  I1026 13:38:41.654910 19 service_latency.go:356] Created: latency-svc-bzkmb
  I1026 13:38:41.692406 19 service_latency.go:363] Got endpoints: latency-svc-xcnrz [749.472801ms]
  I1026 13:38:41.705373 19 service_latency.go:356] Created: latency-svc-bbsqm
  I1026 13:38:41.741484 19 service_latency.go:363] Got endpoints: latency-svc-5jq6m [750.129347ms]
  I1026 13:38:41.752442 19 service_latency.go:356] Created: latency-svc-stfcn
  I1026 13:38:41.792144 19 service_latency.go:363] Got endpoints: latency-svc-7vjjd [747.413373ms]
  I1026 13:38:41.803029 19 service_latency.go:356] Created: latency-svc-z5kvh
  I1026 13:38:41.844175 19 service_latency.go:363] Got endpoints: latency-svc-bvhgl [750.701168ms]
  I1026 13:38:41.855531 19 service_latency.go:356] Created: latency-svc-9jzwb
  I1026 13:38:41.894495 19 service_latency.go:363] Got endpoints: latency-svc-svshz [752.579354ms]
  I1026 13:38:41.905732 19 service_latency.go:356] Created: latency-svc-7vs29
  I1026 13:38:41.942883 19 service_latency.go:363] Got endpoints: latency-svc-tcdvr [750.352134ms]
  I1026 13:38:41.954959 19 service_latency.go:356] Created: latency-svc-xhlbj
  I1026 13:38:41.993600 19 service_latency.go:363] Got endpoints: latency-svc-kvlrv [750.483437ms]
  I1026 13:38:42.004588 19 service_latency.go:356] Created: latency-svc-4ffk8
  I1026 13:38:42.043925 19 service_latency.go:363] Got endpoints: latency-svc-qpfhv [749.876384ms]
  I1026 13:38:42.055596 19 service_latency.go:356] Created: latency-svc-dxqg7
  I1026 13:38:42.092769 19 service_latency.go:363] Got endpoints: latency-svc-bxh5q [749.414132ms]
  I1026 13:38:42.104777 19 service_latency.go:356] Created: latency-svc-49lls
  I1026 13:38:42.142391 19 service_latency.go:363] Got endpoints: latency-svc-qvg25 [748.935666ms]
  I1026 13:38:42.155190 19 service_latency.go:356] Created: latency-svc-sm87v
  I1026 13:38:42.192844 19 service_latency.go:363] Got endpoints: latency-svc-lzg5l [749.724195ms]
  I1026 13:38:42.203969 19 service_latency.go:356] Created: latency-svc-9k2xc
  I1026 13:38:42.242971 19 service_latency.go:363] Got endpoints: latency-svc-q57vj [750.540932ms]
  I1026 13:38:42.254391 19 service_latency.go:356] Created: latency-svc-5x9fz
  I1026 13:38:42.293608 19 service_latency.go:363] Got endpoints: latency-svc-k8ds6 [749.255794ms]
  I1026 13:38:42.305189 19 service_latency.go:356] Created: latency-svc-p9cmt
  I1026 13:38:42.341780 19 service_latency.go:363] Got endpoints: latency-svc-sdz5f [747.594848ms]
  I1026 13:38:42.353617 19 service_latency.go:356] Created: latency-svc-lhmvx
  I1026 13:38:42.392008 19 service_latency.go:363] Got endpoints: latency-svc-bzkmb [748.98957ms]
  I1026 13:38:42.405551 19 service_latency.go:356] Created: latency-svc-lmhn6
  I1026 13:38:42.442579 19 service_latency.go:363] Got endpoints: latency-svc-bbsqm [750.143197ms]
  I1026 13:38:42.454072 19 service_latency.go:356] Created: latency-svc-hvkn4
  E1026 13:38:42.483340      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:42.493981 19 service_latency.go:363] Got endpoints: latency-svc-stfcn [752.46622ms]
  I1026 13:38:42.505033 19 service_latency.go:356] Created: latency-svc-gp79n
  I1026 13:38:42.544229 19 service_latency.go:363] Got endpoints: latency-svc-z5kvh [752.048203ms]
  I1026 13:38:42.556084 19 service_latency.go:356] Created: latency-svc-9ghtd
  I1026 13:38:42.592466 19 service_latency.go:363] Got endpoints: latency-svc-9jzwb [748.264222ms]
  I1026 13:38:42.606348 19 service_latency.go:356] Created: latency-svc-z47sz
  I1026 13:38:42.641899 19 service_latency.go:363] Got endpoints: latency-svc-7vs29 [747.377448ms]
  I1026 13:38:42.653944 19 service_latency.go:356] Created: latency-svc-gnssw
  I1026 13:38:42.693695 19 service_latency.go:363] Got endpoints: latency-svc-xhlbj [750.777756ms]
  I1026 13:38:42.704592 19 service_latency.go:356] Created: latency-svc-hw8ng
  I1026 13:38:42.743274 19 service_latency.go:363] Got endpoints: latency-svc-4ffk8 [749.645453ms]
  I1026 13:38:42.754498 19 service_latency.go:356] Created: latency-svc-pq5tt
  I1026 13:38:42.793143 19 service_latency.go:363] Got endpoints: latency-svc-dxqg7 [749.179057ms]
  I1026 13:38:42.805802 19 service_latency.go:356] Created: latency-svc-bmlf4
  I1026 13:38:42.842694 19 service_latency.go:363] Got endpoints: latency-svc-49lls [749.85981ms]
  I1026 13:38:42.852836 19 service_latency.go:356] Created: latency-svc-pwv7r
  I1026 13:38:42.895298 19 service_latency.go:363] Got endpoints: latency-svc-sm87v [752.874245ms]
  I1026 13:38:42.906791 19 service_latency.go:356] Created: latency-svc-sgjwb
  I1026 13:38:42.943455 19 service_latency.go:363] Got endpoints: latency-svc-9k2xc [750.573276ms]
  I1026 13:38:42.953507 19 service_latency.go:356] Created: latency-svc-ftqrt
  I1026 13:38:42.993576 19 service_latency.go:363] Got endpoints: latency-svc-5x9fz [750.569733ms]
  I1026 13:38:43.004737 19 service_latency.go:356] Created: latency-svc-h48xr
  I1026 13:38:43.042295 19 service_latency.go:363] Got endpoints: latency-svc-p9cmt [748.653402ms]
  I1026 13:38:43.057072 19 service_latency.go:356] Created: latency-svc-94r48
  I1026 13:38:43.091515 19 service_latency.go:363] Got endpoints: latency-svc-lhmvx [749.706145ms]
  I1026 13:38:43.102000 19 service_latency.go:356] Created: latency-svc-tkgzt
  I1026 13:38:43.144326 19 service_latency.go:363] Got endpoints: latency-svc-lmhn6 [752.273227ms]
  I1026 13:38:43.156580 19 service_latency.go:356] Created: latency-svc-wjbwh
  I1026 13:38:43.193027 19 service_latency.go:363] Got endpoints: latency-svc-hvkn4 [750.407062ms]
  I1026 13:38:43.204199 19 service_latency.go:356] Created: latency-svc-wx4lm
  I1026 13:38:43.243219 19 service_latency.go:363] Got endpoints: latency-svc-gp79n [749.205511ms]
  I1026 13:38:43.253716 19 service_latency.go:356] Created: latency-svc-srxxr
  I1026 13:38:43.291812 19 service_latency.go:363] Got endpoints: latency-svc-9ghtd [747.550123ms]
  I1026 13:38:43.304944 19 service_latency.go:356] Created: latency-svc-lqsnc
  I1026 13:38:43.341551 19 service_latency.go:363] Got endpoints: latency-svc-z47sz [749.051273ms]
  I1026 13:38:43.354658 19 service_latency.go:356] Created: latency-svc-ffdng
  I1026 13:38:43.392274 19 service_latency.go:363] Got endpoints: latency-svc-gnssw [750.346167ms]
  I1026 13:38:43.404492 19 service_latency.go:356] Created: latency-svc-5hr8t
  I1026 13:38:43.442056 19 service_latency.go:363] Got endpoints: latency-svc-hw8ng [748.325876ms]
  I1026 13:38:43.452937 19 service_latency.go:356] Created: latency-svc-psmsq
  E1026 13:38:43.484019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:43.492629 19 service_latency.go:363] Got endpoints: latency-svc-pq5tt [749.32533ms]
  I1026 13:38:43.504235 19 service_latency.go:356] Created: latency-svc-mh5s2
  I1026 13:38:43.542927 19 service_latency.go:363] Got endpoints: latency-svc-bmlf4 [749.751997ms]
  I1026 13:38:43.553783 19 service_latency.go:356] Created: latency-svc-ktxsq
  I1026 13:38:43.591765 19 service_latency.go:363] Got endpoints: latency-svc-pwv7r [749.04279ms]
  I1026 13:38:43.605138 19 service_latency.go:356] Created: latency-svc-6mzbv
  I1026 13:38:43.643289 19 service_latency.go:363] Got endpoints: latency-svc-sgjwb [747.938631ms]
  I1026 13:38:43.655331 19 service_latency.go:356] Created: latency-svc-kphld
  I1026 13:38:43.693066 19 service_latency.go:363] Got endpoints: latency-svc-ftqrt [749.577883ms]
  I1026 13:38:43.703024 19 service_latency.go:356] Created: latency-svc-n6wqg
  I1026 13:38:43.742973 19 service_latency.go:363] Got endpoints: latency-svc-h48xr [749.356844ms]
  I1026 13:38:43.755026 19 service_latency.go:356] Created: latency-svc-prc2h
  I1026 13:38:43.792858 19 service_latency.go:363] Got endpoints: latency-svc-94r48 [750.523191ms]
  I1026 13:38:43.805568 19 service_latency.go:356] Created: latency-svc-7s7qs
  I1026 13:38:43.841874 19 service_latency.go:363] Got endpoints: latency-svc-tkgzt [750.323361ms]
  I1026 13:38:43.853100 19 service_latency.go:356] Created: latency-svc-5nk5g
  I1026 13:38:43.892428 19 service_latency.go:363] Got endpoints: latency-svc-wjbwh [748.071505ms]
  I1026 13:38:43.902988 19 service_latency.go:356] Created: latency-svc-zmhl8
  I1026 13:38:43.944014 19 service_latency.go:363] Got endpoints: latency-svc-wx4lm [750.954595ms]
  I1026 13:38:43.955829 19 service_latency.go:356] Created: latency-svc-8wz8q
  I1026 13:38:43.993100 19 service_latency.go:363] Got endpoints: latency-svc-srxxr [749.810559ms]
  I1026 13:38:44.003099 19 service_latency.go:356] Created: latency-svc-f4zvm
  I1026 13:38:44.042093 19 service_latency.go:363] Got endpoints: latency-svc-lqsnc [750.245091ms]
  I1026 13:38:44.055166 19 service_latency.go:356] Created: latency-svc-ftbjn
  I1026 13:38:44.092772 19 service_latency.go:363] Got endpoints: latency-svc-ffdng [751.161652ms]
  I1026 13:38:44.103654 19 service_latency.go:356] Created: latency-svc-4bt6h
  I1026 13:38:44.143182 19 service_latency.go:363] Got endpoints: latency-svc-5hr8t [750.855914ms]
  I1026 13:38:44.154328 19 service_latency.go:356] Created: latency-svc-8z8vd
  I1026 13:38:44.193892 19 service_latency.go:363] Got endpoints: latency-svc-psmsq [751.796592ms]
  I1026 13:38:44.205697 19 service_latency.go:356] Created: latency-svc-jdvpr
  I1026 13:38:44.242775 19 service_latency.go:363] Got endpoints: latency-svc-mh5s2 [750.114259ms]
  I1026 13:38:44.256005 19 service_latency.go:356] Created: latency-svc-qgzkn
  I1026 13:38:44.291236 19 service_latency.go:363] Got endpoints: latency-svc-ktxsq [748.271265ms]
  I1026 13:38:44.301448 19 service_latency.go:356] Created: latency-svc-c8hd5
  I1026 13:38:44.342920 19 service_latency.go:363] Got endpoints: latency-svc-6mzbv [751.084614ms]
  I1026 13:38:44.353766 19 service_latency.go:356] Created: latency-svc-nxjdr
  I1026 13:38:44.393541 19 service_latency.go:363] Got endpoints: latency-svc-kphld [750.142159ms]
  I1026 13:38:44.404806 19 service_latency.go:356] Created: latency-svc-949ht
  I1026 13:38:44.441129 19 service_latency.go:363] Got endpoints: latency-svc-n6wqg [748.022716ms]
  I1026 13:38:44.453759 19 service_latency.go:356] Created: latency-svc-xgs8h
  E1026 13:38:44.485016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:44.492885 19 service_latency.go:363] Got endpoints: latency-svc-prc2h [749.877177ms]
  I1026 13:38:44.502612 19 service_latency.go:356] Created: latency-svc-2b7bc
  I1026 13:38:44.543545 19 service_latency.go:363] Got endpoints: latency-svc-7s7qs [750.607399ms]
  I1026 13:38:44.553451 19 service_latency.go:356] Created: latency-svc-swfff
  I1026 13:38:44.592289 19 service_latency.go:363] Got endpoints: latency-svc-5nk5g [750.352562ms]
  I1026 13:38:44.601942 19 service_latency.go:356] Created: latency-svc-v4c6f
  I1026 13:38:44.642467 19 service_latency.go:363] Got endpoints: latency-svc-zmhl8 [749.996337ms]
  I1026 13:38:44.653837 19 service_latency.go:356] Created: latency-svc-6zxkb
  I1026 13:38:44.693182 19 service_latency.go:363] Got endpoints: latency-svc-8wz8q [749.132354ms]
  I1026 13:38:44.704627 19 service_latency.go:356] Created: latency-svc-ttr87
  I1026 13:38:44.742273 19 service_latency.go:363] Got endpoints: latency-svc-f4zvm [749.145734ms]
  I1026 13:38:44.754740 19 service_latency.go:356] Created: latency-svc-4l6cl
  I1026 13:38:44.792656 19 service_latency.go:363] Got endpoints: latency-svc-ftbjn [750.512229ms]
  I1026 13:38:44.806661 19 service_latency.go:356] Created: latency-svc-2r862
  I1026 13:38:44.841983 19 service_latency.go:363] Got endpoints: latency-svc-4bt6h [749.164985ms]
  I1026 13:38:44.853260 19 service_latency.go:356] Created: latency-svc-httx2
  I1026 13:38:44.892579 19 service_latency.go:363] Got endpoints: latency-svc-8z8vd [749.360144ms]
  I1026 13:38:44.903154 19 service_latency.go:356] Created: latency-svc-8zc8s
  I1026 13:38:44.944352 19 service_latency.go:363] Got endpoints: latency-svc-jdvpr [750.413835ms]
  I1026 13:38:44.955779 19 service_latency.go:356] Created: latency-svc-mhgmv
  I1026 13:38:44.992085 19 service_latency.go:363] Got endpoints: latency-svc-qgzkn [749.270303ms]
  I1026 13:38:45.004999 19 service_latency.go:356] Created: latency-svc-vq62t
  I1026 13:38:45.041581 19 service_latency.go:363] Got endpoints: latency-svc-c8hd5 [750.307653ms]
  I1026 13:38:45.052354 19 service_latency.go:356] Created: latency-svc-j2pzh
  I1026 13:38:45.093912 19 service_latency.go:363] Got endpoints: latency-svc-nxjdr [750.94849ms]
  I1026 13:38:45.104126 19 service_latency.go:356] Created: latency-svc-gvv66
  I1026 13:38:45.142991 19 service_latency.go:363] Got endpoints: latency-svc-949ht [749.412488ms]
  I1026 13:38:45.155558 19 service_latency.go:356] Created: latency-svc-gs8w7
  I1026 13:38:45.191847 19 service_latency.go:363] Got endpoints: latency-svc-xgs8h [750.582175ms]
  I1026 13:38:45.204887 19 service_latency.go:356] Created: latency-svc-82v85
  I1026 13:38:45.242172 19 service_latency.go:363] Got endpoints: latency-svc-2b7bc [749.243153ms]
  I1026 13:38:45.256145 19 service_latency.go:356] Created: latency-svc-pk8dt
  I1026 13:38:45.293098 19 service_latency.go:363] Got endpoints: latency-svc-swfff [749.511596ms]
  I1026 13:38:45.305613 19 service_latency.go:356] Created: latency-svc-b7n99
  I1026 13:38:45.341134 19 service_latency.go:363] Got endpoints: latency-svc-v4c6f [748.805564ms]
  I1026 13:38:45.351323 19 service_latency.go:356] Created: latency-svc-x8kxq
  I1026 13:38:45.393918 19 service_latency.go:363] Got endpoints: latency-svc-6zxkb [751.415214ms]
  I1026 13:38:45.404549 19 service_latency.go:356] Created: latency-svc-xjr44
  I1026 13:38:45.443827 19 service_latency.go:363] Got endpoints: latency-svc-ttr87 [750.60421ms]
  I1026 13:38:45.455088 19 service_latency.go:356] Created: latency-svc-k692s
  E1026 13:38:45.485363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:45.491842 19 service_latency.go:363] Got endpoints: latency-svc-4l6cl [749.536548ms]
  I1026 13:38:45.503235 19 service_latency.go:356] Created: latency-svc-9lzjr
  I1026 13:38:45.542071 19 service_latency.go:363] Got endpoints: latency-svc-2r862 [749.35421ms]
  I1026 13:38:45.554477 19 service_latency.go:356] Created: latency-svc-5tjdx
  I1026 13:38:45.593494 19 service_latency.go:363] Got endpoints: latency-svc-httx2 [751.469341ms]
  I1026 13:38:45.604807 19 service_latency.go:356] Created: latency-svc-mnndh
  I1026 13:38:45.642930 19 service_latency.go:363] Got endpoints: latency-svc-8zc8s [750.313132ms]
  I1026 13:38:45.653700 19 service_latency.go:356] Created: latency-svc-ksc65
  I1026 13:38:45.692884 19 service_latency.go:363] Got endpoints: latency-svc-mhgmv [748.501682ms]
  I1026 13:38:45.706371 19 service_latency.go:356] Created: latency-svc-qfqmh
  I1026 13:38:45.742017 19 service_latency.go:363] Got endpoints: latency-svc-vq62t [749.888073ms]
  I1026 13:38:45.755904 19 service_latency.go:356] Created: latency-svc-qgvz2
  I1026 13:38:45.793412 19 service_latency.go:363] Got endpoints: latency-svc-j2pzh [751.760428ms]
  I1026 13:38:45.804159 19 service_latency.go:356] Created: latency-svc-qhchg
  I1026 13:38:45.842775 19 service_latency.go:363] Got endpoints: latency-svc-gvv66 [748.812364ms]
  I1026 13:38:45.853014 19 service_latency.go:356] Created: latency-svc-tjv2z
  I1026 13:38:45.894746 19 service_latency.go:363] Got endpoints: latency-svc-gs8w7 [751.691608ms]
  I1026 13:38:45.905877 19 service_latency.go:356] Created: latency-svc-ptgsc
  I1026 13:38:45.941655 19 service_latency.go:363] Got endpoints: latency-svc-82v85 [749.718378ms]
  I1026 13:38:45.954767 19 service_latency.go:356] Created: latency-svc-pbzn9
  I1026 13:38:45.993072 19 service_latency.go:363] Got endpoints: latency-svc-pk8dt [750.851665ms]
  I1026 13:38:46.005116 19 service_latency.go:356] Created: latency-svc-gvhkw
  I1026 13:38:46.043393 19 service_latency.go:363] Got endpoints: latency-svc-b7n99 [750.247745ms]
  I1026 13:38:46.056190 19 service_latency.go:356] Created: latency-svc-jwpx5
  I1026 13:38:46.093904 19 service_latency.go:363] Got endpoints: latency-svc-x8kxq [752.728763ms]
  I1026 13:38:46.103859 19 service_latency.go:356] Created: latency-svc-95ndg
  I1026 13:38:46.141963 19 service_latency.go:363] Got endpoints: latency-svc-xjr44 [748.004015ms]
  I1026 13:38:46.155352 19 service_latency.go:356] Created: latency-svc-vhzwp
  I1026 13:38:46.191836 19 service_latency.go:363] Got endpoints: latency-svc-k692s [747.971211ms]
  I1026 13:38:46.202249 19 service_latency.go:356] Created: latency-svc-z6w2m
  I1026 13:38:46.243401 19 service_latency.go:363] Got endpoints: latency-svc-9lzjr [751.481894ms]
  I1026 13:38:46.254964 19 service_latency.go:356] Created: latency-svc-j54rs
  I1026 13:38:46.293268 19 service_latency.go:363] Got endpoints: latency-svc-5tjdx [751.160507ms]
  I1026 13:38:46.304884 19 service_latency.go:356] Created: latency-svc-8z8qd
  I1026 13:38:46.345166 19 service_latency.go:363] Got endpoints: latency-svc-mnndh [751.640576ms]
  I1026 13:38:46.358774 19 service_latency.go:356] Created: latency-svc-bg87w
  I1026 13:38:46.392078 19 service_latency.go:363] Got endpoints: latency-svc-ksc65 [749.109035ms]
  I1026 13:38:46.404659 19 service_latency.go:356] Created: latency-svc-rj6z7
  I1026 13:38:46.442803 19 service_latency.go:363] Got endpoints: latency-svc-qfqmh [749.882625ms]
  I1026 13:38:46.454483 19 service_latency.go:356] Created: latency-svc-hqxlm
  E1026 13:38:46.486433      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:46.494265 19 service_latency.go:363] Got endpoints: latency-svc-qgvz2 [752.200717ms]
  I1026 13:38:46.505316 19 service_latency.go:356] Created: latency-svc-tqxw9
  I1026 13:38:46.543721 19 service_latency.go:363] Got endpoints: latency-svc-qhchg [750.273415ms]
  I1026 13:38:46.555290 19 service_latency.go:356] Created: latency-svc-tqx2r
  I1026 13:38:46.591776 19 service_latency.go:363] Got endpoints: latency-svc-tjv2z [748.955945ms]
  I1026 13:38:46.605118 19 service_latency.go:356] Created: latency-svc-m7srt
  I1026 13:38:46.641549 19 service_latency.go:363] Got endpoints: latency-svc-ptgsc [746.759987ms]
  I1026 13:38:46.654303 19 service_latency.go:356] Created: latency-svc-twbhb
  I1026 13:38:46.694592 19 service_latency.go:363] Got endpoints: latency-svc-pbzn9 [752.879537ms]
  I1026 13:38:46.705812 19 service_latency.go:356] Created: latency-svc-b624b
  I1026 13:38:46.746506 19 service_latency.go:363] Got endpoints: latency-svc-gvhkw [753.402271ms]
  I1026 13:38:46.757853 19 service_latency.go:356] Created: latency-svc-5j5gb
  I1026 13:38:46.791640 19 service_latency.go:363] Got endpoints: latency-svc-jwpx5 [748.204011ms]
  I1026 13:38:46.805102 19 service_latency.go:356] Created: latency-svc-6gq9g
  I1026 13:38:46.841740 19 service_latency.go:363] Got endpoints: latency-svc-95ndg [747.799365ms]
  I1026 13:38:46.855181 19 service_latency.go:356] Created: latency-svc-gmzh2
  I1026 13:38:46.894354 19 service_latency.go:363] Got endpoints: latency-svc-vhzwp [752.35231ms]
  I1026 13:38:46.906229 19 service_latency.go:356] Created: latency-svc-bk8cv
  I1026 13:38:46.943727 19 service_latency.go:363] Got endpoints: latency-svc-z6w2m [751.847841ms]
  I1026 13:38:46.956260 19 service_latency.go:356] Created: latency-svc-zx5wl
  I1026 13:38:46.993627 19 service_latency.go:363] Got endpoints: latency-svc-j54rs [750.154224ms]
  I1026 13:38:47.007101 19 service_latency.go:356] Created: latency-svc-gznjb
  I1026 13:38:47.042824 19 service_latency.go:363] Got endpoints: latency-svc-8z8qd [749.521898ms]
  I1026 13:38:47.056242 19 service_latency.go:356] Created: latency-svc-dqndm
  I1026 13:38:47.091879 19 service_latency.go:363] Got endpoints: latency-svc-bg87w [746.68168ms]
  I1026 13:38:47.103176 19 service_latency.go:356] Created: latency-svc-7dvnh
  I1026 13:38:47.142856 19 service_latency.go:363] Got endpoints: latency-svc-rj6z7 [750.731654ms]
  I1026 13:38:47.152539 19 service_latency.go:356] Created: latency-svc-wwn55
  I1026 13:38:47.193806 19 service_latency.go:363] Got endpoints: latency-svc-hqxlm [750.88097ms]
  I1026 13:38:47.205422 19 service_latency.go:356] Created: latency-svc-g9l9n
  I1026 13:38:47.244113 19 service_latency.go:363] Got endpoints: latency-svc-tqxw9 [749.816353ms]
  I1026 13:38:47.256363 19 service_latency.go:356] Created: latency-svc-jrpmg
  I1026 13:38:47.291799 19 service_latency.go:363] Got endpoints: latency-svc-tqx2r [748.042821ms]
  I1026 13:38:47.303941 19 service_latency.go:356] Created: latency-svc-2gkrp
  I1026 13:38:47.342670 19 service_latency.go:363] Got endpoints: latency-svc-m7srt [750.852736ms]
  I1026 13:38:47.355544 19 service_latency.go:356] Created: latency-svc-p6tkp
  I1026 13:38:47.391763 19 service_latency.go:363] Got endpoints: latency-svc-twbhb [750.173857ms]
  I1026 13:38:47.405119 19 service_latency.go:356] Created: latency-svc-jw5t8
  I1026 13:38:47.441576 19 service_latency.go:363] Got endpoints: latency-svc-b624b [746.939251ms]
  I1026 13:38:47.452148 19 service_latency.go:356] Created: latency-svc-pqvlc
  E1026 13:38:47.487453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:47.493205 19 service_latency.go:363] Got endpoints: latency-svc-5j5gb [746.663702ms]
  I1026 13:38:47.504555 19 service_latency.go:356] Created: latency-svc-j6wth
  I1026 13:38:47.544076 19 service_latency.go:363] Got endpoints: latency-svc-6gq9g [752.3772ms]
  I1026 13:38:47.555566 19 service_latency.go:356] Created: latency-svc-vgvkn
  I1026 13:38:47.591948 19 service_latency.go:363] Got endpoints: latency-svc-gmzh2 [750.174178ms]
  I1026 13:38:47.604162 19 service_latency.go:356] Created: latency-svc-57rjn
  I1026 13:38:47.642824 19 service_latency.go:363] Got endpoints: latency-svc-bk8cv [748.429124ms]
  I1026 13:38:47.654015 19 service_latency.go:356] Created: latency-svc-5wv5p
  I1026 13:38:47.694308 19 service_latency.go:363] Got endpoints: latency-svc-zx5wl [750.540978ms]
  I1026 13:38:47.705612 19 service_latency.go:356] Created: latency-svc-nl4kw
  I1026 13:38:47.743925 19 service_latency.go:363] Got endpoints: latency-svc-gznjb [750.253748ms]
  I1026 13:38:47.755153 19 service_latency.go:356] Created: latency-svc-dkxx7
  I1026 13:38:47.791574 19 service_latency.go:363] Got endpoints: latency-svc-dqndm [748.711854ms]
  I1026 13:38:47.803910 19 service_latency.go:356] Created: latency-svc-sm6cv
  I1026 13:38:47.841737 19 service_latency.go:363] Got endpoints: latency-svc-7dvnh [749.818001ms]
  I1026 13:38:47.853732 19 service_latency.go:356] Created: latency-svc-cwlh5
  I1026 13:38:47.893188 19 service_latency.go:363] Got endpoints: latency-svc-wwn55 [750.290384ms]
  I1026 13:38:47.902809 19 service_latency.go:356] Created: latency-svc-gzct2
  I1026 13:38:47.944421 19 service_latency.go:363] Got endpoints: latency-svc-g9l9n [750.568493ms]
  I1026 13:38:47.955951 19 service_latency.go:356] Created: latency-svc-7m8kt
  I1026 13:38:47.993277 19 service_latency.go:363] Got endpoints: latency-svc-jrpmg [749.131974ms]
  I1026 13:38:48.005300 19 service_latency.go:356] Created: latency-svc-hlm8w
  I1026 13:38:48.042711 19 service_latency.go:363] Got endpoints: latency-svc-2gkrp [750.883394ms]
  I1026 13:38:48.056043 19 service_latency.go:356] Created: latency-svc-pd7lm
  I1026 13:38:48.097562 19 service_latency.go:363] Got endpoints: latency-svc-p6tkp [754.840951ms]
  I1026 13:38:48.107887 19 service_latency.go:356] Created: latency-svc-x98jq
  I1026 13:38:48.142608 19 service_latency.go:363] Got endpoints: latency-svc-jw5t8 [750.808146ms]
  I1026 13:38:48.153659 19 service_latency.go:356] Created: latency-svc-p54xv
  I1026 13:38:48.193008 19 service_latency.go:363] Got endpoints: latency-svc-pqvlc [751.401941ms]
  I1026 13:38:48.208546 19 service_latency.go:356] Created: latency-svc-s7jh5
  I1026 13:38:48.243414 19 service_latency.go:363] Got endpoints: latency-svc-j6wth [750.180678ms]
  I1026 13:38:48.256592 19 service_latency.go:356] Created: latency-svc-qmgkp
  I1026 13:38:48.291376 19 service_latency.go:363] Got endpoints: latency-svc-vgvkn [747.267386ms]
  I1026 13:38:48.304850 19 service_latency.go:356] Created: latency-svc-dwsrj
  I1026 13:38:48.342895 19 service_latency.go:363] Got endpoints: latency-svc-57rjn [750.918133ms]
  I1026 13:38:48.352783 19 service_latency.go:356] Created: latency-svc-6ckq6
  I1026 13:38:48.392532 19 service_latency.go:363] Got endpoints: latency-svc-5wv5p [749.677272ms]
  I1026 13:38:48.403567 19 service_latency.go:356] Created: latency-svc-2wxpl
  I1026 13:38:48.443788 19 service_latency.go:363] Got endpoints: latency-svc-nl4kw [749.438554ms]
  E1026 13:38:48.487864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:48.491731 19 service_latency.go:363] Got endpoints: latency-svc-dkxx7 [747.765462ms]
  I1026 13:38:48.542637 19 service_latency.go:363] Got endpoints: latency-svc-sm6cv [751.034751ms]
  I1026 13:38:48.592278 19 service_latency.go:363] Got endpoints: latency-svc-cwlh5 [750.509887ms]
  I1026 13:38:48.643035 19 service_latency.go:363] Got endpoints: latency-svc-gzct2 [749.804433ms]
  I1026 13:38:48.692783 19 service_latency.go:363] Got endpoints: latency-svc-7m8kt [748.321369ms]
  I1026 13:38:48.743444 19 service_latency.go:363] Got endpoints: latency-svc-hlm8w [750.104538ms]
  I1026 13:38:48.791879 19 service_latency.go:363] Got endpoints: latency-svc-pd7lm [749.131671ms]
  I1026 13:38:48.844169 19 service_latency.go:363] Got endpoints: latency-svc-x98jq [746.575581ms]
  I1026 13:38:48.892599 19 service_latency.go:363] Got endpoints: latency-svc-p54xv [749.947634ms]
  I1026 13:38:48.942777 19 service_latency.go:363] Got endpoints: latency-svc-s7jh5 [749.711635ms]
  I1026 13:38:48.992298 19 service_latency.go:363] Got endpoints: latency-svc-qmgkp [748.849633ms]
  I1026 13:38:49.042619 19 service_latency.go:363] Got endpoints: latency-svc-dwsrj [751.199233ms]
  I1026 13:38:49.092632 19 service_latency.go:363] Got endpoints: latency-svc-6ckq6 [749.676587ms]
  I1026 13:38:49.148756 19 service_latency.go:363] Got endpoints: latency-svc-2wxpl [756.190601ms]
  I1026 13:38:49.150761 19 service_latency.go:114] Latencies: [18.523466ms 28.882275ms 36.587586ms 42.288749ms 50.43884ms 59.318408ms 66.093622ms 72.68513ms 82.355073ms 88.305892ms 96.795855ms 102.315632ms 109.771978ms 111.252213ms 111.309148ms 112.279648ms 112.462651ms 113.034258ms 113.036575ms 113.154462ms 113.430715ms 113.629835ms 113.800077ms 113.900805ms 114.14932ms 114.154195ms 114.337127ms 114.815012ms 114.952069ms 115.129024ms 115.241992ms 115.882018ms 118.78888ms 128.012999ms 132.407076ms 174.571242ms 217.770283ms 262.155954ms 302.577599ms 345.382243ms 388.080249ms 430.351396ms 475.43109ms 515.053612ms 559.057519ms 600.561886ms 641.141621ms 685.400476ms 729.546999ms 746.575581ms 746.663702ms 746.68168ms 746.759987ms 746.939251ms 747.267386ms 747.377448ms 747.413373ms 747.550123ms 747.594848ms 747.765462ms 747.799365ms 747.938631ms 747.971211ms 748.004015ms 748.022716ms 748.042821ms 748.071505ms 748.204011ms 748.264222ms 748.271265ms 748.321369ms 748.325876ms 748.429124ms 748.501682ms 748.653402ms 748.711854ms 748.805564ms 748.812364ms 748.849633ms 748.935666ms 748.955945ms 748.98957ms 749.04279ms 749.051273ms 749.109035ms 749.131671ms 749.131974ms 749.132354ms 749.145734ms 749.164985ms 749.179057ms 749.205511ms 749.243153ms 749.255794ms 749.270303ms 749.32533ms 749.35421ms 749.356844ms 749.360144ms 749.412488ms 749.414132ms 749.438554ms 749.472801ms 749.511596ms 749.521898ms 749.536548ms 749.577883ms 749.645453ms 749.676587ms 749.677272ms 749.706145ms 749.711635ms 749.718378ms 749.724195ms 749.751997ms 749.804433ms 749.810559ms 749.816353ms 749.818001ms 749.85981ms 749.876384ms 749.877177ms 749.882625ms 749.888073ms 749.947634ms 749.996337ms 750.077625ms 750.104538ms 750.114259ms 750.129347ms 750.142159ms 750.143197ms 750.154224ms 750.173857ms 750.174178ms 750.180678ms 750.245091ms 750.247745ms 750.253748ms 750.273415ms 750.290384ms 750.307653ms 750.313132ms 750.323361ms 750.346167ms 750.352134ms 750.352562ms 750.407062ms 750.413835ms 750.483437ms 750.509887ms 750.512229ms 750.523191ms 750.540932ms 750.540978ms 750.568493ms 750.569733ms 750.573276ms 750.582175ms 750.60421ms 750.607399ms 750.701168ms 750.731654ms 750.777756ms 750.808146ms 750.851665ms 750.852736ms 750.855914ms 750.88097ms 750.883394ms 750.918133ms 750.94849ms 750.954595ms 751.034751ms 751.084614ms 751.160507ms 751.161652ms 751.199233ms 751.401941ms 751.415214ms 751.469341ms 751.481894ms 751.640576ms 751.691608ms 751.760428ms 751.796592ms 751.847841ms 752.048203ms 752.200717ms 752.273227ms 752.35231ms 752.3772ms 752.46622ms 752.579354ms 752.728763ms 752.874245ms 752.879537ms 753.402271ms 754.840951ms 756.190601ms]
  I1026 13:38:49.151183 19 service_latency.go:118] 50 %ile: 749.414132ms
  I1026 13:38:49.151380 19 service_latency.go:119] 90 %ile: 751.469341ms
  I1026 13:38:49.151388 19 service_latency.go:120] 99 %ile: 754.840951ms
  I1026 13:38:49.151394 19 service_latency.go:121] Total sample count: 200
  I1026 13:38:49.151743 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-6254" for this suite. @ 10/26/24 13:38:49.159
• [9.779 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3184
  STEP: Creating a kubernetes client @ 10/26/24 13:38:49.169
  I1026 13:38:49.169269 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:38:49.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:38:49.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:38:49.193
  STEP: fetching services @ 10/26/24 13:38:49.196
  I1026 13:38:49.203876 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2285" for this suite. @ 10/26/24 13:38:49.207
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 10/26/24 13:38:49.215
  I1026 13:38:49.215705 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename daemonsets @ 10/26/24 13:38:49.216
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:38:49.234
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:38:49.237
  STEP: Creating simple DaemonSet "daemon-set" @ 10/26/24 13:38:49.262
  STEP: Check that daemon pods launch on every node of the cluster. @ 10/26/24 13:38:49.267
  I1026 13:38:49.275308 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:49.275342 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:49.278157 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:38:49.278178 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 13:38:49.488573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:50.273049 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:50.273085 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:50.277861 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 13:38:50.277881 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 10/26/24 13:38:50.282
  I1026 13:38:50.301431 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:50.301459 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:50.305205 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1026 13:38:50.305228 19 fixtures.go:130] Node ip-172-31-8-187 is running 0 daemon pod, expected 1
  E1026 13:38:50.489580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:51.302074 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:51.302114 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:51.305545 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1026 13:38:51.305565 19 fixtures.go:130] Node ip-172-31-8-187 is running 0 daemon pod, expected 1
  E1026 13:38:51.489727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:52.300847 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:52.300902 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:52.304122 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I1026 13:38:52.304141 19 fixtures.go:130] Node ip-172-31-8-187 is running 0 daemon pod, expected 1
  E1026 13:38:52.490440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:53.302163 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:53.302206 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:38:53.305830 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 13:38:53.305850 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 10/26/24 13:38:53.309
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9494, will wait for the garbage collector to delete the pods @ 10/26/24 13:38:53.309
  I1026 13:38:53.372312 19 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 9.088984ms
  I1026 13:38:53.473402 19 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.083288ms
  E1026 13:38:53.490655      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:54.491233      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:55.278469 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:38:55.278538 19 fixtures.go:135] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I1026 13:38:55.288101 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44088"},"items":null}

  I1026 13:38:55.294702 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44090"},"items":null}

  I1026 13:38:55.315760 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9494" for this suite. @ 10/26/24 13:38:55.32
• [6.117 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:139
  STEP: Creating a kubernetes client @ 10/26/24 13:38:55.333
  I1026 13:38:55.333106 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename dns @ 10/26/24 13:38:55.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:38:55.354
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:38:55.358
  STEP: Creating a test headless service @ 10/26/24 13:38:55.363
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2152.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2152.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2152.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2152.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2152.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2152.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2152.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2152.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2152.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2152.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 195.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.195_udp@PTR;check="$$(dig +tcp +noall +answer +search 195.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.195_tcp@PTR;sleep 1; done
   @ 10/26/24 13:38:55.382
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2152.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2152.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2152.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2152.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2152.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2152.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2152.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2152.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2152.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2152.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 195.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.195_udp@PTR;check="$$(dig +tcp +noall +answer +search 195.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.195_tcp@PTR;sleep 1; done
   @ 10/26/24 13:38:55.382
  STEP: creating a pod to probe DNS @ 10/26/24 13:38:55.382
  STEP: submitting the pod to kubernetes @ 10/26/24 13:38:55.383
  E1026 13:38:55.491694      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:56.491862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 13:38:57.407
  STEP: looking for the results for each expected name from probers @ 10/26/24 13:38:57.412
  I1026 13:38:57.419023 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service.dns-2152.svc.cluster.local from pod dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514: the server could not find the requested resource (get pods dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514)
  I1026 13:38:57.422783 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service.dns-2152.svc.cluster.local from pod dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514: the server could not find the requested resource (get pods dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514)
  I1026 13:38:57.426589 19 dns_common.go:478] Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local from pod dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514: the server could not find the requested resource (get pods dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514)
  I1026 13:38:57.432133 19 dns_common.go:478] Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local from pod dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514: the server could not find the requested resource (get pods dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514)
  I1026 13:38:57.453152 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service.dns-2152.svc.cluster.local from pod dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514: the server could not find the requested resource (get pods dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514)
  I1026 13:38:57.457697 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service.dns-2152.svc.cluster.local from pod dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514: the server could not find the requested resource (get pods dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514)
  I1026 13:38:57.463537 19 dns_common.go:478] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local from pod dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514: the server could not find the requested resource (get pods dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514)
  I1026 13:38:57.467170 19 dns_common.go:478] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local from pod dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514: the server could not find the requested resource (get pods dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514)
  I1026 13:38:57.491415 19 dns_common.go:489] Lookups using dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514 failed for: [wheezy_udp@dns-test-service.dns-2152.svc.cluster.local wheezy_tcp@dns-test-service.dns-2152.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local jessie_udp@dns-test-service.dns-2152.svc.cluster.local jessie_tcp@dns-test-service.dns-2152.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2152.svc.cluster.local]

  E1026 13:38:57.492492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:38:57.499646 19 dns_common.go:495] Pod client logs for webserver: 
  I1026 13:38:57.504899 19 dns_common.go:495] Pod client logs for querier: 
  I1026 13:38:57.513130 19 dns_common.go:495] Pod client logs for jessie-querier: 
  E1026 13:38:58.493032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:38:59.493150      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:00.493257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:01.493453      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:39:02.488167 19 dns_common.go:527] DNS probes using dns-2152/dns-test-5a3b927f-4b31-4a80-8c23-56bc303b2514 succeeded

  STEP: deleting the pod @ 10/26/24 13:39:02.488
  E1026 13:39:02.494311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the test service @ 10/26/24 13:39:02.507
  STEP: deleting the test headless service @ 10/26/24 13:39:02.524
  I1026 13:39:02.537443 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2152" for this suite. @ 10/26/24 13:39:02.542
• [7.218 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 10/26/24 13:39:02.55
  I1026 13:39:02.550962 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename endpointslicemirroring @ 10/26/24 13:39:02.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:39:02.569
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:39:02.572
  STEP: mirroring a new custom Endpoint @ 10/26/24 13:39:02.585
  I1026 13:39:02.596349 19 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  E1026 13:39:03.495214      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:04.495936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 10/26/24 13:39:04.602
  I1026 13:39:04.611255 19 endpointslicemirroring.go:171] Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E1026 13:39:05.496917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:06.497043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 10/26/24 13:39:06.617
  I1026 13:39:06.629720 19 endpointslicemirroring.go:194] Waiting for 0 EndpointSlices to exist, got 1
  E1026 13:39:07.497965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:08.498300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:39:08.636501 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-643" for this suite. @ 10/26/24 13:39:08.64
• [6.098 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 10/26/24 13:39:08.649
  I1026 13:39:08.649609 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename custom-resource-definition @ 10/26/24 13:39:08.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:39:08.67
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:39:08.673
  I1026 13:39:08.676568 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  I1026 13:39:09.223860 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9187" for this suite. @ 10/26/24 13:39:09.233
• [0.594 seconds]
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 10/26/24 13:39:09.243
  I1026 13:39:09.243451 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubelet-test @ 10/26/24 13:39:09.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:39:09.265
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:39:09.268
  E1026 13:39:09.498405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:10.498665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:39:11.307206 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1600" for this suite. @ 10/26/24 13:39:11.311
• [2.074 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:270
  STEP: Creating a kubernetes client @ 10/26/24 13:39:11.317
  I1026 13:39:11.317669 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:39:11.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:39:11.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:39:11.341
  STEP: Setting up server cert @ 10/26/24 13:39:11.369
  E1026 13:39:11.498850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:39:11.808
  STEP: Deploying the webhook pod @ 10/26/24 13:39:11.819
  STEP: Wait for the deployment to be ready @ 10/26/24 13:39:11.834
  I1026 13:39:11.846769 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:39:12.499243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:13.500142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:39:13.859
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:39:13.875
  E1026 13:39:14.500185      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:39:14.875643 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 10/26/24 13:39:14.886
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 10/26/24 13:39:14.901
  STEP: Creating a dummy validating-webhook-configuration object @ 10/26/24 13:39:14.914
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 10/26/24 13:39:14.923
  STEP: Creating a dummy mutating-webhook-configuration object @ 10/26/24 13:39:14.929
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 10/26/24 13:39:14.94
  I1026 13:39:15.001519 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7925" for this suite. @ 10/26/24 13:39:15.006
  STEP: Destroying namespace "webhook-markers-1513" for this suite. @ 10/26/24 13:39:15.013
• [3.705 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 10/26/24 13:39:15.022
  I1026 13:39:15.022918 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename cronjob @ 10/26/24 13:39:15.023
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:39:15.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:39:15.044
  STEP: Creating a cronjob @ 10/26/24 13:39:15.05
  STEP: Ensuring more than one job is running at a time @ 10/26/24 13:39:15.056
  E1026 13:39:15.500912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:16.501015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:17.501135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:18.501472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:19.501857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:20.501940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:21.502666      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:22.502855      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:23.503519      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:24.503617      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:25.503742      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:26.503883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:27.503975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:28.504041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:29.504368      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:30.504921      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:31.505015      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:32.505341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:33.505449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:34.505652      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:35.505806      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:36.506034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:37.506957      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:38.507078      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:39.507220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:40.507868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:41.508072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:42.508255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:43.508311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:44.508569      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:45.508804      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:46.508940      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:47.509133      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:48.510129      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:49.511204      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:50.511298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:51.511634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:52.511846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:53.512182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:54.512343      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:55.512435      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:56.512534      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:57.513318      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:58.514311      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:39:59.514862      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:00.514965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:01.515877      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:02.516100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:03.516879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:04.517072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:05.517208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:06.517295      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:07.518190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:08.519220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:09.520284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:10.520515      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:11.521050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:12.521164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:13.522222      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:14.523208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:15.523690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:16.523830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:17.524154      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:18.525088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:19.525870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:20.526870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:21.527646      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:22.527811      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:23.528251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:24.528338      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:25.529256      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:26.529354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:27.529614      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:28.529783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:29.529819      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:30.530884      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:31.530995      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:32.531871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:33.532269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:34.532456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:35.532820      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:36.532969      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:37.533177      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:38.534141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:39.534234      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:40.534871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:41.535594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:42.535727      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:43.536707      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:44.536892      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:45.537798      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:46.537941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:47.538100      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:48.539142      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:49.539902      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:50.540071      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:51.540208      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:52.540886      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:53.541322      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:54.541508      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:55.542179      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:56.542405      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:57.542539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:58.543212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:40:59.543460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:00.543622      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 10/26/24 13:41:01.061
  STEP: Removing cronjob @ 10/26/24 13:41:01.065
  I1026 13:41:01.072873 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1269" for this suite. @ 10/26/24 13:41:01.076
• [106.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:814
  STEP: Creating a kubernetes client @ 10/26/24 13:41:01.085
  I1026 13:41:01.085812 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-preemption @ 10/26/24 13:41:01.086
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:41:01.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:41:01.115
  I1026 13:41:01.134326 19 wait.go:50] Waiting up to 1m0s for all nodes to be ready
  E1026 13:41:01.543780      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:02.543826      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:03.544743      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:04.544868      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:05.545448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:06.546145      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:07.546898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:08.547894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:09.548410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:10.548632      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:11.549370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:12.549979      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:13.550586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:14.550858      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:15.550996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:16.551124      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:17.551988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:18.552031      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:19.552158      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:20.552341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:21.552630      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:22.552824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:23.553870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:24.554875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:25.555859      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:26.555965      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:27.556898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:28.557102      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:29.557802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:30.557996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:31.558796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:32.559139      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:33.559912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:34.560111      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:35.561075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:36.561183      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:37.561959      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:38.562090      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:39.562499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:40.562669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:41.563462      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:42.563582      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:43.564478      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:44.564883      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:45.565870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:46.566055      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:47.566936      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:48.567879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:49.568444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:50.568626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:51.568768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:52.569036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:53.569974      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:54.570091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:55.570874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:56.571057      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:57.572149      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:58.573155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:41:59.573618      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:00.573812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:01.141267 19 util.go:393] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 10/26/24 13:42:01.146
  I1026 13:42:01.146658 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-preemption-path @ 10/26/24 13:42:01.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:42:01.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:42:01.175
  I1026 13:42:01.194018 19 preemption.go:820] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I1026 13:42:01.198872 19 preemption.go:826] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  I1026 13:42:01.279337 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4474" for this suite. @ 10/26/24 13:42:01.283
  I1026 13:42:01.290227 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4586" for this suite. @ 10/26/24 13:42:01.294
• [60.215 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:167
  STEP: Creating a kubernetes client @ 10/26/24 13:42:01.301
  I1026 13:42:01.301498 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename disruption @ 10/26/24 13:42:01.302
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:42:01.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:42:01.325
  STEP: Waiting for the pdb to be processed @ 10/26/24 13:42:01.333
  E1026 13:42:01.574835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:02.574931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 10/26/24 13:42:03.339
  STEP: Waiting for all pods to be running @ 10/26/24 13:42:03.35
  I1026 13:42:03.354544 19 disruption.go:691] running pods: 0 < 1
  E1026 13:42:03.575900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:04.576077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 10/26/24 13:42:05.356
  STEP: Waiting for the pdb to be processed @ 10/26/24 13:42:05.372
  STEP: Patching PodDisruptionBudget status @ 10/26/24 13:42:05.381
  STEP: Waiting for the pdb to be processed @ 10/26/24 13:42:05.391
  I1026 13:42:05.395381 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5233" for this suite. @ 10/26/24 13:42:05.399
• [4.105 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:400
  STEP: Creating a kubernetes client @ 10/26/24 13:42:05.406
  I1026 13:42:05.406872 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:42:05.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:42:05.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:42:05.429
  STEP: Setting up server cert @ 10/26/24 13:42:05.456
  E1026 13:42:05.577117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:42:05.716
  STEP: Deploying the webhook pod @ 10/26/24 13:42:05.726
  STEP: Wait for the deployment to be ready @ 10/26/24 13:42:05.739
  I1026 13:42:05.753105 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:42:06.577255      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:07.577463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:42:07.767
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:42:07.781
  E1026 13:42:08.578466      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:08.781795 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 10/26/24 13:42:08.79
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 10/26/24 13:42:08.805
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 10/26/24 13:42:08.811
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 10/26/24 13:42:08.823
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 10/26/24 13:42:08.835
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 10/26/24 13:42:08.842
  I1026 13:42:08.892181 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3029" for this suite. @ 10/26/24 13:42:08.895
  STEP: Destroying namespace "webhook-markers-2372" for this suite. @ 10/26/24 13:42:08.903
• [3.503 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 10/26/24 13:42:08.909
  I1026 13:42:08.909644 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 13:42:08.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:42:08.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:42:08.928
  STEP: Creating pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860 @ 10/26/24 13:42:08.931
  E1026 13:42:09.578863      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:10.579043      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 10/26/24 13:42:10.951
  I1026 13:42:10.954611 19 container_probe.go:1749] Initial restart count of pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 is 0
  I1026 13:42:10.959535 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:11.579184      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:12.579391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:12.966171 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:13.579927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:14.580913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:14.971057 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:15.581914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:16.582040      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:16.976359 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:17.583077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:18.583153      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:18.981761 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:19.583837      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:20.584899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:20.987832 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:21.584994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:22.585101      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:22.993263 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:23.585967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:24.586167      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:24.998570 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:25.586354      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:26.586449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:27.003172 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:27.586571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:28.586834      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:29.009540 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:29.586874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:30.587084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:31.014465 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:31.587166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:32.587280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:33.020733 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:33.588286      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:34.588356      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:35.025479 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:35.589178      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:36.589389      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:37.031466 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:37.590220      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:38.590512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:39.036503 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:39.591197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:40.591421      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:41.042036 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:41.591500      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:42.591640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:43.048634 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:43.592526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:44.592637      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:45.055479 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:45.592917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:46.593013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:47.061230 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:47.593650      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:48.593813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:49.066268 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:49.594437      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:50.594541      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:51.072776 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:51.594896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:52.595009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:53.078134 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:53.595824      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:54.595931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:55.082961 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:55.596720      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:56.596970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:57.089818 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:57.597064      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:42:58.597217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:42:59.096120 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:42:59.597505      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:00.597640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:01.102481 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:43:01.598005      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:02.598244      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:03.107813 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:43:03.598460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:04.598642      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:05.114530 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:43:05.598796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:06.599013      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:07.119631 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:43:07.599187      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:08.600037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:09.125961 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:43:09.600117      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:10.600241      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:11.132351 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:43:11.601014      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:12.601099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:13.137601 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  E1026 13:43:13.601210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:14.601300      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:15.142338 19 container_probe.go:1759] Get pod test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 in namespace container-probe-860
  I1026 13:43:15.142374 19 container_probe.go:1763] Restart count of pod container-probe-860/test-grpc-49831959-5b7b-47d6-8333-2c65f4d8b162 is now 1 (1m4.187740895s elapsed)
  STEP: deleting the pod @ 10/26/24 13:43:15.142
  I1026 13:43:15.156688 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-860" for this suite. @ 10/26/24 13:43:15.16
• [66.259 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:350
  STEP: Creating a kubernetes client @ 10/26/24 13:43:15.168
  I1026 13:43:15.168706 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 13:43:15.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:15.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:15.191
  STEP: creating a replication controller @ 10/26/24 13:43:15.195
  I1026 13:43:15.195163 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 create -f -'
  I1026 13:43:15.282496 19 builder.go:146] stderr: ""
  I1026 13:43:15.282530 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 10/26/24 13:43:15.282
  I1026 13:43:15.282606 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1026 13:43:15.331198 19 builder.go:146] stderr: ""
  I1026 13:43:15.331237 19 builder.go:147] stdout: "update-demo-nautilus-6lbcv update-demo-nautilus-l8wzj "
  I1026 13:43:15.331287 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-6lbcv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:43:15.373203 19 builder.go:146] stderr: ""
  I1026 13:43:15.373245 19 builder.go:147] stdout: ""
  I1026 13:43:15.373255 19 kubectl.go:2502] update-demo-nautilus-6lbcv is created but not running
  E1026 13:43:15.601563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:16.601769      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:17.602691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:18.602937      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:19.603106      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:20.373781 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1026 13:43:20.420754 19 builder.go:146] stderr: ""
  I1026 13:43:20.420802 19 builder.go:147] stdout: "update-demo-nautilus-6lbcv update-demo-nautilus-l8wzj "
  I1026 13:43:20.420837 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-6lbcv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:43:20.464211 19 builder.go:146] stderr: ""
  I1026 13:43:20.464242 19 builder.go:147] stdout: "true"
  I1026 13:43:20.464280 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-6lbcv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1026 13:43:20.504201 19 builder.go:146] stderr: ""
  I1026 13:43:20.504238 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1026 13:43:20.504253 19 kubectl.go:2393] validating pod update-demo-nautilus-6lbcv
  I1026 13:43:20.510643 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1026 13:43:20.510700 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1026 13:43:20.510710 19 kubectl.go:2520] update-demo-nautilus-6lbcv is verified up and running
  I1026 13:43:20.510738 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-l8wzj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:43:20.552046 19 builder.go:146] stderr: ""
  I1026 13:43:20.552069 19 builder.go:147] stdout: "true"
  I1026 13:43:20.552108 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-l8wzj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1026 13:43:20.596357 19 builder.go:146] stderr: ""
  I1026 13:43:20.596386 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1026 13:43:20.596398 19 kubectl.go:2393] validating pod update-demo-nautilus-l8wzj
  I1026 13:43:20.602044 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1026 13:43:20.602095 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1026 13:43:20.602234 19 kubectl.go:2520] update-demo-nautilus-l8wzj is verified up and running
  STEP: scaling down the replication controller @ 10/26/24 13:43:20.602
  I1026 13:43:20.603016 19 kubectl.go:319] scanned /root for discovery docs: <nil>
  I1026 13:43:20.603042 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E1026 13:43:20.603280      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:21.603387      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:21.667001 19 builder.go:146] stderr: ""
  I1026 13:43:21.667036 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 10/26/24 13:43:21.667
  I1026 13:43:21.667114 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1026 13:43:21.712846 19 builder.go:146] stderr: ""
  I1026 13:43:21.712887 19 builder.go:147] stdout: "update-demo-nautilus-l8wzj "
  I1026 13:43:21.712942 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-l8wzj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:43:21.754239 19 builder.go:146] stderr: ""
  I1026 13:43:21.754278 19 builder.go:147] stdout: "true"
  I1026 13:43:21.754315 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-l8wzj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1026 13:43:21.798030 19 builder.go:146] stderr: ""
  I1026 13:43:21.798064 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1026 13:43:21.798077 19 kubectl.go:2393] validating pod update-demo-nautilus-l8wzj
  I1026 13:43:21.803936 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1026 13:43:21.804018 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1026 13:43:21.804029 19 kubectl.go:2520] update-demo-nautilus-l8wzj is verified up and running
  STEP: scaling up the replication controller @ 10/26/24 13:43:21.804
  I1026 13:43:21.804776 19 kubectl.go:319] scanned /root for discovery docs: <nil>
  I1026 13:43:21.804803 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E1026 13:43:22.603843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:22.868395 19 builder.go:146] stderr: ""
  I1026 13:43:22.868435 19 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 10/26/24 13:43:22.868
  I1026 13:43:22.868612 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1026 13:43:22.915427 19 builder.go:146] stderr: ""
  I1026 13:43:22.915463 19 builder.go:147] stdout: "update-demo-nautilus-l8wzj update-demo-nautilus-zpqv6 "
  I1026 13:43:22.915502 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-l8wzj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:43:22.964282 19 builder.go:146] stderr: ""
  I1026 13:43:22.964315 19 builder.go:147] stdout: "true"
  I1026 13:43:22.964352 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-l8wzj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1026 13:43:23.004860 19 builder.go:146] stderr: ""
  I1026 13:43:23.004898 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1026 13:43:23.004917 19 kubectl.go:2393] validating pod update-demo-nautilus-l8wzj
  I1026 13:43:23.010331 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1026 13:43:23.010379 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1026 13:43:23.010446 19 kubectl.go:2520] update-demo-nautilus-l8wzj is verified up and running
  I1026 13:43:23.010478 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-zpqv6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:43:23.054158 19 builder.go:146] stderr: ""
  I1026 13:43:23.054187 19 builder.go:147] stdout: ""
  I1026 13:43:23.054197 19 kubectl.go:2502] update-demo-nautilus-zpqv6 is created but not running
  E1026 13:43:23.604898      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:24.604971      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:25.605079      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:26.605197      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:27.605299      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:28.054841 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I1026 13:43:28.100193 19 builder.go:146] stderr: ""
  I1026 13:43:28.100230 19 builder.go:147] stdout: "update-demo-nautilus-l8wzj update-demo-nautilus-zpqv6 "
  I1026 13:43:28.100277 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-l8wzj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:43:28.142533 19 builder.go:146] stderr: ""
  I1026 13:43:28.142577 19 builder.go:147] stdout: "true"
  I1026 13:43:28.142624 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-l8wzj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1026 13:43:28.187925 19 builder.go:146] stderr: ""
  I1026 13:43:28.187960 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1026 13:43:28.187973 19 kubectl.go:2393] validating pod update-demo-nautilus-l8wzj
  I1026 13:43:28.192540 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1026 13:43:28.192586 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1026 13:43:28.192597 19 kubectl.go:2520] update-demo-nautilus-l8wzj is verified up and running
  I1026 13:43:28.192632 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-zpqv6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I1026 13:43:28.236438 19 builder.go:146] stderr: ""
  I1026 13:43:28.236477 19 builder.go:147] stdout: "true"
  I1026 13:43:28.236521 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods update-demo-nautilus-zpqv6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I1026 13:43:28.279599 19 builder.go:146] stderr: ""
  I1026 13:43:28.279633 19 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I1026 13:43:28.279644 19 kubectl.go:2393] validating pod update-demo-nautilus-zpqv6
  I1026 13:43:28.287812 19 kubectl.go:2413] got data: {
    "image": "nautilus.jpg"
  }

  I1026 13:43:28.287854 19 kubectl.go:2418] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I1026 13:43:28.287865 19 kubectl.go:2520] update-demo-nautilus-zpqv6 is verified up and running
  STEP: using delete to clean up resources @ 10/26/24 13:43:28.287
  I1026 13:43:28.287931 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 delete --grace-period=0 --force -f -'
  I1026 13:43:28.333980 19 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I1026 13:43:28.334059 19 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I1026 13:43:28.334103 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get rc,svc -l name=update-demo --no-headers'
  I1026 13:43:28.395507 19 builder.go:146] stderr: "No resources found in kubectl-8077 namespace.\n"
  I1026 13:43:28.395546 19 builder.go:147] stdout: ""
  I1026 13:43:28.395608 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-8077 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I1026 13:43:28.457701 19 builder.go:146] stderr: ""
  I1026 13:43:28.457745 19 builder.go:147] stdout: ""
  I1026 13:43:28.457859 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8077" for this suite. @ 10/26/24 13:43:28.461
• [13.300 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 10/26/24 13:43:28.468
  I1026 13:43:28.468528 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 13:43:28.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:28.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:28.492
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 10/26/24 13:43:28.496
  E1026 13:43:28.605430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:29.605559      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:30.606196      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:31.606456      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:43:32.524
  I1026 13:43:32.529800 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-3d4bde68-c29e-4f40-b548-ec7727b81f2c container test-container: <nil>
  STEP: delete the pod @ 10/26/24 13:43:32.542
  I1026 13:43:32.558638 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1953" for this suite. @ 10/26/24 13:43:32.562
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 10/26/24 13:43:32.571
  I1026 13:43:32.571815 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:43:32.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:32.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:32.598
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:43:32.601
  E1026 13:43:32.607028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:33.607212      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:34.607323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:35.607447      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:36.607560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:43:36.627
  I1026 13:43:36.631041 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-087adfe1-63fc-4152-a637-44cc6fb36e48 container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:43:36.642
  I1026 13:43:36.663190 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-789" for this suite. @ 10/26/24 13:43:36.668
• [4.110 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 10/26/24 13:43:36.681
  I1026 13:43:36.681635 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:43:36.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:36.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:36.707
  STEP: Creating the pod @ 10/26/24 13:43:36.71
  E1026 13:43:37.607800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:38.608269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:39.258083 19 pod_client.go:173] Successfully updated pod "labelsupdatedcf5b72b-1ad3-4488-a0a0-a1bf14ee35d2"
  E1026 13:43:39.608450      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:40.608731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:41.609518      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:42.609643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:43.285529 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8896" for this suite. @ 10/26/24 13:43:43.289
• [6.618 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 10/26/24 13:43:43.299
  I1026 13:43:43.299720 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:43:43.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:43.32
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:43.323
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:43:43.325
  E1026 13:43:43.610460      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:44.610695      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:45.610897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:46.611016      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:43:47.35
  I1026 13:43:47.355536 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-7ed6fa3e-eeae-4a40-963c-c953f2df402f container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:43:47.364
  I1026 13:43:47.381168 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9972" for this suite. @ 10/26/24 13:43:47.385
• [4.094 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 10/26/24 13:43:47.393
  I1026 13:43:47.393488 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename downward-api @ 10/26/24 13:43:47.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:47.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:47.417
  STEP: Creating a pod to test downward api env vars @ 10/26/24 13:43:47.42
  E1026 13:43:47.611306      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:48.611352      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:49.612021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:50.612131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:43:51.447
  I1026 13:43:51.450568 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downward-api-5c0a23d0-90a9-4630-b49e-aa08d58c5fc4 container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 13:43:51.458
  I1026 13:43:51.477786 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2472" for this suite. @ 10/26/24 13:43:51.483
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 10/26/24 13:43:51.492
  I1026 13:43:51.492227 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename limitrange @ 10/26/24 13:43:51.492
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:51.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:51.514
  STEP: Creating a LimitRange @ 10/26/24 13:43:51.517
  STEP: Setting up watch @ 10/26/24 13:43:51.517
  E1026 13:43:51.613054      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Submitting a LimitRange @ 10/26/24 13:43:51.622
  STEP: Verifying LimitRange creation was observed @ 10/26/24 13:43:51.63
  STEP: Fetching the LimitRange to ensure it has proper values @ 10/26/24 13:43:51.63
  I1026 13:43:51.634724 19 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I1026 13:43:51.634752 19 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 10/26/24 13:43:51.634
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 10/26/24 13:43:51.642
  I1026 13:43:51.650934 19 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I1026 13:43:51.650957 19 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 10/26/24 13:43:51.65
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 10/26/24 13:43:51.657
  I1026 13:43:51.666151 19 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I1026 13:43:51.666180 19 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 10/26/24 13:43:51.666
  STEP: Failing to create a Pod with more than max resources @ 10/26/24 13:43:51.668
  STEP: Updating a LimitRange @ 10/26/24 13:43:51.671
  STEP: Verifying LimitRange updating is effective @ 10/26/24 13:43:51.679
  E1026 13:43:52.614121      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:53.614873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 10/26/24 13:43:53.684
  STEP: Failing to create a Pod with more than max resources @ 10/26/24 13:43:53.69
  STEP: Deleting a LimitRange @ 10/26/24 13:43:53.692
  STEP: Verifying the LimitRange was deleted @ 10/26/24 13:43:53.702
  E1026 13:43:54.615004      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:55.615098      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:56.615168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:57.615269      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:43:58.616206      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:43:58.706596 19 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 10/26/24 13:43:58.706
  I1026 13:43:58.715237 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-8537" for this suite. @ 10/26/24 13:43:58.719
• [7.235 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1723
  STEP: Creating a kubernetes client @ 10/26/24 13:43:58.727
  I1026 13:43:58.727906 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename kubectl @ 10/26/24 13:43:58.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:58.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:58.75
  I1026 13:43:58.753540 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=kubectl-2865 version'
  I1026 13:43:58.789335 19 builder.go:146] stderr: ""
  I1026 13:43:58.789363 19 builder.go:147] stdout: "Client Version: v1.31.2\nKustomize Version: v5.4.2\nServer Version: v1.31.2\n"
  I1026 13:43:58.789571 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2865" for this suite. @ 10/26/24 13:43:58.793
• [0.074 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1435
  STEP: Creating a kubernetes client @ 10/26/24 13:43:58.802
  I1026 13:43:58.802205 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:43:58.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:43:58.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:43:58.821
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-3762 @ 10/26/24 13:43:58.824
  STEP: changing the ExternalName service to type=NodePort @ 10/26/24 13:43:58.83
  STEP: creating replication controller externalname-service in namespace services-3762 @ 10/26/24 13:43:58.851
  I1026 13:43:58.861366      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3762, replica count: 2
  E1026 13:43:59.616928      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:00.617045      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:01.617164      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:01.912738      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 13:44:01.912771 19 resource.go:361] Creating new exec pod
  E1026 13:44:02.617272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:03.618324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:04.619231      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:04.941873 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3762 exec execpod72z89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I1026 13:44:05.030984 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I1026 13:44:05.031028 19 builder.go:147] stdout: ""
  E1026 13:44:05.619669      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:05.942168 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3762 exec execpod72z89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I1026 13:44:06.024663 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I1026 13:44:06.024729 19 builder.go:147] stdout: ""
  E1026 13:44:06.619878      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:06.942494 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3762 exec execpod72z89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I1026 13:44:07.027797 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I1026 13:44:07.027841 19 builder.go:147] stdout: ""
  E1026 13:44:07.620463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:07.942059 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3762 exec execpod72z89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I1026 13:44:08.022988 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  I1026 13:44:08.023026 19 builder.go:147] stdout: "externalname-service-pbwhw"
  I1026 13:44:08.023111 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3762 exec execpod72z89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.227 80'
  I1026 13:44:08.104290 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.227 80\nConnection to 10.152.183.227 80 port [tcp/http] succeeded!\n"
  I1026 13:44:08.104325 19 builder.go:147] stdout: "externalname-service-vgbw9"
  I1026 13:44:08.104394 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3762 exec execpod72z89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.35.104 30452'
  I1026 13:44:08.190401 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.35.104 30452\nConnection to 172.31.35.104 30452 port [tcp/*] succeeded!\n"
  I1026 13:44:08.190447 19 builder.go:147] stdout: ""
  E1026 13:44:08.621169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:09.104804 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3762 exec execpod72z89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.35.104 30452'
  I1026 13:44:09.211980 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.35.104 30452\nConnection to 172.31.35.104 30452 port [tcp/*] succeeded!\n"
  I1026 13:44:09.212030 19 builder.go:147] stdout: "externalname-service-pbwhw"
  I1026 13:44:09.212177 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-3762 exec execpod72z89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.30.144 30452'
  I1026 13:44:09.298588 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.30.144 30452\nConnection to 172.31.30.144 30452 port [tcp/*] succeeded!\n"
  I1026 13:44:09.298629 19 builder.go:147] stdout: "externalname-service-pbwhw"
  I1026 13:44:09.298808 19 service.go:1444] Cleaning up the ExternalName to NodePort test service
  I1026 13:44:09.322322 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3762" for this suite. @ 10/26/24 13:44:09.326
• [10.531 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 10/26/24 13:44:09.333
  I1026 13:44:09.333413 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename gc @ 10/26/24 13:44:09.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:44:09.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:44:09.354
  STEP: create the deployment @ 10/26/24 13:44:09.357
  W1026 13:44:09.362269      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 10/26/24 13:44:09.362
  E1026 13:44:09.621571      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 10/26/24 13:44:09.871
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 10/26/24 13:44:09.881
  STEP: Gathering metrics @ 10/26/24 13:44:10.403
  W1026 13:44:10.408727      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1026 13:44:10.408757 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1026 13:44:10.408941 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7790" for this suite. @ 10/26/24 13:44:10.412
• [1.088 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 10/26/24 13:44:10.421
  I1026 13:44:10.421183 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:44:10.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:44:10.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:44:10.447
  STEP: Creating secret with name projected-secret-test-25980add-93f1-447c-aa1d-d7325478307e @ 10/26/24 13:44:10.45
  STEP: Creating a pod to test consume secrets @ 10/26/24 13:44:10.455
  E1026 13:44:10.622512      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:11.623135      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:12.623704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:13.623841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:44:14.479
  I1026 13:44:14.483583 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-projected-secrets-70500568-1aca-4386-87da-88545330dcf5 container secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 13:44:14.503
  I1026 13:44:14.532105 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7208" for this suite. @ 10/26/24 13:44:14.535
• [4.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 10/26/24 13:44:14.543
  I1026 13:44:14.543175 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename sched-pred @ 10/26/24 13:44:14.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:44:14.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:44:14.579
  I1026 13:44:14.582450 19 helper.go:122] Waiting up to 1m0s for all (but 0) nodes to be ready
  I1026 13:44:14.590500 19 util.go:393] Waiting for terminating namespaces to be deleted...
  I1026 13:44:14.593690 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-30-144 before test
  I1026 13:44:14.598372 19 predicates.go:957] simpletest.deployment-6fdcbc5df4-5l2kz from gc-7790 started at 2024-10-26 13:44:09 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.598393 19 predicates.go:959] 	Container nginx ready: true, restart count 0
  I1026 13:44:14.598400 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-7dwlf from ingress-nginx-kubernetes-worker started at 2024-10-26 12:55:59 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.598419 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:44:14.598426 19 predicates.go:957] calico-node-mh8sl from kube-system started at 2024-10-26 12:05:37 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.598431 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:44:14.598441 19 predicates.go:957] execpod72z89 from services-3762 started at 2024-10-26 13:44:01 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.598446 19 predicates.go:959] 	Container agnhost-container ready: true, restart count 0
  I1026 13:44:14.598453 19 predicates.go:957] externalname-service-vgbw9 from services-3762 started at 2024-10-26 13:43:58 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.598458 19 predicates.go:959] 	Container externalname-service ready: true, restart count 0
  I1026 13:44:14.598464 19 predicates.go:957] sonobuoy from sonobuoy started at 2024-10-26 12:09:56 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.598469 19 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I1026 13:44:14.598476 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-cj9w2 from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:44:14.598490 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:44:14.598495 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1026 13:44:14.598501 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-35-104 before test
  I1026 13:44:14.604436 19 predicates.go:957] simpletest.deployment-6fdcbc5df4-jb6qs from gc-7790 started at 2024-10-26 13:44:09 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.604453 19 predicates.go:959] 	Container nginx ready: true, restart count 0
  I1026 13:44:14.604460 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-j79fd from ingress-nginx-kubernetes-worker started at 2024-10-26 12:00:11 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.604466 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:44:14.604473 19 predicates.go:957] calico-node-7mt8z from kube-system started at 2024-10-26 12:06:48 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.604478 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:44:14.604484 19 predicates.go:957] externalname-service-pbwhw from services-3762 started at 2024-10-26 13:43:58 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.604488 19 predicates.go:959] 	Container externalname-service ready: true, restart count 0
  I1026 13:44:14.604494 19 predicates.go:957] sonobuoy-e2e-job-f2d0e8def796404a from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:44:14.604500 19 predicates.go:959] 	Container e2e ready: true, restart count 0
  I1026 13:44:14.604505 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:44:14.604515 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-x5lp5 from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:44:14.604520 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:44:14.604525 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I1026 13:44:14.604531 19 predicates.go:119] 
  Logging pods the apiserver thinks is on node ip-172-31-8-187 before test
  I1026 13:44:14.610400 19 predicates.go:957] nginx-ingress-controller-kubernetes-worker-bkqfk from ingress-nginx-kubernetes-worker started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.610419 19 predicates.go:959] 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  I1026 13:44:14.610426 19 predicates.go:957] calico-node-gctkm from kube-system started at 2024-10-26 12:07:09 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.610431 19 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I1026 13:44:14.610437 19 predicates.go:957] coredns-5b4857d7c8-l5pcc from kube-system started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.610442 19 predicates.go:959] 	Container coredns ready: true, restart count 0
  I1026 13:44:14.610447 19 predicates.go:957] kube-state-metrics-5d7bdccd49-nxf5p from kube-system started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.610453 19 predicates.go:959] 	Container kube-state-metrics ready: true, restart count 2
  I1026 13:44:14.610459 19 predicates.go:957] metrics-server-v0.7.1-6c77d69467-cbtf8 from kube-system started at 2024-10-26 11:50:52 +0000 UTC (2 container statuses recorded)
  I1026 13:44:14.610527 19 predicates.go:959] 	Container metrics-server ready: true, restart count 1
  I1026 13:44:14.610537 19 predicates.go:959] 	Container metrics-server-nanny ready: true, restart count 0
  I1026 13:44:14.610544 19 predicates.go:957] dashboard-metrics-scraper-64757cf48d-6lj85 from kubernetes-dashboard started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.610550 19 predicates.go:959] 	Container dashboard-metrics-scraper ready: true, restart count 0
  I1026 13:44:14.610555 19 predicates.go:957] kubernetes-dashboard-7b6b7bcb5d-ntk95 from kubernetes-dashboard started at 2024-10-26 11:50:52 +0000 UTC (1 container statuses recorded)
  I1026 13:44:14.610569 19 predicates.go:959] 	Container kubernetes-dashboard ready: true, restart count 4
  I1026 13:44:14.610576 19 predicates.go:957] sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-wv9nc from sonobuoy started at 2024-10-26 12:09:58 +0000 UTC (2 container statuses recorded)
  I1026 13:44:14.610607 19 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I1026 13:44:14.610613 19 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  E1026 13:44:14.624691      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: verifying the node has the label node ip-172-31-30-144 @ 10/26/24 13:44:14.625
  STEP: verifying the node has the label node ip-172-31-35-104 @ 10/26/24 13:44:14.639
  STEP: verifying the node has the label node ip-172-31-8-187 @ 10/26/24 13:44:14.652
  I1026 13:44:14.667822 19 predicates.go:372] Pod simpletest.deployment-6fdcbc5df4-5l2kz requesting resource cpu=0m on Node ip-172-31-30-144
  I1026 13:44:14.667850 19 predicates.go:372] Pod simpletest.deployment-6fdcbc5df4-jb6qs requesting resource cpu=0m on Node ip-172-31-35-104
  I1026 13:44:14.667857 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-7dwlf requesting resource cpu=0m on Node ip-172-31-30-144
  I1026 13:44:14.667864 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-bkqfk requesting resource cpu=0m on Node ip-172-31-8-187
  I1026 13:44:14.667870 19 predicates.go:372] Pod nginx-ingress-controller-kubernetes-worker-j79fd requesting resource cpu=0m on Node ip-172-31-35-104
  I1026 13:44:14.667939 19 predicates.go:372] Pod calico-node-7mt8z requesting resource cpu=250m on Node ip-172-31-35-104
  I1026 13:44:14.667951 19 predicates.go:372] Pod calico-node-gctkm requesting resource cpu=250m on Node ip-172-31-8-187
  I1026 13:44:14.668005 19 predicates.go:372] Pod calico-node-mh8sl requesting resource cpu=250m on Node ip-172-31-30-144
  I1026 13:44:14.668011 19 predicates.go:372] Pod coredns-5b4857d7c8-l5pcc requesting resource cpu=100m on Node ip-172-31-8-187
  I1026 13:44:14.668016 19 predicates.go:372] Pod kube-state-metrics-5d7bdccd49-nxf5p requesting resource cpu=0m on Node ip-172-31-8-187
  I1026 13:44:14.668024 19 predicates.go:372] Pod metrics-server-v0.7.1-6c77d69467-cbtf8 requesting resource cpu=5m on Node ip-172-31-8-187
  I1026 13:44:14.668185 19 predicates.go:372] Pod dashboard-metrics-scraper-64757cf48d-6lj85 requesting resource cpu=0m on Node ip-172-31-8-187
  I1026 13:44:14.668198 19 predicates.go:372] Pod kubernetes-dashboard-7b6b7bcb5d-ntk95 requesting resource cpu=0m on Node ip-172-31-8-187
  I1026 13:44:14.668204 19 predicates.go:372] Pod execpod72z89 requesting resource cpu=0m on Node ip-172-31-30-144
  I1026 13:44:14.668210 19 predicates.go:372] Pod externalname-service-pbwhw requesting resource cpu=0m on Node ip-172-31-35-104
  I1026 13:44:14.668216 19 predicates.go:372] Pod externalname-service-vgbw9 requesting resource cpu=0m on Node ip-172-31-30-144
  I1026 13:44:14.668223 19 predicates.go:372] Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-30-144
  I1026 13:44:14.668229 19 predicates.go:372] Pod sonobuoy-e2e-job-f2d0e8def796404a requesting resource cpu=0m on Node ip-172-31-35-104
  I1026 13:44:14.668237 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-cj9w2 requesting resource cpu=0m on Node ip-172-31-30-144
  I1026 13:44:14.668748 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-wv9nc requesting resource cpu=0m on Node ip-172-31-8-187
  I1026 13:44:14.668769 19 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-865227fe84dd475e-x5lp5 requesting resource cpu=0m on Node ip-172-31-35-104
  STEP: Starting Pods to consume most of the cluster CPU. @ 10/26/24 13:44:14.668
  I1026 13:44:14.668847 19 predicates.go:382] Creating a pod which consumes cpu=1225m on Node ip-172-31-30-144
  I1026 13:44:14.676945 19 predicates.go:382] Creating a pod which consumes cpu=1225m on Node ip-172-31-35-104
  I1026 13:44:14.685060 19 predicates.go:382] Creating a pod which consumes cpu=1151m on Node ip-172-31-8-187
  E1026 13:44:15.624913      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:16.625092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 10/26/24 13:44:16.711
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3cc36dba-3ac2-48ec-a66f-7d944d5e08c4.18020497495bd157], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4925/filler-pod-3cc36dba-3ac2-48ec-a66f-7d944d5e08c4 to ip-172-31-30-144] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3cc36dba-3ac2-48ec-a66f-7d944d5e08c4.1802049766487994], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3cc36dba-3ac2-48ec-a66f-7d944d5e08c4.18020497675c035d], Reason = [Created], Message = [Created container filler-pod-3cc36dba-3ac2-48ec-a66f-7d944d5e08c4] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3cc36dba-3ac2-48ec-a66f-7d944d5e08c4.1802049769d7da71], Reason = [Started], Message = [Started container filler-pod-3cc36dba-3ac2-48ec-a66f-7d944d5e08c4] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-78c8eba8-84b9-4c60-a768-0cd1b261b755.1802049749e915a3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4925/filler-pod-78c8eba8-84b9-4c60-a768-0cd1b261b755 to ip-172-31-35-104] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-78c8eba8-84b9-4c60-a768-0cd1b261b755.180204976712414e], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-78c8eba8-84b9-4c60-a768-0cd1b261b755.1802049767f77eae], Reason = [Created], Message = [Created container filler-pod-78c8eba8-84b9-4c60-a768-0cd1b261b755] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-78c8eba8-84b9-4c60-a768-0cd1b261b755.180204976a2b9502], Reason = [Started], Message = [Started container filler-pod-78c8eba8-84b9-4c60-a768-0cd1b261b755] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-b11e1452-1d2f-49ba-9ab0-503bd6083332.180204974a6398e7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4925/filler-pod-b11e1452-1d2f-49ba-9ab0-503bd6083332 to ip-172-31-8-187] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-b11e1452-1d2f-49ba-9ab0-503bd6083332.18020497676e10b8], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-b11e1452-1d2f-49ba-9ab0-503bd6083332.18020497687be87f], Reason = [Created], Message = [Created container filler-pod-b11e1452-1d2f-49ba-9ab0-503bd6083332] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-b11e1452-1d2f-49ba-9ab0-503bd6083332.180204976ad5e527], Reason = [Started], Message = [Started container filler-pod-b11e1452-1d2f-49ba-9ab0-503bd6083332] @ 10/26/24 13:44:16.718
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.18020497c35ca98f], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] @ 10/26/24 13:44:16.742
  E1026 13:44:17.625977      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: removing the label node off the node ip-172-31-30-144 @ 10/26/24 13:44:17.734
  STEP: verifying the node doesn't have the label node @ 10/26/24 13:44:17.745
  STEP: removing the label node off the node ip-172-31-35-104 @ 10/26/24 13:44:17.751
  STEP: verifying the node doesn't have the label node @ 10/26/24 13:44:17.762
  STEP: removing the label node off the node ip-172-31-8-187 @ 10/26/24 13:44:17.768
  STEP: verifying the node doesn't have the label node @ 10/26/24 13:44:17.781
  I1026 13:44:17.786879 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-4925" for this suite. @ 10/26/24 13:44:17.79
• [3.256 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:851
  STEP: Creating a kubernetes client @ 10/26/24 13:44:17.798
  I1026 13:44:17.798906 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename daemonsets @ 10/26/24 13:44:17.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:44:17.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:44:17.819
  STEP: Creating simple DaemonSet "daemon-set" @ 10/26/24 13:44:17.841
  STEP: Check that daemon pods launch on every node of the cluster. @ 10/26/24 13:44:17.847
  I1026 13:44:17.854117 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:44:17.854149 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:44:17.857143 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I1026 13:44:17.857158 19 fixtures.go:130] Node ip-172-31-30-144 is running 0 daemon pod, expected 1
  E1026 13:44:18.626912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:18.852633 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-34-127 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:44:18.852668 19 fixtures.go:89] DaemonSet pods can't tolerate node ip-172-31-70-148 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  I1026 13:44:18.855791 19 fixtures.go:125] Number of nodes with available pods controlled by daemonset daemon-set: 3
  I1026 13:44:18.855812 19 fixtures.go:135] Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 10/26/24 13:44:18.858
  STEP: DeleteCollection of the DaemonSets @ 10/26/24 13:44:18.862
  STEP: Verify that ReplicaSets have been deleted @ 10/26/24 13:44:18.872
  I1026 13:44:18.884714 19 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"46561"},"items":null}

  I1026 13:44:18.889650 19 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"46562"},"items":[{"metadata":{"name":"daemon-set-62plk","generateName":"daemon-set-","namespace":"daemonsets-6596","uid":"c8eddd59-d9e7-4913-b8c7-04773c101095","resourceVersion":"46562","creationTimestamp":"2024-10-26T13:44:17Z","deletionTimestamp":"2024-10-26T13:44:48Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"61efcc19-e844-4b08-bfc8-443b4e934219","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-10-26T13:44:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"61efcc19-e844-4b08-bfc8-443b4e934219\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-10-26T13:44:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.93\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-llmx5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-llmx5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-35-104","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-35-104"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:17Z"}],"hostIP":"172.31.35.104","hostIPs":[{"ip":"172.31.35.104"}],"podIP":"192.168.46.93","podIPs":[{"ip":"192.168.46.93"}],"startTime":"2024-10-26T13:44:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-10-26T13:44:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://a4e7fc6631923166721fcf40b3adcf93c33ab230403dff21b1abd0dce146371f","started":true,"volumeMounts":[{"name":"kube-api-access-llmx5","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-8phwd","generateName":"daemon-set-","namespace":"daemonsets-6596","uid":"9d28ddfd-efd6-431d-ab2e-b70bf048647f","resourceVersion":"46557","creationTimestamp":"2024-10-26T13:44:17Z","labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"61efcc19-e844-4b08-bfc8-443b4e934219","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-10-26T13:44:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"61efcc19-e844-4b08-bfc8-443b4e934219\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-10-26T13:44:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.232.103\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-tktqk","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-tktqk","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-8-187","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-8-187"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:17Z"}],"hostIP":"172.31.8.187","hostIPs":[{"ip":"172.31.8.187"}],"podIP":"192.168.232.103","podIPs":[{"ip":"192.168.232.103"}],"startTime":"2024-10-26T13:44:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-10-26T13:44:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://7e6eacbaa541d34c8016fc012f1a906ae08a4bf70dfe33d1ea1c61ad7fe3487f","started":true,"volumeMounts":[{"name":"kube-api-access-tktqk","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-q9m46","generateName":"daemon-set-","namespace":"daemonsets-6596","uid":"8e5f4233-12e7-4288-b7d6-5a4db2c3ed71","resourceVersion":"46559","creationTimestamp":"2024-10-26T13:44:17Z","labels":{"controller-revision-hash":"6fc6fb49db","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"61efcc19-e844-4b08-bfc8-443b4e934219","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-10-26T13:44:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"61efcc19-e844-4b08-bfc8-443b4e934219\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-10-26T13:44:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.29.180\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-z4d7x","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-z4d7x","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-30-144","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-30-144"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-10-26T13:44:17Z"}],"hostIP":"172.31.30.144","hostIPs":[{"ip":"172.31.30.144"}],"podIP":"192.168.29.180","podIPs":[{"ip":"192.168.29.180"}],"startTime":"2024-10-26T13:44:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-10-26T13:44:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://15a8ec20ffba1a28e4b1642ad2b89c16c54402e76c4d7f28f3a41955c9db7a86","started":true,"volumeMounts":[{"name":"kube-api-access-z4d7x","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}}]}

  I1026 13:44:18.906943 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6596" for this suite. @ 10/26/24 13:44:18.911
• [1.122 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 10/26/24 13:44:18.921
  I1026 13:44:18.921509 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename container-probe @ 10/26/24 13:44:18.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:44:18.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:44:18.945
  STEP: Creating pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182 @ 10/26/24 13:44:18.948
  E1026 13:44:19.627096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:20.627199      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 10/26/24 13:44:20.97
  I1026 13:44:20.974809 19 container_probe.go:1749] Initial restart count of pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 is 0
  I1026 13:44:20.979643 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:21.627410      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:22.627621      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:22.987603 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:23.628292      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:24.628499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:24.992001 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:25.628741      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:26.628847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:26.998545 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:27.629099      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:28.629386      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:29.003008 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:29.629490      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:30.629640      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:31.010269 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:31.629832      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:32.629967      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:33.015021 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:33.630835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:34.631018      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:35.021751 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:35.631130      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:36.631226      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:37.027346 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:37.632203      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:38.633028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:39.034747 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:39.633903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:40.633998      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:41.040355 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:41.635027      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:42.635901      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:43.047783 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:43.636217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:44.636323      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:45.052634 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:45.637298      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:46.637517      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:47.059491 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:47.637668      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:48.637875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:49.065479 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:49.638038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:50.638272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:51.071842 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:51.638499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:52.638603      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:53.077506 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:53.639444      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:54.639656      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:55.083557 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:55.639836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:56.639962      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:57.089951 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:57.640661      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:44:58.640917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:44:59.095080 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:44:59.641768      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:00.641915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:01.100812 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:01.642036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:02.642331      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:03.105236 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:03.642930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:04.643156      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:05.110819 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:05.644218      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:06.644308      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:07.115351 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:07.644917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:08.645193      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:09.121735 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:09.645626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:10.645737      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:11.126953 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:11.646561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:12.646663      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:13.133281 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:13.646970      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:14.647094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:15.137497 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:15.647168      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:16.647283      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:17.142916 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:17.647385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:18.648321      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:19.153933 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:19.648383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:20.648619      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:21.161888 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:21.649594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:22.649996      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:23.168206 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:23.650923      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:24.651157      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:25.174071 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:25.651635      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:26.651836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:27.178987 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:27.652570      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:28.653169      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:29.185209 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:29.653782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:30.653818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:31.189954 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:31.654564      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:32.654793      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:33.197613 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:33.655243      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:34.655318      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:35.202517 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:35.655857      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:36.656001      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:37.207310 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:37.656963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:38.657069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:39.213976 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:39.657656      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:40.657912      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:41.219746 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:41.658069      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:42.658259      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:43.224747 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:43.658900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:44.659988      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:45.231146 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:45.660783      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:46.660899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:47.236178 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:47.661803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:48.661876      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:49.241844 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:49.662342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:50.662987      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:51.247427 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:51.663951      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:52.664882      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:53.254032 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:53.665605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:54.665814      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:55.259545 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:55.665907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:56.666870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:57.265764 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:57.666980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:45:58.667495      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:45:59.272285 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:45:59.667775      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:00.667833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:01.278082 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:01.668643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:02.668853      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:03.283203 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:03.669791      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:04.669927      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:05.289126 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:05.670610      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:06.670821      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:07.293620 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:07.670906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:08.671870      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:09.298833 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:09.672278      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:10.672474      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:11.303366 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:11.672573      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:12.673620      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:13.310616 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:13.674072      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:14.674166      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:15.315808 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:15.674190      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:16.674874      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:17.322045 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:17.675459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:18.676365      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:19.327963 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:19.677407      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:20.677526      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:21.334012 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:21.678491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:22.678608      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:23.339479 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:23.678781      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:24.679009      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:25.345536 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:25.680000      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:26.680209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:27.349551 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:27.681089      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:28.681272      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:29.355510 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:29.681980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:30.682087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:31.361909 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:31.682268      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:32.683118      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:33.367579 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:33.683982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:34.684083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:35.373808 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:35.684915      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:36.685245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:37.379952 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:37.685312      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:38.686334      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:39.385027 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:39.686448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:40.686552      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:41.392049 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:41.687432      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:42.687594      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:43.397908 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:43.688369      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:44.688588      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:45.404497 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:45.688860      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:46.689084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:47.409952 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:47.689257      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:48.689350      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:49.416521 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:49.689963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:50.690061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:51.421995 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:51.690599      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:52.690852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:53.428740 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:53.690975      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:54.691201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:55.432718 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:55.692123      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:56.692245      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:57.438520 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:57.692914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:46:58.693903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:46:59.444936 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:46:59.694162      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:00.694242      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:01.449720 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:01.694897      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:02.695909      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:03.456835 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:03.696012      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:04.696113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:05.461790 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:05.697147      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:06.697383      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:07.467711 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:07.698077      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:08.698172      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:09.474246 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:09.698580      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:10.698803      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:11.480020 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:11.699370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:12.699493      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:13.486018 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:13.700539      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:14.701191      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:15.492005 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:15.701366      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:16.701557      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:17.498139 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:17.701578      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:18.702481      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:19.502837 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:19.703302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:20.703397      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:21.508892 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:21.704211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:22.704313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:23.515390 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:23.704572      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:24.704710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:25.520908 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:25.705228      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:26.705925      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:27.526767 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:27.706894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:28.707025      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:29.532910 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:29.707131      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:30.707341      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:31.537891 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:31.708217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:32.708558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:33.543510 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:33.708818      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:34.709034      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:35.548990 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:35.709132      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:36.709342      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:37.556233 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:37.709442      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:38.710507      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:39.562208 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:39.711499      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:40.711712      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:41.568075 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:41.712302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:42.712417      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:43.573866 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:43.713261      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:44.713362      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:45.581313 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:45.713449      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:46.713954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:47.586475 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:47.714690      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:48.714802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:49.593399 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:49.715710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:50.715896      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:51.598806 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:51.716875      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:52.717906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:53.605254 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:53.718443      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:54.718626      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:55.611139 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:55.719353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:56.719486      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:57.616296 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:57.719528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:47:58.720491      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:47:59.622830 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:47:59.721021      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:00.721140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:01.629111 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:01.721345      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:02.721561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:03.634851 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:03.722037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:04.722173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:05.641140 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:05.722285      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:06.722563      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:07.646514 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:07.722631      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:08.722917      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:09.651836 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:09.722939      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:10.723141      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:11.657484 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:11.723778      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:12.723879      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:13.664418 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:13.724615      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:14.724908      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:15.669465 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:15.725558      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:16.725704      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:17.674610 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:17.725735      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:18.725809      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:19.682088 19 container_probe.go:1759] Get pod test-grpc-5bebbec3-4b36-487b-afde-b8207780fc41 in namespace container-probe-6182
  E1026 13:48:19.726211      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:20.726326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 10/26/24 13:48:21.682
  I1026 13:48:21.698818 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6182" for this suite. @ 10/26/24 13:48:21.704
• [242.791 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 10/26/24 13:48:21.713
  I1026 13:48:21.713150 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename projected @ 10/26/24 13:48:21.713
  E1026 13:48:21.726568      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:48:21.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:48:21.742
  STEP: Creating a pod to test downward API volume plugin @ 10/26/24 13:48:21.745
  E1026 13:48:22.726847      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:23.727084      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:24.727840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:25.728906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:48:25.774
  I1026 13:48:25.778420 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod downwardapi-volume-2fcb1289-7c98-40b7-a1d7-9d084f08fecc container client-container: <nil>
  STEP: delete the pod @ 10/26/24 13:48:25.792
  I1026 13:48:25.810851 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3490" for this suite. @ 10/26/24 13:48:25.814
• [4.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 10/26/24 13:48:25.823
  I1026 13:48:25.823344 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename replication-controller @ 10/26/24 13:48:25.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:48:25.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:48:25.843
  STEP: Creating ReplicationController "e2e-rc-78tlv" @ 10/26/24 13:48:25.847
  I1026 13:48:25.853770 19 rc.go:792] Get Replication Controller "e2e-rc-78tlv" to confirm replicas
  E1026 13:48:26.729385      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:26.854657 19 rc.go:792] Get Replication Controller "e2e-rc-78tlv" to confirm replicas
  I1026 13:48:26.859435 19 rc.go:801] Found 1 replicas for "e2e-rc-78tlv" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-78tlv" @ 10/26/24 13:48:26.859
  STEP: Updating a scale subresource @ 10/26/24 13:48:26.862
  STEP: Verifying replicas where modified for replication controller "e2e-rc-78tlv" @ 10/26/24 13:48:26.868
  I1026 13:48:26.868912 19 rc.go:792] Get Replication Controller "e2e-rc-78tlv" to confirm replicas
  E1026 13:48:27.729525      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:27.869916 19 rc.go:792] Get Replication Controller "e2e-rc-78tlv" to confirm replicas
  I1026 13:48:27.875349 19 rc.go:801] Found 2 replicas for "e2e-rc-78tlv" replication controller
  I1026 13:48:27.875468 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1044" for this suite. @ 10/26/24 13:48:27.88
• [2.064 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 10/26/24 13:48:27.887
  I1026 13:48:27.887564 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename gc @ 10/26/24 13:48:27.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:48:27.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:48:27.909
  STEP: create the deployment @ 10/26/24 13:48:27.912
  W1026 13:48:27.919791      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 10/26/24 13:48:27.919
  STEP: delete the deployment @ 10/26/24 13:48:28.426
  STEP: wait for all rs to be garbage collected @ 10/26/24 13:48:28.432
  STEP: expected 0 rs, got 1 rs @ 10/26/24 13:48:28.442
  STEP: expected 0 pods, got 2 pods @ 10/26/24 13:48:28.446
  E1026 13:48:28.729914      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 10/26/24 13:48:28.947
  W1026 13:48:28.952924      19 metrics_grabber.go:156] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  I1026 13:48:28.952958 19 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I1026 13:48:28.953165 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2708" for this suite. @ 10/26/24 13:48:28.957
• [1.077 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:207
  STEP: Creating a kubernetes client @ 10/26/24 13:48:28.964
  I1026 13:48:28.964836 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:48:28.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:48:28.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:48:28.987
  STEP: Setting up server cert @ 10/26/24 13:48:29.017
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:48:29.444
  STEP: Deploying the webhook pod @ 10/26/24 13:48:29.456
  STEP: Wait for the deployment to be ready @ 10/26/24 13:48:29.472
  I1026 13:48:29.484154 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:48:29.730551      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:30.730797      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:48:31.496
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:48:31.507
  E1026 13:48:31.731523      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:32.508146 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 10/26/24 13:48:32.516
  STEP: create a pod @ 10/26/24 13:48:32.53
  E1026 13:48:32.732003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:33.732036      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 10/26/24 13:48:34.548
  I1026 13:48:34.548281 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=webhook-9684 attach --namespace=webhook-9684 to-be-attached-pod -i -c=container1'
  I1026 13:48:34.608480 19 builder.go:135] rc: 1
  I1026 13:48:34.656801 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9684" for this suite. @ 10/26/24 13:48:34.661
  STEP: Destroying namespace "webhook-markers-4266" for this suite. @ 10/26/24 13:48:34.669
• [5.711 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:247
  STEP: Creating a kubernetes client @ 10/26/24 13:48:34.676
  I1026 13:48:34.676278 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:48:34.676
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:48:34.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:48:34.697
  STEP: Setting up server cert @ 10/26/24 13:48:34.725
  E1026 13:48:34.732209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:48:34.949
  STEP: Deploying the webhook pod @ 10/26/24 13:48:34.958
  STEP: Wait for the deployment to be ready @ 10/26/24 13:48:34.973
  I1026 13:48:34.984065 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:48:35.732797      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:36.733019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:48:36.996
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:48:37.008
  E1026 13:48:37.733929      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:38.008339 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 10/26/24 13:48:38.018
  STEP: create a configmap that should be updated by the webhook @ 10/26/24 13:48:38.032
  I1026 13:48:38.094433 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6894" for this suite. @ 10/26/24 13:48:38.098
  STEP: Destroying namespace "webhook-markers-2597" for this suite. @ 10/26/24 13:48:38.104
• [3.436 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:368
  STEP: Creating a kubernetes client @ 10/26/24 13:48:38.112
  I1026 13:48:38.112615 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename webhook @ 10/26/24 13:48:38.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:48:38.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:48:38.134
  STEP: Setting up server cert @ 10/26/24 13:48:38.164
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 10/26/24 13:48:38.38
  STEP: Deploying the webhook pod @ 10/26/24 13:48:38.387
  STEP: Wait for the deployment to be ready @ 10/26/24 13:48:38.401
  I1026 13:48:38.410390 19 deployment.go:222] deployment "sample-webhook-deployment" doesn't have the required revision set
  E1026 13:48:38.734624      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:39.735003      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 10/26/24 13:48:40.424
  STEP: Verifying the service has paired with the endpoint @ 10/26/24 13:48:40.433
  E1026 13:48:40.735561      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:41.434138 19 util.go:420] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 10/26/24 13:48:41.442
  STEP: Registering slow webhook via the AdmissionRegistration API @ 10/26/24 13:48:41.442
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 10/26/24 13:48:41.458
  E1026 13:48:41.736284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 10/26/24 13:48:42.471
  STEP: Registering slow webhook via the AdmissionRegistration API @ 10/26/24 13:48:42.471
  E1026 13:48:42.737217      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 10/26/24 13:48:43.505
  STEP: Registering slow webhook via the AdmissionRegistration API @ 10/26/24 13:48:43.505
  E1026 13:48:43.737440      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:44.737575      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:45.737665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:46.737850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:47.738052      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 10/26/24 13:48:48.541
  STEP: Registering slow webhook via the AdmissionRegistration API @ 10/26/24 13:48:48.541
  E1026 13:48:48.738274      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:49.738404      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:50.738494      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:51.738771      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:52.739046      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:53.630866 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6565" for this suite. @ 10/26/24 13:48:53.635
  STEP: Destroying namespace "webhook-markers-2812" for this suite. @ 10/26/24 13:48:53.643
• [15.538 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2194
  STEP: Creating a kubernetes client @ 10/26/24 13:48:53.651
  I1026 13:48:53.651241 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:48:53.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:48:53.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:48:53.671
  STEP: creating service in namespace services-2777 @ 10/26/24 13:48:53.675
  STEP: creating service affinity-nodeport in namespace services-2777 @ 10/26/24 13:48:53.675
  STEP: creating replication controller affinity-nodeport in namespace services-2777 @ 10/26/24 13:48:53.693
  I1026 13:48:53.699257      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-2777, replica count: 3
  E1026 13:48:53.739251      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:54.739496      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:55.739665      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:56.739833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:56.750146      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I1026 13:48:56.762600 19 resource.go:361] Creating new exec pod
  E1026 13:48:57.740919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:58.741010      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:48:59.741836      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:48:59.793137 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2777 exec execpod-affinitymkfc4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  I1026 13:48:59.872609 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  I1026 13:48:59.872650 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:48:59.872803 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2777 exec execpod-affinitymkfc4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.191 80'
  I1026 13:48:59.957620 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.191 80\nConnection to 10.152.183.191 80 port [tcp/http] succeeded!\n"
  I1026 13:48:59.957661 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:48:59.957869 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2777 exec execpod-affinitymkfc4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.8.187 30849'
  I1026 13:49:00.037754 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.8.187 30849\nConnection to 172.31.8.187 30849 port [tcp/*] succeeded!\n"
  I1026 13:49:00.037797 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:49:00.037874 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2777 exec execpod-affinitymkfc4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.30.144 30849'
  I1026 13:49:00.119885 19 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.30.144 30849\nConnection to 172.31.30.144 30849 port [tcp/*] succeeded!\n"
  I1026 13:49:00.119927 19 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I1026 13:49:00.119997 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=services-2777 exec execpod-affinitymkfc4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.30.144:30849/ ; done'
  I1026 13:49:00.269364 19 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.30.144:30849/\n"
  I1026 13:49:00.269415 19 builder.go:147] stdout: "\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg\naffinity-nodeport-n8dhg"
  I1026 13:49:00.269429 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269454 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269462 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269468 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269476 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269487 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269524 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269532 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269538 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269543 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269549 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269555 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269560 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269566 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269597 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269614 19 service.go:242] Received response from host: affinity-nodeport-n8dhg
  I1026 13:49:00.269775 19 service.go:4061] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-2777, will wait for the garbage collector to delete the pods @ 10/26/24 13:49:00.283
  I1026 13:49:00.347134 19 resources.go:139] Deleting ReplicationController affinity-nodeport took: 7.418546ms
  I1026 13:49:00.447254 19 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 100.114099ms
  E1026 13:49:00.741918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:01.742485      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:02.742833      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:49:03.369498 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2777" for this suite. @ 10/26/24 13:49:03.374
• [9.731 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 10/26/24 13:49:03.382
  I1026 13:49:03.382571 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename configmap @ 10/26/24 13:49:03.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:49:03.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:49:03.407
  STEP: Creating configMap with name configmap-test-volume-ee252f02-f0ad-47e5-99d2-01ffe94f4a35 @ 10/26/24 13:49:03.41
  STEP: Creating a pod to test consume configMaps @ 10/26/24 13:49:03.416
  E1026 13:49:03.743605      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:04.744061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:05.744864      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:06.745019      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:49:07.444
  I1026 13:49:07.449770 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-configmaps-02c7efea-3b56-41b2-8c54-65b45f924ba5 container agnhost-container: <nil>
  STEP: delete the pod @ 10/26/24 13:49:07.463
  I1026 13:49:07.479596 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7762" for this suite. @ 10/26/24 13:49:07.483
• [4.109 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 10/26/24 13:49:07.491
  I1026 13:49:07.491749 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename custom-resource-definition @ 10/26/24 13:49:07.492
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:49:07.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:49:07.514
  I1026 13:49:07.517741 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:49:07.745782      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:08.746201      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:09.746592      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:10.746931      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:11.747899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:12.747982      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:13.748790      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:49:13.755946 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5832" for this suite. @ 10/26/24 13:49:13.762
• [6.280 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 10/26/24 13:49:13.772
  I1026 13:49:13.772126 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename namespaces @ 10/26/24 13:49:13.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:49:13.793
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:49:13.796
  STEP: Creating a test namespace @ 10/26/24 13:49:13.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:49:13.817
  STEP: Creating a service in the namespace @ 10/26/24 13:49:13.82
  STEP: Deleting the namespace @ 10/26/24 13:49:13.83
  STEP: Waiting for the namespace to be removed. @ 10/26/24 13:49:13.841
  E1026 13:49:14.748842      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:15.748999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:16.749189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:17.749303      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:18.750125      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:19.750846      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 10/26/24 13:49:19.846
  STEP: Verifying there is no service in the namespace @ 10/26/24 13:49:19.868
  I1026 13:49:19.872703 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7838" for this suite. @ 10/26/24 13:49:19.876
  STEP: Destroying namespace "nsdeletetest-8666" for this suite. @ 10/26/24 13:49:19.883
  I1026 13:49:19.888126 19 framework.go:370] Namespace nsdeletetest-8666 was already deleted
  STEP: Destroying namespace "nsdeletetest-6595" for this suite. @ 10/26/24 13:49:19.888
• [6.122 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 10/26/24 13:49:19.894
  I1026 13:49:19.894102 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename crd-publish-openapi @ 10/26/24 13:49:19.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:49:19.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:49:19.913
  I1026 13:49:19.917140 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  E1026 13:49:20.751399      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 10/26/24 13:49:21.159
  I1026 13:49:21.159972 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 create -f -'
  I1026 13:49:21.231923 19 builder.go:146] stderr: ""
  I1026 13:49:21.231960 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5220-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I1026 13:49:21.232001 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 delete e2e-test-crd-publish-openapi-5220-crds test-foo'
  I1026 13:49:21.291379 19 builder.go:146] stderr: ""
  I1026 13:49:21.291429 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5220-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I1026 13:49:21.291468 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 apply -f -'
  I1026 13:49:21.347877 19 builder.go:146] stderr: ""
  I1026 13:49:21.347911 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5220-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I1026 13:49:21.347999 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 delete e2e-test-crd-publish-openapi-5220-crds test-foo'
  I1026 13:49:21.397241 19 builder.go:146] stderr: ""
  I1026 13:49:21.397277 19 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5220-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 10/26/24 13:49:21.397
  I1026 13:49:21.397340 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 create -f -'
  I1026 13:49:21.441748 19 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 10/26/24 13:49:21.441
  I1026 13:49:21.441859 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 create -f -'
  I1026 13:49:21.482348 19 builder.go:135] rc: 1
  I1026 13:49:21.482472 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 apply -f -'
  I1026 13:49:21.537085 19 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 10/26/24 13:49:21.537
  I1026 13:49:21.537202 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 create -f -'
  I1026 13:49:21.583344 19 builder.go:135] rc: 1
  I1026 13:49:21.583420 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 --namespace=crd-publish-openapi-836 apply -f -'
  I1026 13:49:21.632181 19 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 10/26/24 13:49:21.632
  I1026 13:49:21.632300 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 explain e2e-test-crd-publish-openapi-5220-crds'
  I1026 13:49:21.675989 19 builder.go:146] stderr: ""
  I1026 13:49:21.676038 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5220-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 10/26/24 13:49:21.676
  I1026 13:49:21.676260 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 explain e2e-test-crd-publish-openapi-5220-crds.metadata'
  I1026 13:49:21.716807 19 builder.go:146] stderr: ""
  I1026 13:49:21.716927 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5220-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I1026 13:49:21.717121 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 explain e2e-test-crd-publish-openapi-5220-crds.spec'
  E1026 13:49:21.752448      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:49:21.759066 19 builder.go:146] stderr: ""
  I1026 13:49:21.759098 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5220-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I1026 13:49:21.759194 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 explain e2e-test-crd-publish-openapi-5220-crds.spec.bars'
  I1026 13:49:21.802965 19 builder.go:146] stderr: ""
  I1026 13:49:21.803012 19 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5220-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 10/26/24 13:49:21.803
  I1026 13:49:21.803211 19 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4102499143 --namespace=crd-publish-openapi-836 explain e2e-test-crd-publish-openapi-5220-crds.spec.bars2'
  I1026 13:49:21.844712 19 builder.go:135] rc: 1
  E1026 13:49:22.752560      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:49:23.069870 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-836" for this suite. @ 10/26/24 13:49:23.076
• [3.190 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 10/26/24 13:49:23.083
  I1026 13:49:23.083837 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename var-expansion @ 10/26/24 13:49:23.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:49:23.101
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:49:23.103
  STEP: Creating a pod to test substitution in container's args @ 10/26/24 13:49:23.105
  E1026 13:49:23.753562      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:24.754189      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:25.754248      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:26.754315      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:49:27.129
  I1026 13:49:27.133487 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod var-expansion-3d4129ff-48d1-4356-8ea8-46cf4f3c500a container dapi-container: <nil>
  STEP: delete the pod @ 10/26/24 13:49:27.145
  I1026 13:49:27.161034 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-271" for this suite. @ 10/26/24 13:49:27.164
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 10/26/24 13:49:27.171
  I1026 13:49:27.171412 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename svcaccounts @ 10/26/24 13:49:27.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:49:27.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:49:27.189
  I1026 13:49:27.207140 19 service_accounts.go:618] created pod
  E1026 13:49:27.754430      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:28.754871      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:29.754994      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:30.755088      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:49:31.222
  E1026 13:49:31.755173      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:32.755284      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:33.755382      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:34.755483      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:35.755643      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:36.755845      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:37.756028      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:38.756919      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:39.757092      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:40.757302      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:41.757528      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:42.757747      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:43.758073      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:44.758170      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:45.758459      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:46.758586      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:47.758801      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:48.759050      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:49.759326      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:50.759542      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:51.759752      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:52.759973      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:53.760083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:54.760264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:55.760445      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:56.760644      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:57.760802      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:58.761202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:49:59.761414      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:00.761607      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:50:01.223255 19 service_accounts.go:624] polling logs
  I1026 13:50:01.233033 19 service_accounts.go:634] Pod logs: 
  I1026 13:49:27.763854       1 log.go:245] OK: Got token
  I1026 13:49:27.763921       1 log.go:245] validating with in-cluster discovery
  I1026 13:49:27.764194       1 log.go:245] OK: got issuer https://kubernetes.default.svc
  I1026 13:49:27.764385       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7137:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0002a4fe0), NotBefore:(*jwt.NumericDate)(0xc0002a50d0), IssuedAt:(*jwt.NumericDate)(0xc0002a4ff0), ID:"261aae6d-38af-4f10-9b5c-ecde92a96798"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7137", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"385aca94-b0fb-47c2-9ea3-c4fe791df336"}}}
  I1026 13:49:27.773781       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I1026 13:49:27.779986       1 log.go:245] OK: Validated signature on JWT
  I1026 13:49:27.780090       1 log.go:245] OK: Got valid claims from token!
  I1026 13:49:27.780137       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7137:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0002a5d30), NotBefore:(*jwt.NumericDate)(0xc0002a5d58), IssuedAt:(*jwt.NumericDate)(0xc0002a5d38), ID:"261aae6d-38af-4f10-9b5c-ecde92a96798"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7137", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"385aca94-b0fb-47c2-9ea3-c4fe791df336"}}}

  I1026 13:50:01.233076 19 service_accounts.go:638] completed pod
  I1026 13:50:01.241937 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7137" for this suite. @ 10/26/24 13:50:01.246
• [34.082 seconds]
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:288
  STEP: Creating a kubernetes client @ 10/26/24 13:50:01.253
  I1026 13:50:01.253783 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename dns @ 10/26/24 13:50:01.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:50:01.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:50:01.271
  STEP: Creating a test headless service @ 10/26/24 13:50:01.273
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4466.svc.cluster.local;sleep 1; done
   @ 10/26/24 13:50:01.279
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4466.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4466.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4466.svc.cluster.local;sleep 1; done
   @ 10/26/24 13:50:01.279
  STEP: creating a pod to probe DNS @ 10/26/24 13:50:01.279
  STEP: submitting the pod to kubernetes @ 10/26/24 13:50:01.279
  E1026 13:50:01.761812      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:02.762061      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 10/26/24 13:50:03.3
  STEP: looking for the results for each expected name from probers @ 10/26/24 13:50:03.303
  I1026 13:50:03.309714 19 dns_common.go:478] Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local from pod dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb: the server could not find the requested resource (get pods dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb)
  I1026 13:50:03.314056 19 dns_common.go:478] Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local from pod dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb: the server could not find the requested resource (get pods dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb)
  I1026 13:50:03.319233 19 dns_common.go:478] Unable to read wheezy_udp@dns-test-service-2.dns-4466.svc.cluster.local from pod dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb: the server could not find the requested resource (get pods dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb)
  I1026 13:50:03.323479 19 dns_common.go:478] Unable to read wheezy_tcp@dns-test-service-2.dns-4466.svc.cluster.local from pod dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb: the server could not find the requested resource (get pods dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb)
  I1026 13:50:03.327190 19 dns_common.go:478] Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local from pod dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb: the server could not find the requested resource (get pods dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb)
  I1026 13:50:03.331865 19 dns_common.go:478] Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local from pod dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb: the server could not find the requested resource (get pods dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb)
  I1026 13:50:03.336574 19 dns_common.go:478] Unable to read jessie_udp@dns-test-service-2.dns-4466.svc.cluster.local from pod dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb: the server could not find the requested resource (get pods dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb)
  I1026 13:50:03.340379 19 dns_common.go:478] Unable to read jessie_tcp@dns-test-service-2.dns-4466.svc.cluster.local from pod dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb: the server could not find the requested resource (get pods dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb)
  I1026 13:50:03.340407 19 dns_common.go:489] Lookups using dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4466.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4466.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4466.svc.cluster.local jessie_udp@dns-test-service-2.dns-4466.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4466.svc.cluster.local]

  I1026 13:50:03.347179 19 dns_common.go:495] Pod client logs for webserver: 
  I1026 13:50:03.354731 19 dns_common.go:495] Pod client logs for querier: 
  I1026 13:50:03.361107 19 dns_common.go:495] Pod client logs for jessie-querier: 
  E1026 13:50:03.762800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:04.762849      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:05.763731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:06.763893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:07.763990      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:50:08.341089 19 dns_common.go:527] DNS probes using dns-4466/dns-test-16accb46-9fb2-4be0-adbc-66063dc01cfb succeeded

  STEP: deleting the pod @ 10/26/24 13:50:08.341
  STEP: deleting the test headless service @ 10/26/24 13:50:08.363
  I1026 13:50:08.378350 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4466" for this suite. @ 10/26/24 13:50:08.381
• [7.134 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 10/26/24 13:50:08.387
  I1026 13:50:08.387863 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename lease-test @ 10/26/24 13:50:08.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:50:08.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:50:08.405
  I1026 13:50:08.456735 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-7099" for this suite. @ 10/26/24 13:50:08.46
• [0.079 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 10/26/24 13:50:08.466
  I1026 13:50:08.466950 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 13:50:08.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:50:08.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:50:08.486
  STEP: Creating secret with name secret-test-49996cf0-e0ba-486d-9328-b7c58cd2864e @ 10/26/24 13:50:08.487
  STEP: Creating a pod to test consume secrets @ 10/26/24 13:50:08.491
  E1026 13:50:08.764755      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:09.765026      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:10.765891      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:11.766096      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:50:12.516
  I1026 13:50:12.520022 19 output.go:196] Trying to get logs from node ip-172-31-30-144 pod pod-secrets-ae614a50-fd98-4aa1-9048-c63f92c400f2 container secret-volume-test: <nil>
  STEP: delete the pod @ 10/26/24 13:50:12.528
  I1026 13:50:12.548692 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7292" for this suite. @ 10/26/24 13:50:12.552
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 10/26/24 13:50:12.559
  I1026 13:50:12.559137 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename secrets @ 10/26/24 13:50:12.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:50:12.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:50:12.577
  STEP: Creating secret with name s-test-opt-del-55c0f067-bf25-4fdb-a047-6c31edd2c763 @ 10/26/24 13:50:12.583
  STEP: Creating secret with name s-test-opt-upd-9bc60179-8c01-4baf-814e-ac6fe57ca781 @ 10/26/24 13:50:12.587
  STEP: Creating the pod @ 10/26/24 13:50:12.595
  E1026 13:50:12.766794      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:13.767083      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-55c0f067-bf25-4fdb-a047-6c31edd2c763 @ 10/26/24 13:50:14.637
  STEP: Updating secret s-test-opt-upd-9bc60179-8c01-4baf-814e-ac6fe57ca781 @ 10/26/24 13:50:14.644
  STEP: Creating secret with name s-test-opt-create-e83d89af-d5da-47bf-a320-9001f89dfece @ 10/26/24 13:50:14.651
  STEP: waiting to observe update in volume @ 10/26/24 13:50:14.657
  E1026 13:50:14.767758      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:15.767976      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:16.768662      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:17.768835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:18.769850      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:19.769949      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:20.771038      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:21.771134      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:22.771773      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:23.772020      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:24.772710      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:25.772835      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:26.773221      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:27.773353      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:28.773484      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:29.773963      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:30.773985      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:31.774903      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:32.775718      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:33.775813      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:34.775852      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:35.776032      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:36.776387      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:37.776531      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:38.776731      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:39.776893      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:40.776948      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:41.777087      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:42.777182      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:43.777290      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:44.777514      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:45.777887      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:46.778060      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:47.778202      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:48.778472      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:49.779412      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:50.779634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:51.779840      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:52.780037      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:53.780155      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:54.780391      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:55.780918      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:56.781114      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:57.781210      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:58.781390      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:50:59.781634      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:00.781838      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:01.782041      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:02.782264      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:03.782363      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:04.782980      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:05.783895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:06.783999      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:07.784113      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:08.784370      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:09.784800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:10.784843      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:11.784941      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:12.785044      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:13.785140      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:14.785232      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:15.785900      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:16.786907      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:17.787906      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:18.788091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:19.788559      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:20.788899      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:21.789873      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:22.790091      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:23.790296      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:24.790796      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:25.790954      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:26.791324      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:27.791463      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:28.792492      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:29.792589      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:30.792830      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:31.792997      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:32.793075      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:33.793800      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:34.793841      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:51:35.057557 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6016" for this suite. @ 10/26/24 13:51:35.061
• [82.509 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 10/26/24 13:51:35.068
  I1026 13:51:35.068098 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename endpointslice @ 10/26/24 13:51:35.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:51:35.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:51:35.086
  E1026 13:51:35.793933      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:36.794895      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:51:37.138967 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2909" for this suite. @ 10/26/24 13:51:37.142
• [2.081 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 10/26/24 13:51:37.149
  I1026 13:51:37.149215 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename namespaces @ 10/26/24 13:51:37.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:51:37.165
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:51:37.168
  STEP: Updating Namespace "namespaces-3848" @ 10/26/24 13:51:37.17
  I1026 13:51:37.178530 19 namespace.go:389] Namespace "namespaces-3848" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"4f86a21b-dd31-4e45-b53e-bf3ec6810827", "kubernetes.io/metadata.name":"namespaces-3848", "namespaces-3848":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I1026 13:51:37.178615 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3848" for this suite. @ 10/26/24 13:51:37.182
• [0.044 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3619
  STEP: Creating a kubernetes client @ 10/26/24 13:51:37.192
  I1026 13:51:37.192988 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename services @ 10/26/24 13:51:37.193
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:51:37.207
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:51:37.209
  STEP: creating a collection of services @ 10/26/24 13:51:37.211
  I1026 13:51:37.211821 19 service.go:3655] Creating e2e-svc-a-ppqfz
  I1026 13:51:37.221226 19 service.go:3655] Creating e2e-svc-b-dq6jj
  I1026 13:51:37.233068 19 service.go:3655] Creating e2e-svc-c-8x7dw
  STEP: deleting service collection @ 10/26/24 13:51:37.248
  I1026 13:51:37.278801 19 service.go:3690] Collection of services has been deleted
  I1026 13:51:37.278932 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3740" for this suite. @ 10/26/24 13:51:37.282
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 10/26/24 13:51:37.29
  I1026 13:51:37.290172 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename proxy @ 10/26/24 13:51:37.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:51:37.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:51:37.305
  I1026 13:51:37.306937 19 proxy.go:293] Creating pod...
  E1026 13:51:37.795930      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:38.796894      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  I1026 13:51:39.328211 19 proxy.go:317] Creating service...
  I1026 13:51:39.341200 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/pods/agnhost/proxy/some/path/with/DELETE
  I1026 13:51:39.349465 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I1026 13:51:39.349497 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/pods/agnhost/proxy/some/path/with/GET
  I1026 13:51:39.352820 19 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I1026 13:51:39.352852 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/pods/agnhost/proxy/some/path/with/HEAD
  I1026 13:51:39.356404 19 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I1026 13:51:39.356426 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/pods/agnhost/proxy/some/path/with/OPTIONS
  I1026 13:51:39.359109 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I1026 13:51:39.359130 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/pods/agnhost/proxy/some/path/with/PATCH
  I1026 13:51:39.361867 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I1026 13:51:39.361885 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/pods/agnhost/proxy/some/path/with/POST
  I1026 13:51:39.365486 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I1026 13:51:39.365504 19 proxy.go:354] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/pods/agnhost/proxy/some/path/with/PUT
  I1026 13:51:39.368282 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I1026 13:51:39.368306 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/services/test-service/proxy/some/path/with/DELETE
  I1026 13:51:39.372719 19 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I1026 13:51:39.372749 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/services/test-service/proxy/some/path/with/GET
  I1026 13:51:39.378462 19 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I1026 13:51:39.378482 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/services/test-service/proxy/some/path/with/HEAD
  I1026 13:51:39.383414 19 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I1026 13:51:39.383432 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/services/test-service/proxy/some/path/with/OPTIONS
  I1026 13:51:39.388283 19 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I1026 13:51:39.388308 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/services/test-service/proxy/some/path/with/PATCH
  I1026 13:51:39.394708 19 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I1026 13:51:39.394736 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/services/test-service/proxy/some/path/with/POST
  I1026 13:51:39.399649 19 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I1026 13:51:39.399669 19 proxy.go:365] Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7085/services/test-service/proxy/some/path/with/PUT
  I1026 13:51:39.403665 19 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I1026 13:51:39.403822 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7085" for this suite. @ 10/26/24 13:51:39.407
• [2.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 10/26/24 13:51:39.416
  I1026 13:51:39.416941 19 util.go:499] >>> kubeConfig: /tmp/kubeconfig-4102499143
  STEP: Building a namespace api object, basename emptydir @ 10/26/24 13:51:39.417
  STEP: Waiting for a default service account to be provisioned in namespace @ 10/26/24 13:51:39.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 10/26/24 13:51:39.435
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 10/26/24 13:51:39.437
  E1026 13:51:39.797062      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:40.797094      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:41.797209      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  E1026 13:51:42.797313      19 retrywatcher.go:131] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 10/26/24 13:51:43.461
  I1026 13:51:43.464339 19 output.go:196] Trying to get logs from node ip-172-31-35-104 pod pod-5861d09a-310c-4bbc-8cf2-a451af6cb587 container test-container: <nil>
  STEP: delete the pod @ 10/26/24 13:51:43.481
  I1026 13:51:43.498735 19 helper.go:122] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-697" for this suite. @ 10/26/24 13:51:43.501
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I1026 13:51:43.508957 19 suites.go:34] Running AfterSuite actions on node 1
  I1026 13:51:43.509000 19 util.go:607] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:158
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:612
[ReportAfterSuite] PASSED [0.029 seconds]
------------------------------

Ran 404 of 6605 Specs in 6095.018 seconds
SUCCESS! -- 404 Passed | 0 Failed | 0 Pending | 6201 Skipped
PASS

Ginkgo ran 1 suite in 1h41m35.744143424s
Test Suite Passed
