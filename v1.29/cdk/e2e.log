  I0615 12:05:56.752231      19 e2e.go:117] Starting e2e run "95188bf7-85a8-44db-92ad-a0aaa244f60b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1718453156 - will randomize all specs

Will run 388 of 7408 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:157
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:77
  Jun 15 12:05:57.060: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:05:57.061: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Jun 15 12:05:57.099: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Jun 15 12:05:57.105: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  Jun 15 12:05:57.105: INFO: e2e test version: v1.29.6
  Jun 15 12:05:57.106: INFO: kube-apiserver version: v1.29.6
  Jun 15 12:05:57.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:05:57.113: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 06/15/24 12:05:57.375
  Jun 15 12:05:57.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:05:57.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:05:57.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:05:57.399
  STEP: Creating configMap with name configmap-test-upd-ecb721b6-f618-4fab-8ed8-19f68fde1bbb @ 06/15/24 12:05:57.409
  STEP: Creating the pod @ 06/15/24 12:05:57.417
  STEP: Updating configmap configmap-test-upd-ecb721b6-f618-4fab-8ed8-19f68fde1bbb @ 06/15/24 12:06:01.461
  STEP: waiting to observe update in volume @ 06/15/24 12:06:01.466
  Jun 15 12:07:31.845: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1377" for this suite. @ 06/15/24 12:07:31.849
• [94.482 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:611
  STEP: Creating a kubernetes client @ 06/15/24 12:07:31.858
  Jun 15 12:07:31.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename security-context-test @ 06/15/24 12:07:31.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:07:31.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:07:31.876
  Jun 15 12:07:35.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6593" for this suite. @ 06/15/24 12:07:35.918
• [4.068 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:136
  STEP: Creating a kubernetes client @ 06/15/24 12:07:35.926
  Jun 15 12:07:35.926: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 06/15/24 12:07:35.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:07:35.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:07:35.944
  STEP: create the container to handle the HTTPGet hook request. @ 06/15/24 12:07:35.95
  STEP: create the pod with lifecycle hook @ 06/15/24 12:07:37.979
  STEP: check poststart hook @ 06/15/24 12:07:42.005
  STEP: delete the pod with lifecycle hook @ 06/15/24 12:07:42.012
  Jun 15 12:07:46.034: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9050" for this suite. @ 06/15/24 12:07:46.039
• [10.120 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 06/15/24 12:07:46.046
  Jun 15 12:07:46.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename namespaces @ 06/15/24 12:07:46.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:07:46.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:07:46.066
  STEP: creating a Namespace @ 06/15/24 12:07:46.071
  STEP: patching the Namespace @ 06/15/24 12:07:46.082
  STEP: get the Namespace and ensuring it has the label @ 06/15/24 12:07:46.09
  Jun 15 12:07:46.095: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-380" for this suite. @ 06/15/24 12:07:46.099
  STEP: Destroying namespace "nspatchtest-382c3746-27b0-422f-b785-7e1b5eb124f9-4108" for this suite. @ 06/15/24 12:07:46.106
• [0.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 06/15/24 12:07:46.112
  Jun 15 12:07:46.112: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename dns @ 06/15/24 12:07:46.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:07:46.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:07:46.128
  STEP: Creating a test headless service @ 06/15/24 12:07:46.132
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3475.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3475.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 06/15/24 12:07:46.139
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3475.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3475.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 06/15/24 12:07:46.139
  STEP: creating a pod to probe DNS @ 06/15/24 12:07:46.139
  STEP: submitting the pod to kubernetes @ 06/15/24 12:07:46.139
  STEP: retrieving the pod @ 06/15/24 12:07:52.17
  STEP: looking for the results for each expected name from probers @ 06/15/24 12:07:52.174
  Jun 15 12:07:52.192: INFO: DNS probes using dns-3475/dns-test-033a7af1-218b-4f05-82ff-ba3efee735b5 succeeded

  STEP: deleting the pod @ 06/15/24 12:07:52.192
  STEP: deleting the test headless service @ 06/15/24 12:07:52.204
  Jun 15 12:07:52.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3475" for this suite. @ 06/15/24 12:07:52.221
• [6.115 seconds]
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 06/15/24 12:07:52.227
  Jun 15 12:07:52.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pod-network-test @ 06/15/24 12:07:52.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:07:52.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:07:52.246
  STEP: Performing setup for networking test in namespace pod-network-test-5403 @ 06/15/24 12:07:52.251
  STEP: creating a selector @ 06/15/24 12:07:52.251
  STEP: Creating the service pods in kubernetes @ 06/15/24 12:07:52.251
  Jun 15 12:07:52.251: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 06/15/24 12:08:14.368
  Jun 15 12:08:16.385: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Jun 15 12:08:16.385: INFO: Breadth first check of 192.168.0.70 on host 172.31.17.110...
  Jun 15 12:08:16.388: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.164.134:9080/dial?request=hostname&protocol=udp&host=192.168.0.70&port=8081&tries=1'] Namespace:pod-network-test-5403 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:08:16.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:08:16.388: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:08:16.389: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5403/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.164.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.0.70%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Jun 15 12:08:16.450: INFO: Waiting for responses: map[]
  Jun 15 12:08:16.450: INFO: reached 192.168.0.70 after 0/1 tries
  Jun 15 12:08:16.450: INFO: Breadth first check of 192.168.40.196 on host 172.31.43.132...
  Jun 15 12:08:16.454: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.164.134:9080/dial?request=hostname&protocol=udp&host=192.168.40.196&port=8081&tries=1'] Namespace:pod-network-test-5403 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:08:16.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:08:16.454: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:08:16.454: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5403/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.164.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.40.196%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Jun 15 12:08:16.504: INFO: Waiting for responses: map[]
  Jun 15 12:08:16.504: INFO: reached 192.168.40.196 after 0/1 tries
  Jun 15 12:08:16.504: INFO: Breadth first check of 192.168.164.133 on host 172.31.7.7...
  Jun 15 12:08:16.509: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.164.134:9080/dial?request=hostname&protocol=udp&host=192.168.164.133&port=8081&tries=1'] Namespace:pod-network-test-5403 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:08:16.509: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:08:16.509: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:08:16.509: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5403/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.164.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.164.133%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Jun 15 12:08:16.552: INFO: Waiting for responses: map[]
  Jun 15 12:08:16.552: INFO: reached 192.168.164.133 after 0/1 tries
  Jun 15 12:08:16.552: INFO: Going to retry 0 out of 3 pods....
  Jun 15 12:08:16.553: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-5403" for this suite. @ 06/15/24 12:08:16.557
• [24.336 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 06/15/24 12:08:16.564
  Jun 15 12:08:16.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:08:16.565
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:08:16.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:08:16.582
  STEP: Setting up server cert @ 06/15/24 12:08:16.603
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:08:16.992
  STEP: Deploying the webhook pod @ 06/15/24 12:08:17.001
  STEP: Wait for the deployment to be ready @ 06/15/24 12:08:17.016
  Jun 15 12:08:17.026: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 06/15/24 12:08:19.04
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:08:19.051
  Jun 15 12:08:20.051: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 06/15/24 12:08:20.126
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 06/15/24 12:08:20.15
  STEP: Deleting the collection of validation webhooks @ 06/15/24 12:08:20.172
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 06/15/24 12:08:20.224
  Jun 15 12:08:20.277: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4102" for this suite. @ 06/15/24 12:08:20.28
  STEP: Destroying namespace "webhook-markers-1907" for this suite. @ 06/15/24 12:08:20.288
• [3.732 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 06/15/24 12:08:20.297
  Jun 15 12:08:20.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:08:20.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:08:20.309
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:08:20.314
  STEP: Creating configMap with name configmap-test-volume-map-330f05d0-91ec-42cd-9a12-3218e15dc865 @ 06/15/24 12:08:20.317
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:08:20.322
  STEP: Saw pod success @ 06/15/24 12:08:22.343
  Jun 15 12:08:22.346: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-configmaps-d80e5818-d8a2-490c-87ee-30473d619bda container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:08:22.362
  Jun 15 12:08:22.377: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3563" for this suite. @ 06/15/24 12:08:22.381
• [2.093 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 06/15/24 12:08:22.389
  Jun 15 12:08:22.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:08:22.39
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:08:22.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:08:22.406
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:08:22.409
  STEP: Saw pod success @ 06/15/24 12:08:26.441
  Jun 15 12:08:26.446: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-2007d2c7-87db-43ee-832c-8eacbdd4ae6c container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:08:26.452
  Jun 15 12:08:26.466: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2752" for this suite. @ 06/15/24 12:08:26.47
• [4.088 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 06/15/24 12:08:26.477
  Jun 15 12:08:26.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-runtime @ 06/15/24 12:08:26.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:08:26.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:08:26.496
  STEP: create the container @ 06/15/24 12:08:26.499
  W0615 12:08:26.506911      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 06/15/24 12:08:26.507
  STEP: get the container status @ 06/15/24 12:08:29.527
  STEP: the container should be terminated @ 06/15/24 12:08:29.53
  STEP: the termination message should be set @ 06/15/24 12:08:29.53
  Jun 15 12:08:29.530: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 06/15/24 12:08:29.53
  Jun 15 12:08:29.545: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7681" for this suite. @ 06/15/24 12:08:29.548
• [3.079 seconds]
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:183
  STEP: Creating a kubernetes client @ 06/15/24 12:08:29.557
  Jun 15 12:08:29.557: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubelet-test @ 06/15/24 12:08:29.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:08:29.57
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:08:29.574
  Jun 15 12:08:31.606: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1244" for this suite. @ 06/15/24 12:08:31.611
• [2.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 06/15/24 12:08:31.621
  Jun 15 12:08:31.621: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 12:08:31.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:08:31.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:08:31.645
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 06/15/24 12:08:31.65
  STEP: Saw pod success @ 06/15/24 12:08:35.678
  Jun 15 12:08:35.682: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-278f8505-fd3e-4e02-b321-0b48acee0874 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:08:35.688
  Jun 15 12:08:35.706: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8145" for this suite. @ 06/15/24 12:08:35.711
• [4.096 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:177
  STEP: Creating a kubernetes client @ 06/15/24 12:08:35.717
  Jun 15 12:08:35.717: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-webhook @ 06/15/24 12:08:35.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:08:35.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:08:35.736
  STEP: Setting up server cert @ 06/15/24 12:08:35.744
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 06/15/24 12:08:35.956
  STEP: Deploying the custom resource conversion webhook pod @ 06/15/24 12:08:35.962
  STEP: Wait for the deployment to be ready @ 06/15/24 12:08:35.977
  Jun 15 12:08:35.987: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 06/15/24 12:08:37.998
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:08:38.009
  Jun 15 12:08:39.010: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Jun 15 12:08:39.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Creating a v1 custom resource @ 06/15/24 12:08:41.572
  STEP: Create a v2 custom resource @ 06/15/24 12:08:41.587
  STEP: List CRs in v1 @ 06/15/24 12:08:41.613
  STEP: List CRs in v2 @ 06/15/24 12:08:41.617
  Jun 15 12:08:42.177: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-199" for this suite. @ 06/15/24 12:08:42.181
• [6.474 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 06/15/24 12:08:42.191
  Jun 15 12:08:42.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename watch @ 06/15/24 12:08:42.191
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:08:42.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:08:42.208
  STEP: creating a watch on configmaps with label A @ 06/15/24 12:08:42.211
  STEP: creating a watch on configmaps with label B @ 06/15/24 12:08:42.212
  STEP: creating a watch on configmaps with label A or B @ 06/15/24 12:08:42.213
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 06/15/24 12:08:42.215
  Jun 15 12:08:42.220: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3150  86b33b50-612d-41d5-9089-97880b4b240f 4823 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:08:42.220: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3150  86b33b50-612d-41d5-9089-97880b4b240f 4823 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 06/15/24 12:08:42.22
  Jun 15 12:08:42.228: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3150  86b33b50-612d-41d5-9089-97880b4b240f 4824 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:08:42.228: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3150  86b33b50-612d-41d5-9089-97880b4b240f 4824 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 06/15/24 12:08:42.228
  Jun 15 12:08:42.237: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3150  86b33b50-612d-41d5-9089-97880b4b240f 4825 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:08:42.237: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3150  86b33b50-612d-41d5-9089-97880b4b240f 4825 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 06/15/24 12:08:42.238
  Jun 15 12:08:42.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3150  86b33b50-612d-41d5-9089-97880b4b240f 4826 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:08:42.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3150  86b33b50-612d-41d5-9089-97880b4b240f 4826 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 06/15/24 12:08:42.245
  Jun 15 12:08:42.250: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3150  045d22ab-6dbc-432e-a7f2-3119f9d70058 4827 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:08:42.250: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3150  045d22ab-6dbc-432e-a7f2-3119f9d70058 4827 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 06/15/24 12:08:52.25
  Jun 15 12:08:52.259: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3150  045d22ab-6dbc-432e-a7f2-3119f9d70058 4862 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:08:52.259: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3150  045d22ab-6dbc-432e-a7f2-3119f9d70058 4862 0 2024-06-15 12:08:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-06-15 12:08:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:09:02.260: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3150" for this suite. @ 06/15/24 12:09:02.266
• [20.084 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:531
  STEP: Creating a kubernetes client @ 06/15/24 12:09:02.275
  Jun 15 12:09:02.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename svcaccounts @ 06/15/24 12:09:02.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:02.29
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:09:02.293
  Jun 15 12:09:02.309: INFO: created pod
  STEP: Saw pod success @ 06/15/24 12:09:04.319
  Jun 15 12:09:34.319: INFO: polling logs
  Jun 15 12:09:34.327: INFO: Pod logs: 
  I0615 12:09:02.860162       1 log.go:245] OK: Got token
  I0615 12:09:02.860205       1 log.go:245] validating with in-cluster discovery
  I0615 12:09:02.860436       1 log.go:245] OK: got issuer https://kubernetes.default.svc
  I0615 12:09:02.860477       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-9087:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0003c5000), NotBefore:(*jwt.NumericDate)(0xc0003c50e8), IssuedAt:(*jwt.NumericDate)(0xc0003c5010), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9087", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"9dcee365-5fd4-48cd-b52b-8cacd51d2548"}}}
  I0615 12:09:02.867162       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I0615 12:09:02.870768       1 log.go:245] OK: Validated signature on JWT
  I0615 12:09:02.870882       1 log.go:245] OK: Got valid claims from token!
  I0615 12:09:02.870911       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-9087:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00041b620), NotBefore:(*jwt.NumericDate)(0xc00041b648), IssuedAt:(*jwt.NumericDate)(0xc00041b628), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9087", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"9dcee365-5fd4-48cd-b52b-8cacd51d2548"}}}

  Jun 15 12:09:34.327: INFO: completed pod
  Jun 15 12:09:34.333: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9087" for this suite. @ 06/15/24 12:09:34.337
• [32.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 06/15/24 12:09:34.345
  Jun 15 12:09:34.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:09:34.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:34.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:09:34.37
  STEP: Creating configMap with name configmap-projected-all-test-volume-f4ae634c-e907-4420-838b-1a5a162f7165 @ 06/15/24 12:09:34.373
  STEP: Creating secret with name secret-projected-all-test-volume-140e157f-3563-4484-a7cf-d5e32b0ac9fb @ 06/15/24 12:09:34.379
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 06/15/24 12:09:34.383
  STEP: Saw pod success @ 06/15/24 12:09:36.404
  Jun 15 12:09:36.408: INFO: Trying to get logs from node ip-172-31-7-7 pod projected-volume-3bbdd8f0-49c0-447f-908b-3b0c64b99cce container projected-all-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:09:36.415
  Jun 15 12:09:36.432: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9899" for this suite. @ 06/15/24 12:09:36.435
• [2.098 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 06/15/24 12:09:36.443
  Jun 15 12:09:36.443: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 12:09:36.443
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:36.458
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:09:36.46
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 06/15/24 12:09:36.463
  STEP: Saw pod success @ 06/15/24 12:09:38.48
  Jun 15 12:09:38.484: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-459b90bd-5d2f-4e12-9249-fb4be0231fb7 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:09:38.492
  Jun 15 12:09:38.506: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8525" for this suite. @ 06/15/24 12:09:38.509
• [2.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 06/15/24 12:09:38.517
  Jun 15 12:09:38.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:09:38.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:38.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:09:38.535
  STEP: creating service endpoint-test2 in namespace services-6268 @ 06/15/24 12:09:38.538
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6268 to expose endpoints map[] @ 06/15/24 12:09:38.549
  Jun 15 12:09:38.563: INFO: successfully validated that service endpoint-test2 in namespace services-6268 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-6268 @ 06/15/24 12:09:38.563
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6268 to expose endpoints map[pod1:[80]] @ 06/15/24 12:09:40.586
  Jun 15 12:09:40.599: INFO: successfully validated that service endpoint-test2 in namespace services-6268 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 06/15/24 12:09:40.599
  Jun 15 12:09:40.599: INFO: Creating new exec pod
  Jun 15 12:09:43.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6268 exec execpodmbtf2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Jun 15 12:09:43.730: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Jun 15 12:09:43.730: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:09:43.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6268 exec execpodmbtf2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.229 80'
  Jun 15 12:09:43.820: INFO: stderr: "+ nc -v -t -w 2 10.152.183.229 80\nConnection to 10.152.183.229 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Jun 15 12:09:43.820: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-6268 @ 06/15/24 12:09:43.82
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6268 to expose endpoints map[pod1:[80] pod2:[80]] @ 06/15/24 12:09:45.842
  Jun 15 12:09:45.857: INFO: successfully validated that service endpoint-test2 in namespace services-6268 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 06/15/24 12:09:45.857
  Jun 15 12:09:46.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6268 exec execpodmbtf2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Jun 15 12:09:46.953: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Jun 15 12:09:46.953: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:09:46.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6268 exec execpodmbtf2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.229 80'
  Jun 15 12:09:47.040: INFO: stderr: "+ nc -v -t -w 2 10.152.183.229 80\nConnection to 10.152.183.229 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Jun 15 12:09:47.040: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-6268 @ 06/15/24 12:09:47.04
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6268 to expose endpoints map[pod2:[80]] @ 06/15/24 12:09:47.061
  Jun 15 12:09:47.076: INFO: successfully validated that service endpoint-test2 in namespace services-6268 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 06/15/24 12:09:47.076
  Jun 15 12:09:48.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6268 exec execpodmbtf2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Jun 15 12:09:48.174: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Jun 15 12:09:48.174: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:09:48.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6268 exec execpodmbtf2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.229 80'
  Jun 15 12:09:48.265: INFO: stderr: "+ nc -v -t -w 2 10.152.183.229 80\n+ echo hostName\nConnection to 10.152.183.229 80 port [tcp/http] succeeded!\n"
  Jun 15 12:09:48.265: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-6268 @ 06/15/24 12:09:48.265
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6268 to expose endpoints map[] @ 06/15/24 12:09:48.28
  Jun 15 12:09:49.301: INFO: successfully validated that service endpoint-test2 in namespace services-6268 exposes endpoints map[]
  Jun 15 12:09:49.317: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6268" for this suite. @ 06/15/24 12:09:49.32
• [10.811 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 06/15/24 12:09:49.328
  Jun 15 12:09:49.328: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replication-controller @ 06/15/24 12:09:49.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:49.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:09:49.344
  STEP: Given a ReplicationController is created @ 06/15/24 12:09:49.347
  STEP: When the matched label of one of its pods change @ 06/15/24 12:09:49.352
  Jun 15 12:09:49.356: INFO: Pod name pod-release: Found 0 pods out of 1
  Jun 15 12:09:54.360: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 06/15/24 12:09:54.373
  Jun 15 12:09:55.386: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8336" for this suite. @ 06/15/24 12:09:55.391
• [6.069 seconds]
------------------------------
SS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:141
  STEP: Creating a kubernetes client @ 06/15/24 12:09:55.397
  Jun 15 12:09:55.397: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 12:09:55.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:55.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:09:55.414
  STEP: Creating projection with secret that has name secret-emptykey-test-58df282d-9c74-47ac-b40f-0a3ce755ec8b @ 06/15/24 12:09:55.422
  Jun 15 12:09:55.424: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9558" for this suite. @ 06/15/24 12:09:55.429
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 06/15/24 12:09:55.436
  Jun 15 12:09:55.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replication-controller @ 06/15/24 12:09:55.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:55.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:09:55.454
  STEP: Creating ReplicationController "e2e-rc-sfnpk" @ 06/15/24 12:09:55.457
  Jun 15 12:09:55.463: INFO: Get Replication Controller "e2e-rc-sfnpk" to confirm replicas
  Jun 15 12:09:56.463: INFO: Get Replication Controller "e2e-rc-sfnpk" to confirm replicas
  Jun 15 12:09:56.469: INFO: Found 1 replicas for "e2e-rc-sfnpk" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-sfnpk" @ 06/15/24 12:09:56.469
  STEP: Updating a scale subresource @ 06/15/24 12:09:56.473
  STEP: Verifying replicas where modified for replication controller "e2e-rc-sfnpk" @ 06/15/24 12:09:56.478
  Jun 15 12:09:56.478: INFO: Get Replication Controller "e2e-rc-sfnpk" to confirm replicas
  Jun 15 12:09:57.479: INFO: Get Replication Controller "e2e-rc-sfnpk" to confirm replicas
  Jun 15 12:09:57.484: INFO: Found 2 replicas for "e2e-rc-sfnpk" replication controller
  Jun 15 12:09:57.484: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2082" for this suite. @ 06/15/24 12:09:57.489
• [2.060 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 06/15/24 12:09:57.497
  Jun 15 12:09:57.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename namespaces @ 06/15/24 12:09:57.497
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:57.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:09:57.515
  STEP: Creating a test namespace @ 06/15/24 12:09:57.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:09:57.532
  STEP: Creating a pod in the namespace @ 06/15/24 12:09:57.534
  STEP: Waiting for the pod to have running status @ 06/15/24 12:09:57.544
  STEP: Deleting the namespace @ 06/15/24 12:09:59.553
  STEP: Waiting for the namespace to be removed. @ 06/15/24 12:09:59.561
  STEP: Recreating the namespace @ 06/15/24 12:10:10.567
  STEP: Verifying there are no pods in the namespace @ 06/15/24 12:10:10.583
  Jun 15 12:10:10.587: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6518" for this suite. @ 06/15/24 12:10:10.59
  STEP: Destroying namespace "nsdeletetest-8377" for this suite. @ 06/15/24 12:10:10.597
  Jun 15 12:10:10.599: INFO: Namespace nsdeletetest-8377 was already deleted
  STEP: Destroying namespace "nsdeletetest-8157" for this suite. @ 06/15/24 12:10:10.6
• [13.109 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 06/15/24 12:10:10.607
  Jun 15 12:10:10.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename endpointslice @ 06/15/24 12:10:10.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:10.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:10.622
  Jun 15 12:10:12.683: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1520" for this suite. @ 06/15/24 12:10:12.686
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 06/15/24 12:10:12.694
  Jun 15 12:10:12.694: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename field-validation @ 06/15/24 12:10:12.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:12.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:12.711
  Jun 15 12:10:12.714: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  W0615 12:10:15.252841      19 warnings.go:70] unknown field "alpha"
  W0615 12:10:15.252861      19 warnings.go:70] unknown field "beta"
  W0615 12:10:15.252864      19 warnings.go:70] unknown field "delta"
  W0615 12:10:15.252867      19 warnings.go:70] unknown field "epsilon"
  W0615 12:10:15.252870      19 warnings.go:70] unknown field "gamma"
  Jun 15 12:10:15.798: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5617" for this suite. @ 06/15/24 12:10:15.802
• [3.116 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 06/15/24 12:10:15.81
  Jun 15 12:10:15.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename tables @ 06/15/24 12:10:15.811
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:15.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:15.878
  Jun 15 12:10:15.884: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-4602" for this suite. @ 06/15/24 12:10:15.887
• [0.085 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 06/15/24 12:10:15.895
  Jun 15 12:10:15.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pod-network-test @ 06/15/24 12:10:15.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:15.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:15.912
  STEP: Performing setup for networking test in namespace pod-network-test-2965 @ 06/15/24 12:10:15.915
  STEP: creating a selector @ 06/15/24 12:10:15.915
  STEP: Creating the service pods in kubernetes @ 06/15/24 12:10:15.915
  Jun 15 12:10:15.915: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 06/15/24 12:10:27.998
  Jun 15 12:10:30.033: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Jun 15 12:10:30.033: INFO: Going to poll 192.168.0.71 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Jun 15 12:10:30.035: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.0.71:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2965 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:10:30.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:10:30.036: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:10:30.036: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2965/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.0.71%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Jun 15 12:10:30.097: INFO: Found all 1 expected endpoints: [netserver-0]
  Jun 15 12:10:30.097: INFO: Going to poll 192.168.40.202 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Jun 15 12:10:30.101: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.40.202:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2965 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:10:30.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:10:30.101: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:10:30.101: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2965/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.40.202%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Jun 15 12:10:30.150: INFO: Found all 1 expected endpoints: [netserver-1]
  Jun 15 12:10:30.150: INFO: Going to poll 192.168.164.148 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Jun 15 12:10:30.155: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.164.148:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2965 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:10:30.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:10:30.155: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:10:30.155: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-2965/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.164.148%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Jun 15 12:10:30.212: INFO: Found all 1 expected endpoints: [netserver-2]
  Jun 15 12:10:30.212: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2965" for this suite. @ 06/15/24 12:10:30.217
• [14.329 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 06/15/24 12:10:30.225
  Jun 15 12:10:30.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename proxy @ 06/15/24 12:10:30.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:30.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:30.242
  Jun 15 12:10:30.246: INFO: Creating pod...
  Jun 15 12:10:32.266: INFO: Creating service...
  Jun 15 12:10:32.277: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/pods/agnhost/proxy?method=DELETE
  Jun 15 12:10:32.285: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Jun 15 12:10:32.285: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/pods/agnhost/proxy?method=OPTIONS
  Jun 15 12:10:32.289: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Jun 15 12:10:32.289: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/pods/agnhost/proxy?method=PATCH
  Jun 15 12:10:32.293: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Jun 15 12:10:32.293: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/pods/agnhost/proxy?method=POST
  Jun 15 12:10:32.296: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Jun 15 12:10:32.296: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/pods/agnhost/proxy?method=PUT
  Jun 15 12:10:32.299: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Jun 15 12:10:32.299: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/services/e2e-proxy-test-service/proxy?method=DELETE
  Jun 15 12:10:32.304: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Jun 15 12:10:32.304: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Jun 15 12:10:32.310: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Jun 15 12:10:32.310: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/services/e2e-proxy-test-service/proxy?method=PATCH
  Jun 15 12:10:32.314: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Jun 15 12:10:32.314: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/services/e2e-proxy-test-service/proxy?method=POST
  Jun 15 12:10:32.319: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Jun 15 12:10:32.319: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/services/e2e-proxy-test-service/proxy?method=PUT
  Jun 15 12:10:32.325: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Jun 15 12:10:32.325: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/pods/agnhost/proxy?method=GET
  Jun 15 12:10:32.328: INFO: http.Client request:GET StatusCode:301
  Jun 15 12:10:32.328: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/services/e2e-proxy-test-service/proxy?method=GET
  Jun 15 12:10:32.334: INFO: http.Client request:GET StatusCode:301
  Jun 15 12:10:32.334: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/pods/agnhost/proxy?method=HEAD
  Jun 15 12:10:32.337: INFO: http.Client request:HEAD StatusCode:301
  Jun 15 12:10:32.337: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9443/services/e2e-proxy-test-service/proxy?method=HEAD
  Jun 15 12:10:32.340: INFO: http.Client request:HEAD StatusCode:301
  Jun 15 12:10:32.341: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-9443" for this suite. @ 06/15/24 12:10:32.345
• [2.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 06/15/24 12:10:32.353
  Jun 15 12:10:32.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:10:32.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:32.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:32.372
  STEP: Creating configMap with name configmap-test-volume-df99e3c8-32b9-4f49-9283-869a8ec3dc10 @ 06/15/24 12:10:32.375
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:10:32.382
  STEP: Saw pod success @ 06/15/24 12:10:36.406
  Jun 15 12:10:36.409: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-configmaps-d8bd80e0-1bf0-4ae4-aeec-e740157830dc container configmap-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:10:36.421
  Jun 15 12:10:36.435: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2869" for this suite. @ 06/15/24 12:10:36.437
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:139
  STEP: Creating a kubernetes client @ 06/15/24 12:10:36.444
  Jun 15 12:10:36.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:10:36.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:36.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:36.46
  STEP: Creating configMap that has name configmap-test-emptyKey-ba34b034-fd70-4089-90c2-6d25df9fce9a @ 06/15/24 12:10:36.464
  Jun 15 12:10:36.465: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8488" for this suite. @ 06/15/24 12:10:36.469
• [0.033 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 06/15/24 12:10:36.478
  Jun 15 12:10:36.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:10:36.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:36.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:36.494
  Jun 15 12:10:36.534: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9646" for this suite. @ 06/15/24 12:10:36.536
• [0.066 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 06/15/24 12:10:36.544
  Jun 15 12:10:36.544: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename gc @ 06/15/24 12:10:36.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:36.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:36.565
  Jun 15 12:10:36.601: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"bba0f330-256f-4917-826e-71b4211bf172", Controller:(*bool)(0xc000ec7536), BlockOwnerDeletion:(*bool)(0xc000ec7537)}}
  Jun 15 12:10:36.618: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4c2af5fe-0c3b-4003-9c4b-badb67e73b06", Controller:(*bool)(0xc000ec776e), BlockOwnerDeletion:(*bool)(0xc000ec776f)}}
  Jun 15 12:10:36.625: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"3757bd4b-16d9-4236-9623-41a30b4c82bc", Controller:(*bool)(0xc00409fa1e), BlockOwnerDeletion:(*bool)(0xc00409fa1f)}}
  Jun 15 12:10:41.645: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3532" for this suite. @ 06/15/24 12:10:41.649
• [5.115 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 06/15/24 12:10:41.659
  Jun 15 12:10:41.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 12:10:41.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:41.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:41.678
  Jun 15 12:10:41.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: creating the pod @ 06/15/24 12:10:41.682
  STEP: submitting the pod to kubernetes @ 06/15/24 12:10:41.682
  Jun 15 12:10:43.722: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8622" for this suite. @ 06/15/24 12:10:43.726
• [2.076 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:78
  STEP: Creating a kubernetes client @ 06/15/24 12:10:43.735
  Jun 15 12:10:43.735: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 12:10:43.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:43.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:43.753
  STEP: Counting existing ResourceQuota @ 06/15/24 12:10:43.758
  STEP: Creating a ResourceQuota @ 06/15/24 12:10:48.762
  STEP: Ensuring resource quota status is calculated @ 06/15/24 12:10:48.769
  Jun 15 12:10:50.774: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3352" for this suite. @ 06/15/24 12:10:50.779
• [7.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 06/15/24 12:10:50.785
  Jun 15 12:10:50.785: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:10:50.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:50.799
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:50.803
  STEP: Creating configMap with name configmap-test-volume-map-72ba78d0-cd64-446a-aa59-e7d24836a7ad @ 06/15/24 12:10:50.807
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:10:50.813
  STEP: Saw pod success @ 06/15/24 12:10:54.841
  Jun 15 12:10:54.844: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-configmaps-a19a8200-f6b1-49ee-916c-b2e005c7c6ef container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:10:54.851
  Jun 15 12:10:54.868: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7393" for this suite. @ 06/15/24 12:10:54.873
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 06/15/24 12:10:54.881
  Jun 15 12:10:54.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:10:54.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:10:54.896
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:10:54.899
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4068 @ 06/15/24 12:10:54.903
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 06/15/24 12:10:54.914
  STEP: creating service externalsvc in namespace services-4068 @ 06/15/24 12:10:54.915
  STEP: creating replication controller externalsvc in namespace services-4068 @ 06/15/24 12:10:54.928
  I0615 12:10:54.939431      19 runners.go:197] Created replication controller with name: externalsvc, namespace: services-4068, replica count: 2
  I0615 12:10:57.990847      19 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 06/15/24 12:10:57.995
  Jun 15 12:10:58.012: INFO: Creating new exec pod
  Jun 15 12:11:00.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4068 exec execpod6rb55 -- /bin/sh -x -c nslookup clusterip-service.services-4068.svc.cluster.local'
  Jun 15 12:11:00.131: INFO: stderr: "+ nslookup clusterip-service.services-4068.svc.cluster.local\n"
  Jun 15 12:11:00.131: INFO: stdout: "Server:\t\t10.152.183.120\nAddress:\t10.152.183.120#53\n\nclusterip-service.services-4068.svc.cluster.local\tcanonical name = externalsvc.services-4068.svc.cluster.local.\nName:\texternalsvc.services-4068.svc.cluster.local\nAddress: 10.152.183.246\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-4068, will wait for the garbage collector to delete the pods @ 06/15/24 12:11:00.131
  Jun 15 12:11:00.193: INFO: Deleting ReplicationController externalsvc took: 7.525897ms
  Jun 15 12:11:00.293: INFO: Terminating ReplicationController externalsvc pods took: 100.654989ms
  Jun 15 12:11:03.512: INFO: Cleaning up the ClusterIP to ExternalName test service
  Jun 15 12:11:03.524: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4068" for this suite. @ 06/15/24 12:11:03.53
• [8.656 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:103
  STEP: Creating a kubernetes client @ 06/15/24 12:11:03.538
  Jun 15 12:11:03.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 12:11:03.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:11:03.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:11:03.554
  STEP: Counting existing ResourceQuota @ 06/15/24 12:11:03.557
  STEP: Creating a ResourceQuota @ 06/15/24 12:11:08.56
  STEP: Ensuring resource quota status is calculated @ 06/15/24 12:11:08.566
  STEP: Creating a Service @ 06/15/24 12:11:10.57
  STEP: Creating a NodePort Service @ 06/15/24 12:11:10.588
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 06/15/24 12:11:10.612
  STEP: Ensuring resource quota status captures service creation @ 06/15/24 12:11:10.631
  STEP: Deleting Services @ 06/15/24 12:11:12.636
  STEP: Ensuring resource quota status released usage @ 06/15/24 12:11:12.674
  Jun 15 12:11:14.678: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6083" for this suite. @ 06/15/24 12:11:14.685
• [11.157 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 06/15/24 12:11:14.695
  Jun 15 12:11:14.695: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename dns @ 06/15/24 12:11:14.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:11:14.707
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:11:14.71
  STEP: Creating a test externalName service @ 06/15/24 12:11:14.713
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2550.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2550.svc.cluster.local; sleep 1; done
   @ 06/15/24 12:11:14.719
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2550.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2550.svc.cluster.local; sleep 1; done
   @ 06/15/24 12:11:14.719
  STEP: creating a pod to probe DNS @ 06/15/24 12:11:14.719
  STEP: submitting the pod to kubernetes @ 06/15/24 12:11:14.719
  STEP: retrieving the pod @ 06/15/24 12:11:16.739
  STEP: looking for the results for each expected name from probers @ 06/15/24 12:11:16.743
  Jun 15 12:11:16.752: INFO: DNS probes using dns-test-eb464d67-bb4c-4535-afe7-91fe233a6f99 succeeded

  STEP: changing the externalName to bar.example.com @ 06/15/24 12:11:16.752
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2550.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2550.svc.cluster.local; sleep 1; done
   @ 06/15/24 12:11:16.76
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2550.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2550.svc.cluster.local; sleep 1; done
   @ 06/15/24 12:11:16.76
  STEP: creating a second pod to probe DNS @ 06/15/24 12:11:16.76
  STEP: submitting the pod to kubernetes @ 06/15/24 12:11:16.76
  STEP: retrieving the pod @ 06/15/24 12:11:22.783
  STEP: looking for the results for each expected name from probers @ 06/15/24 12:11:22.786
  Jun 15 12:11:22.795: INFO: DNS probes using dns-test-ef0ed768-1055-4128-9514-027caf322183 succeeded

  STEP: changing the service to type=ClusterIP @ 06/15/24 12:11:22.795
  W0615 12:11:22.809308      19 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2550.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2550.svc.cluster.local; sleep 1; done
   @ 06/15/24 12:11:22.809
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2550.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2550.svc.cluster.local; sleep 1; done
   @ 06/15/24 12:11:22.809
  STEP: creating a third pod to probe DNS @ 06/15/24 12:11:22.809
  STEP: submitting the pod to kubernetes @ 06/15/24 12:11:22.813
  STEP: retrieving the pod @ 06/15/24 12:11:24.833
  STEP: looking for the results for each expected name from probers @ 06/15/24 12:11:24.836
  Jun 15 12:11:24.845: INFO: DNS probes using dns-test-c6353a39-c263-46b7-8aac-1d900db41cfc succeeded

  STEP: deleting the pod @ 06/15/24 12:11:24.845
  STEP: deleting the pod @ 06/15/24 12:11:24.86
  STEP: deleting the pod @ 06/15/24 12:11:24.872
  STEP: deleting the test externalName service @ 06/15/24 12:11:24.887
  Jun 15 12:11:24.904: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-2550" for this suite. @ 06/15/24 12:11:24.907
• [10.219 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:169
  STEP: Creating a kubernetes client @ 06/15/24 12:11:24.915
  Jun 15 12:11:24.915: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 06/15/24 12:11:24.915
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:11:24.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:11:24.933
  STEP: create the container to handle the HTTPGet hook request. @ 06/15/24 12:11:24.94
  STEP: create the pod with lifecycle hook @ 06/15/24 12:11:26.966
  STEP: check poststart hook @ 06/15/24 12:11:28.987
  STEP: delete the pod with lifecycle hook @ 06/15/24 12:11:28.993
  Jun 15 12:11:31.008: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5876" for this suite. @ 06/15/24 12:11:31.014
• [6.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 06/15/24 12:11:31.021
  Jun 15 12:11:31.021: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename events @ 06/15/24 12:11:31.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:11:31.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:11:31.038
  STEP: creating a test event @ 06/15/24 12:11:31.041
  STEP: listing events in all namespaces @ 06/15/24 12:11:31.045
  STEP: listing events in test namespace @ 06/15/24 12:11:31.056
  STEP: listing events with field selection filtering on source @ 06/15/24 12:11:31.06
  STEP: listing events with field selection filtering on reportingController @ 06/15/24 12:11:31.063
  STEP: getting the test event @ 06/15/24 12:11:31.066
  STEP: patching the test event @ 06/15/24 12:11:31.07
  STEP: getting the test event @ 06/15/24 12:11:31.078
  STEP: updating the test event @ 06/15/24 12:11:31.082
  STEP: getting the test event @ 06/15/24 12:11:31.088
  STEP: deleting the test event @ 06/15/24 12:11:31.092
  STEP: listing events in all namespaces @ 06/15/24 12:11:31.099
  STEP: listing events in test namespace @ 06/15/24 12:11:31.108
  Jun 15 12:11:31.110: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6337" for this suite. @ 06/15/24 12:11:31.114
• [0.100 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 06/15/24 12:11:31.121
  Jun 15 12:11:31.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename deployment @ 06/15/24 12:11:31.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:11:31.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:11:31.139
  Jun 15 12:11:31.144: INFO: Creating deployment "webserver-deployment"
  Jun 15 12:11:31.152: INFO: Waiting for observed generation 1
  Jun 15 12:11:33.163: INFO: Waiting for all required pods to come up
  Jun 15 12:11:33.166: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 06/15/24 12:11:33.166
  Jun 15 12:11:37.181: INFO: Waiting for deployment "webserver-deployment" to complete
  Jun 15 12:11:37.187: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Jun 15 12:11:37.197: INFO: Updating deployment webserver-deployment
  Jun 15 12:11:37.197: INFO: Waiting for observed generation 2
  Jun 15 12:11:39.205: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Jun 15 12:11:39.210: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Jun 15 12:11:39.214: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Jun 15 12:11:39.224: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Jun 15 12:11:39.224: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Jun 15 12:11:39.227: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Jun 15 12:11:39.234: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Jun 15 12:11:39.234: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Jun 15 12:11:39.244: INFO: Updating deployment webserver-deployment
  Jun 15 12:11:39.244: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Jun 15 12:11:39.251: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Jun 15 12:11:39.259: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Jun 15 12:11:39.276: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "66bc74d5-5c6a-4fce-836a-49cc06e304f3",
      ResourceVersion: (string) (len=4) "6659",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Jun 15 12:11:39.286: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
      ResourceVersion: (string) (len=4) "6653",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "66bc74d5-5c6a-4fce-836a-49cc06e304f3",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 36 62 63 37 34  64 35 2d 35 63 36 61 2d  |\"66bc74d5-5c6a-|
              00000120  34 66 63 65 2d 38 33 36  61 2d 34 39 63 63 30 36  |4fce-836a-49cc06|
              00000130  65 33 30 34 66 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e304f3\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:11:39.288: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Jun 15 12:11:39.288: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
      ResourceVersion: (string) (len=4) "6650",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "66bc74d5-5c6a-4fce-836a-49cc06e304f3",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 36 62 63 37 34  64 35 2d 35 63 36 61 2d  |\"66bc74d5-5c6a-|
              00000120  34 66 63 65 2d 38 33 36  61 2d 34 39 63 63 30 36  |4fce-836a-49cc06|
              00000130  65 33 30 34 66 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |e304f3\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:11:39.302: INFO: Pod "webserver-deployment-557759b7c7-44ljr" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-44ljr",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "81967ed4-cfd2-4660-9b25-6fbf47cd112f",
      ResourceVersion: (string) (len=4) "6480",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 30  2e 32 30 39 5c 22 7d 22  |2.168.40.209\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bvwx7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bvwx7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-43-132",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.43.132",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.43.132"
        }
      },
      PodIP: (string) (len=14) "192.168.40.209",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.40.209"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050291,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b3a34b1e65a00b1481941e1bf8281c1f15496602f44addd9f172bda3d773915f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.305: INFO: Pod "webserver-deployment-557759b7c7-49zdj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-49zdj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d911b396-d823-4665-8cd5-9aa0102cfdeb",
      ResourceVersion: (string) (len=4) "6670",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jzfkc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jzfkc",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.309: INFO: Pod "webserver-deployment-557759b7c7-4prd8" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-4prd8",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1460ad5d-ffdc-40c4-9982-b8ecd4358ac4",
      ResourceVersion: (string) (len=4) "6503",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 30 2e  37 32 5c 22 7d 22 3a 7b  |2.168.0.72\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8pmx6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8pmx6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-110",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.110",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.110"
        }
      },
      PodIP: (string) (len=12) "192.168.0.72",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "192.168.0.72"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050294,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://cfdcb592b1fa84895c3c6c3ae7b5c25fee7d88bf08a58f83bf06a0b5f1597302",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.310: INFO: Pod "webserver-deployment-557759b7c7-8l9vw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-8l9vw",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ec12d4c0-ac22-440d-bc37-74ddeed32c05",
      ResourceVersion: (string) (len=4) "6674",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ptv24",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ptv24",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-110",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.312: INFO: Pod "webserver-deployment-557759b7c7-97txm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-97txm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "52842635-e3e3-41ce-8c9e-e4d6773e216b",
      ResourceVersion: (string) (len=4) "6506",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 30 2e  37 34 5c 22 7d 22 3a 7b  |2.168.0.74\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zxl6z",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zxl6z",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-110",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.110",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.110"
        }
      },
      PodIP: (string) (len=12) "192.168.0.74",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "192.168.0.74"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050295,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://17d837f5042e2df64ad41b8a7c19c29cc2c8b7d355da4c4b75e1573dd99490f8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.313: INFO: Pod "webserver-deployment-557759b7c7-b8hn5" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-b8hn5",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9d7a15d3-20fb-437c-98e2-fed1bc7068ca",
      ResourceVersion: (string) (len=4) "6671",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5lxhx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5lxhx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.315: INFO: Pod "webserver-deployment-557759b7c7-bllgg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-bllgg",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f5c03e94-199f-4d72-9dc1-0b03d1032223",
      ResourceVersion: (string) (len=4) "6500",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 30 2e  37 33 5c 22 7d 22 3a 7b  |2.168.0.73\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-x769d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-x769d",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-110",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050295,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.110",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.110"
        }
      },
      PodIP: (string) (len=12) "192.168.0.73",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "192.168.0.73"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050294,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://e5247d66b46d5bf9e5d2f8d8d671433889d8f92d13ddeef74a98df485f9a9466",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.318: INFO: Pod "webserver-deployment-557759b7c7-jr6vb" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-jr6vb",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0d4a6455-a017-4856-9a9f-61aa30079942",
      ResourceVersion: (string) (len=4) "6470",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  34 2e 31 35 39 5c 22 7d  |2.168.164.159\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hncnh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hncnh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) (len=15) "192.168.164.159",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.164.159"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050292,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://07a293af3f8f3e2ffa3cb0071b9cf1c193acdf3e81b543a8ea12c2ddda652af0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.320: INFO: Pod "webserver-deployment-557759b7c7-mf2mc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-mf2mc",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5822cbe0-82a2-4684-92ab-579898d80d55",
      ResourceVersion: (string) (len=4) "6660",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-72f57",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-72f57",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.321: INFO: Pod "webserver-deployment-557759b7c7-mfwrj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-mfwrj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2a64ae7b-5b9a-40e5-9100-089931f68ea2",
      ResourceVersion: (string) (len=4) "6477",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 30  2e 32 31 31 5c 22 7d 22  |2.168.40.211\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-847xh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-847xh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-43-132",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.43.132",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.43.132"
        }
      },
      PodIP: (string) (len=14) "192.168.40.211",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.40.211"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050291,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d5bde972df46907213c9ba141ecb87a35a2222679ec83b6c833a8cb421dbb086",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.323: INFO: Pod "webserver-deployment-557759b7c7-nj58t" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-nj58t",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5cb27cfa-6848-4fd1-9416-0df327b4093b",
      ResourceVersion: (string) (len=4) "6664",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rfwn8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rfwn8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-43-132",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.324: INFO: Pod "webserver-deployment-557759b7c7-t6nh7" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-t6nh7",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c6f787e2-0290-4c5f-b3f9-62a5ff710409",
      ResourceVersion: (string) (len=4) "6474",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  34 2e 31 35 36 5c 22 7d  |2.168.164.156\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7h5g8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7h5g8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) (len=15) "192.168.164.156",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.164.156"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050291,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://18091ce19d0e4090e90e92944919058643c55ce884de22107612ae2fe7308298",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.325: INFO: Pod "webserver-deployment-557759b7c7-tr6vm" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-tr6vm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9c31c961-f280-40b4-b36c-1c1ef7afc02e",
      ResourceVersion: (string) (len=4) "6676",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rkkxg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rkkxg",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.326: INFO: Pod "webserver-deployment-557759b7c7-xrbvd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-xrbvd",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d21d2562-7d68-4910-8e74-956e5fb1d7d2",
      ResourceVersion: (string) (len=4) "6483",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 30  2e 32 31 30 5c 22 7d 22  |2.168.40.210\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7mlr2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7mlr2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-43-132",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050292,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050291,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.43.132",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.43.132"
        }
      },
      PodIP: (string) (len=14) "192.168.40.210",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.40.210"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050291,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050291,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://7733b9919b01819267576c47cafa8c5695e507a5d583428a7413d11e0f9fcce9",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.328: INFO: Pod "webserver-deployment-557759b7c7-xsdvt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-xsdvt",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "445d12b8-6cf7-409d-8feb-cd438217aadc",
      ResourceVersion: (string) (len=4) "6654",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d08a47b8-31b3-48ef-b657-2c440f659467",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  38 61 34 37 62 38 2d 33  |d\":\"d08a47b8-3|
              00000090  31 62 33 2d 34 38 65 66  2d 62 36 35 37 2d 32 63  |1b3-48ef-b657-2c|
              000000a0  34 34 30 66 36 35 39 34  36 37 5c 22 7d 22 3a 7b  |440f659467\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vnqw8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vnqw8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.329: INFO: Pod "webserver-deployment-9b4f5bf69-47sxn" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-47sxn",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2c373eb4-fec8-46ec-9a3e-ce9a63c006f1",
      ResourceVersion: (string) (len=4) "6633",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  64 38 64 32 62 33 2d 39  |d\":\"95d8d2b3-9|
              00000090  63 61 32 2d 34 32 36 64  2d 62 31 37 32 2d 34 31  |ca2-426d-b172-41|
              000000a0  33 63 61 38 62 65 31 30  38 66 5c 22 7d 22 3a 7b  |3ca8be108f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 36 34 2e 31  36 30 5c 22 7d 22 3a 7b  |68.164.160\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pjxqc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pjxqc",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) (len=15) "192.168.164.160",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.164.160"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.330: INFO: Pod "webserver-deployment-9b4f5bf69-4gvbc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-4gvbc",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "46c030e5-876c-4530-8059-f8a3f37844a9",
      ResourceVersion: (string) (len=4) "6630",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  64 38 64 32 62 33 2d 39  |d\":\"95d8d2b3-9|
              00000090  63 61 32 2d 34 32 36 64  2d 62 31 37 32 2d 34 31  |ca2-426d-b172-41|
              000000a0  33 63 61 38 62 65 31 30  38 66 5c 22 7d 22 3a 7b  |3ca8be108f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=709) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 31 36 34 2e 31  36 31 5c 22 7d 22 3a 7b  |68.164.161\"}":{|
              000002a0  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              000002b0  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              000002c0  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bpnh9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bpnh9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) (len=15) "192.168.164.161",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.164.161"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.332: INFO: Pod "webserver-deployment-9b4f5bf69-76rxk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-76rxk",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c9227b39-91fc-4522-b349-70ba48988971",
      ResourceVersion: (string) (len=4) "6636",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  64 38 64 32 62 33 2d 39  |d\":\"95d8d2b3-9|
              00000090  63 61 32 2d 34 32 36 64  2d 62 31 37 32 2d 34 31  |ca2-426d-b172-41|
              000000a0  33 63 61 38 62 65 31 30  38 66 5c 22 7d 22 3a 7b  |3ca8be108f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=706) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 30 2e 37 35 5c  22 7d 22 3a 7b 22 2e 22  |68.0.75\"}":{"."|
              000002a0  3a 7b 7d 2c 22 66 3a 69  70 22 3a 7b 7d 7d 7d 2c  |:{},"f:ip":{}}},|
              000002b0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000002c0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4pp7j",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4pp7j",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-110",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.17.110",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.17.110"
        }
      },
      PodIP: (string) (len=12) "192.168.0.75",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "192.168.0.75"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.334: INFO: Pod "webserver-deployment-9b4f5bf69-8wfkp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-8wfkp",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "51e9c38c-ef41-4d8e-bdd2-8690ab0682ee",
      ResourceVersion: (string) (len=4) "6639",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  64 38 64 32 62 33 2d 39  |d\":\"95d8d2b3-9|
              00000090  63 61 32 2d 34 32 36 64  2d 62 31 37 32 2d 34 31  |ca2-426d-b172-41|
              000000a0  33 63 61 38 62 65 31 30  38 66 5c 22 7d 22 3a 7b  |3ca8be108f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 34 30 2e 32 31  32 5c 22 7d 22 3a 7b 22  |68.40.212\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ff2pn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ff2pn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-43-132",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.43.132",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.43.132"
        }
      },
      PodIP: (string) (len=14) "192.168.40.212",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.40.212"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.335: INFO: Pod "webserver-deployment-9b4f5bf69-gzdrh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-gzdrh",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "63fa109e-b71f-4e24-9bad-3eb555b2966d",
      ResourceVersion: (string) (len=4) "6669",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  64 38 64 32 62 33 2d 39  |d\":\"95d8d2b3-9|
              00000090  63 61 32 2d 34 32 36 64  2d 62 31 37 32 2d 34 31  |ca2-426d-b172-41|
              000000a0  33 63 61 38 62 65 31 30  38 66 5c 22 7d 22 3a 7b  |3ca8be108f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4f798",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4f798",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.336: INFO: Pod "webserver-deployment-9b4f5bf69-jc7pr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-jc7pr",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "24454565-27dd-43e6-9f67-3a48c04b9e6b",
      ResourceVersion: (string) (len=4) "6663",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  64 38 64 32 62 33 2d 39  |d\":\"95d8d2b3-9|
              00000090  63 61 32 2d 34 32 36 64  2d 62 31 37 32 2d 34 31  |ca2-426d-b172-41|
              000000a0  33 63 61 38 62 65 31 30  38 66 5c 22 7d 22 3a 7b  |3ca8be108f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qz9jx",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qz9jx",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-17-110",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.337: INFO: Pod "webserver-deployment-9b4f5bf69-kgmzh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-kgmzh",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5b61ac28-1296-41ca-a1eb-ce02092109ca",
      ResourceVersion: (string) (len=4) "6642",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  64 38 64 32 62 33 2d 39  |d\":\"95d8d2b3-9|
              00000090  63 61 32 2d 34 32 36 64  2d 62 31 37 32 2d 34 31  |ca2-426d-b172-41|
              000000a0  33 63 61 38 62 65 31 30  38 66 5c 22 7d 22 3a 7b  |3ca8be108f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=708) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 70 6f 64 49 50 22 3a  7b 7d 2c 22 66 3a 70 6f  |:podIP":{},"f:po|
              00000270  64 49 50 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |dIPs":{".":{},"k|
              00000280  3a 7b 5c 22 69 70 5c 22  3a 5c 22 31 39 32 2e 31  |:{\"ip\":\"192.1|
              00000290  36 38 2e 34 30 2e 32 31  33 5c 22 7d 22 3a 7b 22  |68.40.213\"}":{"|
              000002a0  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              000002b0  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              000002c0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fdxq9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fdxq9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-43-132",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050298,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050297,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.43.132",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.43.132"
        }
      },
      PodIP: (string) (len=14) "192.168.40.213",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.40.213"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050297,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.338: INFO: Pod "webserver-deployment-9b4f5bf69-mwnmr" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-mwnmr",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-8688",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "551daf4f-4dc1-430e-8f65-ca8161ccf47a",
      ResourceVersion: (string) (len=4) "6668",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050299,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "95d8d2b3-9ca2-426d-b172-413ca8be108f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050299,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 35  64 38 64 32 62 33 2d 39  |d\":\"95d8d2b3-9|
              00000090  63 61 32 2d 34 32 36 64  2d 62 31 37 32 2d 34 31  |ca2-426d-b172-41|
              000000a0  33 63 61 38 62 65 31 30  38 66 5c 22 7d 22 3a 7b  |3ca8be108f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nvl5d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nvl5d",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:11:39.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8688" for this suite. @ 06/15/24 12:11:39.356
• [8.256 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 06/15/24 12:11:39.378
  Jun 15 12:11:39.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replication-controller @ 06/15/24 12:11:39.379
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:11:39.401
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:11:39.407
  STEP: Creating replication controller my-hostname-basic-712877a3-fbf4-4257-8149-1319a5e79444 @ 06/15/24 12:11:39.411
  Jun 15 12:11:39.424: INFO: Pod name my-hostname-basic-712877a3-fbf4-4257-8149-1319a5e79444: Found 0 pods out of 1
  Jun 15 12:11:44.431: INFO: Pod name my-hostname-basic-712877a3-fbf4-4257-8149-1319a5e79444: Found 1 pods out of 1
  Jun 15 12:11:44.431: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-712877a3-fbf4-4257-8149-1319a5e79444" are running
  Jun 15 12:11:44.435: INFO: Pod "my-hostname-basic-712877a3-fbf4-4257-8149-1319a5e79444-nkr75" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:11:40 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:11:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:11:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:11:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:11:39 +0000 UTC Reason: Message:}])
  Jun 15 12:11:44.435: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 06/15/24 12:11:44.435
  Jun 15 12:11:44.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2106" for this suite. @ 06/15/24 12:11:44.455
• [5.086 seconds]
------------------------------
SS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 06/15/24 12:11:44.464
  Jun 15 12:11:44.464: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename hostport @ 06/15/24 12:11:44.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:11:44.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:11:44.481
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 06/15/24 12:11:44.489
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.17.110 on the node which pod1 resides and expect scheduled @ 06/15/24 12:11:46.506
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.17.110 but use UDP protocol on the node which pod2 resides @ 06/15/24 12:11:50.524
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 06/15/24 12:12:04.584
  Jun 15 12:12:04.584: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.17.110 http://127.0.0.1:54323/hostname] Namespace:hostport-2274 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:12:04.584: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:12:04.584: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:12:04.584: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2274/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.17.110+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.17.110, port: 54323 @ 06/15/24 12:12:04.646
  Jun 15 12:12:04.646: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.17.110:54323/hostname] Namespace:hostport-2274 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:12:04.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:12:04.647: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:12:04.647: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2274/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.17.110%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.17.110, port: 54323 UDP @ 06/15/24 12:12:04.693
  Jun 15 12:12:04.693: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.17.110 54323] Namespace:hostport-2274 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:12:04.693: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:12:04.694: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:12:04.694: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2274/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.17.110+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  Jun 15 12:12:09.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-2274" for this suite. @ 06/15/24 12:12:09.745
• [25.288 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 06/15/24 12:12:09.753
  Jun 15 12:12:09.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename var-expansion @ 06/15/24 12:12:09.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:12:09.765
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:12:09.771
  STEP: creating the pod @ 06/15/24 12:12:09.774
  STEP: waiting for pod running @ 06/15/24 12:12:09.784
  STEP: creating a file in subpath @ 06/15/24 12:12:11.795
  Jun 15 12:12:11.800: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-1649 PodName:var-expansion-3bb1d9ff-a4e1-45bf-856b-c3a6889fa921 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:12:11.800: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:12:11.800: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:12:11.800: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-1649/pods/var-expansion-3bb1d9ff-a4e1-45bf-856b-c3a6889fa921/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 06/15/24 12:12:11.855
  Jun 15 12:12:11.859: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-1649 PodName:var-expansion-3bb1d9ff-a4e1-45bf-856b-c3a6889fa921 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:12:11.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:12:11.859: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:12:11.860: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-1649/pods/var-expansion-3bb1d9ff-a4e1-45bf-856b-c3a6889fa921/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 06/15/24 12:12:11.902
  Jun 15 12:12:12.415: INFO: Successfully updated pod "var-expansion-3bb1d9ff-a4e1-45bf-856b-c3a6889fa921"
  STEP: waiting for annotated pod running @ 06/15/24 12:12:12.415
  STEP: deleting the pod gracefully @ 06/15/24 12:12:12.419
  Jun 15 12:12:12.419: INFO: Deleting pod "var-expansion-3bb1d9ff-a4e1-45bf-856b-c3a6889fa921" in namespace "var-expansion-1649"
  Jun 15 12:12:12.427: INFO: Wait up to 5m0s for pod "var-expansion-3bb1d9ff-a4e1-45bf-856b-c3a6889fa921" to be fully deleted
  Jun 15 12:12:44.513: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1649" for this suite. @ 06/15/24 12:12:44.517
• [34.772 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:330
  STEP: Creating a kubernetes client @ 06/15/24 12:12:44.525
  Jun 15 12:12:44.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 12:12:44.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:12:44.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:12:44.542
  STEP: Counting existing ResourceQuota @ 06/15/24 12:13:01.551
  STEP: Creating a ResourceQuota @ 06/15/24 12:13:06.556
  STEP: Ensuring resource quota status is calculated @ 06/15/24 12:13:06.562
  STEP: Creating a ConfigMap @ 06/15/24 12:13:08.568
  STEP: Ensuring resource quota status captures configMap creation @ 06/15/24 12:13:08.578
  STEP: Deleting a ConfigMap @ 06/15/24 12:13:10.582
  STEP: Ensuring resource quota status released usage @ 06/15/24 12:13:10.589
  Jun 15 12:13:12.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5258" for this suite. @ 06/15/24 12:13:12.606
• [28.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 06/15/24 12:13:12.624
  Jun 15 12:13:12.624: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 12:13:12.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:13:12.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:13:12.642
  STEP: set up a multi version CRD @ 06/15/24 12:13:12.647
  Jun 15 12:13:12.647: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: mark a version not serverd @ 06/15/24 12:13:15.911
  STEP: check the unserved version gets removed @ 06/15/24 12:13:15.929
  STEP: check the other version is not changed @ 06/15/24 12:13:16.704
  Jun 15 12:13:19.223: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2819" for this suite. @ 06/15/24 12:13:19.23
• [6.611 seconds]
------------------------------
SS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 06/15/24 12:13:19.235
  Jun 15 12:13:19.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename podtemplate @ 06/15/24 12:13:19.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:13:19.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:13:19.253
  STEP: Create set of pod templates @ 06/15/24 12:13:19.256
  Jun 15 12:13:19.261: INFO: created test-podtemplate-1
  Jun 15 12:13:19.266: INFO: created test-podtemplate-2
  Jun 15 12:13:19.272: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 06/15/24 12:13:19.272
  STEP: delete collection of pod templates @ 06/15/24 12:13:19.275
  Jun 15 12:13:19.275: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 06/15/24 12:13:19.29
  Jun 15 12:13:19.290: INFO: requesting list of pod templates to confirm quantity
  Jun 15 12:13:19.294: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-6274" for this suite. @ 06/15/24 12:13:19.298
• [0.068 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 06/15/24 12:13:19.303
  Jun 15 12:13:19.303: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename field-validation @ 06/15/24 12:13:19.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:13:19.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:13:19.326
  Jun 15 12:13:19.329: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  W0615 12:13:19.330466      19 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc004db5150 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W0615 12:13:21.866165      19 warnings.go:70] unknown field "alpha"
  W0615 12:13:21.866184      19 warnings.go:70] unknown field "beta"
  W0615 12:13:21.866188      19 warnings.go:70] unknown field "delta"
  W0615 12:13:21.866190      19 warnings.go:70] unknown field "epsilon"
  W0615 12:13:21.866193      19 warnings.go:70] unknown field "gamma"
  Jun 15 12:13:22.410: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3230" for this suite. @ 06/15/24 12:13:22.415
• [3.117 seconds]
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 06/15/24 12:13:22.42
  Jun 15 12:13:22.420: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:13:22.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:13:22.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:13:22.439
  STEP: Creating secret with name s-test-opt-del-948616ed-ef66-4247-8254-926bce725c04 @ 06/15/24 12:13:22.446
  STEP: Creating secret with name s-test-opt-upd-f120c3dd-a91d-4044-838c-1936a6c21985 @ 06/15/24 12:13:22.451
  STEP: Creating the pod @ 06/15/24 12:13:22.455
  STEP: Deleting secret s-test-opt-del-948616ed-ef66-4247-8254-926bce725c04 @ 06/15/24 12:13:24.504
  STEP: Updating secret s-test-opt-upd-f120c3dd-a91d-4044-838c-1936a6c21985 @ 06/15/24 12:13:24.509
  STEP: Creating secret with name s-test-opt-create-6ece06e4-bc8f-4d37-b95a-16ffe2c3f0ce @ 06/15/24 12:13:24.515
  STEP: waiting to observe update in volume @ 06/15/24 12:13:24.52
  Jun 15 12:14:28.808: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2479" for this suite. @ 06/15/24 12:14:28.811
• [66.397 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1084
  STEP: Creating a kubernetes client @ 06/15/24 12:14:28.817
  Jun 15 12:14:28.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 12:14:28.818
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:28.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:28.837
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 06/15/24 12:14:28.841
  Jun 15 12:14:28.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-7898 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Jun 15 12:14:28.890: INFO: stderr: ""
  Jun 15 12:14:28.890: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 06/15/24 12:14:28.89
  Jun 15 12:14:28.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-7898 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  Jun 15 12:14:28.941: INFO: stderr: ""
  Jun 15 12:14:28.941: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 06/15/24 12:14:28.941
  Jun 15 12:14:28.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-7898 delete pods e2e-test-httpd-pod'
  Jun 15 12:14:30.779: INFO: stderr: ""
  Jun 15 12:14:30.779: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Jun 15 12:14:30.779: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7898" for this suite. @ 06/15/24 12:14:30.784
• [1.972 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 06/15/24 12:14:30.789
  Jun 15 12:14:30.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 12:14:30.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:30.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:30.809
  STEP: Create a pod @ 06/15/24 12:14:30.813
  STEP: patching /status @ 06/15/24 12:14:32.83
  Jun 15 12:14:32.837: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Jun 15 12:14:32.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7284" for this suite. @ 06/15/24 12:14:32.841
• [2.057 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 06/15/24 12:14:32.846
  Jun 15 12:14:32.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename proxy @ 06/15/24 12:14:32.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:32.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:32.863
  Jun 15 12:14:32.866: INFO: Creating pod...
  Jun 15 12:14:34.882: INFO: Creating service...
  Jun 15 12:14:34.894: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/pods/agnhost/proxy/some/path/with/DELETE
  Jun 15 12:14:34.899: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Jun 15 12:14:34.900: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/pods/agnhost/proxy/some/path/with/GET
  Jun 15 12:14:34.905: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Jun 15 12:14:34.905: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/pods/agnhost/proxy/some/path/with/HEAD
  Jun 15 12:14:34.908: INFO: http.Client request:HEAD | StatusCode:200
  Jun 15 12:14:34.908: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/pods/agnhost/proxy/some/path/with/OPTIONS
  Jun 15 12:14:34.912: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Jun 15 12:14:34.912: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/pods/agnhost/proxy/some/path/with/PATCH
  Jun 15 12:14:34.917: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Jun 15 12:14:34.917: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/pods/agnhost/proxy/some/path/with/POST
  Jun 15 12:14:34.921: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Jun 15 12:14:34.921: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/pods/agnhost/proxy/some/path/with/PUT
  Jun 15 12:14:34.924: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Jun 15 12:14:34.924: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/services/test-service/proxy/some/path/with/DELETE
  Jun 15 12:14:34.932: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Jun 15 12:14:34.932: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/services/test-service/proxy/some/path/with/GET
  Jun 15 12:14:34.937: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Jun 15 12:14:34.937: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/services/test-service/proxy/some/path/with/HEAD
  Jun 15 12:14:34.942: INFO: http.Client request:HEAD | StatusCode:200
  Jun 15 12:14:34.942: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/services/test-service/proxy/some/path/with/OPTIONS
  Jun 15 12:14:34.948: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Jun 15 12:14:34.948: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/services/test-service/proxy/some/path/with/PATCH
  Jun 15 12:14:34.952: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Jun 15 12:14:34.952: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/services/test-service/proxy/some/path/with/POST
  Jun 15 12:14:34.958: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Jun 15 12:14:34.958: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5264/services/test-service/proxy/some/path/with/PUT
  Jun 15 12:14:34.963: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Jun 15 12:14:34.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-5264" for this suite. @ 06/15/24 12:14:34.966
• [2.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 06/15/24 12:14:34.974
  Jun 15 12:14:34.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir-wrapper @ 06/15/24 12:14:34.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:34.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:34.994
  STEP: Cleaning up the secret @ 06/15/24 12:14:37.027
  STEP: Cleaning up the configmap @ 06/15/24 12:14:37.034
  STEP: Cleaning up the pod @ 06/15/24 12:14:37.04
  Jun 15 12:14:37.050: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-9540" for this suite. @ 06/15/24 12:14:37.055
• [2.086 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 06/15/24 12:14:37.061
  Jun 15 12:14:37.061: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename containers @ 06/15/24 12:14:37.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:37.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:37.08
  STEP: Creating a pod to test override arguments @ 06/15/24 12:14:37.083
  STEP: Saw pod success @ 06/15/24 12:14:41.105
  Jun 15 12:14:41.108: INFO: Trying to get logs from node ip-172-31-7-7 pod client-containers-e21c49b7-6c06-49b1-8c20-ba493878606b container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:14:41.116
  Jun 15 12:14:41.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6485" for this suite. @ 06/15/24 12:14:41.138
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 06/15/24 12:14:41.146
  Jun 15 12:14:41.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:14:41.146
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:41.162
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:41.165
  STEP: creating service multi-endpoint-test in namespace services-1790 @ 06/15/24 12:14:41.168
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1790 to expose endpoints map[] @ 06/15/24 12:14:41.177
  Jun 15 12:14:41.181: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  Jun 15 12:14:42.189: INFO: successfully validated that service multi-endpoint-test in namespace services-1790 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-1790 @ 06/15/24 12:14:42.189
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1790 to expose endpoints map[pod1:[100]] @ 06/15/24 12:14:44.211
  Jun 15 12:14:44.221: INFO: successfully validated that service multi-endpoint-test in namespace services-1790 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-1790 @ 06/15/24 12:14:44.221
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1790 to expose endpoints map[pod1:[100] pod2:[101]] @ 06/15/24 12:14:46.239
  Jun 15 12:14:46.251: INFO: successfully validated that service multi-endpoint-test in namespace services-1790 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 06/15/24 12:14:46.251
  Jun 15 12:14:46.251: INFO: Creating new exec pod
  Jun 15 12:14:49.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1790 exec execpod24cdk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Jun 15 12:14:49.361: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Jun 15 12:14:49.361: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:14:49.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1790 exec execpod24cdk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.248 80'
  Jun 15 12:14:49.448: INFO: stderr: "+ nc -v -t -w 2 10.152.183.248 80\n+ echo hostName\nConnection to 10.152.183.248 80 port [tcp/http] succeeded!\n"
  Jun 15 12:14:49.448: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:14:49.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1790 exec execpod24cdk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Jun 15 12:14:49.542: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Jun 15 12:14:49.542: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:14:49.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1790 exec execpod24cdk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.248 81'
  Jun 15 12:14:49.633: INFO: stderr: "+ nc -v -t -w 2 10.152.183.248 81\n+ echo hostName\nConnection to 10.152.183.248 81 port [tcp/*] succeeded!\n"
  Jun 15 12:14:49.633: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-1790 @ 06/15/24 12:14:49.633
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1790 to expose endpoints map[pod2:[101]] @ 06/15/24 12:14:49.654
  Jun 15 12:14:49.669: INFO: successfully validated that service multi-endpoint-test in namespace services-1790 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-1790 @ 06/15/24 12:14:49.669
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1790 to expose endpoints map[] @ 06/15/24 12:14:49.679
  Jun 15 12:14:50.697: INFO: successfully validated that service multi-endpoint-test in namespace services-1790 exposes endpoints map[]
  Jun 15 12:14:50.717: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1790" for this suite. @ 06/15/24 12:14:50.719
• [9.580 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 06/15/24 12:14:50.725
  Jun 15 12:14:50.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename custom-resource-definition @ 06/15/24 12:14:50.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:50.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:50.746
  Jun 15 12:14:50.749: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:14:51.772: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3241" for this suite. @ 06/15/24 12:14:51.777
• [1.058 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 06/15/24 12:14:51.784
  Jun 15 12:14:51.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 12:14:51.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:51.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:51.805
  STEP: Creating secret with name secret-test-070fc77e-5033-4003-8dd7-db0b5ed0475e @ 06/15/24 12:14:51.809
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:14:51.814
  STEP: Saw pod success @ 06/15/24 12:14:55.832
  Jun 15 12:14:55.836: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-secrets-acb12e0e-58f9-400a-a330-4006756be675 container secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:14:55.843
  Jun 15 12:14:55.856: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2802" for this suite. @ 06/15/24 12:14:55.859
• [4.081 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 06/15/24 12:14:55.866
  Jun 15 12:14:55.866: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:14:55.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:55.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:55.883
  STEP: Setting up server cert @ 06/15/24 12:14:55.908
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:14:56.038
  STEP: Deploying the webhook pod @ 06/15/24 12:14:56.046
  STEP: Wait for the deployment to be ready @ 06/15/24 12:14:56.057
  Jun 15 12:14:56.064: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 06/15/24 12:14:58.076
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:14:58.084
  Jun 15 12:14:59.084: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 06/15/24 12:14:59.093
  STEP: Creating a custom resource definition that should be denied by the webhook @ 06/15/24 12:14:59.108
  Jun 15 12:14:59.108: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:14:59.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1242" for this suite. @ 06/15/24 12:14:59.162
  STEP: Destroying namespace "webhook-markers-3195" for this suite. @ 06/15/24 12:14:59.176
• [3.318 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 06/15/24 12:14:59.183
  Jun 15 12:14:59.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:14:59.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:14:59.198
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:14:59.201
  STEP: Creating configMap with name projected-configmap-test-volume-868de238-1967-4f6c-96f9-ea20dd604f42 @ 06/15/24 12:14:59.204
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:14:59.208
  STEP: Saw pod success @ 06/15/24 12:15:03.231
  Jun 15 12:15:03.236: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-configmaps-9ad8e4b2-c3af-4d72-8f62-7fe3a139273d container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:15:03.243
  Jun 15 12:15:03.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8718" for this suite. @ 06/15/24 12:15:03.258
• [4.081 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:430
  STEP: Creating a kubernetes client @ 06/15/24 12:15:03.265
  Jun 15 12:15:03.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pv @ 06/15/24 12:15:03.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:15:03.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:15:03.286
  STEP: Creating initial PV and PVC @ 06/15/24 12:15:03.289
  Jun 15 12:15:03.289: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-2650" @ 06/15/24 12:15:03.303
  STEP: Listing PVCs in namespace "pv-2650" @ 06/15/24 12:15:03.306
  STEP: Patching the PV "pv-2650-bn2wl" @ 06/15/24 12:15:03.31
  STEP: Patching the PVC "pvc-thcvk" @ 06/15/24 12:15:03.318
  STEP: Getting PV "pv-2650-bn2wl" @ 06/15/24 12:15:03.325
  STEP: Getting PVC "pvc-thcvk" @ 06/15/24 12:15:03.329
  STEP: Deleting PVC "pvc-thcvk" @ 06/15/24 12:15:03.335
  STEP: Confirm deletion of PVC "pvc-thcvk" @ 06/15/24 12:15:03.343
  STEP: Deleting PV "pv-2650-bn2wl" @ 06/15/24 12:15:05.351
  STEP: Confirm deletion of PV "pv-2650-bn2wl" @ 06/15/24 12:15:05.358
  STEP: Recreating another PV & PVC @ 06/15/24 12:15:07.368
  Jun 15 12:15:07.368: INFO: Creating a PV followed by a PVC
  STEP: Updating the PV "pv-2650-r4ldc" @ 06/15/24 12:15:07.381
  STEP: Updating the PVC "pvc-n9p9x" @ 06/15/24 12:15:07.414
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-n9p9x=updated" @ 06/15/24 12:15:07.422
  STEP: Deleting PVC "pvc-n9p9x" via DeleteCollection @ 06/15/24 12:15:07.425
  STEP: Confirm deletion of PVC "pvc-n9p9x" @ 06/15/24 12:15:07.434
  STEP: Deleting PV "pv-2650-r4ldc" via DeleteCollection @ 06/15/24 12:15:09.442
  STEP: Confirm deletion of PV "pv-2650-r4ldc" @ 06/15/24 12:15:09.452
  Jun 15 12:15:11.460: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Jun 15 12:15:11.461: INFO: Deleting PersistentVolumeClaim "pvc-n9p9x"
  Jun 15 12:15:11.464: INFO: Deleting PersistentVolume "pv-2650-r4ldc"
  Jun 15 12:15:11.469: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-2650" for this suite. @ 06/15/24 12:15:11.473
• [8.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 06/15/24 12:15:11.482
  Jun 15 12:15:11.482: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename daemonsets @ 06/15/24 12:15:11.483
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:15:11.497
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:15:11.499
  STEP: Creating simple DaemonSet "daemon-set" @ 06/15/24 12:15:11.524
  STEP: Check that daemon pods launch on every node of the cluster. @ 06/15/24 12:15:11.528
  Jun 15 12:15:11.531: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:11.531: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:11.536: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:15:11.536: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  Jun 15 12:15:12.534: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:12.534: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:12.537: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:15:12.537: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  Jun 15 12:15:13.532: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:13.532: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:13.536: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 12:15:13.536: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 06/15/24 12:15:13.54
  Jun 15 12:15:13.555: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:13.555: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:13.558: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Jun 15 12:15:13.558: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  Jun 15 12:15:14.557: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:14.558: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:14.562: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Jun 15 12:15:14.562: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  Jun 15 12:15:15.558: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:15.558: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:15:15.561: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 12:15:15.561: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 06/15/24 12:15:15.564
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-441, will wait for the garbage collector to delete the pods @ 06/15/24 12:15:15.564
  Jun 15 12:15:15.625: INFO: Deleting DaemonSet.extensions daemon-set took: 7.941596ms
  Jun 15 12:15:15.726: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.066735ms
  Jun 15 12:15:16.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:15:16.930: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Jun 15 12:15:16.936: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8284"},"items":null}

  Jun 15 12:15:16.940: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8284"},"items":null}

  Jun 15 12:15:16.953: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-441" for this suite. @ 06/15/24 12:15:16.958
• [5.482 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:153
  STEP: Creating a kubernetes client @ 06/15/24 12:15:16.964
  Jun 15 12:15:16.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 06/15/24 12:15:16.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:15:16.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:15:16.984
  STEP: create the container to handle the HTTPGet hook request. @ 06/15/24 12:15:16.99
  STEP: create the pod with lifecycle hook @ 06/15/24 12:15:19.01
  STEP: delete the pod with lifecycle hook @ 06/15/24 12:15:21.031
  STEP: check prestop hook @ 06/15/24 12:15:23.047
  Jun 15 12:15:23.063: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7936" for this suite. @ 06/15/24 12:15:23.068
• [6.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 06/15/24 12:15:23.075
  Jun 15 12:15:23.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:15:23.076
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:15:23.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:15:23.093
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:15:23.096
  STEP: Saw pod success @ 06/15/24 12:15:25.111
  Jun 15 12:15:25.115: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-45b2369d-cdee-4d64-9c05-567fd461d6db container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:15:25.12
  Jun 15 12:15:25.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9815" for this suite. @ 06/15/24 12:15:25.136
• [2.070 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3649
  STEP: Creating a kubernetes client @ 06/15/24 12:15:25.146
  Jun 15 12:15:25.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:15:25.146
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:15:25.163
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:15:25.166
  STEP: creating service multiprotocol-test in namespace services-4754 @ 06/15/24 12:15:25.169
  STEP: creating pod pod1 in namespace services-4754 @ 06/15/24 12:15:25.177
  STEP: Creating pod pod1 in namespace services-4754 @ 06/15/24 12:15:25.177
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-4754 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 06/15/24 12:15:27.201
  Jun 15 12:15:27.212: INFO: successfully validated that service multiprotocol-test in namespace services-4754 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 06/15/24 12:15:27.212
  Jun 15 12:15:27.212: INFO: Creating new exec pod
  Jun 15 12:15:29.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.179 80'
  Jun 15 12:15:29.327: INFO: stderr: "+ nc -v -t -w 2 10.152.183.179 80\n+ echo hostName\nConnection to 10.152.183.179 80 port [tcp/http] succeeded!\n"
  Jun 15 12:15:29.327: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:15:29.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.179 80'
  Jun 15 12:15:33.420: INFO: stderr: "+ nc -v -u -w 2 10.152.183.179 80\n+ echo hostName\nConnection to 10.152.183.179 80 port [udp/*] succeeded!\n"
  Jun 15 12:15:33.420: INFO: stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 06/15/24 12:15:33.42
  Jun 15 12:15:33.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.179 80'
  Jun 15 12:15:33.538: INFO: stderr: "+ nc -v -t -w 2 10.152.183.179 80\n+ echo hostName\nConnection to 10.152.183.179 80 port [tcp/http] succeeded!\n"
  Jun 15 12:15:33.538: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:15:33.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.179 80'
  Jun 15 12:15:37.634: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.179 80\nConnection to 10.152.183.179 80 port [udp/*] succeeded!\n"
  Jun 15 12:15:37.634: INFO: stdout: ""
  Jun 15 12:15:37.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.179 80'
  Jun 15 12:15:41.728: INFO: stderr: "+ nc -v -u -w 2 10.152.183.179 80\n+ echo hostName\nConnection to 10.152.183.179 80 port [udp/*] succeeded!\n"
  Jun 15 12:15:41.728: INFO: stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 06/15/24 12:15:41.728
  Jun 15 12:15:41.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -u -w 2 10.152.183.179 80'
  Jun 15 12:15:45.891: INFO: stderr: "+ echo hostName\n+ nc -v -u -w 2 10.152.183.179 80\nConnection to 10.152.183.179 80 port [udp/*] succeeded!\n"
  Jun 15 12:15:45.891: INFO: stdout: "pod1"
  Jun 15 12:15:45.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.179 80'
  Jun 15 12:15:47.983: INFO: rc: 1
  Jun 15 12:15:47.983: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.179 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.152.183.179 80
  nc: connect to 10.152.183.179 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Jun 15 12:15:47.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.179 80'
  Jun 15 12:15:50.080: INFO: rc: 1
  Jun 15 12:15:50.080: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.179 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 10.152.183.179 80
  + echo hostName
  nc: connect to 10.152.183.179 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Jun 15 12:15:50.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.179 80'
  Jun 15 12:15:52.183: INFO: rc: 1
  Jun 15 12:15:52.183: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4754 exec execpodd2mfw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.179 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 10.152.183.179 80
  nc: connect to 10.152.183.179 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Jun 15 12:15:52.183: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4754" for this suite. @ 06/15/24 12:15:52.188
• [27.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:335
  STEP: Creating a kubernetes client @ 06/15/24 12:15:52.195
  Jun 15 12:15:52.195: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-pred @ 06/15/24 12:15:52.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:15:52.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:15:52.217
  Jun 15 12:15:52.220: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Jun 15 12:15:52.226: INFO: Waiting for terminating namespaces to be deleted...
  Jun 15 12:15:52.229: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-17-110 before test
  Jun 15 12:15:52.233: INFO: nginx-ingress-controller-kubernetes-worker-pfb28 from ingress-nginx-kubernetes-worker started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.233: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: calico-node-hkrvf from kube-system started at 2024-06-15 12:04:11 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.233: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: coredns-bddfd76d7-mp2lw from kube-system started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.233: INFO: 	Container coredns ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: kube-state-metrics-6f48cdd76-fzrm6 from kube-system started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.233: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: metrics-server-v0.6.3-69d7fbfdf8-nhfgd from kube-system started at 2024-06-15 11:55:24 +0000 UTC (2 container statuses recorded)
  Jun 15 12:15:52.233: INFO: 	Container metrics-server ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: dashboard-metrics-scraper-5dd7cb5fc-6zmr5 from kubernetes-dashboard started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.233: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: kubernetes-dashboard-7b899cb9d9-444dc from kubernetes-dashboard started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.233: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-nhpcv from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 12:15:52.233: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: 	Container systemd-logs ready: true, restart count 0
  Jun 15 12:15:52.233: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-43-132 before test
  Jun 15 12:15:52.239: INFO: nginx-ingress-controller-kubernetes-worker-z9k8m from ingress-nginx-kubernetes-worker started at 2024-06-15 12:01:27 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.239: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 12:15:52.239: INFO: calico-node-f899m from kube-system started at 2024-06-15 12:04:32 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.239: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 12:15:52.239: INFO: execpodd2mfw from services-4754 started at 2024-06-15 12:15:27 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.239: INFO: 	Container agnhost-container ready: true, restart count 0
  Jun 15 12:15:52.239: INFO: sonobuoy-e2e-job-6485ce82c274498d from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 12:15:52.239: INFO: 	Container e2e ready: true, restart count 0
  Jun 15 12:15:52.239: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 12:15:52.239: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-xzkdr from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 12:15:52.239: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 12:15:52.239: INFO: 	Container systemd-logs ready: true, restart count 0
  Jun 15 12:15:52.239: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-7-7 before test
  Jun 15 12:15:52.244: INFO: nginx-ingress-controller-kubernetes-worker-xctb6 from ingress-nginx-kubernetes-worker started at 2024-06-15 12:03:46 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.244: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 12:15:52.244: INFO: calico-node-6rvnh from kube-system started at 2024-06-15 12:03:27 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.244: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 12:15:52.244: INFO: pod1 from services-4754 started at 2024-06-15 12:15:25 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.244: INFO: 	Container agnhost-container ready: true, restart count 0
  Jun 15 12:15:52.244: INFO: sonobuoy from sonobuoy started at 2024-06-15 12:05:44 +0000 UTC (1 container statuses recorded)
  Jun 15 12:15:52.244: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Jun 15 12:15:52.244: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-mkhb2 from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 12:15:52.244: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 12:15:52.244: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-17-110 @ 06/15/24 12:15:52.258
  STEP: verifying the node has the label node ip-172-31-43-132 @ 06/15/24 12:15:52.269
  STEP: verifying the node has the label node ip-172-31-7-7 @ 06/15/24 12:15:52.282
  Jun 15 12:15:52.294: INFO: Pod nginx-ingress-controller-kubernetes-worker-pfb28 requesting resource cpu=0m on Node ip-172-31-17-110
  Jun 15 12:15:52.294: INFO: Pod nginx-ingress-controller-kubernetes-worker-xctb6 requesting resource cpu=0m on Node ip-172-31-7-7
  Jun 15 12:15:52.294: INFO: Pod nginx-ingress-controller-kubernetes-worker-z9k8m requesting resource cpu=0m on Node ip-172-31-43-132
  Jun 15 12:15:52.294: INFO: Pod calico-node-6rvnh requesting resource cpu=250m on Node ip-172-31-7-7
  Jun 15 12:15:52.294: INFO: Pod calico-node-f899m requesting resource cpu=250m on Node ip-172-31-43-132
  Jun 15 12:15:52.294: INFO: Pod calico-node-hkrvf requesting resource cpu=250m on Node ip-172-31-17-110
  Jun 15 12:15:52.294: INFO: Pod coredns-bddfd76d7-mp2lw requesting resource cpu=100m on Node ip-172-31-17-110
  Jun 15 12:15:52.294: INFO: Pod kube-state-metrics-6f48cdd76-fzrm6 requesting resource cpu=0m on Node ip-172-31-17-110
  Jun 15 12:15:52.294: INFO: Pod metrics-server-v0.6.3-69d7fbfdf8-nhfgd requesting resource cpu=5m on Node ip-172-31-17-110
  Jun 15 12:15:52.294: INFO: Pod dashboard-metrics-scraper-5dd7cb5fc-6zmr5 requesting resource cpu=0m on Node ip-172-31-17-110
  Jun 15 12:15:52.294: INFO: Pod kubernetes-dashboard-7b899cb9d9-444dc requesting resource cpu=0m on Node ip-172-31-17-110
  Jun 15 12:15:52.294: INFO: Pod execpodd2mfw requesting resource cpu=0m on Node ip-172-31-43-132
  Jun 15 12:15:52.294: INFO: Pod pod1 requesting resource cpu=0m on Node ip-172-31-7-7
  Jun 15 12:15:52.294: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-7-7
  Jun 15 12:15:52.294: INFO: Pod sonobuoy-e2e-job-6485ce82c274498d requesting resource cpu=0m on Node ip-172-31-43-132
  Jun 15 12:15:52.294: INFO: Pod sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-mkhb2 requesting resource cpu=0m on Node ip-172-31-7-7
  Jun 15 12:15:52.294: INFO: Pod sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-nhpcv requesting resource cpu=0m on Node ip-172-31-17-110
  Jun 15 12:15:52.294: INFO: Pod sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-xzkdr requesting resource cpu=0m on Node ip-172-31-43-132
  STEP: Starting Pods to consume most of the cluster CPU. @ 06/15/24 12:15:52.294
  Jun 15 12:15:52.295: INFO: Creating a pod which consumes cpu=1151m on Node ip-172-31-17-110
  Jun 15 12:15:52.306: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-43-132
  Jun 15 12:15:52.314: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-7-7
  STEP: Creating another pod that requires unavailable amount of CPU. @ 06/15/24 12:15:54.341
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1a73356d-544a-4346-a93b-4abb5e11dc6c.17d92c953db85330], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8373/filler-pod-1a73356d-544a-4346-a93b-4abb5e11dc6c to ip-172-31-17-110] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1a73356d-544a-4346-a93b-4abb5e11dc6c.17d92c955b05211b], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.9"] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1a73356d-544a-4346-a93b-4abb5e11dc6c.17d92c955f646d19], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.9" in 73ms (73ms including waiting)] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1a73356d-544a-4346-a93b-4abb5e11dc6c.17d92c95607221d2], Reason = [Created], Message = [Created container filler-pod-1a73356d-544a-4346-a93b-4abb5e11dc6c] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1a73356d-544a-4346-a93b-4abb5e11dc6c.17d92c95634d4a8c], Reason = [Started], Message = [Started container filler-pod-1a73356d-544a-4346-a93b-4abb5e11dc6c] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1b2b7e67-f4de-490b-ba40-a74d573dabde.17d92c953df2385b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8373/filler-pod-1b2b7e67-f4de-490b-ba40-a74d573dabde to ip-172-31-43-132] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1b2b7e67-f4de-490b-ba40-a74d573dabde.17d92c955ce8fdaa], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1b2b7e67-f4de-490b-ba40-a74d573dabde.17d92c955dd59ca4], Reason = [Created], Message = [Created container filler-pod-1b2b7e67-f4de-490b-ba40-a74d573dabde] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1b2b7e67-f4de-490b-ba40-a74d573dabde.17d92c9560cf3857], Reason = [Started], Message = [Started container filler-pod-1b2b7e67-f4de-490b-ba40-a74d573dabde] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-366af431-ca82-4fab-a2db-902bcb6bb1bb.17d92c953e8dd516], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8373/filler-pod-366af431-ca82-4fab-a2db-902bcb6bb1bb to ip-172-31-7-7] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-366af431-ca82-4fab-a2db-902bcb6bb1bb.17d92c955cabd44d], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-366af431-ca82-4fab-a2db-902bcb6bb1bb.17d92c955d895d06], Reason = [Created], Message = [Created container filler-pod-366af431-ca82-4fab-a2db-902bcb6bb1bb] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-366af431-ca82-4fab-a2db-902bcb6bb1bb.17d92c955fead7ac], Reason = [Started], Message = [Started container filler-pod-366af431-ca82-4fab-a2db-902bcb6bb1bb] @ 06/15/24 12:15:54.345
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17d92c95b71aff84], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] @ 06/15/24 12:15:54.357
  STEP: removing the label node off the node ip-172-31-17-110 @ 06/15/24 12:15:55.357
  STEP: verifying the node doesn't have the label node @ 06/15/24 12:15:55.369
  STEP: removing the label node off the node ip-172-31-43-132 @ 06/15/24 12:15:55.372
  STEP: verifying the node doesn't have the label node @ 06/15/24 12:15:55.383
  STEP: removing the label node off the node ip-172-31-7-7 @ 06/15/24 12:15:55.387
  STEP: verifying the node doesn't have the label node @ 06/15/24 12:15:55.399
  Jun 15 12:15:55.402: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8373" for this suite. @ 06/15/24 12:15:55.407
• [3.218 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 06/15/24 12:15:55.413
  Jun 15 12:15:55.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename init-container @ 06/15/24 12:15:55.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:15:55.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:15:55.433
  STEP: creating the pod @ 06/15/24 12:15:55.437
  Jun 15 12:15:55.437: INFO: PodSpec: initContainers in spec.initContainers
  Jun 15 12:15:59.002: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5702" for this suite. @ 06/15/24 12:15:59.005
• [3.598 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 06/15/24 12:15:59.012
  Jun 15 12:15:59.012: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:15:59.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:15:59.027
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:15:59.032
  STEP: Setting up server cert @ 06/15/24 12:15:59.055
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:15:59.279
  STEP: Deploying the webhook pod @ 06/15/24 12:15:59.286
  STEP: Wait for the deployment to be ready @ 06/15/24 12:15:59.298
  Jun 15 12:15:59.306: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 06/15/24 12:16:01.318
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:16:01.327
  Jun 15 12:16:02.328: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Jun 15 12:16:02.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8120-crds.webhook.example.com via the AdmissionRegistration API @ 06/15/24 12:16:02.85
  STEP: Creating a custom resource that should be mutated by the webhook @ 06/15/24 12:16:02.863
  Jun 15 12:16:05.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-854" for this suite. @ 06/15/24 12:16:05.461
  STEP: Destroying namespace "webhook-markers-630" for this suite. @ 06/15/24 12:16:05.471
• [6.466 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:134
  STEP: Creating a kubernetes client @ 06/15/24 12:16:05.479
  Jun 15 12:16:05.479: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubelet-test @ 06/15/24 12:16:05.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:16:05.494
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:16:05.497
  Jun 15 12:16:05.525: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6403" for this suite. @ 06/15/24 12:16:05.528
• [0.055 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 06/15/24 12:16:05.534
  Jun 15 12:16:05.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-preemption @ 06/15/24 12:16:05.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:16:05.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:16:05.553
  Jun 15 12:16:05.568: INFO: Waiting up to 1m0s for all nodes to be ready
  Jun 15 12:17:05.575: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 06/15/24 12:17:05.579
  Jun 15 12:17:05.598: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Jun 15 12:17:05.606: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Jun 15 12:17:05.623: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Jun 15 12:17:05.631: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Jun 15 12:17:05.646: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Jun 15 12:17:05.653: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 06/15/24 12:17:05.653
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 06/15/24 12:17:09.685
  Jun 15 12:17:13.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3779" for this suite. @ 06/15/24 12:17:13.762
• [68.235 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 06/15/24 12:17:13.77
  Jun 15 12:17:13.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 12:17:13.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:17:13.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:17:13.792
  STEP: Creating pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883 @ 06/15/24 12:17:13.795
  STEP: checking the pod's current state and verifying that restartCount is present @ 06/15/24 12:17:15.811
  Jun 15 12:17:15.814: INFO: Initial restart count of pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 is 0
  Jun 15 12:17:15.818: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:17.823: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:19.832: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:21.836: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:23.840: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:25.846: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:27.852: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:29.857: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:31.862: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:33.867: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:35.873: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:37.879: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:39.883: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:41.888: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:43.893: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:45.899: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:47.905: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:49.911: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:51.916: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:53.922: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:55.927: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:57.932: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:17:59.936: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:18:01.941: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:18:03.947: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:18:05.952: INFO: Get pod busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 in namespace container-probe-2883
  Jun 15 12:18:05.952: INFO: Restart count of pod container-probe-2883/busybox-38e9f88e-07f6-453b-8c5b-fc0d88142765 is now 1 (50.138057948s elapsed)
  STEP: deleting the pod @ 06/15/24 12:18:05.952
  Jun 15 12:18:05.967: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2883" for this suite. @ 06/15/24 12:18:05.97
• [52.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 06/15/24 12:18:05.977
  Jun 15 12:18:05.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename deployment @ 06/15/24 12:18:05.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:18:05.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:18:05.997
  Jun 15 12:18:06.007: INFO: Pod name rollover-pod: Found 0 pods out of 1
  Jun 15 12:18:11.015: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 06/15/24 12:18:11.015
  Jun 15 12:18:11.015: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  Jun 15 12:18:13.021: INFO: Creating deployment "test-rollover-deployment"
  Jun 15 12:18:13.032: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  Jun 15 12:18:15.040: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Jun 15 12:18:15.048: INFO: Ensure that both replica sets have 1 created replica
  Jun 15 12:18:15.054: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Jun 15 12:18:15.064: INFO: Updating deployment test-rollover-deployment
  Jun 15 12:18:15.064: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  Jun 15 12:18:17.073: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Jun 15 12:18:17.079: INFO: Make sure deployment "test-rollover-deployment" is complete
  Jun 15 12:18:17.086: INFO: all replica sets need to contain the pod-template-hash label
  Jun 15 12:18:17.086: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:19.095: INFO: all replica sets need to contain the pod-template-hash label
  Jun 15 12:18:19.095: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:21.094: INFO: all replica sets need to contain the pod-template-hash label
  Jun 15 12:18:21.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:23.094: INFO: all replica sets need to contain the pod-template-hash label
  Jun 15 12:18:23.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:25.096: INFO: all replica sets need to contain the pod-template-hash label
  Jun 15 12:18:25.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 16, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:27.093: INFO: 
  Jun 15 12:18:27.093: INFO: Ensure that both old replica sets have no replicas
  Jun 15 12:18:27.103: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3ef2bf56-8e3c-4b35-a760-eca3acfb5afc",
      ResourceVersion: (string) (len=4) "9414",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050693,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050706,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050693,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050693,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050706,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050693,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-68774655d5\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Jun 15 12:18:27.108: INFO: New ReplicaSet "test-rollover-deployment-68774655d5" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-68774655d5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "de70ac48-4af8-4555-bd7d-c3989b6f7c0b",
      ResourceVersion: (string) (len=4) "9404",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050695,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "3ef2bf56-8e3c-4b35-a760-eca3acfb5afc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 65 66 32 62 66  35 36 2d 38 65 33 63 2d  |\"3ef2bf56-8e3c-|
              00000120  34 62 33 35 2d 61 37 36  30 2d 65 63 61 33 61 63  |4b35-a760-eca3ac|
              00000130  66 62 35 61 66 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |fb5afc\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050706,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:18:27.109: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Jun 15 12:18:27.109: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b2e237cf-8572-4d81-b1a5-da62f3f38bf2",
      ResourceVersion: (string) (len=4) "9413",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050686,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "3ef2bf56-8e3c-4b35-a760-eca3acfb5afc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050686,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050706,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  33 65 66 32 62 66 35 36  2d 38 65 33 63 2d 34 62  |3ef2bf56-8e3c-4b|
              000000c0  33 35 2d 61 37 36 30 2d  65 63 61 33 61 63 66 62  |35-a760-eca3acfb|
              000000d0  35 61 66 63 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |5afc\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050706,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:18:27.110: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2761732e-8c2c-42f8-82d8-a405a3ad6e08",
      ResourceVersion: (string) (len=4) "9362",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050693,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "3ef2bf56-8e3c-4b35-a760-eca3acfb5afc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 65 66 32 62 66  35 36 2d 38 65 33 63 2d  |\"3ef2bf56-8e3c-|
              00000120  34 62 33 35 2d 61 37 36  30 2d 65 63 61 33 61 63  |4b35-a760-eca3ac|
              00000130  66 62 35 61 66 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |fb5afc\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:18:27.115: INFO: Pod "test-rollover-deployment-68774655d5-zcwr6" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-68774655d5-zcwr6",
      GenerateName: (string) (len=36) "test-rollover-deployment-68774655d5-",
      Namespace: (string) (len=15) "deployment-4740",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "11483c44-8432-409a-9f09-9f533236879b",
      ResourceVersion: (string) (len=4) "9383",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050695,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-68774655d5",
          UID: (types.UID) (len=36) "de70ac48-4af8-4555-bd7d-c3989b6f7c0b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 65  37 30 61 63 34 38 2d 34  |d\":\"de70ac48-4|
              00000090  61 66 38 2d 34 35 35 35  2d 62 64 37 64 2d 63 33  |af8-4555-bd7d-c3|
              000000a0  39 38 39 62 36 66 37 63  30 62 5c 22 7d 22 3a 7b  |989b6f7c0b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050696,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  34 2e 31 38 33 5c 22 7d  |2.168.164.183\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-spw9t",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-spw9t",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050696,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050696,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050696,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854050695,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) (len=15) "192.168.164.183",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.164.183"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854050695,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854050695,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://148fb684ec76c360c8dc2de8fe473eea3bb7e5270ed02c00f90d26ab0305167f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:18:27.116: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4740" for this suite. @ 06/15/24 12:18:27.12
• [21.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:96
  STEP: Creating a kubernetes client @ 06/15/24 12:18:27.128
  Jun 15 12:18:27.128: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 12:18:27.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:18:27.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:18:27.148
  STEP: creating secret secrets-5093/secret-test-16d41593-b198-4c05-9c01-8755f57026fb @ 06/15/24 12:18:27.151
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:18:27.155
  STEP: Saw pod success @ 06/15/24 12:18:31.177
  Jun 15 12:18:31.180: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-configmaps-69c224a3-e6c1-4576-a91f-b3ddf1e72a36 container env-test: <nil>
  STEP: delete the pod @ 06/15/24 12:18:31.194
  Jun 15 12:18:31.212: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5093" for this suite. @ 06/15/24 12:18:31.216
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 06/15/24 12:18:31.224
  Jun 15 12:18:31.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename aggregator @ 06/15/24 12:18:31.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:18:31.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:18:31.243
  Jun 15 12:18:31.246: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Registering the sample API server. @ 06/15/24 12:18:31.247
  Jun 15 12:18:31.539: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Jun 15 12:18:31.567: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  Jun 15 12:18:33.611: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:35.617: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:37.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:39.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:41.617: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:43.618: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:45.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:47.617: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:49.617: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:51.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:53.617: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:55.616: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:57.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Jun 15 12:18:59.735: INFO: Waited 110.891542ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 06/15/24 12:18:59.771
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 06/15/24 12:18:59.776
  STEP: List APIServices @ 06/15/24 12:18:59.783
  Jun 15 12:18:59.787: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 06/15/24 12:18:59.787
  Jun 15 12:18:59.804: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 06/15/24 12:18:59.804
  Jun 15 12:18:59.815: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.June, 15, 12, 18, 59, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 06/15/24 12:18:59.815
  Jun 15 12:18:59.818: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-06-15 12:18:59 +0000 UTC Passed all checks passed}
  Jun 15 12:18:59.818: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Jun 15 12:18:59.818: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 06/15/24 12:18:59.818
  Jun 15 12:18:59.827: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1472978435" @ 06/15/24 12:18:59.828
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 06/15/24 12:18:59.838
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 06/15/24 12:18:59.844
  STEP: Patch APIService Status @ 06/15/24 12:18:59.848
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 06/15/24 12:18:59.854
  Jun 15 12:18:59.859: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-06-15 12:18:59 +0000 UTC Passed all checks passed}
  Jun 15 12:18:59.859: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Jun 15 12:18:59.859: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Jun 15 12:18:59.859: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 06/15/24 12:18:59.859
  STEP: Confirm that the generated APIService has been deleted @ 06/15/24 12:18:59.867
  Jun 15 12:18:59.867: INFO: Requesting list of APIServices to confirm quantity
  Jun 15 12:18:59.871: INFO: Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  Jun 15 12:18:59.871: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Jun 15 12:18:59.969: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-2351" for this suite. @ 06/15/24 12:18:59.973
• [28.755 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 06/15/24 12:18:59.979
  Jun 15 12:18:59.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 12:18:59.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:18:59.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:00
  Jun 15 12:19:22.079: INFO: Container started at 2024-06-15 12:19:00 +0000 UTC, pod became ready at 2024-06-15 12:19:20 +0000 UTC
  Jun 15 12:19:22.079: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4317" for this suite. @ 06/15/24 12:19:22.084
• [22.112 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 06/15/24 12:19:22.091
  Jun 15 12:19:22.091: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename runtimeclass @ 06/15/24 12:19:22.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:22.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:22.111
  Jun 15 12:19:24.144: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4628" for this suite. @ 06/15/24 12:19:24.147
• [2.063 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 06/15/24 12:19:24.154
  Jun 15 12:19:24.154: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 12:19:24.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:24.17
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:24.172
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 06/15/24 12:19:24.175
  Jun 15 12:19:24.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:19:25.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:19:30.290: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1360" for this suite. @ 06/15/24 12:19:30.296
• [6.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:572
  STEP: Creating a kubernetes client @ 06/15/24 12:19:30.305
  Jun 15 12:19:30.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename job @ 06/15/24 12:19:30.305
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:30.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:30.326
  STEP: Creating a job @ 06/15/24 12:19:30.329
  STEP: Ensuring job reaches completions @ 06/15/24 12:19:30.336
  Jun 15 12:19:40.344: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2168" for this suite. @ 06/15/24 12:19:40.349
• [10.051 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 06/15/24 12:19:40.356
  Jun 15 12:19:40.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:19:40.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:40.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:40.375
  STEP: Creating configMap with name projected-configmap-test-volume-map-5a924d7d-5510-46d0-b42f-3bdac749ef54 @ 06/15/24 12:19:40.378
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:19:40.383
  STEP: Saw pod success @ 06/15/24 12:19:44.407
  Jun 15 12:19:44.410: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-configmaps-5f003c2c-b6f2-422d-9b42-73b9d71d0390 container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:19:44.415
  Jun 15 12:19:44.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1991" for this suite. @ 06/15/24 12:19:44.438
• [4.088 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 06/15/24 12:19:44.444
  Jun 15 12:19:44.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 12:19:44.444
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:44.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:44.463
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 06/15/24 12:19:44.466
  STEP: Saw pod success @ 06/15/24 12:19:46.485
  Jun 15 12:19:46.489: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-045a271a-1854-4c68-a690-6d65bb88f22e container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:19:46.495
  Jun 15 12:19:46.512: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7086" for this suite. @ 06/15/24 12:19:46.514
• [2.077 seconds]
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 06/15/24 12:19:46.521
  Jun 15 12:19:46.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename var-expansion @ 06/15/24 12:19:46.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:46.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:46.542
  STEP: Creating a pod to test substitution in volume subpath @ 06/15/24 12:19:46.545
  STEP: Saw pod success @ 06/15/24 12:19:48.563
  Jun 15 12:19:48.567: INFO: Trying to get logs from node ip-172-31-7-7 pod var-expansion-cf1373ec-e836-4847-9d73-f7631b681d78 container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 12:19:48.574
  Jun 15 12:19:48.588: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6039" for this suite. @ 06/15/24 12:19:48.591
• [2.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:399
  STEP: Creating a kubernetes client @ 06/15/24 12:19:48.6
  Jun 15 12:19:48.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 12:19:48.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:48.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:48.624
  STEP: creating all guestbook components @ 06/15/24 12:19:48.626
  Jun 15 12:19:48.626: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Jun 15 12:19:48.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 create -f -'
  Jun 15 12:19:48.721: INFO: stderr: ""
  Jun 15 12:19:48.721: INFO: stdout: "service/agnhost-replica created\n"
  Jun 15 12:19:48.721: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Jun 15 12:19:48.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 create -f -'
  Jun 15 12:19:48.817: INFO: stderr: ""
  Jun 15 12:19:48.817: INFO: stdout: "service/agnhost-primary created\n"
  Jun 15 12:19:48.817: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Jun 15 12:19:48.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 create -f -'
  Jun 15 12:19:48.901: INFO: stderr: ""
  Jun 15 12:19:48.901: INFO: stdout: "service/frontend created\n"
  Jun 15 12:19:48.901: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Jun 15 12:19:48.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 create -f -'
  Jun 15 12:19:48.970: INFO: stderr: ""
  Jun 15 12:19:48.970: INFO: stdout: "deployment.apps/frontend created\n"
  Jun 15 12:19:48.970: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Jun 15 12:19:48.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 create -f -'
  Jun 15 12:19:49.035: INFO: stderr: ""
  Jun 15 12:19:49.035: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Jun 15 12:19:49.035: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Jun 15 12:19:49.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 create -f -'
  Jun 15 12:19:49.100: INFO: stderr: ""
  Jun 15 12:19:49.100: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 06/15/24 12:19:49.1
  Jun 15 12:19:49.100: INFO: Waiting for all frontend pods to be Running.
  Jun 15 12:19:54.151: INFO: Waiting for frontend to serve content.
  Jun 15 12:19:54.159: INFO: Trying to add a new entry to the guestbook.
  Jun 15 12:19:54.176: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 06/15/24 12:19:54.185
  Jun 15 12:19:54.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 delete --grace-period=0 --force -f -'
  Jun 15 12:19:54.247: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 12:19:54.247: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 06/15/24 12:19:54.247
  Jun 15 12:19:54.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 delete --grace-period=0 --force -f -'
  Jun 15 12:19:54.307: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 12:19:54.307: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 06/15/24 12:19:54.307
  Jun 15 12:19:54.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 delete --grace-period=0 --force -f -'
  Jun 15 12:19:54.365: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 12:19:54.365: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 06/15/24 12:19:54.365
  Jun 15 12:19:54.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 delete --grace-period=0 --force -f -'
  Jun 15 12:19:54.411: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 12:19:54.411: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 06/15/24 12:19:54.411
  Jun 15 12:19:54.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 delete --grace-period=0 --force -f -'
  Jun 15 12:19:54.474: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 12:19:54.474: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 06/15/24 12:19:54.474
  Jun 15 12:19:54.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2347 delete --grace-period=0 --force -f -'
  Jun 15 12:19:54.537: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 12:19:54.537: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Jun 15 12:19:54.537: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2347" for this suite. @ 06/15/24 12:19:54.542
• [5.949 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 06/15/24 12:19:54.549
  Jun 15 12:19:54.549: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename gc @ 06/15/24 12:19:54.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:54.569
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:54.572
  STEP: create the deployment @ 06/15/24 12:19:54.575
  W0615 12:19:54.582736      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 06/15/24 12:19:54.582
  STEP: delete the deployment @ 06/15/24 12:19:54.587
  STEP: wait for all rs to be garbage collected @ 06/15/24 12:19:54.598
  STEP: expected 0 rs, got 1 rs @ 06/15/24 12:19:54.607
  STEP: expected 0 pods, got 2 pods @ 06/15/24 12:19:54.614
  STEP: Gathering metrics @ 06/15/24 12:19:55.11
  W0615 12:19:55.114469      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Jun 15 12:19:55.114: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Jun 15 12:19:55.114: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4420" for this suite. @ 06/15/24 12:19:55.118
• [0.575 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:793
  STEP: Creating a kubernetes client @ 06/15/24 12:19:55.125
  Jun 15 12:19:55.125: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename statefulset @ 06/15/24 12:19:55.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:19:55.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:19:55.15
  STEP: Creating service test in namespace statefulset-1299 @ 06/15/24 12:19:55.153
  STEP: Looking for a node to schedule stateful set and pod @ 06/15/24 12:19:55.157
  STEP: Creating pod with conflicting port in namespace statefulset-1299 @ 06/15/24 12:19:55.16
  STEP: Waiting until pod test-pod will start running in namespace statefulset-1299 @ 06/15/24 12:19:55.17
  STEP: Creating statefulset with conflicting port in namespace statefulset-1299 @ 06/15/24 12:19:57.179
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1299 @ 06/15/24 12:19:57.185
  Jun 15 12:19:57.215: INFO: Observed stateful pod in namespace: statefulset-1299, name: ss-0, uid: f23a6518-6dfb-4a21-bb75-51f5fe6491fc, status phase: Pending. Waiting for statefulset controller to delete.
  Jun 15 12:19:57.236: INFO: Observed stateful pod in namespace: statefulset-1299, name: ss-0, uid: f23a6518-6dfb-4a21-bb75-51f5fe6491fc, status phase: Failed. Waiting for statefulset controller to delete.
  Jun 15 12:19:57.253: INFO: Observed stateful pod in namespace: statefulset-1299, name: ss-0, uid: f23a6518-6dfb-4a21-bb75-51f5fe6491fc, status phase: Failed. Waiting for statefulset controller to delete.
  Jun 15 12:19:57.257: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1299
  STEP: Removing pod with conflicting port in namespace statefulset-1299 @ 06/15/24 12:19:57.257
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1299 and will be in running state @ 06/15/24 12:19:57.271
  Jun 15 12:19:59.279: INFO: Deleting all statefulset in ns statefulset-1299
  Jun 15 12:19:59.283: INFO: Scaling statefulset ss to 0
  Jun 15 12:20:09.295: INFO: Waiting for statefulset status.replicas updated to 0
  Jun 15 12:20:09.300: INFO: Deleting statefulset ss
  Jun 15 12:20:09.313: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1299" for this suite. @ 06/15/24 12:20:09.317
• [14.198 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:695
  STEP: Creating a kubernetes client @ 06/15/24 12:20:09.323
  Jun 15 12:20:09.323: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 12:20:09.324
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:20:09.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:20:09.342
  STEP: Creating a ResourceQuota with terminating scope @ 06/15/24 12:20:09.345
  STEP: Ensuring ResourceQuota status is calculated @ 06/15/24 12:20:09.349
  STEP: Creating a ResourceQuota with not terminating scope @ 06/15/24 12:20:11.355
  STEP: Ensuring ResourceQuota status is calculated @ 06/15/24 12:20:11.36
  STEP: Creating a long running pod @ 06/15/24 12:20:13.365
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 06/15/24 12:20:13.379
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 06/15/24 12:20:15.384
  STEP: Deleting the pod @ 06/15/24 12:20:17.388
  STEP: Ensuring resource quota status released the pod usage @ 06/15/24 12:20:17.399
  STEP: Creating a terminating pod @ 06/15/24 12:20:19.405
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 06/15/24 12:20:19.417
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 06/15/24 12:20:21.422
  STEP: Deleting the pod @ 06/15/24 12:20:23.427
  STEP: Ensuring resource quota status released the pod usage @ 06/15/24 12:20:23.438
  Jun 15 12:20:25.442: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3931" for this suite. @ 06/15/24 12:20:25.446
• [16.128 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 06/15/24 12:20:25.452
  Jun 15 12:20:25.452: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 12:20:25.452
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:20:25.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:20:25.472
  STEP: Creating pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981 @ 06/15/24 12:20:25.475
  STEP: checking the pod's current state and verifying that restartCount is present @ 06/15/24 12:20:27.495
  Jun 15 12:20:27.499: INFO: Initial restart count of pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 is 0
  Jun 15 12:20:27.503: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:29.508: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:31.513: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:33.516: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:35.521: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:37.526: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:39.533: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:41.539: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:43.544: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:45.549: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:47.555: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:49.560: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:51.565: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:53.572: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:55.577: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:57.583: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:20:59.588: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:01.592: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:03.597: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:05.605: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:07.608: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:09.614: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:11.619: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:13.626: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:15.631: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:17.637: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:19.642: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:21.646: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:23.652: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:25.657: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:27.661: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:29.667: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:31.672: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:33.678: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:35.684: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:37.690: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:39.696: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:41.700: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:43.705: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:45.710: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:47.714: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:49.721: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:51.727: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:53.731: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:55.736: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:57.742: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:21:59.747: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:01.752: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:03.757: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:05.761: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:07.765: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:09.770: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:11.775: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:13.781: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:15.787: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:17.793: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:19.798: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:21.802: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:23.808: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:25.812: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:27.816: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:29.822: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:31.828: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:33.832: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:35.837: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:37.841: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:39.847: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:41.853: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:43.858: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:45.864: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:47.870: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:49.876: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:51.882: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:53.888: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:55.894: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:57.899: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:22:59.903: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:01.908: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:03.913: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:05.919: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:07.926: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:09.931: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:11.937: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:13.941: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:15.947: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:17.952: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:19.957: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:21.963: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:23.967: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:25.973: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:27.979: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:29.984: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:31.989: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:33.994: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:35.999: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:38.005: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:40.010: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:42.015: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:44.019: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:46.025: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:48.031: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:50.035: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:52.039: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:54.044: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:56.049: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:23:58.054: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:00.061: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:02.068: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:04.072: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:06.077: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:08.083: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:10.088: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:12.093: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:14.099: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:16.104: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:18.110: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:20.115: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:22.121: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:24.126: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  Jun 15 12:24:26.132: INFO: Get pod busybox-17dc61e7-104c-47f5-adcc-4870ce1e21a9 in namespace container-probe-4981
  STEP: deleting the pod @ 06/15/24 12:24:28.132
  Jun 15 12:24:28.149: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4981" for this suite. @ 06/15/24 12:24:28.152
• [242.707 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 06/15/24 12:24:28.158
  Jun 15 12:24:28.158: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 12:24:28.159
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:24:28.174
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:24:28.177
  STEP: Creating secret with name secret-test-9484fe28-c96e-4f2d-bef8-c1bf65406c55 @ 06/15/24 12:24:28.18
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:24:28.185
  STEP: Saw pod success @ 06/15/24 12:24:32.208
  Jun 15 12:24:32.212: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-secrets-4460d011-4259-41bb-8e44-b37471226e3f container secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:24:32.226
  Jun 15 12:24:32.245: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-887" for this suite. @ 06/15/24 12:24:32.248
• [4.096 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 06/15/24 12:24:32.254
  Jun 15 12:24:32.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:24:32.254
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:24:32.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:24:32.272
  STEP: Setting up server cert @ 06/15/24 12:24:32.296
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:24:32.427
  STEP: Deploying the webhook pod @ 06/15/24 12:24:32.438
  STEP: Wait for the deployment to be ready @ 06/15/24 12:24:32.448
  Jun 15 12:24:32.458: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 06/15/24 12:24:34.473
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:24:34.483
  Jun 15 12:24:35.484: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 06/15/24 12:24:35.49
  STEP: create a pod that should be updated by the webhook @ 06/15/24 12:24:35.503
  Jun 15 12:24:35.562: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7083" for this suite. @ 06/15/24 12:24:35.565
  STEP: Destroying namespace "webhook-markers-9343" for this suite. @ 06/15/24 12:24:35.572
• [3.324 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 06/15/24 12:24:35.58
  Jun 15 12:24:35.580: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 12:24:35.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:24:35.596
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:24:35.599
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 06/15/24 12:24:35.603
  STEP: Saw pod success @ 06/15/24 12:24:39.627
  Jun 15 12:24:39.632: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-b7e86aa6-3216-4b6f-8e21-6a651c9ad1bb container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:24:39.639
  Jun 15 12:24:39.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3610" for this suite. @ 06/15/24 12:24:39.658
• [4.084 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 06/15/24 12:24:39.664
  Jun 15 12:24:39.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 12:24:39.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:24:39.682
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:24:39.685
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 06/15/24 12:24:39.688
  STEP: Saw pod success @ 06/15/24 12:24:43.715
  Jun 15 12:24:43.719: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-d1281072-9a0a-4801-a6d6-d2f206728a20 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:24:43.733
  Jun 15 12:24:43.750: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7914" for this suite. @ 06/15/24 12:24:43.754
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 06/15/24 12:24:43.762
  Jun 15 12:24:43.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename deployment @ 06/15/24 12:24:43.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:24:43.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:24:43.78
  Jun 15 12:24:43.782: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Jun 15 12:24:43.788: INFO: Pod name sample-pod: Found 0 pods out of 1
  Jun 15 12:24:48.792: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 06/15/24 12:24:48.792
  Jun 15 12:24:48.792: INFO: Creating deployment "test-rolling-update-deployment"
  Jun 15 12:24:48.796: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Jun 15 12:24:48.804: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  Jun 15 12:24:50.812: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Jun 15 12:24:50.815: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Jun 15 12:24:50.824: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7873",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d360d872-9a1f-4dfa-9795-f88ab3b2a777",
      ResourceVersion: (string) (len=5) "11361",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854051088,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-7ddb77f68b\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Jun 15 12:24:50.830: INFO: New ReplicaSet "test-rolling-update-deployment-7ddb77f68b" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7873",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d8feb09d-6bfb-4b32-853c-7432e023c93e",
      ResourceVersion: (string) (len=5) "11351",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854051088,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "d360d872-9a1f-4dfa-9795-f88ab3b2a777",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 33 36 30 64 38  37 32 2d 39 61 31 66 2d  |\"d360d872-9a1f-|
              00000120  34 64 66 61 2d 39 37 39  35 2d 66 38 38 61 62 33  |4dfa-9795-f88ab3|
              00000130  62 32 61 37 37 37 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |b2a777\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b",
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:24:50.831: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Jun 15 12:24:50.831: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7873",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "474dd6a2-2c1c-43d8-bedd-4558b05722d0",
      ResourceVersion: (string) (len=5) "11360",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854051083,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "d360d872-9a1f-4dfa-9795-f88ab3b2a777",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051083,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 64 33 36 30 64 38 37  |"uid\":\"d360d87|
              000000b0  32 2d 39 61 31 66 2d 34  64 66 61 2d 39 37 39 35  |2-9a1f-4dfa-9795|
              000000c0  2d 66 38 38 61 62 33 62  32 61 37 37 37 5c 22 7d  |-f88ab3b2a777\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:24:50.835: INFO: Pod "test-rolling-update-deployment-7ddb77f68b-hcqxf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-7ddb77f68b-hcqxf",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-7ddb77f68b-",
      Namespace: (string) (len=15) "deployment-7873",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1b09c4e0-1ddc-4fb7-a858-59fafc3bdc0d",
      ResourceVersion: (string) (len=5) "11350",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854051088,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
          UID: (types.UID) (len=36) "d8feb09d-6bfb-4b32-853c-7432e023c93e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 38  66 65 62 30 39 64 2d 36  |d\":\"d8feb09d-6|
              00000090  62 66 62 2d 34 62 33 32  2d 38 35 33 63 2d 37 34  |bfb-4b32-853c-74|
              000000a0  33 32 65 30 32 33 63 39  33 65 5c 22 7d 22 3a 7b  |32e023c93e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=663) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 34 30  2e 32 32 39 5c 22 7d 22  |2.168.40.229\"}"|
              00000270  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000280  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000290  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vbrch",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vbrch",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-43-132",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854051088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.43.132",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.43.132"
        }
      },
      PodIP: (string) (len=14) "192.168.40.229",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.40.229"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854051088,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854051089,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://3503e7e5a27ce0dc6a4347c5cf64a1217345a67d8474827e9138ba89ecfb345f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:24:50.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7873" for this suite. @ 06/15/24 12:24:50.841
• [7.086 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 06/15/24 12:24:50.848
  Jun 15 12:24:50.848: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename cronjob @ 06/15/24 12:24:50.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:24:50.866
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:24:50.869
  STEP: Creating a suspended cronjob @ 06/15/24 12:24:50.872
  STEP: Ensuring no jobs are scheduled @ 06/15/24 12:24:50.879
  STEP: Ensuring no job exists by listing jobs explicitly @ 06/15/24 12:29:50.889
  STEP: Removing cronjob @ 06/15/24 12:29:50.892
  Jun 15 12:29:50.899: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4793" for this suite. @ 06/15/24 12:29:50.903
• [300.060 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 06/15/24 12:29:50.909
  Jun 15 12:29:50.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename svc-latency @ 06/15/24 12:29:50.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:29:50.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:29:50.929
  Jun 15 12:29:50.932: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-2502 @ 06/15/24 12:29:50.933
  I0615 12:29:50.941373      19 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2502, replica count: 1
  I0615 12:29:51.992297      19 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0615 12:29:52.992438      19 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 12:29:53.103: INFO: Created: latency-svc-55rpg
  Jun 15 12:29:53.118: INFO: Got endpoints: latency-svc-55rpg [25.054887ms]
  Jun 15 12:29:53.129: INFO: Created: latency-svc-w2nc7
  Jun 15 12:29:53.134: INFO: Created: latency-svc-78mqn
  Jun 15 12:29:53.136: INFO: Got endpoints: latency-svc-w2nc7 [17.965654ms]
  Jun 15 12:29:53.141: INFO: Got endpoints: latency-svc-78mqn [22.799717ms]
  Jun 15 12:29:53.145: INFO: Created: latency-svc-m9szz
  Jun 15 12:29:53.147: INFO: Created: latency-svc-xwrmf
  Jun 15 12:29:53.154: INFO: Got endpoints: latency-svc-m9szz [35.620771ms]
  Jun 15 12:29:53.154: INFO: Created: latency-svc-wpxxl
  Jun 15 12:29:53.155: INFO: Got endpoints: latency-svc-xwrmf [36.768483ms]
  Jun 15 12:29:53.163: INFO: Got endpoints: latency-svc-wpxxl [44.74099ms]
  Jun 15 12:29:53.165: INFO: Created: latency-svc-66cvr
  Jun 15 12:29:53.170: INFO: Got endpoints: latency-svc-66cvr [51.639855ms]
  Jun 15 12:29:53.171: INFO: Created: latency-svc-pq46p
  Jun 15 12:29:53.175: INFO: Created: latency-svc-hbczt
  Jun 15 12:29:53.176: INFO: Got endpoints: latency-svc-pq46p [57.550266ms]
  Jun 15 12:29:53.186: INFO: Got endpoints: latency-svc-hbczt [66.991867ms]
  Jun 15 12:29:53.186: INFO: Created: latency-svc-2nkst
  Jun 15 12:29:53.190: INFO: Created: latency-svc-zgg72
  Jun 15 12:29:53.198: INFO: Created: latency-svc-9v66n
  Jun 15 12:29:53.205: INFO: Got endpoints: latency-svc-2nkst [86.159762ms]
  Jun 15 12:29:53.208: INFO: Got endpoints: latency-svc-zgg72 [89.047254ms]
  Jun 15 12:29:53.208: INFO: Got endpoints: latency-svc-9v66n [88.733187ms]
  Jun 15 12:29:53.214: INFO: Created: latency-svc-9fcdx
  Jun 15 12:29:53.220: INFO: Got endpoints: latency-svc-9fcdx [101.011228ms]
  Jun 15 12:29:53.221: INFO: Created: latency-svc-tw82d
  Jun 15 12:29:53.225: INFO: Created: latency-svc-qpn25
  Jun 15 12:29:53.226: INFO: Got endpoints: latency-svc-tw82d [107.077024ms]
  Jun 15 12:29:53.230: INFO: Got endpoints: latency-svc-qpn25 [110.732629ms]
  Jun 15 12:29:53.235: INFO: Created: latency-svc-pc6xw
  Jun 15 12:29:53.240: INFO: Created: latency-svc-nfkcs
  Jun 15 12:29:53.242: INFO: Got endpoints: latency-svc-pc6xw [123.602551ms]
  Jun 15 12:29:53.246: INFO: Got endpoints: latency-svc-nfkcs [109.613577ms]
  Jun 15 12:29:53.248: INFO: Created: latency-svc-jzpxq
  Jun 15 12:29:53.253: INFO: Got endpoints: latency-svc-jzpxq [112.273519ms]
  Jun 15 12:29:53.260: INFO: Created: latency-svc-vj7r9
  Jun 15 12:29:53.268: INFO: Got endpoints: latency-svc-vj7r9 [113.733954ms]
  Jun 15 12:29:53.268: INFO: Created: latency-svc-mdb82
  Jun 15 12:29:53.273: INFO: Got endpoints: latency-svc-mdb82 [117.450251ms]
  Jun 15 12:29:53.277: INFO: Created: latency-svc-rj6b5
  Jun 15 12:29:53.283: INFO: Got endpoints: latency-svc-rj6b5 [119.54154ms]
  Jun 15 12:29:53.285: INFO: Created: latency-svc-fp8hl
  Jun 15 12:29:53.290: INFO: Created: latency-svc-6pg56
  Jun 15 12:29:53.297: INFO: Got endpoints: latency-svc-6pg56 [120.995528ms]
  Jun 15 12:29:53.297: INFO: Got endpoints: latency-svc-fp8hl [126.817002ms]
  Jun 15 12:29:53.298: INFO: Created: latency-svc-mq2qx
  Jun 15 12:29:53.304: INFO: Got endpoints: latency-svc-mq2qx [118.497116ms]
  Jun 15 12:29:53.306: INFO: Created: latency-svc-b9rnb
  Jun 15 12:29:53.311: INFO: Got endpoints: latency-svc-b9rnb [105.923868ms]
  Jun 15 12:29:53.315: INFO: Created: latency-svc-zshgg
  Jun 15 12:29:53.318: INFO: Got endpoints: latency-svc-zshgg [110.225838ms]
  Jun 15 12:29:53.320: INFO: Created: latency-svc-x2nkl
  Jun 15 12:29:53.327: INFO: Got endpoints: latency-svc-x2nkl [119.196866ms]
  Jun 15 12:29:53.331: INFO: Created: latency-svc-wq7sl
  Jun 15 12:29:53.336: INFO: Got endpoints: latency-svc-wq7sl [115.643509ms]
  Jun 15 12:29:53.338: INFO: Created: latency-svc-f8tcs
  Jun 15 12:29:53.344: INFO: Got endpoints: latency-svc-f8tcs [117.553113ms]
  Jun 15 12:29:53.346: INFO: Created: latency-svc-ng9mn
  Jun 15 12:29:53.350: INFO: Got endpoints: latency-svc-ng9mn [120.02465ms]
  Jun 15 12:29:53.354: INFO: Created: latency-svc-q7vsp
  Jun 15 12:29:53.358: INFO: Got endpoints: latency-svc-q7vsp [115.641367ms]
  Jun 15 12:29:53.363: INFO: Created: latency-svc-95dcq
  Jun 15 12:29:53.366: INFO: Created: latency-svc-r7xd6
  Jun 15 12:29:53.368: INFO: Got endpoints: latency-svc-95dcq [122.1323ms]
  Jun 15 12:29:53.372: INFO: Got endpoints: latency-svc-r7xd6 [118.94116ms]
  Jun 15 12:29:53.376: INFO: Created: latency-svc-vj69b
  Jun 15 12:29:53.383: INFO: Got endpoints: latency-svc-vj69b [114.764526ms]
  Jun 15 12:29:53.385: INFO: Created: latency-svc-qplrc
  Jun 15 12:29:53.388: INFO: Got endpoints: latency-svc-qplrc [115.565151ms]
  Jun 15 12:29:53.389: INFO: Created: latency-svc-f2rgm
  Jun 15 12:29:53.398: INFO: Created: latency-svc-kch98
  Jun 15 12:29:53.403: INFO: Created: latency-svc-khfp7
  Jun 15 12:29:53.408: INFO: Got endpoints: latency-svc-f2rgm [125.300235ms]
  Jun 15 12:29:53.409: INFO: Created: latency-svc-dlpsk
  Jun 15 12:29:53.417: INFO: Created: latency-svc-b2wsw
  Jun 15 12:29:53.422: INFO: Created: latency-svc-6sz29
  Jun 15 12:29:53.428: INFO: Created: latency-svc-wk8gq
  Jun 15 12:29:53.435: INFO: Created: latency-svc-r6nzc
  Jun 15 12:29:53.441: INFO: Created: latency-svc-thr9n
  Jun 15 12:29:53.445: INFO: Created: latency-svc-6sjkn
  Jun 15 12:29:53.453: INFO: Created: latency-svc-shlvr
  Jun 15 12:29:53.459: INFO: Created: latency-svc-tp7nw
  Jun 15 12:29:53.460: INFO: Got endpoints: latency-svc-kch98 [162.433508ms]
  Jun 15 12:29:53.465: INFO: Created: latency-svc-qxxd7
  Jun 15 12:29:53.471: INFO: Created: latency-svc-rt2cs
  Jun 15 12:29:53.476: INFO: Created: latency-svc-2qs78
  Jun 15 12:29:53.480: INFO: Created: latency-svc-2c6v8
  Jun 15 12:29:53.490: INFO: Created: latency-svc-kgglp
  Jun 15 12:29:53.507: INFO: Got endpoints: latency-svc-khfp7 [209.667388ms]
  Jun 15 12:29:53.518: INFO: Created: latency-svc-qxskd
  Jun 15 12:29:53.557: INFO: Got endpoints: latency-svc-dlpsk [252.427348ms]
  Jun 15 12:29:53.565: INFO: Created: latency-svc-4ssvn
  Jun 15 12:29:53.609: INFO: Got endpoints: latency-svc-b2wsw [298.568951ms]
  Jun 15 12:29:53.619: INFO: Created: latency-svc-lhsmt
  Jun 15 12:29:53.659: INFO: Got endpoints: latency-svc-6sz29 [340.947086ms]
  Jun 15 12:29:53.669: INFO: Created: latency-svc-p6sqz
  Jun 15 12:29:53.707: INFO: Got endpoints: latency-svc-wk8gq [379.814812ms]
  Jun 15 12:29:53.717: INFO: Created: latency-svc-hnqcn
  Jun 15 12:29:53.758: INFO: Got endpoints: latency-svc-r6nzc [421.803907ms]
  Jun 15 12:29:53.768: INFO: Created: latency-svc-4m9wt
  Jun 15 12:29:53.809: INFO: Got endpoints: latency-svc-thr9n [465.40684ms]
  Jun 15 12:29:53.821: INFO: Created: latency-svc-9xqnk
  Jun 15 12:29:53.861: INFO: Got endpoints: latency-svc-6sjkn [510.893061ms]
  Jun 15 12:29:53.869: INFO: Created: latency-svc-tclmz
  Jun 15 12:29:53.909: INFO: Got endpoints: latency-svc-shlvr [551.130656ms]
  Jun 15 12:29:53.922: INFO: Created: latency-svc-dlkkp
  Jun 15 12:29:53.959: INFO: Got endpoints: latency-svc-tp7nw [590.9846ms]
  Jun 15 12:29:53.970: INFO: Created: latency-svc-fnfhj
  Jun 15 12:29:54.009: INFO: Got endpoints: latency-svc-qxxd7 [636.03315ms]
  Jun 15 12:29:54.019: INFO: Created: latency-svc-hj8nn
  Jun 15 12:29:54.059: INFO: Got endpoints: latency-svc-rt2cs [676.174167ms]
  Jun 15 12:29:54.068: INFO: Created: latency-svc-gnz95
  Jun 15 12:29:54.110: INFO: Got endpoints: latency-svc-2qs78 [721.217745ms]
  Jun 15 12:29:54.120: INFO: Created: latency-svc-qqpvl
  Jun 15 12:29:54.160: INFO: Got endpoints: latency-svc-2c6v8 [751.560527ms]
  Jun 15 12:29:54.168: INFO: Created: latency-svc-27kr5
  Jun 15 12:29:54.208: INFO: Got endpoints: latency-svc-kgglp [748.142676ms]
  Jun 15 12:29:54.219: INFO: Created: latency-svc-h5vhm
  Jun 15 12:29:54.258: INFO: Got endpoints: latency-svc-qxskd [750.940683ms]
  Jun 15 12:29:54.268: INFO: Created: latency-svc-jmlm5
  Jun 15 12:29:54.309: INFO: Got endpoints: latency-svc-4ssvn [751.941291ms]
  Jun 15 12:29:54.319: INFO: Created: latency-svc-rdfsr
  Jun 15 12:29:54.360: INFO: Got endpoints: latency-svc-lhsmt [750.202224ms]
  Jun 15 12:29:54.370: INFO: Created: latency-svc-7nvtf
  Jun 15 12:29:54.408: INFO: Got endpoints: latency-svc-p6sqz [748.538807ms]
  Jun 15 12:29:54.420: INFO: Created: latency-svc-qc7v5
  Jun 15 12:29:54.457: INFO: Got endpoints: latency-svc-hnqcn [750.306031ms]
  Jun 15 12:29:54.467: INFO: Created: latency-svc-k9vnn
  Jun 15 12:29:54.509: INFO: Got endpoints: latency-svc-4m9wt [751.037883ms]
  Jun 15 12:29:54.519: INFO: Created: latency-svc-6ttw5
  Jun 15 12:29:54.559: INFO: Got endpoints: latency-svc-9xqnk [749.066602ms]
  Jun 15 12:29:54.569: INFO: Created: latency-svc-8bd62
  Jun 15 12:29:54.609: INFO: Got endpoints: latency-svc-tclmz [748.138439ms]
  Jun 15 12:29:54.618: INFO: Created: latency-svc-gm8zd
  Jun 15 12:29:54.659: INFO: Got endpoints: latency-svc-dlkkp [749.29797ms]
  Jun 15 12:29:54.669: INFO: Created: latency-svc-fcxhq
  Jun 15 12:29:54.708: INFO: Got endpoints: latency-svc-fnfhj [748.553034ms]
  Jun 15 12:29:54.719: INFO: Created: latency-svc-24dtw
  Jun 15 12:29:54.757: INFO: Got endpoints: latency-svc-hj8nn [748.827239ms]
  Jun 15 12:29:54.766: INFO: Created: latency-svc-9dkt4
  Jun 15 12:29:54.809: INFO: Got endpoints: latency-svc-gnz95 [750.109025ms]
  Jun 15 12:29:54.819: INFO: Created: latency-svc-5w95j
  Jun 15 12:29:54.859: INFO: Got endpoints: latency-svc-qqpvl [749.848174ms]
  Jun 15 12:29:54.869: INFO: Created: latency-svc-66fxc
  Jun 15 12:29:54.907: INFO: Got endpoints: latency-svc-27kr5 [747.108231ms]
  Jun 15 12:29:54.920: INFO: Created: latency-svc-kn97c
  Jun 15 12:29:54.958: INFO: Got endpoints: latency-svc-h5vhm [749.693366ms]
  Jun 15 12:29:54.968: INFO: Created: latency-svc-8pv2s
  Jun 15 12:29:55.008: INFO: Got endpoints: latency-svc-jmlm5 [750.042653ms]
  Jun 15 12:29:55.017: INFO: Created: latency-svc-4vpjc
  Jun 15 12:29:55.059: INFO: Got endpoints: latency-svc-rdfsr [750.025388ms]
  Jun 15 12:29:55.067: INFO: Created: latency-svc-mrw2t
  Jun 15 12:29:55.111: INFO: Got endpoints: latency-svc-7nvtf [751.094896ms]
  Jun 15 12:29:55.122: INFO: Created: latency-svc-hfqn9
  Jun 15 12:29:55.159: INFO: Got endpoints: latency-svc-qc7v5 [751.181537ms]
  Jun 15 12:29:55.171: INFO: Created: latency-svc-s4ckh
  Jun 15 12:29:55.207: INFO: Got endpoints: latency-svc-k9vnn [750.086088ms]
  Jun 15 12:29:55.217: INFO: Created: latency-svc-qdt86
  Jun 15 12:29:55.259: INFO: Got endpoints: latency-svc-6ttw5 [750.163659ms]
  Jun 15 12:29:55.269: INFO: Created: latency-svc-flh4j
  Jun 15 12:29:55.308: INFO: Got endpoints: latency-svc-8bd62 [749.588414ms]
  Jun 15 12:29:55.318: INFO: Created: latency-svc-j29wl
  Jun 15 12:29:55.360: INFO: Got endpoints: latency-svc-gm8zd [750.415774ms]
  Jun 15 12:29:55.370: INFO: Created: latency-svc-hg5t4
  Jun 15 12:29:55.409: INFO: Got endpoints: latency-svc-fcxhq [750.057936ms]
  Jun 15 12:29:55.422: INFO: Created: latency-svc-6j8pt
  Jun 15 12:29:55.457: INFO: Got endpoints: latency-svc-24dtw [749.771123ms]
  Jun 15 12:29:55.467: INFO: Created: latency-svc-c679s
  Jun 15 12:29:55.508: INFO: Got endpoints: latency-svc-9dkt4 [750.127322ms]
  Jun 15 12:29:55.516: INFO: Created: latency-svc-cvqfs
  Jun 15 12:29:55.561: INFO: Got endpoints: latency-svc-5w95j [751.62307ms]
  Jun 15 12:29:55.571: INFO: Created: latency-svc-s9trm
  Jun 15 12:29:55.610: INFO: Got endpoints: latency-svc-66fxc [750.297158ms]
  Jun 15 12:29:55.621: INFO: Created: latency-svc-b2ns9
  Jun 15 12:29:55.658: INFO: Got endpoints: latency-svc-kn97c [750.355836ms]
  Jun 15 12:29:55.669: INFO: Created: latency-svc-qw9vz
  Jun 15 12:29:55.708: INFO: Got endpoints: latency-svc-8pv2s [749.544646ms]
  Jun 15 12:29:55.717: INFO: Created: latency-svc-wsxhq
  Jun 15 12:29:55.759: INFO: Got endpoints: latency-svc-4vpjc [750.696455ms]
  Jun 15 12:29:55.768: INFO: Created: latency-svc-g5sq7
  Jun 15 12:29:55.810: INFO: Got endpoints: latency-svc-mrw2t [751.082895ms]
  Jun 15 12:29:55.818: INFO: Created: latency-svc-hmlb2
  Jun 15 12:29:55.859: INFO: Got endpoints: latency-svc-hfqn9 [747.529451ms]
  Jun 15 12:29:55.870: INFO: Created: latency-svc-2v6d4
  Jun 15 12:29:55.908: INFO: Got endpoints: latency-svc-s4ckh [749.192076ms]
  Jun 15 12:29:55.920: INFO: Created: latency-svc-44f9f
  Jun 15 12:29:55.957: INFO: Got endpoints: latency-svc-qdt86 [749.687996ms]
  Jun 15 12:29:55.967: INFO: Created: latency-svc-hmwsk
  Jun 15 12:29:56.008: INFO: Got endpoints: latency-svc-flh4j [748.347211ms]
  Jun 15 12:29:56.019: INFO: Created: latency-svc-svzpf
  Jun 15 12:29:56.059: INFO: Got endpoints: latency-svc-j29wl [750.761837ms]
  Jun 15 12:29:56.068: INFO: Created: latency-svc-72cgx
  Jun 15 12:29:56.111: INFO: Got endpoints: latency-svc-hg5t4 [751.15361ms]
  Jun 15 12:29:56.120: INFO: Created: latency-svc-stm6k
  Jun 15 12:29:56.157: INFO: Got endpoints: latency-svc-6j8pt [748.734866ms]
  Jun 15 12:29:56.170: INFO: Created: latency-svc-ztdt8
  Jun 15 12:29:56.209: INFO: Got endpoints: latency-svc-c679s [751.216492ms]
  Jun 15 12:29:56.220: INFO: Created: latency-svc-7hs8l
  Jun 15 12:29:56.259: INFO: Got endpoints: latency-svc-cvqfs [751.208804ms]
  Jun 15 12:29:56.269: INFO: Created: latency-svc-dfnr7
  Jun 15 12:29:56.309: INFO: Got endpoints: latency-svc-s9trm [748.327642ms]
  Jun 15 12:29:56.319: INFO: Created: latency-svc-wmn8n
  Jun 15 12:29:56.361: INFO: Got endpoints: latency-svc-b2ns9 [751.152394ms]
  Jun 15 12:29:56.375: INFO: Created: latency-svc-htsbj
  Jun 15 12:29:56.407: INFO: Got endpoints: latency-svc-qw9vz [749.578724ms]
  Jun 15 12:29:56.417: INFO: Created: latency-svc-stbw2
  Jun 15 12:29:56.457: INFO: Got endpoints: latency-svc-wsxhq [749.60443ms]
  Jun 15 12:29:56.468: INFO: Created: latency-svc-mvngr
  Jun 15 12:29:56.510: INFO: Got endpoints: latency-svc-g5sq7 [750.947403ms]
  Jun 15 12:29:56.519: INFO: Created: latency-svc-6jvvr
  Jun 15 12:29:56.558: INFO: Got endpoints: latency-svc-hmlb2 [748.286202ms]
  Jun 15 12:29:56.566: INFO: Created: latency-svc-lqwlk
  Jun 15 12:29:56.609: INFO: Got endpoints: latency-svc-2v6d4 [750.249967ms]
  Jun 15 12:29:56.620: INFO: Created: latency-svc-p4nz2
  Jun 15 12:29:56.658: INFO: Got endpoints: latency-svc-44f9f [749.212999ms]
  Jun 15 12:29:56.670: INFO: Created: latency-svc-tffb6
  Jun 15 12:29:56.708: INFO: Got endpoints: latency-svc-hmwsk [750.940009ms]
  Jun 15 12:29:56.716: INFO: Created: latency-svc-r55wk
  Jun 15 12:29:56.758: INFO: Got endpoints: latency-svc-svzpf [750.447365ms]
  Jun 15 12:29:56.768: INFO: Created: latency-svc-spc7t
  Jun 15 12:29:56.810: INFO: Got endpoints: latency-svc-72cgx [750.738956ms]
  Jun 15 12:29:56.821: INFO: Created: latency-svc-wqwfm
  Jun 15 12:29:56.860: INFO: Got endpoints: latency-svc-stm6k [748.760998ms]
  Jun 15 12:29:56.868: INFO: Created: latency-svc-q8mhx
  Jun 15 12:29:56.908: INFO: Got endpoints: latency-svc-ztdt8 [750.451146ms]
  Jun 15 12:29:56.919: INFO: Created: latency-svc-6kvfs
  Jun 15 12:29:56.960: INFO: Got endpoints: latency-svc-7hs8l [751.384303ms]
  Jun 15 12:29:56.971: INFO: Created: latency-svc-f4qgx
  Jun 15 12:29:57.008: INFO: Got endpoints: latency-svc-dfnr7 [749.302746ms]
  Jun 15 12:29:57.017: INFO: Created: latency-svc-gjf5m
  Jun 15 12:29:57.059: INFO: Got endpoints: latency-svc-wmn8n [749.941916ms]
  Jun 15 12:29:57.070: INFO: Created: latency-svc-9xxp8
  Jun 15 12:29:57.108: INFO: Got endpoints: latency-svc-htsbj [746.784495ms]
  Jun 15 12:29:57.120: INFO: Created: latency-svc-x29r9
  Jun 15 12:29:57.158: INFO: Got endpoints: latency-svc-stbw2 [751.049017ms]
  Jun 15 12:29:57.167: INFO: Created: latency-svc-lq4sp
  Jun 15 12:29:57.208: INFO: Got endpoints: latency-svc-mvngr [750.551594ms]
  Jun 15 12:29:57.217: INFO: Created: latency-svc-xww7f
  Jun 15 12:29:57.260: INFO: Got endpoints: latency-svc-6jvvr [750.354724ms]
  Jun 15 12:29:57.272: INFO: Created: latency-svc-48lhb
  Jun 15 12:29:57.310: INFO: Got endpoints: latency-svc-lqwlk [751.363261ms]
  Jun 15 12:29:57.318: INFO: Created: latency-svc-ffq2c
  Jun 15 12:29:57.358: INFO: Got endpoints: latency-svc-p4nz2 [748.950085ms]
  Jun 15 12:29:57.368: INFO: Created: latency-svc-2ltf7
  Jun 15 12:29:57.409: INFO: Got endpoints: latency-svc-tffb6 [750.863519ms]
  Jun 15 12:29:57.420: INFO: Created: latency-svc-gzk2j
  Jun 15 12:29:57.465: INFO: Got endpoints: latency-svc-r55wk [756.34485ms]
  Jun 15 12:29:57.473: INFO: Created: latency-svc-fw2t4
  Jun 15 12:29:57.509: INFO: Got endpoints: latency-svc-spc7t [751.110245ms]
  Jun 15 12:29:57.518: INFO: Created: latency-svc-nsbwr
  Jun 15 12:29:57.558: INFO: Got endpoints: latency-svc-wqwfm [748.056407ms]
  Jun 15 12:29:57.569: INFO: Created: latency-svc-84kf6
  Jun 15 12:29:57.607: INFO: Got endpoints: latency-svc-q8mhx [747.72388ms]
  Jun 15 12:29:57.617: INFO: Created: latency-svc-mmpbf
  Jun 15 12:29:57.657: INFO: Got endpoints: latency-svc-6kvfs [748.593221ms]
  Jun 15 12:29:57.666: INFO: Created: latency-svc-vbd8x
  Jun 15 12:29:57.709: INFO: Got endpoints: latency-svc-f4qgx [748.492878ms]
  Jun 15 12:29:57.720: INFO: Created: latency-svc-xc28s
  Jun 15 12:29:57.760: INFO: Got endpoints: latency-svc-gjf5m [751.296539ms]
  Jun 15 12:29:57.768: INFO: Created: latency-svc-w7zhs
  Jun 15 12:29:57.808: INFO: Got endpoints: latency-svc-9xxp8 [748.645079ms]
  Jun 15 12:29:57.818: INFO: Created: latency-svc-xntk6
  Jun 15 12:29:57.860: INFO: Got endpoints: latency-svc-x29r9 [751.998868ms]
  Jun 15 12:29:57.871: INFO: Created: latency-svc-swtq7
  Jun 15 12:29:57.908: INFO: Got endpoints: latency-svc-lq4sp [750.031883ms]
  Jun 15 12:29:57.918: INFO: Created: latency-svc-8z5bh
  Jun 15 12:29:57.959: INFO: Got endpoints: latency-svc-xww7f [750.497505ms]
  Jun 15 12:29:57.967: INFO: Created: latency-svc-klxkd
  Jun 15 12:29:58.008: INFO: Got endpoints: latency-svc-48lhb [747.65391ms]
  Jun 15 12:29:58.023: INFO: Created: latency-svc-qlsph
  Jun 15 12:29:58.058: INFO: Got endpoints: latency-svc-ffq2c [748.349698ms]
  Jun 15 12:29:58.067: INFO: Created: latency-svc-t97w9
  Jun 15 12:29:58.108: INFO: Got endpoints: latency-svc-2ltf7 [749.563591ms]
  Jun 15 12:29:58.118: INFO: Created: latency-svc-55cn4
  Jun 15 12:29:58.160: INFO: Got endpoints: latency-svc-gzk2j [750.422556ms]
  Jun 15 12:29:58.171: INFO: Created: latency-svc-bzp9s
  Jun 15 12:29:58.209: INFO: Got endpoints: latency-svc-fw2t4 [744.445469ms]
  Jun 15 12:29:58.218: INFO: Created: latency-svc-k98dq
  Jun 15 12:29:58.259: INFO: Got endpoints: latency-svc-nsbwr [749.916488ms]
  Jun 15 12:29:58.270: INFO: Created: latency-svc-wzrlh
  Jun 15 12:29:58.311: INFO: Got endpoints: latency-svc-84kf6 [752.615265ms]
  Jun 15 12:29:58.322: INFO: Created: latency-svc-fh7wv
  Jun 15 12:29:58.358: INFO: Got endpoints: latency-svc-mmpbf [750.096548ms]
  Jun 15 12:29:58.366: INFO: Created: latency-svc-qnrqs
  Jun 15 12:29:58.408: INFO: Got endpoints: latency-svc-vbd8x [751.242149ms]
  Jun 15 12:29:58.418: INFO: Created: latency-svc-pv2n5
  Jun 15 12:29:58.460: INFO: Got endpoints: latency-svc-xc28s [750.559582ms]
  Jun 15 12:29:58.470: INFO: Created: latency-svc-hzgrm
  Jun 15 12:29:58.509: INFO: Got endpoints: latency-svc-w7zhs [749.570555ms]
  Jun 15 12:29:58.518: INFO: Created: latency-svc-tplbl
  Jun 15 12:29:58.557: INFO: Got endpoints: latency-svc-xntk6 [748.809119ms]
  Jun 15 12:29:58.567: INFO: Created: latency-svc-j2ckj
  Jun 15 12:29:58.608: INFO: Got endpoints: latency-svc-swtq7 [747.654021ms]
  Jun 15 12:29:58.619: INFO: Created: latency-svc-gh226
  Jun 15 12:29:58.656: INFO: Got endpoints: latency-svc-8z5bh [747.96978ms]
  Jun 15 12:29:58.665: INFO: Created: latency-svc-dqt82
  Jun 15 12:29:58.710: INFO: Got endpoints: latency-svc-klxkd [751.429096ms]
  Jun 15 12:29:58.719: INFO: Created: latency-svc-k27gt
  Jun 15 12:29:58.760: INFO: Got endpoints: latency-svc-qlsph [751.617131ms]
  Jun 15 12:29:58.770: INFO: Created: latency-svc-dvfqq
  Jun 15 12:29:58.808: INFO: Got endpoints: latency-svc-t97w9 [750.076511ms]
  Jun 15 12:29:58.818: INFO: Created: latency-svc-fmth7
  Jun 15 12:29:58.858: INFO: Got endpoints: latency-svc-55cn4 [750.689685ms]
  Jun 15 12:29:58.868: INFO: Created: latency-svc-m7qvf
  Jun 15 12:29:58.908: INFO: Got endpoints: latency-svc-bzp9s [748.121867ms]
  Jun 15 12:29:58.918: INFO: Created: latency-svc-7vh8k
  Jun 15 12:29:58.959: INFO: Got endpoints: latency-svc-k98dq [750.058598ms]
  Jun 15 12:29:58.969: INFO: Created: latency-svc-h54r6
  Jun 15 12:29:59.008: INFO: Got endpoints: latency-svc-wzrlh [748.90517ms]
  Jun 15 12:29:59.020: INFO: Created: latency-svc-fbj67
  Jun 15 12:29:59.058: INFO: Got endpoints: latency-svc-fh7wv [746.549364ms]
  Jun 15 12:29:59.069: INFO: Created: latency-svc-xcw6p
  Jun 15 12:29:59.108: INFO: Got endpoints: latency-svc-qnrqs [750.144504ms]
  Jun 15 12:29:59.121: INFO: Created: latency-svc-xfgq5
  Jun 15 12:29:59.160: INFO: Got endpoints: latency-svc-pv2n5 [751.177645ms]
  Jun 15 12:29:59.169: INFO: Created: latency-svc-5tk2s
  Jun 15 12:29:59.210: INFO: Got endpoints: latency-svc-hzgrm [749.667562ms]
  Jun 15 12:29:59.219: INFO: Created: latency-svc-hw5js
  Jun 15 12:29:59.258: INFO: Got endpoints: latency-svc-tplbl [748.004962ms]
  Jun 15 12:29:59.267: INFO: Created: latency-svc-b6frf
  Jun 15 12:29:59.308: INFO: Got endpoints: latency-svc-j2ckj [751.019821ms]
  Jun 15 12:29:59.317: INFO: Created: latency-svc-88j65
  Jun 15 12:29:59.359: INFO: Got endpoints: latency-svc-gh226 [750.86424ms]
  Jun 15 12:29:59.369: INFO: Created: latency-svc-6k6kl
  Jun 15 12:29:59.409: INFO: Got endpoints: latency-svc-dqt82 [752.099164ms]
  Jun 15 12:29:59.419: INFO: Created: latency-svc-kr5r9
  Jun 15 12:29:59.458: INFO: Got endpoints: latency-svc-k27gt [748.099557ms]
  Jun 15 12:29:59.472: INFO: Created: latency-svc-shqkr
  Jun 15 12:29:59.507: INFO: Got endpoints: latency-svc-dvfqq [746.912515ms]
  Jun 15 12:29:59.520: INFO: Created: latency-svc-ddppr
  Jun 15 12:29:59.558: INFO: Got endpoints: latency-svc-fmth7 [749.50599ms]
  Jun 15 12:29:59.567: INFO: Created: latency-svc-tm5w8
  Jun 15 12:29:59.610: INFO: Got endpoints: latency-svc-m7qvf [751.23634ms]
  Jun 15 12:29:59.620: INFO: Created: latency-svc-8v9rz
  Jun 15 12:29:59.660: INFO: Got endpoints: latency-svc-7vh8k [751.323934ms]
  Jun 15 12:29:59.669: INFO: Created: latency-svc-5rsjl
  Jun 15 12:29:59.707: INFO: Got endpoints: latency-svc-h54r6 [747.548299ms]
  Jun 15 12:29:59.717: INFO: Created: latency-svc-5tb6h
  Jun 15 12:29:59.761: INFO: Got endpoints: latency-svc-fbj67 [751.947316ms]
  Jun 15 12:29:59.771: INFO: Created: latency-svc-xg4t8
  Jun 15 12:29:59.809: INFO: Got endpoints: latency-svc-xcw6p [750.98657ms]
  Jun 15 12:29:59.819: INFO: Created: latency-svc-847ff
  Jun 15 12:29:59.859: INFO: Got endpoints: latency-svc-xfgq5 [750.840493ms]
  Jun 15 12:29:59.869: INFO: Created: latency-svc-wcb9l
  Jun 15 12:29:59.908: INFO: Got endpoints: latency-svc-5tk2s [748.402372ms]
  Jun 15 12:29:59.921: INFO: Created: latency-svc-8758l
  Jun 15 12:29:59.958: INFO: Got endpoints: latency-svc-hw5js [748.513404ms]
  Jun 15 12:29:59.970: INFO: Created: latency-svc-s67tg
  Jun 15 12:30:00.007: INFO: Got endpoints: latency-svc-b6frf [749.716882ms]
  Jun 15 12:30:00.016: INFO: Created: latency-svc-v65hb
  Jun 15 12:30:00.060: INFO: Got endpoints: latency-svc-88j65 [751.900358ms]
  Jun 15 12:30:00.071: INFO: Created: latency-svc-xbm58
  Jun 15 12:30:00.109: INFO: Got endpoints: latency-svc-6k6kl [750.311669ms]
  Jun 15 12:30:00.121: INFO: Created: latency-svc-nz8p4
  Jun 15 12:30:00.159: INFO: Got endpoints: latency-svc-kr5r9 [749.649208ms]
  Jun 15 12:30:00.168: INFO: Created: latency-svc-msh8f
  Jun 15 12:30:00.208: INFO: Got endpoints: latency-svc-shqkr [749.561212ms]
  Jun 15 12:30:00.219: INFO: Created: latency-svc-7xtmz
  Jun 15 12:30:00.258: INFO: Got endpoints: latency-svc-ddppr [750.242438ms]
  Jun 15 12:30:00.267: INFO: Created: latency-svc-z6f2f
  Jun 15 12:30:00.309: INFO: Got endpoints: latency-svc-tm5w8 [750.956923ms]
  Jun 15 12:30:00.317: INFO: Created: latency-svc-ps7ml
  Jun 15 12:30:00.360: INFO: Got endpoints: latency-svc-8v9rz [749.638155ms]
  Jun 15 12:30:00.371: INFO: Created: latency-svc-skpds
  Jun 15 12:30:00.408: INFO: Got endpoints: latency-svc-5rsjl [747.965378ms]
  Jun 15 12:30:00.419: INFO: Created: latency-svc-fmhzp
  Jun 15 12:30:00.458: INFO: Got endpoints: latency-svc-5tb6h [751.240142ms]
  Jun 15 12:30:00.468: INFO: Created: latency-svc-6nsjf
  Jun 15 12:30:00.507: INFO: Got endpoints: latency-svc-xg4t8 [746.695572ms]
  Jun 15 12:30:00.517: INFO: Created: latency-svc-hmm2d
  Jun 15 12:30:00.558: INFO: Got endpoints: latency-svc-847ff [749.406875ms]
  Jun 15 12:30:00.568: INFO: Created: latency-svc-bbxmg
  Jun 15 12:30:00.608: INFO: Got endpoints: latency-svc-wcb9l [748.835792ms]
  Jun 15 12:30:00.616: INFO: Created: latency-svc-97p2k
  Jun 15 12:30:00.660: INFO: Got endpoints: latency-svc-8758l [752.062556ms]
  Jun 15 12:30:00.671: INFO: Created: latency-svc-596gg
  Jun 15 12:30:00.708: INFO: Got endpoints: latency-svc-s67tg [749.864586ms]
  Jun 15 12:30:00.721: INFO: Created: latency-svc-l4bcw
  Jun 15 12:30:00.758: INFO: Got endpoints: latency-svc-v65hb [750.313146ms]
  Jun 15 12:30:00.769: INFO: Created: latency-svc-c7j6k
  Jun 15 12:30:00.810: INFO: Got endpoints: latency-svc-xbm58 [749.641091ms]
  Jun 15 12:30:00.820: INFO: Created: latency-svc-vzdzm
  Jun 15 12:30:00.859: INFO: Got endpoints: latency-svc-nz8p4 [749.632161ms]
  Jun 15 12:30:00.869: INFO: Created: latency-svc-5dczz
  Jun 15 12:30:00.908: INFO: Got endpoints: latency-svc-msh8f [749.546119ms]
  Jun 15 12:30:00.917: INFO: Created: latency-svc-dsg6v
  Jun 15 12:30:00.961: INFO: Got endpoints: latency-svc-7xtmz [752.32714ms]
  Jun 15 12:30:01.008: INFO: Got endpoints: latency-svc-z6f2f [750.431895ms]
  Jun 15 12:30:01.059: INFO: Got endpoints: latency-svc-ps7ml [749.95417ms]
  Jun 15 12:30:01.109: INFO: Got endpoints: latency-svc-skpds [749.13118ms]
  Jun 15 12:30:01.160: INFO: Got endpoints: latency-svc-fmhzp [752.316108ms]
  Jun 15 12:30:01.207: INFO: Got endpoints: latency-svc-6nsjf [748.931465ms]
  Jun 15 12:30:01.259: INFO: Got endpoints: latency-svc-hmm2d [751.444535ms]
  Jun 15 12:30:01.309: INFO: Got endpoints: latency-svc-bbxmg [750.746113ms]
  Jun 15 12:30:01.360: INFO: Got endpoints: latency-svc-97p2k [752.306077ms]
  Jun 15 12:30:01.408: INFO: Got endpoints: latency-svc-596gg [748.173131ms]
  Jun 15 12:30:01.460: INFO: Got endpoints: latency-svc-l4bcw [752.028786ms]
  Jun 15 12:30:01.508: INFO: Got endpoints: latency-svc-c7j6k [749.894728ms]
  Jun 15 12:30:01.561: INFO: Got endpoints: latency-svc-vzdzm [750.934842ms]
  Jun 15 12:30:01.608: INFO: Got endpoints: latency-svc-5dczz [748.636434ms]
  Jun 15 12:30:01.660: INFO: Got endpoints: latency-svc-dsg6v [751.620921ms]
  Jun 15 12:30:01.660: INFO: Latencies: [17.965654ms 22.799717ms 35.620771ms 36.768483ms 44.74099ms 51.639855ms 57.550266ms 66.991867ms 86.159762ms 88.733187ms 89.047254ms 101.011228ms 105.923868ms 107.077024ms 109.613577ms 110.225838ms 110.732629ms 112.273519ms 113.733954ms 114.764526ms 115.565151ms 115.641367ms 115.643509ms 117.450251ms 117.553113ms 118.497116ms 118.94116ms 119.196866ms 119.54154ms 120.02465ms 120.995528ms 122.1323ms 123.602551ms 125.300235ms 126.817002ms 162.433508ms 209.667388ms 252.427348ms 298.568951ms 340.947086ms 379.814812ms 421.803907ms 465.40684ms 510.893061ms 551.130656ms 590.9846ms 636.03315ms 676.174167ms 721.217745ms 744.445469ms 746.549364ms 746.695572ms 746.784495ms 746.912515ms 747.108231ms 747.529451ms 747.548299ms 747.65391ms 747.654021ms 747.72388ms 747.965378ms 747.96978ms 748.004962ms 748.056407ms 748.099557ms 748.121867ms 748.138439ms 748.142676ms 748.173131ms 748.286202ms 748.327642ms 748.347211ms 748.349698ms 748.402372ms 748.492878ms 748.513404ms 748.538807ms 748.553034ms 748.593221ms 748.636434ms 748.645079ms 748.734866ms 748.760998ms 748.809119ms 748.827239ms 748.835792ms 748.90517ms 748.931465ms 748.950085ms 749.066602ms 749.13118ms 749.192076ms 749.212999ms 749.29797ms 749.302746ms 749.406875ms 749.50599ms 749.544646ms 749.546119ms 749.561212ms 749.563591ms 749.570555ms 749.578724ms 749.588414ms 749.60443ms 749.632161ms 749.638155ms 749.641091ms 749.649208ms 749.667562ms 749.687996ms 749.693366ms 749.716882ms 749.771123ms 749.848174ms 749.864586ms 749.894728ms 749.916488ms 749.941916ms 749.95417ms 750.025388ms 750.031883ms 750.042653ms 750.057936ms 750.058598ms 750.076511ms 750.086088ms 750.096548ms 750.109025ms 750.127322ms 750.144504ms 750.163659ms 750.202224ms 750.242438ms 750.249967ms 750.297158ms 750.306031ms 750.311669ms 750.313146ms 750.354724ms 750.355836ms 750.415774ms 750.422556ms 750.431895ms 750.447365ms 750.451146ms 750.497505ms 750.551594ms 750.559582ms 750.689685ms 750.696455ms 750.738956ms 750.746113ms 750.761837ms 750.840493ms 750.863519ms 750.86424ms 750.934842ms 750.940009ms 750.940683ms 750.947403ms 750.956923ms 750.98657ms 751.019821ms 751.037883ms 751.049017ms 751.082895ms 751.094896ms 751.110245ms 751.152394ms 751.15361ms 751.177645ms 751.181537ms 751.208804ms 751.216492ms 751.23634ms 751.240142ms 751.242149ms 751.296539ms 751.323934ms 751.363261ms 751.384303ms 751.429096ms 751.444535ms 751.560527ms 751.617131ms 751.620921ms 751.62307ms 751.900358ms 751.941291ms 751.947316ms 751.998868ms 752.028786ms 752.062556ms 752.099164ms 752.306077ms 752.316108ms 752.32714ms 752.615265ms 756.34485ms]
  Jun 15 12:30:01.660: INFO: 50 %ile: 749.563591ms
  Jun 15 12:30:01.661: INFO: 90 %ile: 751.363261ms
  Jun 15 12:30:01.661: INFO: 99 %ile: 752.615265ms
  Jun 15 12:30:01.661: INFO: Total sample count: 200
  Jun 15 12:30:01.661: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-2502" for this suite. @ 06/15/24 12:30:01.665
• [10.763 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 06/15/24 12:30:01.672
  Jun 15 12:30:01.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename endpointslice @ 06/15/24 12:30:01.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:30:01.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:30:01.694
  Jun 15 12:30:01.708: INFO: Endpoints addresses: [172.31.3.208 172.31.94.186] , ports: [6443]
  Jun 15 12:30:01.708: INFO: EndpointSlices addresses: [172.31.3.208 172.31.94.186] , ports: [6443]
  Jun 15 12:30:01.708: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3334" for this suite. @ 06/15/24 12:30:01.713
• [0.047 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 06/15/24 12:30:01.72
  Jun 15 12:30:01.720: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename taint-single-pod @ 06/15/24 12:30:01.72
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:30:01.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:30:01.738
  Jun 15 12:30:01.741: INFO: Waiting up to 1m0s for all nodes to be ready
  Jun 15 12:31:01.741: INFO: Waiting for terminating namespaces to be deleted...
  Jun 15 12:31:01.746: INFO: Starting informer...
  STEP: Starting pod... @ 06/15/24 12:31:01.746
  Jun 15 12:31:01.963: INFO: Pod is running on ip-172-31-7-7. Tainting Node
  STEP: Trying to apply a taint on the Node @ 06/15/24 12:31:01.963
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 06/15/24 12:31:01.973
  STEP: Waiting short time to make sure Pod is queued for deletion @ 06/15/24 12:31:01.977
  Jun 15 12:31:01.977: INFO: Pod wasn't evicted. Proceeding
  Jun 15 12:31:01.977: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 06/15/24 12:31:01.989
  STEP: Waiting some time to make sure that toleration time passed. @ 06/15/24 12:31:01.993
  Jun 15 12:32:16.994: INFO: Pod wasn't evicted. Test successful
  Jun 15 12:32:16.994: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-5395" for this suite. @ 06/15/24 12:32:16.999
• [135.287 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 06/15/24 12:32:17.008
  Jun 15 12:32:17.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 12:32:17.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:32:17.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:32:17.026
  STEP: Creating pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076 @ 06/15/24 12:32:17.029
  STEP: checking the pod's current state and verifying that restartCount is present @ 06/15/24 12:32:19.045
  Jun 15 12:32:19.049: INFO: Initial restart count of pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 is 0
  Jun 15 12:32:19.052: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:21.056: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:23.060: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:25.065: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:27.071: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:29.075: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:31.080: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:33.084: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:35.090: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:37.095: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:39.101: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:39.101: INFO: Restart count of pod container-probe-1076/liveness-007456f9-5add-466f-bf69-2f94b3cb3027 is now 1 (20.05188811s elapsed)
  Jun 15 12:32:41.105: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:43.111: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:45.115: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:47.120: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:49.125: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:51.131: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:53.135: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:55.141: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:57.146: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:59.152: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:32:59.152: INFO: Restart count of pod container-probe-1076/liveness-007456f9-5add-466f-bf69-2f94b3cb3027 is now 2 (40.103253954s elapsed)
  Jun 15 12:33:01.158: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:03.164: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:05.169: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:07.174: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:09.179: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:11.184: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:13.188: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:15.194: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:17.199: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:19.203: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:19.203: INFO: Restart count of pod container-probe-1076/liveness-007456f9-5add-466f-bf69-2f94b3cb3027 is now 3 (1m0.154743854s elapsed)
  Jun 15 12:33:21.210: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:23.214: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:25.220: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:27.225: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:29.229: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:31.233: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:33.239: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:35.243: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:37.248: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:39.255: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:39.255: INFO: Restart count of pod container-probe-1076/liveness-007456f9-5add-466f-bf69-2f94b3cb3027 is now 4 (1m20.206190472s elapsed)
  Jun 15 12:33:41.262: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:43.266: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:45.271: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:47.276: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:49.282: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:51.286: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:53.291: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:55.296: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:57.302: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:33:59.307: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:01.313: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:03.318: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:05.322: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:07.327: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:09.333: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:11.339: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:13.344: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:15.350: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:17.355: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:19.362: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:21.366: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:23.373: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:25.377: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:27.382: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:29.387: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:31.393: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:33.397: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:35.404: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:37.407: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:39.413: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:41.418: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:43.424: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:45.428: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:47.434: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:49.440: INFO: Get pod liveness-007456f9-5add-466f-bf69-2f94b3cb3027 in namespace container-probe-1076
  Jun 15 12:34:49.440: INFO: Restart count of pod container-probe-1076/liveness-007456f9-5add-466f-bf69-2f94b3cb3027 is now 5 (2m30.391368239s elapsed)
  STEP: deleting the pod @ 06/15/24 12:34:49.44
  Jun 15 12:34:49.453: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1076" for this suite. @ 06/15/24 12:34:49.457
• [152.455 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 06/15/24 12:34:49.464
  Jun 15 12:34:49.464: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replication-controller @ 06/15/24 12:34:49.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:34:49.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:34:49.483
  STEP: creating a ReplicationController @ 06/15/24 12:34:49.488
  STEP: waiting for RC to be added @ 06/15/24 12:34:49.495
  STEP: waiting for available Replicas @ 06/15/24 12:34:49.495
  STEP: patching ReplicationController @ 06/15/24 12:34:51.624
  STEP: waiting for RC to be modified @ 06/15/24 12:34:51.631
  STEP: patching ReplicationController status @ 06/15/24 12:34:51.633
  STEP: waiting for RC to be modified @ 06/15/24 12:34:51.637
  STEP: waiting for available Replicas @ 06/15/24 12:34:51.638
  STEP: fetching ReplicationController status @ 06/15/24 12:34:51.645
  STEP: patching ReplicationController scale @ 06/15/24 12:34:51.65
  STEP: waiting for RC to be modified @ 06/15/24 12:34:51.655
  STEP: waiting for ReplicationController's scale to be the max amount @ 06/15/24 12:34:51.656
  STEP: fetching ReplicationController; ensuring that it's patched @ 06/15/24 12:34:53.717
  STEP: updating ReplicationController status @ 06/15/24 12:34:53.72
  STEP: waiting for RC to be modified @ 06/15/24 12:34:53.728
  STEP: listing all ReplicationControllers @ 06/15/24 12:34:53.728
  STEP: checking that ReplicationController has expected values @ 06/15/24 12:34:53.732
  STEP: deleting ReplicationControllers by collection @ 06/15/24 12:34:53.732
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 06/15/24 12:34:53.74
  Jun 15 12:34:53.787: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0615 12:34:53.788045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-6725" for this suite. @ 06/15/24 12:34:53.792
• [4.337 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:135
  STEP: Creating a kubernetes client @ 06/15/24 12:34:53.801
  Jun 15 12:34:53.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename security-context @ 06/15/24 12:34:53.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:34:53.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:34:53.821
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 06/15/24 12:34:53.824
  E0615 12:34:54.788185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:34:55.788271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:34:55.839
  Jun 15 12:34:55.843: INFO: Trying to get logs from node ip-172-31-7-7 pod security-context-0c1fbccc-0fb6-4abd-ac3f-8632e29de059 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:34:55.857
  Jun 15 12:34:55.871: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6699" for this suite. @ 06/15/24 12:34:55.874
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 06/15/24 12:34:55.881
  Jun 15 12:34:55.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 12:34:55.881
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:34:55.897
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:34:55.9
  Jun 15 12:34:55.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 12:34:56.788482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 06/15/24 12:34:57.108
  Jun 15 12:34:57.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-9128 --namespace=crd-publish-openapi-9128 create -f -'
  Jun 15 12:34:57.175: INFO: stderr: ""
  Jun 15 12:34:57.175: INFO: stdout: "e2e-test-crd-publish-openapi-6813-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Jun 15 12:34:57.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-9128 --namespace=crd-publish-openapi-9128 delete e2e-test-crd-publish-openapi-6813-crds test-cr'
  Jun 15 12:34:57.236: INFO: stderr: ""
  Jun 15 12:34:57.236: INFO: stdout: "e2e-test-crd-publish-openapi-6813-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Jun 15 12:34:57.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-9128 --namespace=crd-publish-openapi-9128 apply -f -'
  Jun 15 12:34:57.290: INFO: stderr: ""
  Jun 15 12:34:57.290: INFO: stdout: "e2e-test-crd-publish-openapi-6813-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Jun 15 12:34:57.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-9128 --namespace=crd-publish-openapi-9128 delete e2e-test-crd-publish-openapi-6813-crds test-cr'
  Jun 15 12:34:57.339: INFO: stderr: ""
  Jun 15 12:34:57.339: INFO: stdout: "e2e-test-crd-publish-openapi-6813-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 06/15/24 12:34:57.339
  Jun 15 12:34:57.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-9128 explain e2e-test-crd-publish-openapi-6813-crds'
  Jun 15 12:34:57.380: INFO: stderr: ""
  Jun 15 12:34:57.380: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-6813-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0615 12:34:57.788615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:34:58.700: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9128" for this suite. @ 06/15/24 12:34:58.708
• [2.834 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 06/15/24 12:34:58.715
  Jun 15 12:34:58.715: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:34:58.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:34:58.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:34:58.731
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:34:58.734
  E0615 12:34:58.789535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:34:59.789748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:00.789978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:01.790375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:35:02.76
  Jun 15 12:35:02.764: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-0a288d04-9033-4ad9-96d3-36e9368f652c container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:35:02.774
  E0615 12:35:02.791205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:35:02.792: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8814" for this suite. @ 06/15/24 12:35:02.796
• [4.090 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:170
  STEP: Creating a kubernetes client @ 06/15/24 12:35:02.805
  Jun 15 12:35:02.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename security-context @ 06/15/24 12:35:02.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:35:02.825
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:35:02.829
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 06/15/24 12:35:02.832
  E0615 12:35:03.791288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:04.791390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:35:04.853
  Jun 15 12:35:04.856: INFO: Trying to get logs from node ip-172-31-7-7 pod security-context-39ac0040-3aad-4fb8-b044-13e1aee9896c container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:35:04.861
  Jun 15 12:35:04.876: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6022" for this suite. @ 06/15/24 12:35:04.88
• [2.081 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 06/15/24 12:35:04.886
  Jun 15 12:35:04.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename var-expansion @ 06/15/24 12:35:04.886
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:35:04.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:35:04.901
  E0615 12:35:05.791499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:06.791570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:35:06.926: INFO: Deleting pod "var-expansion-f2132fda-e96f-453b-8c88-c7989d67f098" in namespace "var-expansion-5145"
  Jun 15 12:35:06.935: INFO: Wait up to 5m0s for pod "var-expansion-f2132fda-e96f-453b-8c88-c7989d67f098" to be fully deleted
  E0615 12:35:07.791669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:08.791769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:35:08.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5145" for this suite. @ 06/15/24 12:35:08.948
• [4.070 seconds]
------------------------------
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 06/15/24 12:35:08.956
  Jun 15 12:35:08.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sysctl @ 06/15/24 12:35:08.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:35:08.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:35:08.973
  STEP: Creating a pod with one valid and two invalid sysctls @ 06/15/24 12:35:08.976
  Jun 15 12:35:08.983: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-2205" for this suite. @ 06/15/24 12:35:08.987
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 06/15/24 12:35:08.993
  Jun 15 12:35:08.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename var-expansion @ 06/15/24 12:35:08.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:35:09.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:35:09.012
  STEP: creating the pod with failed condition @ 06/15/24 12:35:09.015
  E0615 12:35:09.792335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:10.792518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:11.793533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:12.793718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:13.793829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:14.793983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:15.794028      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:16.794182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:17.794351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:18.794447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:19.794541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:20.794632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:21.795562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:22.795663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:23.795743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:24.795829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:25.795936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:26.796442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:27.796553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:28.797454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:29.798107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:30.798294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:31.799046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:32.799251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:33.799333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:34.800326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:35.801104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:36.801584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:37.801774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:38.802485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:39.802585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:40.802788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:41.803674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:42.803753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:43.803851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:44.803951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:45.804036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:46.804526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:47.804618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:48.804812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:49.805906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:50.805994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:51.806272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:52.807295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:53.808119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:54.808276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:55.808934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:56.810025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:57.810080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:58.810353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:35:59.810480      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:00.810565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:01.811387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:02.811482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:03.812496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:04.812746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:05.812843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:06.813288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:07.813831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:08.814048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:09.814159      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:10.814354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:11.814577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:12.814667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:13.815574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:14.815670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:15.815929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:16.816428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:17.817145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:18.817338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:19.818401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:20.818633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:21.819564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:22.819657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:23.819977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:24.820049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:25.820663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:26.821578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:27.821938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:28.822132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:29.822581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:30.822829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:31.823386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:32.823486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:33.824369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:34.825402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:35.826252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:36.826561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:37.827226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:38.827268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:39.828223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:40.829253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:41.829590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:42.829841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:43.829975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:44.830067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:45.831052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:46.831522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:47.832339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:48.832515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:49.833158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:50.833410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:51.833990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:52.834281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:53.835252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:54.836323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:55.836502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:56.836524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:57.836738      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:58.836858      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:36:59.837641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:00.837814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:01.838586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:02.838703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:03.839563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:04.839653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:05.839766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:06.840574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:07.841131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:08.841330      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 06/15/24 12:37:09.024
  Jun 15 12:37:09.536: INFO: Successfully updated pod "var-expansion-073fe377-aaf4-4460-b021-820be3095068"
  STEP: waiting for pod running @ 06/15/24 12:37:09.536
  E0615 12:37:09.842434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:10.842740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 06/15/24 12:37:11.547
  Jun 15 12:37:11.547: INFO: Deleting pod "var-expansion-073fe377-aaf4-4460-b021-820be3095068" in namespace "var-expansion-4382"
  Jun 15 12:37:11.557: INFO: Wait up to 5m0s for pod "var-expansion-073fe377-aaf4-4460-b021-820be3095068" to be fully deleted
  E0615 12:37:11.843668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:12.844583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:13.845059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:14.845167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:15.845358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:16.845617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:17.846099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:18.846382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:19.847266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:20.847318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:21.847394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:22.847499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:23.848505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:24.848571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:25.849051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:26.849560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:27.850171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:28.850372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:29.851064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:30.851291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:31.852372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:32.852455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:33.853071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:34.853204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:35.853635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:36.854049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:37.855091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:38.855285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:39.855392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:40.855505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:41.855767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:42.855850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:37:43.641: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4382" for this suite. @ 06/15/24 12:37:43.646
• [154.662 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 06/15/24 12:37:43.655
  Jun 15 12:37:43.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replicaset @ 06/15/24 12:37:43.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:37:43.669
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:37:43.672
  Jun 15 12:37:43.688: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0615 12:37:43.856380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:44.856580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:45.856647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:46.857566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:47.858241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:37:48.693: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 06/15/24 12:37:48.693
  STEP: Scaling up "test-rs" replicaset @ 06/15/24 12:37:48.693
  Jun 15 12:37:48.703: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 06/15/24 12:37:48.703
  Jun 15 12:37:48.724: INFO: observed ReplicaSet test-rs in namespace replicaset-4943 with ReadyReplicas 1, AvailableReplicas 1
  Jun 15 12:37:48.730: INFO: observed ReplicaSet test-rs in namespace replicaset-4943 with ReadyReplicas 1, AvailableReplicas 1
  Jun 15 12:37:48.745: INFO: observed ReplicaSet test-rs in namespace replicaset-4943 with ReadyReplicas 1, AvailableReplicas 1
  Jun 15 12:37:48.757: INFO: observed ReplicaSet test-rs in namespace replicaset-4943 with ReadyReplicas 1, AvailableReplicas 1
  E0615 12:37:48.859051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:49.859416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:37:49.986: INFO: observed ReplicaSet test-rs in namespace replicaset-4943 with ReadyReplicas 2, AvailableReplicas 2
  Jun 15 12:37:50.058: INFO: observed Replicaset test-rs in namespace replicaset-4943 with ReadyReplicas 3 found true
  Jun 15 12:37:50.058: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4943" for this suite. @ 06/15/24 12:37:50.062
• [6.413 seconds]
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:558
  STEP: Creating a kubernetes client @ 06/15/24 12:37:50.068
  Jun 15 12:37:50.068: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename ingress @ 06/15/24 12:37:50.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:37:50.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:37:50.088
  STEP: getting /apis @ 06/15/24 12:37:50.091
  STEP: getting /apis/networking.k8s.io @ 06/15/24 12:37:50.094
  STEP: getting /apis/networking.k8s.iov1 @ 06/15/24 12:37:50.095
  STEP: creating @ 06/15/24 12:37:50.096
  STEP: getting @ 06/15/24 12:37:50.118
  STEP: listing @ 06/15/24 12:37:50.124
  STEP: watching @ 06/15/24 12:37:50.127
  Jun 15 12:37:50.127: INFO: starting watch
  STEP: cluster-wide listing @ 06/15/24 12:37:50.128
  STEP: cluster-wide watching @ 06/15/24 12:37:50.132
  Jun 15 12:37:50.132: INFO: starting watch
  STEP: patching @ 06/15/24 12:37:50.134
  STEP: updating @ 06/15/24 12:37:50.14
  Jun 15 12:37:50.151: INFO: waiting for watch events with expected annotations
  Jun 15 12:37:50.151: INFO: saw patched and updated annotations
  STEP: patching /status @ 06/15/24 12:37:50.151
  STEP: updating /status @ 06/15/24 12:37:50.161
  STEP: get /status @ 06/15/24 12:37:50.171
  STEP: deleting @ 06/15/24 12:37:50.186
  STEP: deleting a collection @ 06/15/24 12:37:50.211
  Jun 15 12:37:50.229: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-2065" for this suite. @ 06/15/24 12:37:50.237
• [0.175 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3129
  STEP: Creating a kubernetes client @ 06/15/24 12:37:50.244
  Jun 15 12:37:50.244: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:37:50.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:37:50.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:37:50.266
  STEP: fetching services @ 06/15/24 12:37:50.274
  Jun 15 12:37:50.279: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5625" for this suite. @ 06/15/24 12:37:50.283
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 06/15/24 12:37:50.289
  Jun 15 12:37:50.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 12:37:50.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:37:50.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:37:50.312
  STEP: set up a multi version CRD @ 06/15/24 12:37:50.316
  Jun 15 12:37:50.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 12:37:50.860251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:51.860980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:52.861555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 06/15/24 12:37:53.373
  STEP: check the new version name is served @ 06/15/24 12:37:53.386
  E0615 12:37:53.861622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 06/15/24 12:37:54.181
  STEP: check the other version is not changed @ 06/15/24 12:37:54.784
  E0615 12:37:54.861895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:55.862735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:56.863565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:37:57.327: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9400" for this suite. @ 06/15/24 12:37:57.334
• [7.052 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 06/15/24 12:37:57.341
  Jun 15 12:37:57.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename field-validation @ 06/15/24 12:37:57.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:37:57.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:37:57.361
  Jun 15 12:37:57.364: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 12:37:57.864375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:58.864541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:37:59.864719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0615 12:37:59.901442      19 warnings.go:70] unknown field "alpha"
  W0615 12:37:59.901460      19 warnings.go:70] unknown field "beta"
  W0615 12:37:59.901463      19 warnings.go:70] unknown field "delta"
  W0615 12:37:59.901466      19 warnings.go:70] unknown field "epsilon"
  W0615 12:37:59.901468      19 warnings.go:70] unknown field "gamma"
  Jun 15 12:38:00.451: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5145" for this suite. @ 06/15/24 12:38:00.456
• [3.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 06/15/24 12:38:00.463
  Jun 15 12:38:00.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:38:00.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:38:00.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:38:00.481
  STEP: Creating secret with name projected-secret-test-2d898684-6636-4a82-b9c5-ea50acfe0ca3 @ 06/15/24 12:38:00.484
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:38:00.489
  E0615 12:38:00.865363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:01.865693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:02.866026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:03.866120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:38:04.514
  Jun 15 12:38:04.517: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-secrets-72f564ef-c175-4878-ac6c-0e9a449a3d98 container secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:38:04.528
  Jun 15 12:38:04.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6663" for this suite. @ 06/15/24 12:38:04.552
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 06/15/24 12:38:04.559
  Jun 15 12:38:04.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 12:38:04.56
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:38:04.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:38:04.577
  STEP: Creating secret with name s-test-opt-del-255ed92a-fc32-41c4-9a25-62839da95bd2 @ 06/15/24 12:38:04.584
  STEP: Creating secret with name s-test-opt-upd-b683987e-6198-4fd1-b54f-680f762fa651 @ 06/15/24 12:38:04.589
  STEP: Creating the pod @ 06/15/24 12:38:04.594
  E0615 12:38:04.866230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:05.866859      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-255ed92a-fc32-41c4-9a25-62839da95bd2 @ 06/15/24 12:38:06.638
  STEP: Updating secret s-test-opt-upd-b683987e-6198-4fd1-b54f-680f762fa651 @ 06/15/24 12:38:06.644
  STEP: Creating secret with name s-test-opt-create-3fc635b4-19d6-4e2b-8cda-690b235d4edc @ 06/15/24 12:38:06.65
  STEP: waiting to observe update in volume @ 06/15/24 12:38:06.654
  E0615 12:38:06.867553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:07.867658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:08.868698      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:09.868811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:10.869464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:11.869766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:12.870823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:13.870918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:14.871529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:15.871658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:16.871759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:17.872365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:18.872893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:19.873037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:20.873924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:21.874469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:22.874983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:23.875965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:24.876357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:25.876744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:26.876855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:27.877650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:28.877908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:29.878841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:30.879053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:31.879972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:32.880490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:33.880660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:34.881189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:35.881384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:36.882248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:37.882345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:38.883355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:39.883446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:40.883470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:41.883735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:42.883806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:43.883906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:44.884641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:45.884768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:46.885819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:47.885914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:48.886388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:49.886494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:50.886775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:51.887648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:52.888404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:53.888521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:54.889276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:55.889371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:56.890080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:57.890299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:58.890500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:38:59.890717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:00.891421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:01.891511      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:02.892454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:03.892652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:04.892928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:05.893840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:06.894668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:07.894857      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:08.895036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:09.895174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:10.895288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:11.895358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:12.895485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:13.895565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:14.895653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:15.896450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:16.896572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:17.897492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:18.897575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:19.898486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:20.898672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:21.899564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:22.900358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:23.900776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:24.900844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:25.901709      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:26.902061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:27.902843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:28.903806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:29.904256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:30.904368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:31.905194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:32.905269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:33.906263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:34.906494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:39:35.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6248" for this suite. @ 06/15/24 12:39:35.041
• [90.490 seconds]
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 06/15/24 12:39:35.049
  Jun 15 12:39:35.049: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename subjectreview @ 06/15/24 12:39:35.05
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:35.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:35.07
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-3182" @ 06/15/24 12:39:35.073
  Jun 15 12:39:35.078: INFO: saUsername: "system:serviceaccount:subjectreview-3182:e2e"
  Jun 15 12:39:35.078: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-3182"}
  Jun 15 12:39:35.078: INFO: saUID: "3224e9f2-6cb8-43f1-94aa-46f54a0279f2"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-3182:e2e" @ 06/15/24 12:39:35.079
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-3182:e2e" @ 06/15/24 12:39:35.079
  Jun 15 12:39:35.080: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-3182:e2e" api 'list' configmaps in "subjectreview-3182" namespace @ 06/15/24 12:39:35.08
  Jun 15 12:39:35.082: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-3182:e2e" @ 06/15/24 12:39:35.082
  Jun 15 12:39:35.084: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Jun 15 12:39:35.084: INFO: LocalSubjectAccessReview has been verified
  Jun 15 12:39:35.084: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-3182" for this suite. @ 06/15/24 12:39:35.087
• [0.044 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:627
  STEP: Creating a kubernetes client @ 06/15/24 12:39:35.094
  Jun 15 12:39:35.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename job @ 06/15/24 12:39:35.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:35.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:35.11
  STEP: Creating a job @ 06/15/24 12:39:35.114
  STEP: Ensuring active pods == parallelism @ 06/15/24 12:39:35.122
  E0615 12:39:35.907340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:36.907511      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 06/15/24 12:39:37.129
  STEP: deleting Job.batch foo in namespace job-7296, will wait for the garbage collector to delete the pods @ 06/15/24 12:39:37.129
  Jun 15 12:39:37.193: INFO: Deleting Job.batch foo took: 7.163461ms
  Jun 15 12:39:37.294: INFO: Terminating Job.batch foo pods took: 100.571538ms
  E0615 12:39:37.908409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 06/15/24 12:39:38.294
  Jun 15 12:39:38.298: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7296" for this suite. @ 06/15/24 12:39:38.302
• [3.215 seconds]
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 06/15/24 12:39:38.309
  Jun 15 12:39:38.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename csiinlinevolumes @ 06/15/24 12:39:38.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:38.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:38.333
  STEP: Creating two CSIDrivers @ 06/15/24 12:39:38.337
  STEP: Getting "inline-driver-b9338259-c6eb-47f7-ad79-f5b6a2054afb" & "inline-driver-93fb421a-5658-449e-8f47-c7467989321b" @ 06/15/24 12:39:38.352
  STEP: Patching the CSIDriver "inline-driver-93fb421a-5658-449e-8f47-c7467989321b" @ 06/15/24 12:39:38.36
  STEP: Updating the CSIDriver "inline-driver-93fb421a-5658-449e-8f47-c7467989321b" @ 06/15/24 12:39:38.366
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-5925" @ 06/15/24 12:39:38.374
  STEP: Deleting CSIDriver "inline-driver-b9338259-c6eb-47f7-ad79-f5b6a2054afb" @ 06/15/24 12:39:38.377
  STEP: Confirm deletion of CSIDriver "inline-driver-b9338259-c6eb-47f7-ad79-f5b6a2054afb" @ 06/15/24 12:39:38.385
  STEP: Deleting CSIDriver "inline-driver-93fb421a-5658-449e-8f47-c7467989321b" via DeleteCollection @ 06/15/24 12:39:38.388
  STEP: Confirm deletion of CSIDriver "inline-driver-93fb421a-5658-449e-8f47-c7467989321b" @ 06/15/24 12:39:38.397
  Jun 15 12:39:38.400: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5925" for this suite. @ 06/15/24 12:39:38.404
• [0.101 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 06/15/24 12:39:38.41
  Jun 15 12:39:38.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 12:39:38.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:38.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:38.428
  STEP: creating pod @ 06/15/24 12:39:38.431
  E0615 12:39:38.908907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:39.909053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:39:40.459: INFO: Pod pod-hostip-9754575d-88f9-41a2-bfdf-a74ccf336a95 has hostIP: 172.31.43.132
  Jun 15 12:39:40.459: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3398" for this suite. @ 06/15/24 12:39:40.463
• [2.061 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 06/15/24 12:39:40.472
  Jun 15 12:39:40.472: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename field-validation @ 06/15/24 12:39:40.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:40.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:40.493
  Jun 15 12:39:40.496: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 12:39:40.909175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:41.909475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:42.909621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0615 12:39:43.037816      19 warnings.go:70] unknown field "alpha"
  W0615 12:39:43.037836      19 warnings.go:70] unknown field "beta"
  W0615 12:39:43.037839      19 warnings.go:70] unknown field "delta"
  W0615 12:39:43.037842      19 warnings.go:70] unknown field "epsilon"
  W0615 12:39:43.037845      19 warnings.go:70] unknown field "gamma"
  Jun 15 12:39:43.579: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-328" for this suite. @ 06/15/24 12:39:43.584
• [3.120 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 06/15/24 12:39:43.592
  Jun 15 12:39:43.592: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename runtimeclass @ 06/15/24 12:39:43.593
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:43.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:43.609
  Jun 15 12:39:43.641: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9669" for this suite. @ 06/15/24 12:39:43.646
• [0.060 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 06/15/24 12:39:43.653
  Jun 15 12:39:43.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-runtime @ 06/15/24 12:39:43.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:43.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:43.67
  STEP: create the container @ 06/15/24 12:39:43.673
  W0615 12:39:43.680814      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 06/15/24 12:39:43.68
  E0615 12:39:43.910562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:44.910660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:45.910769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 06/15/24 12:39:46.704
  STEP: the container should be terminated @ 06/15/24 12:39:46.709
  STEP: the termination message should be set @ 06/15/24 12:39:46.709
  Jun 15 12:39:46.709: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 06/15/24 12:39:46.709
  Jun 15 12:39:46.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-3980" for this suite. @ 06/15/24 12:39:46.732
• [3.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:742
  STEP: Creating a kubernetes client @ 06/15/24 12:39:46.741
  Jun 15 12:39:46.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename svcaccounts @ 06/15/24 12:39:46.741
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:46.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:46.765
  Jun 15 12:39:46.771: INFO: Got root ca configmap in namespace "svcaccounts-6467"
  Jun 15 12:39:46.778: INFO: Deleted root ca configmap in namespace "svcaccounts-6467"
  E0615 12:39:46.911659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 06/15/24 12:39:47.279
  Jun 15 12:39:47.282: INFO: Recreated root ca configmap in namespace "svcaccounts-6467"
  Jun 15 12:39:47.287: INFO: Updated root ca configmap in namespace "svcaccounts-6467"
  STEP: waiting for the root ca configmap reconciled @ 06/15/24 12:39:47.788
  Jun 15 12:39:47.791: INFO: Reconciled root ca configmap in namespace "svcaccounts-6467"
  Jun 15 12:39:47.792: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6467" for this suite. @ 06/15/24 12:39:47.795
• [1.064 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:332
  STEP: Creating a kubernetes client @ 06/15/24 12:39:47.804
  Jun 15 12:39:47.804: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename statefulset @ 06/15/24 12:39:47.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:39:47.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:39:47.822
  STEP: Creating service test in namespace statefulset-5775 @ 06/15/24 12:39:47.825
  STEP: Creating a new StatefulSet @ 06/15/24 12:39:47.829
  Jun 15 12:39:47.841: INFO: Found 0 stateful pods, waiting for 3
  E0615 12:39:47.911745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:48.912379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:49.912747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:50.912840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:51.913632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:52.913730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:53.913845      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:54.914519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:55.915393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:56.915495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:39:57.844: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 12:39:57.844: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 12:39:57.844: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 06/15/24 12:39:57.858
  Jun 15 12:39:57.879: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 06/15/24 12:39:57.879
  E0615 12:39:57.916156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:58.916584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:39:59.916668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:00.917674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:01.918646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:02.919394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:03.919506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:04.919626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:05.920337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:06.922215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 06/15/24 12:40:07.889
  STEP: Performing a canary update @ 06/15/24 12:40:07.889
  Jun 15 12:40:07.909: INFO: Updating stateful set ss2
  Jun 15 12:40:07.918: INFO: Waiting for Pod statefulset-5775/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0615 12:40:07.923150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:08.923267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:09.924328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:10.925217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:11.925756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:12.925860      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:13.926057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:14.926170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:15.927149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:16.927861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 06/15/24 12:40:17.918
  E0615 12:40:17.928888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:40:17.952: INFO: Found 2 stateful pods, waiting for 3
  E0615 12:40:18.929454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:19.929616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:20.929769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:21.930113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:22.930422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:23.930596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:24.930830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:25.931001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:26.931973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:27.932076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:40:27.952: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 12:40:27.952: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 12:40:27.952: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 06/15/24 12:40:27.958
  Jun 15 12:40:27.980: INFO: Updating stateful set ss2
  Jun 15 12:40:27.989: INFO: Waiting for Pod statefulset-5775/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0615 12:40:28.932232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:29.932335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:30.932444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:31.932711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:32.932865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:33.933056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:34.933232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:35.933315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:36.933607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:37.933726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:40:38.009: INFO: Updating stateful set ss2
  Jun 15 12:40:38.020: INFO: Waiting for StatefulSet statefulset-5775/ss2 to complete update
  Jun 15 12:40:38.020: INFO: Waiting for Pod statefulset-5775/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0615 12:40:38.934096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:39.934183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:40.934264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:41.934568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:42.934739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:43.935023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:44.935297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:45.935398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:46.935713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:47.935785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:40:48.017: INFO: Deleting all statefulset in ns statefulset-5775
  Jun 15 12:40:48.021: INFO: Scaling statefulset ss2 to 0
  E0615 12:40:48.936247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:49.936348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:50.936585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:51.936635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:52.936732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:53.936819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:54.936929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:55.936996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:56.937450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:57.937545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:40:58.037: INFO: Waiting for statefulset status.replicas updated to 0
  Jun 15 12:40:58.041: INFO: Deleting statefulset ss2
  Jun 15 12:40:58.056: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5775" for this suite. @ 06/15/24 12:40:58.06
• [70.263 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 06/15/24 12:40:58.069
  Jun 15 12:40:58.069: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:40:58.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:40:58.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:40:58.088
  STEP: Creating projection with secret that has name projected-secret-test-map-b8b3ad46-424e-4eec-97f6-1c6f017ad341 @ 06/15/24 12:40:58.092
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:40:58.097
  E0615 12:40:58.937657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:40:59.937811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:00.938002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:01.938700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:41:02.122
  Jun 15 12:41:02.126: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-secrets-e2ce6037-6dda-4102-806d-ae5f87c8ec2b container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:41:02.14
  Jun 15 12:41:02.156: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1201" for this suite. @ 06/15/24 12:41:02.159
• [4.098 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:344
  STEP: Creating a kubernetes client @ 06/15/24 12:41:02.167
  Jun 15 12:41:02.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 12:41:02.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:02.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:02.19
  STEP: creating a replication controller @ 06/15/24 12:41:02.193
  Jun 15 12:41:02.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 create -f -'
  Jun 15 12:41:02.272: INFO: stderr: ""
  Jun 15 12:41:02.272: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 06/15/24 12:41:02.272
  Jun 15 12:41:02.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Jun 15 12:41:02.319: INFO: stderr: ""
  Jun 15 12:41:02.319: INFO: stdout: "update-demo-nautilus-qlrfz update-demo-nautilus-trbfp "
  Jun 15 12:41:02.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get pods update-demo-nautilus-qlrfz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:41:02.364: INFO: stderr: ""
  Jun 15 12:41:02.364: INFO: stdout: ""
  Jun 15 12:41:02.364: INFO: update-demo-nautilus-qlrfz is created but not running
  E0615 12:41:02.939308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:03.939466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:04.940357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:05.940555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:06.940672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:41:07.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Jun 15 12:41:07.412: INFO: stderr: ""
  Jun 15 12:41:07.412: INFO: stdout: "update-demo-nautilus-qlrfz update-demo-nautilus-trbfp "
  Jun 15 12:41:07.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get pods update-demo-nautilus-qlrfz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:41:07.457: INFO: stderr: ""
  Jun 15 12:41:07.457: INFO: stdout: "true"
  Jun 15 12:41:07.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get pods update-demo-nautilus-qlrfz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Jun 15 12:41:07.502: INFO: stderr: ""
  Jun 15 12:41:07.502: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Jun 15 12:41:07.502: INFO: validating pod update-demo-nautilus-qlrfz
  Jun 15 12:41:07.508: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Jun 15 12:41:07.508: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Jun 15 12:41:07.508: INFO: update-demo-nautilus-qlrfz is verified up and running
  Jun 15 12:41:07.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get pods update-demo-nautilus-trbfp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:41:07.551: INFO: stderr: ""
  Jun 15 12:41:07.551: INFO: stdout: "true"
  Jun 15 12:41:07.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get pods update-demo-nautilus-trbfp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Jun 15 12:41:07.594: INFO: stderr: ""
  Jun 15 12:41:07.594: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Jun 15 12:41:07.594: INFO: validating pod update-demo-nautilus-trbfp
  Jun 15 12:41:07.600: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Jun 15 12:41:07.600: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Jun 15 12:41:07.600: INFO: update-demo-nautilus-trbfp is verified up and running
  STEP: using delete to clean up resources @ 06/15/24 12:41:07.6
  Jun 15 12:41:07.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 delete --grace-period=0 --force -f -'
  Jun 15 12:41:07.646: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 12:41:07.646: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Jun 15 12:41:07.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get rc,svc -l name=update-demo --no-headers'
  Jun 15 12:41:07.712: INFO: stderr: "No resources found in kubectl-8816 namespace.\n"
  Jun 15 12:41:07.712: INFO: stdout: ""
  Jun 15 12:41:07.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-8816 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Jun 15 12:41:07.760: INFO: stderr: ""
  Jun 15 12:41:07.760: INFO: stdout: ""
  Jun 15 12:41:07.760: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8816" for this suite. @ 06/15/24 12:41:07.765
• [5.607 seconds]
------------------------------
SS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 06/15/24 12:41:07.774
  Jun 15 12:41:07.774: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename certificates @ 06/15/24 12:41:07.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:07.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:07.793
  E0615 12:41:07.940814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting /apis @ 06/15/24 12:41:08.009
  STEP: getting /apis/certificates.k8s.io @ 06/15/24 12:41:08.012
  STEP: getting /apis/certificates.k8s.io/v1 @ 06/15/24 12:41:08.013
  STEP: creating @ 06/15/24 12:41:08.015
  STEP: getting @ 06/15/24 12:41:08.039
  STEP: listing @ 06/15/24 12:41:08.043
  STEP: watching @ 06/15/24 12:41:08.046
  Jun 15 12:41:08.046: INFO: starting watch
  STEP: patching @ 06/15/24 12:41:08.047
  STEP: updating @ 06/15/24 12:41:08.052
  Jun 15 12:41:08.064: INFO: waiting for watch events with expected annotations
  Jun 15 12:41:08.064: INFO: saw patched and updated annotations
  STEP: getting /approval @ 06/15/24 12:41:08.064
  STEP: patching /approval @ 06/15/24 12:41:08.067
  STEP: updating /approval @ 06/15/24 12:41:08.072
  STEP: getting /status @ 06/15/24 12:41:08.079
  STEP: patching /status @ 06/15/24 12:41:08.082
  STEP: updating /status @ 06/15/24 12:41:08.088
  STEP: deleting @ 06/15/24 12:41:08.096
  STEP: deleting a collection @ 06/15/24 12:41:08.107
  Jun 15 12:41:08.122: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-6351" for this suite. @ 06/15/24 12:41:08.125
• [0.357 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 06/15/24 12:41:08.132
  Jun 15 12:41:08.132: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename deployment @ 06/15/24 12:41:08.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:08.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:08.149
  Jun 15 12:41:08.152: INFO: Creating deployment "test-recreate-deployment"
  Jun 15 12:41:08.156: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Jun 15 12:41:08.164: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
  E0615 12:41:08.940986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:09.941142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:41:10.174: INFO: Waiting deployment "test-recreate-deployment" to complete
  Jun 15 12:41:10.178: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Jun 15 12:41:10.186: INFO: Updating deployment test-recreate-deployment
  Jun 15 12:41:10.186: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Jun 15 12:41:10.272: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-955",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2ce78bab-556f-4d85-8390-58255b0161b6",
      ResourceVersion: (string) (len=5) "16574",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052068,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Jun 15 12:41:10.276: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-955",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5385bdc7-ed71-4b69-9b33-77992769ccce",
      ResourceVersion: (string) (len=5) "16573",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052070,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "2ce78bab-556f-4d85-8390-58255b0161b6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 63 65 37 38 62  61 62 2d 35 35 36 66 2d  |\"2ce78bab-556f-|
              00000120  34 64 38 35 2d 38 33 39  30 2d 35 38 32 35 35 62  |4d85-8390-58255b|
              00000130  30 31 36 31 62 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0161b6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:41:10.277: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Jun 15 12:41:10.277: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-5cf87b5b86",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-955",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6d5f2dff-fd2f-462a-a5c9-6533f2cea099",
      ResourceVersion: (string) (len=5) "16563",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052068,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "2ce78bab-556f-4d85-8390-58255b0161b6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 63 65 37 38 62  61 62 2d 35 35 36 66 2d  |\"2ce78bab-556f-|
              00000120  34 64 38 35 2d 38 33 39  30 2d 35 38 32 35 35 62  |4d85-8390-58255b|
              00000130  30 31 36 31 62 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |0161b6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:41:10.280: INFO: Pod "test-recreate-deployment-76fb77d45-7f9qx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-7f9qx",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=14) "deployment-955",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ba78770d-5d15-4439-b38a-f099d0ca4668",
      ResourceVersion: (string) (len=5) "16575",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052070,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "5385bdc7-ed71-4b69-9b33-77992769ccce",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 33  38 35 62 64 63 37 2d 65  |d\":\"5385bdc7-e|
              00000090  64 37 31 2d 34 62 36 39  2d 39 62 33 33 2d 37 37  |d71-4b69-9b33-77|
              000000a0  39 39 32 37 36 39 63 63  63 65 5c 22 7d 22 3a 7b  |992769ccce\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rcgl2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rcgl2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052070,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:41:10.282: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-955" for this suite. @ 06/15/24 12:41:10.286
• [2.161 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:269
  STEP: Creating a kubernetes client @ 06/15/24 12:41:10.293
  Jun 15 12:41:10.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:41:10.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:10.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:10.309
  STEP: Creating a pod to test downward api env vars @ 06/15/24 12:41:10.312
  E0615 12:41:10.941967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:11.942687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:12.943670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:13.943756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:41:14.337
  Jun 15 12:41:14.340: INFO: Trying to get logs from node ip-172-31-43-132 pod downward-api-d8be5696-c536-45b6-8760-99b01c9397f5 container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 12:41:14.359
  Jun 15 12:41:14.374: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8623" for this suite. @ 06/15/24 12:41:14.377
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 06/15/24 12:41:14.385
  Jun 15 12:41:14.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename deployment @ 06/15/24 12:41:14.385
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:14.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:14.403
  STEP: creating a Deployment @ 06/15/24 12:41:14.409
  Jun 15 12:41:14.409: INFO: Creating simple deployment test-deployment-g7smj
  Jun 15 12:41:14.424: INFO: deployment "test-deployment-g7smj" doesn't have the required revision set
  E0615 12:41:14.944163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:15.944235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 06/15/24 12:41:16.439
  Jun 15 12:41:16.442: INFO: Deployment test-deployment-g7smj has Conditions: [{Available True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-g7smj-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 06/15/24 12:41:16.442
  Jun 15 12:41:16.453: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 41, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 41, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.June, 15, 12, 41, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.June, 15, 12, 41, 14, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-g7smj-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 06/15/24 12:41:16.454
  Jun 15 12:41:16.455: INFO: Observed &Deployment event: ADDED
  Jun 15 12:41:16.455: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-g7smj-5d576bd769"}
  Jun 15 12:41:16.456: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.456: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-g7smj-5d576bd769"}
  Jun 15 12:41:16.456: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Jun 15 12:41:16.456: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.456: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Jun 15 12:41:16.456: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-g7smj-5d576bd769" is progressing.}
  Jun 15 12:41:16.456: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.456: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Jun 15 12:41:16.456: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-g7smj-5d576bd769" has successfully progressed.}
  Jun 15 12:41:16.456: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.456: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Jun 15 12:41:16.456: INFO: Observed Deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-g7smj-5d576bd769" has successfully progressed.}
  Jun 15 12:41:16.456: INFO: Found Deployment test-deployment-g7smj in namespace deployment-7213 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Jun 15 12:41:16.456: INFO: Deployment test-deployment-g7smj has an updated status
  STEP: patching the Statefulset Status @ 06/15/24 12:41:16.456
  Jun 15 12:41:16.456: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Jun 15 12:41:16.462: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 06/15/24 12:41:16.462
  Jun 15 12:41:16.464: INFO: Observed &Deployment event: ADDED
  Jun 15 12:41:16.464: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-g7smj-5d576bd769"}
  Jun 15 12:41:16.464: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.464: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-g7smj-5d576bd769"}
  Jun 15 12:41:16.464: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Jun 15 12:41:16.464: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.464: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Jun 15 12:41:16.464: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:14 +0000 UTC 2024-06-15 12:41:14 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-g7smj-5d576bd769" is progressing.}
  Jun 15 12:41:16.465: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.465: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Jun 15 12:41:16.465: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-g7smj-5d576bd769" has successfully progressed.}
  Jun 15 12:41:16.465: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.465: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Jun 15 12:41:16.465: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-06-15 12:41:15 +0000 UTC 2024-06-15 12:41:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-g7smj-5d576bd769" has successfully progressed.}
  Jun 15 12:41:16.465: INFO: Observed deployment test-deployment-g7smj in namespace deployment-7213 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Jun 15 12:41:16.465: INFO: Observed &Deployment event: MODIFIED
  Jun 15 12:41:16.465: INFO: Found deployment test-deployment-g7smj in namespace deployment-7213 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Jun 15 12:41:16.465: INFO: Deployment test-deployment-g7smj has a patched status
  Jun 15 12:41:16.471: INFO: Deployment "test-deployment-g7smj":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-g7smj",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7213",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4e1aa1e5-00ee-45d9-914b-629cb7ed5cc0",
      ResourceVersion: (string) (len=5) "16696",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052074,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052076,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-g7smj-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Jun 15 12:41:16.476: INFO: New ReplicaSet "test-deployment-g7smj-5d576bd769" of Deployment "test-deployment-g7smj":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-g7smj-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7213",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dc3cf5ab-ec8c-41f5-8bbf-42ba8987d527",
      ResourceVersion: (string) (len=5) "16660",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052074,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
        (string) (len=3) "e2e": (string) (len=7) "testing"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-g7smj",
          UID: (types.UID) (len=36) "4e1aa1e5-00ee-45d9-914b-629cb7ed5cc0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 34 65 31  |k:{\"uid\":\"4e1|
              00000120  61 61 31 65 35 2d 30 30  65 65 2d 34 35 64 39 2d  |aa1e5-00ee-45d9-|
              00000130  39 31 34 62 2d 36 32 39  63 62 37 65 64 35 63 63  |914b-629cb7ed5cc|
              00000140  30 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |0\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:41:16.480: INFO: Pod "test-deployment-g7smj-5d576bd769-8j296" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-g7smj-5d576bd769-8j296",
      GenerateName: (string) (len=33) "test-deployment-g7smj-5d576bd769-",
      Namespace: (string) (len=15) "deployment-7213",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5aacb53c-8ee0-46ef-99bd-df23b72906a7",
      ResourceVersion: (string) (len=5) "16659",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052074,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-g7smj-5d576bd769",
          UID: (types.UID) (len=36) "dc3cf5ab-ec8c-41f5-8bbf-42ba8987d527",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 64 63 33 63 66 35 61  62 2d 65 63 38 63 2d 34  |"dc3cf5ab-ec8c-4|
              000000a0  31 66 35 2d 38 62 62 66  2d 34 32 62 61 38 39 38  |1f5-8bbf-42ba898|
              000000b0  37 64 35 32 37 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |7d527\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  34 2e 31 35 38 5c 22 7d  |2.168.164.158\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-srlnl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-srlnl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854052074,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) (len=15) "192.168.164.158",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.164.158"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854052074,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854052074,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://73f6e21df9cc536793e56c3b7efa2cb07cc2412378ea17f5a94ec2034b8117de",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:41:16.482: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7213" for this suite. @ 06/15/24 12:41:16.487
• [2.108 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 06/15/24 12:41:16.493
  Jun 15 12:41:16.493: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replicaset @ 06/15/24 12:41:16.493
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:16.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:16.513
  Jun 15 12:41:16.515: INFO: Creating ReplicaSet my-hostname-basic-8ab273ea-81fa-480b-9493-8bf939d5b16e
  Jun 15 12:41:16.525: INFO: Pod name my-hostname-basic-8ab273ea-81fa-480b-9493-8bf939d5b16e: Found 0 pods out of 1
  E0615 12:41:16.944289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:17.944371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:18.945078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:19.945166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:20.945264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:41:21.538: INFO: Pod name my-hostname-basic-8ab273ea-81fa-480b-9493-8bf939d5b16e: Found 1 pods out of 1
  Jun 15 12:41:21.538: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8ab273ea-81fa-480b-9493-8bf939d5b16e" is running
  Jun 15 12:41:21.541: INFO: Pod "my-hostname-basic-8ab273ea-81fa-480b-9493-8bf939d5b16e-xvx7n" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:41:17 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:41:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:41:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:41:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-06-15 12:41:16 +0000 UTC Reason: Message:}])
  Jun 15 12:41:21.541: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 06/15/24 12:41:21.541
  Jun 15 12:41:21.556: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6665" for this suite. @ 06/15/24 12:41:21.56
• [5.075 seconds]
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 06/15/24 12:41:21.568
  Jun 15 12:41:21.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename field-validation @ 06/15/24 12:41:21.568
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:21.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:21.588
  STEP: apply creating a deployment @ 06/15/24 12:41:21.592
  Jun 15 12:41:21.605: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9426" for this suite. @ 06/15/24 12:41:21.608
• [0.049 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 06/15/24 12:41:21.617
  Jun 15 12:41:21.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:41:21.618
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:21.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:21.636
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:41:21.642
  E0615 12:41:21.945736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:22.945836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:23.946323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:24.946538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:41:25.667
  Jun 15 12:41:25.670: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-92e577c2-c129-483f-a9e6-4596f03cf52f container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:41:25.676
  Jun 15 12:41:25.692: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9554" for this suite. @ 06/15/24 12:41:25.697
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 06/15/24 12:41:25.704
  Jun 15 12:41:25.704: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:41:25.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:25.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:25.722
  STEP: Creating the pod @ 06/15/24 12:41:25.725
  E0615 12:41:25.947024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:26.947411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:27.947487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:41:28.269: INFO: Successfully updated pod "labelsupdate931408c0-ba04-43b4-9034-c30176fcfde9"
  E0615 12:41:28.947815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:29.947914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:41:30.286: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5896" for this suite. @ 06/15/24 12:41:30.289
• [4.593 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 06/15/24 12:41:30.297
  Jun 15 12:41:30.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:41:30.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:30.311
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:30.315
  STEP: Creating configMap with name projected-configmap-test-volume-8717f3c9-9195-483d-9391-650f9054b18a @ 06/15/24 12:41:30.318
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:41:30.324
  E0615 12:41:30.948559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:31.948638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:32.949635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:33.949743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:41:34.351
  Jun 15 12:41:34.355: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-projected-configmaps-a3fc4daf-fdcf-4918-b65c-6bfcb25c8fff container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:41:34.361
  Jun 15 12:41:34.376: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-94" for this suite. @ 06/15/24 12:41:34.38
• [4.089 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 06/15/24 12:41:34.386
  Jun 15 12:41:34.386: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:41:34.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:34.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:34.405
  STEP: Setting up server cert @ 06/15/24 12:41:34.429
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:41:34.611
  STEP: Deploying the webhook pod @ 06/15/24 12:41:34.62
  STEP: Wait for the deployment to be ready @ 06/15/24 12:41:34.632
  Jun 15 12:41:34.646: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0615 12:41:34.950595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:35.950726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 12:41:36.658
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:41:36.668
  E0615 12:41:36.951774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:41:37.668: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Jun 15 12:41:37.675: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 12:41:37.952405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1378-crds.webhook.example.com via the AdmissionRegistration API @ 06/15/24 12:41:38.184
  STEP: Creating a custom resource that should be mutated by the webhook @ 06/15/24 12:41:38.2
  E0615 12:41:38.952819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:39.953019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:41:40.776: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3225" for this suite. @ 06/15/24 12:41:40.781
  STEP: Destroying namespace "webhook-markers-1069" for this suite. @ 06/15/24 12:41:40.787
• [6.409 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 06/15/24 12:41:40.795
  Jun 15 12:41:40.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:41:40.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:40.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:40.812
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:41:40.816
  E0615 12:41:40.953539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:41.953695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:42.953946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:43.954167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:41:44.84
  Jun 15 12:41:44.844: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-2833ef62-9170-40d5-978f-4a1d27684d40 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:41:44.851
  Jun 15 12:41:44.868: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5987" for this suite. @ 06/15/24 12:41:44.871
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 06/15/24 12:41:44.881
  Jun 15 12:41:44.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename podtemplate @ 06/15/24 12:41:44.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:44.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:44.917
  STEP: Create a pod template @ 06/15/24 12:41:44.92
  STEP: Replace a pod template @ 06/15/24 12:41:44.926
  Jun 15 12:41:44.935: INFO: Found updated podtemplate annotation: "true"

  Jun 15 12:41:44.935: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3441" for this suite. @ 06/15/24 12:41:44.939
• [0.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 06/15/24 12:41:44.948
  Jun 15 12:41:44.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename custom-resource-definition @ 06/15/24 12:41:44.949
  E0615 12:41:44.954505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:44.964
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:44.967
  Jun 15 12:41:44.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 12:41:45.954605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:46.955085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:47.955931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:48.956669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:49.956766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:50.956842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:41:51.180: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7669" for this suite. @ 06/15/24 12:41:51.187
• [6.249 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 06/15/24 12:41:51.197
  Jun 15 12:41:51.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename taint-multiple-pods @ 06/15/24 12:41:51.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:41:51.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:41:51.22
  Jun 15 12:41:51.224: INFO: Waiting up to 1m0s for all nodes to be ready
  E0615 12:41:51.957712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:52.957808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:53.958713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:54.958783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:55.959037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:56.959647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:57.959756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:58.960053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:41:59.960534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:00.960737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:01.961288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:02.961376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:03.961483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:04.961606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:05.961715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:06.962673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:07.962772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:08.963092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:09.963266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:10.963382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:11.963813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:12.964327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:13.964447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:14.965321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:15.965526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:16.965964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:17.966889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:18.967629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:19.967719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:20.967804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:21.968399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:22.969072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:23.969203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:24.969268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:25.969364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:26.969439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:27.969496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:28.969672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:29.969797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:30.970041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:31.970828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:32.971044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:33.971212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:34.971283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:35.972335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:36.972712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:37.973207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:38.973399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:39.973659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:40.974006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:41.974043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:42.974260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:43.974473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:44.974675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:45.974807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:46.975256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:47.975580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:48.976328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:49.976405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:50.976628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:42:51.225: INFO: Waiting for terminating namespaces to be deleted...
  Jun 15 12:42:51.231: INFO: Starting informer...
  STEP: Starting pods... @ 06/15/24 12:42:51.231
  Jun 15 12:42:51.459: INFO: Pod1 is running on ip-172-31-7-7. Tainting Node
  E0615 12:42:51.976950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:52.977046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:42:53.682: INFO: Pod2 is running on ip-172-31-7-7. Tainting Node
  STEP: Trying to apply a taint on the Node @ 06/15/24 12:42:53.682
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 06/15/24 12:42:53.691
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 06/15/24 12:42:53.697
  E0615 12:42:53.977711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:54.977807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:55.977901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:56.978380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:57.978447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:42:58.978999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:42:59.396: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E0615 12:42:59.979091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:00.979295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:01.979641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:02.979726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:03.979847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:04.979967      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:05.980798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:06.981712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:07.981818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:08.982765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:09.982895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:10.983237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:11.983639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:12.984418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:13.984514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:14.984693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:15.984946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:16.985412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:17.985640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:18.986584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:43:19.435: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 06/15/24 12:43:19.445
  Jun 15 12:43:19.450: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-1537" for this suite. @ 06/15/24 12:43:19.454
• [88.265 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:530
  STEP: Creating a kubernetes client @ 06/15/24 12:43:19.462
  Jun 15 12:43:19.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename security-context-test @ 06/15/24 12:43:19.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:43:19.492
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:43:19.495
  E0615 12:43:19.986657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:20.987514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:21.987631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:22.988677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:43:23.530: INFO: Got logs for pod "busybox-privileged-false-b46bef68-5d07-492d-b06e-9bcdbae5b076": "ip: RTNETLINK answers: Operation not permitted\n"
  Jun 15 12:43:23.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5438" for this suite. @ 06/15/24 12:43:23.534
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 06/15/24 12:43:23.542
  Jun 15 12:43:23.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename endpointslicemirroring @ 06/15/24 12:43:23.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:43:23.557
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:43:23.56
  STEP: mirroring a new custom Endpoint @ 06/15/24 12:43:23.574
  Jun 15 12:43:23.584: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0615 12:43:23.989361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:24.989524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 06/15/24 12:43:25.589
  Jun 15 12:43:25.597: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0615 12:43:25.990168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:26.990260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 06/15/24 12:43:27.602
  Jun 15 12:43:27.615: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0615 12:43:27.990453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:28.990602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:43:29.621: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-2295" for this suite. @ 06/15/24 12:43:29.626
• [6.092 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 06/15/24 12:43:29.634
  Jun 15 12:43:29.634: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename disruption @ 06/15/24 12:43:29.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:43:29.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:43:29.654
  STEP: Creating a pdb that targets all three pods in a test replica set @ 06/15/24 12:43:29.657
  STEP: Waiting for the pdb to be processed @ 06/15/24 12:43:29.662
  E0615 12:43:29.990664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:30.990759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 06/15/24 12:43:31.675
  STEP: Waiting for all pods to be running @ 06/15/24 12:43:31.675
  Jun 15 12:43:31.678: INFO: pods: 0 < 3
  E0615 12:43:31.991329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:32.991439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 06/15/24 12:43:33.681
  STEP: Updating the pdb to allow a pod to be evicted @ 06/15/24 12:43:33.692
  STEP: Waiting for the pdb to be processed @ 06/15/24 12:43:33.701
  E0615 12:43:33.991744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:34.991816      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 06/15/24 12:43:35.706
  STEP: Waiting for all pods to be running @ 06/15/24 12:43:35.706
  STEP: Waiting for the pdb to observed all healthy pods @ 06/15/24 12:43:35.71
  STEP: Patching the pdb to disallow a pod to be evicted @ 06/15/24 12:43:35.737
  STEP: Waiting for the pdb to be processed @ 06/15/24 12:43:35.755
  E0615 12:43:35.992806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:36.993879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 06/15/24 12:43:37.76
  STEP: locating a running pod @ 06/15/24 12:43:37.765
  STEP: Deleting the pdb to allow a pod to be evicted @ 06/15/24 12:43:37.775
  STEP: Waiting for the pdb to be deleted @ 06/15/24 12:43:37.78
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 06/15/24 12:43:37.784
  STEP: Waiting for all pods to be running @ 06/15/24 12:43:37.784
  Jun 15 12:43:37.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6710" for this suite. @ 06/15/24 12:43:37.81
• [8.190 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 06/15/24 12:43:37.825
  Jun 15 12:43:37.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename events @ 06/15/24 12:43:37.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:43:37.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:43:37.846
  STEP: creating a test event @ 06/15/24 12:43:37.849
  STEP: listing all events in all namespaces @ 06/15/24 12:43:37.853
  STEP: patching the test event @ 06/15/24 12:43:37.9
  STEP: fetching the test event @ 06/15/24 12:43:37.911
  STEP: updating the test event @ 06/15/24 12:43:37.915
  STEP: getting the test event @ 06/15/24 12:43:37.929
  STEP: deleting the test event @ 06/15/24 12:43:37.934
  STEP: listing all events in all namespaces @ 06/15/24 12:43:37.941
  Jun 15 12:43:37.952: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7870" for this suite. @ 06/15/24 12:43:37.956
• [0.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:408
  STEP: Creating a kubernetes client @ 06/15/24 12:43:37.963
  Jun 15 12:43:37.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename job @ 06/15/24 12:43:37.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:43:37.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:43:37.982
  STEP: Creating Indexed job @ 06/15/24 12:43:37.985
  STEP: Ensuring job reaches completions @ 06/15/24 12:43:37.99
  E0615 12:43:37.994339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:38.994520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:39.994837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:40.995290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:41.995318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:42.995405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:43.996018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:44.996157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 06/15/24 12:43:45.995
  E0615 12:43:45.997141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:43:45.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7314" for this suite. @ 06/15/24 12:43:46.001
• [8.046 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:453
  STEP: Creating a kubernetes client @ 06/15/24 12:43:46.009
  Jun 15 12:43:46.009: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 12:43:46.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:43:46.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:43:46.028
  STEP: Counting existing ResourceQuota @ 06/15/24 12:43:46.031
  E0615 12:43:46.997238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:47.997335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:48.997456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:49.997540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:50.997728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 06/15/24 12:43:51.035
  STEP: Ensuring resource quota status is calculated @ 06/15/24 12:43:51.042
  E0615 12:43:51.998548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:52.998642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 06/15/24 12:43:53.047
  STEP: Ensuring resource quota status captures replicaset creation @ 06/15/24 12:43:53.06
  E0615 12:43:53.998757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:54.999022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 06/15/24 12:43:55.066
  STEP: Ensuring resource quota status released usage @ 06/15/24 12:43:55.074
  E0615 12:43:55.999335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:56.999698      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:43:57.079: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7692" for this suite. @ 06/15/24 12:43:57.086
• [11.086 seconds]
------------------------------
SSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:168
  STEP: Creating a kubernetes client @ 06/15/24 12:43:57.094
  Jun 15 12:43:57.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:43:57.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:43:57.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:43:57.113
  STEP: Creating a pod to test downward api env vars @ 06/15/24 12:43:57.115
  E0615 12:43:57.999783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:43:58.999894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:00.000000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:01.000084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:44:01.143
  Jun 15 12:44:01.146: INFO: Trying to get logs from node ip-172-31-7-7 pod downward-api-eb531d6e-0a0c-42f0-888f-e3fc53dca982 container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 12:44:01.152
  Jun 15 12:44:01.168: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5394" for this suite. @ 06/15/24 12:44:01.173
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3565
  STEP: Creating a kubernetes client @ 06/15/24 12:44:01.183
  Jun 15 12:44:01.184: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:44:01.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:44:01.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:44:01.204
  STEP: creating a collection of services @ 06/15/24 12:44:01.207
  Jun 15 12:44:01.207: INFO: Creating e2e-svc-a-28lbl
  Jun 15 12:44:01.218: INFO: Creating e2e-svc-b-m2l2m
  Jun 15 12:44:01.229: INFO: Creating e2e-svc-c-jzgwd
  STEP: deleting service collection @ 06/15/24 12:44:01.244
  Jun 15 12:44:01.274: INFO: Collection of services has been deleted
  Jun 15 12:44:01.274: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7282" for this suite. @ 06/15/24 12:44:01.284
• [0.109 seconds]
------------------------------
S
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 06/15/24 12:44:01.292
  Jun 15 12:44:01.292: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename csiinlinevolumes @ 06/15/24 12:44:01.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:44:01.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:44:01.314
  STEP: creating @ 06/15/24 12:44:01.317
  STEP: getting @ 06/15/24 12:44:01.339
  STEP: listing in namespace @ 06/15/24 12:44:01.343
  STEP: patching @ 06/15/24 12:44:01.349
  STEP: deleting @ 06/15/24 12:44:01.358
  Jun 15 12:44:01.370: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4163" for this suite. @ 06/15/24 12:44:01.373
• [0.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 06/15/24 12:44:01.381
  Jun 15 12:44:01.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pod-network-test @ 06/15/24 12:44:01.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:44:01.395
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:44:01.398
  STEP: Performing setup for networking test in namespace pod-network-test-8731 @ 06/15/24 12:44:01.401
  STEP: creating a selector @ 06/15/24 12:44:01.401
  STEP: Creating the service pods in kubernetes @ 06/15/24 12:44:01.401
  Jun 15 12:44:01.401: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0615 12:44:02.000227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:03.000266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:04.000390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:05.000483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:06.001411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:07.001677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:08.002743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:09.002824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:10.003889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:11.003973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:12.004866      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:13.005045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 06/15/24 12:44:13.488
  E0615 12:44:14.005141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:15.005614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:15.518: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Jun 15 12:44:15.518: INFO: Going to poll 192.168.0.92 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Jun 15 12:44:15.521: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.0.92 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8731 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:44:15.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:44:15.522: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:44:15.522: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8731/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.0.92+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0615 12:44:16.006426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:16.576: INFO: Found all 1 expected endpoints: [netserver-0]
  Jun 15 12:44:16.576: INFO: Going to poll 192.168.40.247 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Jun 15 12:44:16.582: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.40.247 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8731 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:44:16.582: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:44:16.582: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:44:16.582: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8731/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.40.247+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0615 12:44:17.006763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:17.624: INFO: Found all 1 expected endpoints: [netserver-1]
  Jun 15 12:44:17.624: INFO: Going to poll 192.168.164.169 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Jun 15 12:44:17.628: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.164.169 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8731 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:44:17.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:44:17.629: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:44:17.629: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8731/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.164.169+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0615 12:44:18.007860      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:18.680: INFO: Found all 1 expected endpoints: [netserver-2]
  Jun 15 12:44:18.680: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8731" for this suite. @ 06/15/24 12:44:18.685
• [17.311 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 06/15/24 12:44:18.692
  Jun 15 12:44:18.692: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename deployment @ 06/15/24 12:44:18.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:44:18.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:44:18.709
  STEP: creating a Deployment @ 06/15/24 12:44:18.716
  STEP: waiting for Deployment to be created @ 06/15/24 12:44:18.721
  STEP: waiting for all Replicas to be Ready @ 06/15/24 12:44:18.723
  Jun 15 12:44:18.725: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Jun 15 12:44:18.725: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Jun 15 12:44:18.740: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Jun 15 12:44:18.740: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Jun 15 12:44:18.756: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Jun 15 12:44:18.756: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Jun 15 12:44:18.789: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Jun 15 12:44:18.789: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0615 12:44:19.008275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:19.533: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Jun 15 12:44:19.533: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Jun 15 12:44:19.647: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 06/15/24 12:44:19.647
  Jun 15 12:44:19.655: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 06/15/24 12:44:19.655
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 0
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:19.656: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:19.657: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:19.657: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:19.667: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:19.667: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:19.687: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:19.688: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:19.700: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:19.700: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:19.711: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:19.711: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  E0615 12:44:20.008470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:20.673: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:20.673: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:20.697: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  STEP: listing Deployments @ 06/15/24 12:44:20.697
  Jun 15 12:44:20.701: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 06/15/24 12:44:20.701
  Jun 15 12:44:20.710: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 06/15/24 12:44:20.71
  Jun 15 12:44:20.721: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Jun 15 12:44:20.726: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Jun 15 12:44:20.758: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Jun 15 12:44:20.770: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0615 12:44:21.009345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:21.700: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Jun 15 12:44:21.716: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Jun 15 12:44:21.724: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Jun 15 12:44:21.738: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Jun 15 12:44:21.747: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0615 12:44:22.009760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:22.548: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 06/15/24 12:44:22.575
  STEP: fetching the DeploymentStatus @ 06/15/24 12:44:22.584
  Jun 15 12:44:22.603: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:22.603: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:22.603: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:22.603: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 1
  Jun 15 12:44:22.603: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:22.604: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:22.604: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:22.604: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:22.604: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 2
  Jun 15 12:44:22.604: INFO: observed Deployment test-deployment in namespace deployment-9067 with ReadyReplicas 3
  STEP: deleting the Deployment @ 06/15/24 12:44:22.604
  Jun 15 12:44:22.619: INFO: observed event type MODIFIED
  Jun 15 12:44:22.627: INFO: observed event type MODIFIED
  Jun 15 12:44:22.627: INFO: observed event type MODIFIED
  Jun 15 12:44:22.627: INFO: observed event type MODIFIED
  Jun 15 12:44:22.627: INFO: observed event type MODIFIED
  Jun 15 12:44:22.627: INFO: observed event type MODIFIED
  Jun 15 12:44:22.627: INFO: observed event type MODIFIED
  Jun 15 12:44:22.629: INFO: observed event type MODIFIED
  Jun 15 12:44:22.629: INFO: observed event type MODIFIED
  Jun 15 12:44:22.629: INFO: observed event type MODIFIED
  Jun 15 12:44:22.629: INFO: observed event type MODIFIED
  Jun 15 12:44:22.629: INFO: observed event type MODIFIED
  Jun 15 12:44:22.629: INFO: observed event type MODIFIED
  Jun 15 12:44:22.645: INFO: Log out all the ReplicaSets if there is no deployment created
  Jun 15 12:44:22.649: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9067" for this suite. @ 06/15/24 12:44:22.653
• [3.970 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 06/15/24 12:44:22.663
  Jun 15 12:44:22.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename containers @ 06/15/24 12:44:22.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:44:22.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:44:22.699
  STEP: Creating a pod to test override all @ 06/15/24 12:44:22.702
  E0615 12:44:23.010679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:24.010799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:25.010895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:26.011621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:44:26.727
  Jun 15 12:44:26.730: INFO: Trying to get logs from node ip-172-31-43-132 pod client-containers-e49a909f-57d2-4918-8a00-a0ca367579ca container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:44:26.745
  Jun 15 12:44:26.771: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-145" for this suite. @ 06/15/24 12:44:26.781
• [4.131 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2214
  STEP: Creating a kubernetes client @ 06/15/24 12:44:26.795
  Jun 15 12:44:26.796: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:44:26.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:44:26.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:44:26.821
  STEP: creating service in namespace services-5221 @ 06/15/24 12:44:26.824
  STEP: creating service affinity-nodeport in namespace services-5221 @ 06/15/24 12:44:26.824
  STEP: creating replication controller affinity-nodeport in namespace services-5221 @ 06/15/24 12:44:26.842
  I0615 12:44:26.852161      19 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-5221, replica count: 3
  E0615 12:44:27.012458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:28.012579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:29.012684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 12:44:29.903791      19 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 12:44:29.916: INFO: Creating new exec pod
  E0615 12:44:30.013655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:31.013804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:32.014098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:32.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-5221 exec execpod-affinityzc62c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  E0615 12:44:33.014178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:33.027: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport 80\n+ echo hostName\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Jun 15 12:44:33.027: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:44:33.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-5221 exec execpod-affinityzc62c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.106 80'
  Jun 15 12:44:33.121: INFO: stderr: "+ nc -v -t -w 2 10.152.183.106 80\n+ echo hostName\nConnection to 10.152.183.106 80 port [tcp/http] succeeded!\n"
  Jun 15 12:44:33.121: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:44:33.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-5221 exec execpod-affinityzc62c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.132 32184'
  Jun 15 12:44:33.219: INFO: stderr: "+ nc -v -t -w 2 172.31.43.132 32184\n+ echo hostName\nConnection to 172.31.43.132 32184 port [tcp/*] succeeded!\n"
  Jun 15 12:44:33.219: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:44:33.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-5221 exec execpod-affinityzc62c -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.7 32184'
  Jun 15 12:44:33.305: INFO: stderr: "+ nc -v -t -w 2 172.31.7.7 32184\n+ echo hostName\nConnection to 172.31.7.7 32184 port [tcp/*] succeeded!\n"
  Jun 15 12:44:33.305: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:44:33.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-5221 exec execpod-affinityzc62c -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.17.110:32184/ ; done'
  Jun 15 12:44:33.472: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:32184/\n"
  Jun 15 12:44:33.473: INFO: stdout: "\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2\naffinity-nodeport-q2bp2"
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Received response from host: affinity-nodeport-q2bp2
  Jun 15 12:44:33.473: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-5221, will wait for the garbage collector to delete the pods @ 06/15/24 12:44:33.487
  Jun 15 12:44:33.549: INFO: Deleting ReplicationController affinity-nodeport took: 8.768488ms
  Jun 15 12:44:33.650: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.239429ms
  E0615 12:44:34.014800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:35.015626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:36.016367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:36.876: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5221" for this suite. @ 06/15/24 12:44:36.88
• [10.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:142
  STEP: Creating a kubernetes client @ 06/15/24 12:44:36.889
  Jun 15 12:44:36.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-webhook @ 06/15/24 12:44:36.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:44:36.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:44:36.905
  STEP: Setting up server cert @ 06/15/24 12:44:36.908
  E0615 12:44:37.016791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 06/15/24 12:44:37.194
  STEP: Deploying the custom resource conversion webhook pod @ 06/15/24 12:44:37.202
  STEP: Wait for the deployment to be ready @ 06/15/24 12:44:37.213
  Jun 15 12:44:37.223: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0615 12:44:38.017491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:39.017917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 12:44:39.236
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:44:39.244
  E0615 12:44:40.018303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:40.244: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Jun 15 12:44:40.251: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 12:44:41.018536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:42.019583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 06/15/24 12:44:42.803
  STEP: v2 custom resource should be converted @ 06/15/24 12:44:42.81
  E0615 12:44:43.020210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:44:43.367: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-488" for this suite. @ 06/15/24 12:44:43.371
• [6.490 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 06/15/24 12:44:43.379
  Jun 15 12:44:43.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename endpointslice @ 06/15/24 12:44:43.38
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:44:43.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:44:43.4
  E0615 12:44:44.021175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:45.021334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:46.021761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:47.022126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:48.022886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 06/15/24 12:44:48.47
  E0615 12:44:49.023665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:50.024348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:51.024434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:52.024563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:53.024652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 06/15/24 12:44:53.478
  E0615 12:44:54.024771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:55.024854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:56.024935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:57.025751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:44:58.025985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 06/15/24 12:44:58.487
  E0615 12:44:59.026079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:00.026201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:01.026276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:02.026740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:03.026842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 06/15/24 12:45:03.497
  Jun 15 12:45:03.517: INFO: EndpointSlice for Service endpointslice-8827/example-named-port not found
  E0615 12:45:04.027434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:05.027530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:06.028457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:07.028580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:08.028782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:09.029475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:10.029562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:11.029758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:12.030793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:13.030889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:45:13.524: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8827" for this suite. @ 06/15/24 12:45:13.529
• [30.157 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 06/15/24 12:45:13.537
  Jun 15 12:45:13.537: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 12:45:13.537
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:45:13.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:45:13.555
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 06/15/24 12:45:13.558
  E0615 12:45:14.031293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:15.031403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:16.032379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:17.032646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:45:17.585
  Jun 15 12:45:17.589: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-c7224bef-3cd7-4a73-b7d8-14719e182298 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:45:17.594
  Jun 15 12:45:17.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-800" for this suite. @ 06/15/24 12:45:17.613
• [4.086 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 06/15/24 12:45:17.623
  Jun 15 12:45:17.623: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:45:17.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:45:17.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:45:17.639
  STEP: Creating configMap with name cm-test-opt-del-79ec76e8-3642-4a63-a1a8-3356e894c63b @ 06/15/24 12:45:17.647
  STEP: Creating configMap with name cm-test-opt-upd-b3de9635-1f6b-41ca-9313-888ea8c2d0e3 @ 06/15/24 12:45:17.653
  STEP: Creating the pod @ 06/15/24 12:45:17.656
  E0615 12:45:18.033603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:19.033735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-79ec76e8-3642-4a63-a1a8-3356e894c63b @ 06/15/24 12:45:19.696
  STEP: Updating configmap cm-test-opt-upd-b3de9635-1f6b-41ca-9313-888ea8c2d0e3 @ 06/15/24 12:45:19.702
  STEP: Creating configMap with name cm-test-opt-create-5b3d51d3-980f-43b2-91a4-53869dd3c8d6 @ 06/15/24 12:45:19.706
  STEP: waiting to observe update in volume @ 06/15/24 12:45:19.71
  E0615 12:45:20.033771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:21.034012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:22.034594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:23.034690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:24.035277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:25.035381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:26.036434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:27.036843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:28.036947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:29.037044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:30.037520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:31.037634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:32.037756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:33.037848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:34.037932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:35.038034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:36.038121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:37.043567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:38.044178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:39.044346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:40.044888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:41.044990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:42.045079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:43.045269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:44.046212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:45.046224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:46.046314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:47.046853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:48.047634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:49.047719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:50.048093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:51.048187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:52.048595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:53.048688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:54.049208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:55.049963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:56.050567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:57.050728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:58.051675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:45:59.052584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:00.052696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:01.052773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:02.053511      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:03.053541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:04.053898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:05.054088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:06.054908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:07.055814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:08.056359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:09.056561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:10.056932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:11.057259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:12.057990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:13.058082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:14.058501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:15.058599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:16.059529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:17.059922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:18.060536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:19.060611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:20.061012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:21.061092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:22.061591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:23.061651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:24.062374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:25.062602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:26.062677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:27.062771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:28.063552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:29.063663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:30.064487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:31.064813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:32.065429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:33.065528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:46:34.044: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1180" for this suite. @ 06/15/24 12:46:34.048
• [76.432 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 06/15/24 12:46:34.056
  Jun 15 12:46:34.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename endpointslice @ 06/15/24 12:46:34.057
  E0615 12:46:34.065500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:46:34.07
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:46:34.074
  STEP: getting /apis @ 06/15/24 12:46:34.077
  STEP: getting /apis/discovery.k8s.io @ 06/15/24 12:46:34.08
  STEP: getting /apis/discovery.k8s.iov1 @ 06/15/24 12:46:34.081
  STEP: creating @ 06/15/24 12:46:34.082
  STEP: getting @ 06/15/24 12:46:34.097
  STEP: listing @ 06/15/24 12:46:34.1
  STEP: watching @ 06/15/24 12:46:34.103
  Jun 15 12:46:34.103: INFO: starting watch
  STEP: cluster-wide listing @ 06/15/24 12:46:34.105
  STEP: cluster-wide watching @ 06/15/24 12:46:34.108
  Jun 15 12:46:34.108: INFO: starting watch
  STEP: patching @ 06/15/24 12:46:34.109
  STEP: updating @ 06/15/24 12:46:34.116
  Jun 15 12:46:34.123: INFO: waiting for watch events with expected annotations
  Jun 15 12:46:34.123: INFO: saw patched and updated annotations
  STEP: deleting @ 06/15/24 12:46:34.123
  STEP: deleting a collection @ 06/15/24 12:46:34.136
  Jun 15 12:46:34.151: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3506" for this suite. @ 06/15/24 12:46:34.154
• [0.104 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 06/15/24 12:46:34.16
  Jun 15 12:46:34.160: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename namespaces @ 06/15/24 12:46:34.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:46:34.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:46:34.178
  STEP: Read namespace status @ 06/15/24 12:46:34.183
  Jun 15 12:46:34.186: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 06/15/24 12:46:34.186
  Jun 15 12:46:34.192: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 06/15/24 12:46:34.192
  Jun 15 12:46:34.202: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Jun 15 12:46:34.202: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7522" for this suite. @ 06/15/24 12:46:34.207
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 06/15/24 12:46:34.213
  Jun 15 12:46:34.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 12:46:34.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:46:34.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:46:34.23
  STEP: Creating secret with name secret-test-b5169c01-9fe1-4f5f-b373-a999176e3ffc @ 06/15/24 12:46:34.233
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:46:34.237
  E0615 12:46:35.066556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:36.067625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:37.067726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:38.067832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:46:38.262
  Jun 15 12:46:38.266: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-secrets-f652f287-ddab-405c-8d38-6acd8da54216 container secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:46:38.283
  Jun 15 12:46:38.301: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6631" for this suite. @ 06/15/24 12:46:38.305
• [4.099 seconds]
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 06/15/24 12:46:38.313
  Jun 15 12:46:38.313: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:46:38.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:46:38.325
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:46:38.328
  STEP: creating service nodeport-test with type=NodePort in namespace services-7166 @ 06/15/24 12:46:38.333
  STEP: creating replication controller nodeport-test in namespace services-7166 @ 06/15/24 12:46:38.346
  I0615 12:46:38.352192      19 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-7166, replica count: 2
  E0615 12:46:39.068516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:40.069396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:41.070098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 12:46:41.403584      19 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 12:46:41.403: INFO: Creating new exec pod
  E0615 12:46:42.070163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:43.070252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:44.070342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:46:44.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7166 exec execpodwgbkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Jun 15 12:46:44.519: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Jun 15 12:46:44.519: INFO: stdout: "nodeport-test-hkzss"
  Jun 15 12:46:44.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7166 exec execpodwgbkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 80'
  Jun 15 12:46:44.618: INFO: stderr: "+ nc -v -t -w 2 10.152.183.135 80\n+ echo hostName\nConnection to 10.152.183.135 80 port [tcp/http] succeeded!\n"
  Jun 15 12:46:44.618: INFO: stdout: ""
  E0615 12:46:45.070713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:46:45.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7166 exec execpodwgbkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 80'
  Jun 15 12:46:45.608: INFO: stderr: "+ nc -v -t -w 2 10.152.183.135 80\nConnection to 10.152.183.135 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Jun 15 12:46:45.608: INFO: stdout: ""
  E0615 12:46:46.071781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:46:46.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7166 exec execpodwgbkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 80'
  Jun 15 12:46:46.604: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.135 80\nConnection to 10.152.183.135 80 port [tcp/http] succeeded!\n"
  Jun 15 12:46:46.604: INFO: stdout: ""
  E0615 12:46:47.072344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:46:47.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7166 exec execpodwgbkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 80'
  Jun 15 12:46:47.609: INFO: stderr: "+ nc -v -t -w 2 10.152.183.135 80\n+ echo hostName\nConnection to 10.152.183.135 80 port [tcp/http] succeeded!\n"
  Jun 15 12:46:47.609: INFO: stdout: "nodeport-test-hkzss"
  Jun 15 12:46:47.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7166 exec execpodwgbkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.17.110 32411'
  Jun 15 12:46:47.702: INFO: stderr: "+ nc -v -t -w 2 172.31.17.110 32411\n+ echo hostName\nConnection to 172.31.17.110 32411 port [tcp/*] succeeded!\n"
  Jun 15 12:46:47.702: INFO: stdout: ""
  E0615 12:46:48.073085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:46:48.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7166 exec execpodwgbkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.17.110 32411'
  Jun 15 12:46:48.699: INFO: stderr: "+ nc -v -t -w 2 172.31.17.110 32411\n+ echo hostName\nConnection to 172.31.17.110 32411 port [tcp/*] succeeded!\n"
  Jun 15 12:46:48.699: INFO: stdout: "nodeport-test-pclm4"
  Jun 15 12:46:48.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7166 exec execpodwgbkc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.132 32411'
  Jun 15 12:46:48.807: INFO: stderr: "+ nc -v -t -w 2 172.31.43.132 32411\n+ echo hostName\nConnection to 172.31.43.132 32411 port [tcp/*] succeeded!\n"
  Jun 15 12:46:48.807: INFO: stdout: "nodeport-test-pclm4"
  Jun 15 12:46:48.807: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7166" for this suite. @ 06/15/24 12:46:48.812
• [10.507 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 06/15/24 12:46:48.819
  Jun 15 12:46:48.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename subpath @ 06/15/24 12:46:48.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:46:48.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:46:48.84
  STEP: Setting up data @ 06/15/24 12:46:48.843
  STEP: Creating pod pod-subpath-test-projected-zwvn @ 06/15/24 12:46:48.854
  STEP: Creating a pod to test atomic-volume-subpath @ 06/15/24 12:46:48.854
  E0615 12:46:49.073969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:50.074121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:51.074832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:52.074871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:53.075737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:54.075919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:55.076657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:56.076745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:57.077681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:58.077771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:46:59.078147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:00.079048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:01.079084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:02.079558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:03.080627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:04.080716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:05.081666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:06.081760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:07.081911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:08.081997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:09.082459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:10.082546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:11.083246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:12.083647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:47:12.927
  Jun 15 12:47:12.930: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-subpath-test-projected-zwvn container test-container-subpath-projected-zwvn: <nil>
  STEP: delete the pod @ 06/15/24 12:47:12.938
  STEP: Deleting pod pod-subpath-test-projected-zwvn @ 06/15/24 12:47:12.956
  Jun 15 12:47:12.956: INFO: Deleting pod "pod-subpath-test-projected-zwvn" in namespace "subpath-3322"
  Jun 15 12:47:12.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3322" for this suite. @ 06/15/24 12:47:12.967
• [24.155 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 06/15/24 12:47:12.975
  Jun 15 12:47:12.975: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:47:12.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:47:12.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:47:12.994
  STEP: Setting up server cert @ 06/15/24 12:47:13.015
  E0615 12:47:13.084568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:47:13.337
  STEP: Deploying the webhook pod @ 06/15/24 12:47:13.347
  STEP: Wait for the deployment to be ready @ 06/15/24 12:47:13.361
  Jun 15 12:47:13.376: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 12:47:14.084905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:15.085848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 12:47:15.387
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:47:15.399
  E0615 12:47:16.086908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:16.399: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 06/15/24 12:47:16.406
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 06/15/24 12:47:16.419
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 06/15/24 12:47:16.424
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 06/15/24 12:47:16.436
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 06/15/24 12:47:16.446
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 06/15/24 12:47:16.453
  Jun 15 12:47:16.503: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-354" for this suite. @ 06/15/24 12:47:16.509
  STEP: Destroying namespace "webhook-markers-3208" for this suite. @ 06/15/24 12:47:16.516
• [3.548 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 06/15/24 12:47:16.523
  Jun 15 12:47:16.523: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replicaset @ 06/15/24 12:47:16.524
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:47:16.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:47:16.538
  STEP: Create a ReplicaSet @ 06/15/24 12:47:16.542
  STEP: Verify that the required pods have come up @ 06/15/24 12:47:16.547
  Jun 15 12:47:16.550: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0615 12:47:17.087562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:18.087666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:19.087758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:20.087829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:21.087928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:21.553: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 06/15/24 12:47:21.553
  Jun 15 12:47:21.557: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 06/15/24 12:47:21.557
  STEP: DeleteCollection of the ReplicaSets @ 06/15/24 12:47:21.561
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 06/15/24 12:47:21.568
  Jun 15 12:47:21.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4785" for this suite. @ 06/15/24 12:47:21.583
• [5.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 06/15/24 12:47:21.611
  Jun 15 12:47:21.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 12:47:21.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:47:21.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:47:21.63
  STEP: Creating pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776 @ 06/15/24 12:47:21.634
  E0615 12:47:22.088010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:23.088121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 06/15/24 12:47:23.656
  Jun 15 12:47:23.659: INFO: Initial restart count of pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 is 0
  Jun 15 12:47:23.664: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:24.088288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:25.088381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:25.669: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:26.088906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:27.089496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:27.675: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:28.090267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:29.090363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:29.680: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:30.090846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:31.091057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:31.684: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:32.091292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:33.091439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:33.690: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:34.092440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:35.092626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:35.695: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:36.092736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:37.093206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:37.699: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:38.093959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:39.094199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:39.704: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:40.094427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:41.094578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:41.709: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  E0615 12:47:42.094690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:43.094787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:47:43.713: INFO: Get pod liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 in namespace container-probe-8776
  Jun 15 12:47:43.713: INFO: Restart count of pod container-probe-8776/liveness-9c69e8df-af27-48d4-a913-3ec5d4382b65 is now 1 (20.054124546s elapsed)
  STEP: deleting the pod @ 06/15/24 12:47:43.713
  Jun 15 12:47:43.726: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8776" for this suite. @ 06/15/24 12:47:43.73
• [22.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 06/15/24 12:47:43.736
  Jun 15 12:47:43.736: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename chunking @ 06/15/24 12:47:43.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:47:43.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:47:43.759
  STEP: creating a large number of resources @ 06/15/24 12:47:43.763
  E0615 12:47:44.095507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:45.096243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:46.096856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:47.097909      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:48.098282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:49.099254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:50.099420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:51.099781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:52.100595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 12:47:52.597492      19 request.go:697] Waited for 1.002174051s due to client-side throttling, not priority and fairness, request: POST:https://10.152.183.1:443/api/v1/namespaces/chunking-4714/podtemplates
  E0615 12:47:53.100781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:54.101343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:55.102218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:56.103266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:57.104236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:58.104246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:47:59.105127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:00.105462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:01.105946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 06/15/24 12:48:01.443
  Jun 15 12:48:01.492: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Jun 15 12:48:01.542: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Jun 15 12:48:01.592: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Jun 15 12:48:01.642: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Jun 15 12:48:01.691: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Jun 15 12:48:01.741: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Jun 15 12:48:01.795: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Jun 15 12:48:01.841: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Jun 15 12:48:01.891: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Jun 15 12:48:01.942: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Jun 15 12:48:01.991: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Jun 15 12:48:02.041: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Jun 15 12:48:02.092: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  E0615 12:48:02.106020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:02.141: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Jun 15 12:48:02.191: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Jun 15 12:48:02.242: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Jun 15 12:48:02.292: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Jun 15 12:48:02.341: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Jun 15 12:48:02.393: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Jun 15 12:48:02.441: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Jun 15 12:48:02.491: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Jun 15 12:48:02.542: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Jun 15 12:48:02.597: INFO: Retrieved 17/17 results with rv 20067 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjcsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Jun 15 12:48:02.642: INFO: Retrieved 9/17 results with rv 20067 and continue 
  Jun 15 12:48:02.692: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Jun 15 12:48:02.742: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Jun 15 12:48:02.791: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Jun 15 12:48:02.843: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Jun 15 12:48:02.891: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  Jun 15 12:48:02.940: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Jun 15 12:48:02.992: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Jun 15 12:48:03.041: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Jun 15 12:48:03.091: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  E0615 12:48:03.106820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:03.143: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Jun 15 12:48:03.191: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Jun 15 12:48:03.241: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Jun 15 12:48:03.292: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Jun 15 12:48:03.341: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Jun 15 12:48:03.392: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Jun 15 12:48:03.442: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Jun 15 12:48:03.491: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Jun 15 12:48:03.541: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Jun 15 12:48:03.592: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Jun 15 12:48:03.641: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Jun 15 12:48:03.691: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Jun 15 12:48:03.742: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Jun 15 12:48:03.791: INFO: Retrieved 17/17 results with rv 20069 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNjksInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Jun 15 12:48:03.841: INFO: Retrieved 9/17 results with rv 20069 and continue 
  Jun 15 12:48:03.892: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDAxNlx1MDAwMCJ9
  Jun 15 12:48:03.941: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDAzM1x1MDAwMCJ9
  Jun 15 12:48:03.991: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDA1MFx1MDAwMCJ9
  Jun 15 12:48:04.042: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDA2N1x1MDAwMCJ9
  Jun 15 12:48:04.091: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDA4NFx1MDAwMCJ9
  E0615 12:48:04.107435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:04.141: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDEwMVx1MDAwMCJ9
  Jun 15 12:48:04.192: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDExOFx1MDAwMCJ9
  Jun 15 12:48:04.241: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDEzNVx1MDAwMCJ9
  Jun 15 12:48:04.291: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDE1Mlx1MDAwMCJ9
  Jun 15 12:48:04.343: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDE2OVx1MDAwMCJ9
  Jun 15 12:48:04.392: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDE4Nlx1MDAwMCJ9
  Jun 15 12:48:04.441: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDIwM1x1MDAwMCJ9
  Jun 15 12:48:04.492: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDIyMFx1MDAwMCJ9
  Jun 15 12:48:04.541: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDIzN1x1MDAwMCJ9
  Jun 15 12:48:04.590: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDI1NFx1MDAwMCJ9
  Jun 15 12:48:04.641: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDI3MVx1MDAwMCJ9
  Jun 15 12:48:04.690: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDI4OFx1MDAwMCJ9
  Jun 15 12:48:04.741: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDMwNVx1MDAwMCJ9
  Jun 15 12:48:04.792: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDMyMlx1MDAwMCJ9
  Jun 15 12:48:04.841: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDMzOVx1MDAwMCJ9
  Jun 15 12:48:04.890: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDM1Nlx1MDAwMCJ9
  Jun 15 12:48:04.941: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDM3M1x1MDAwMCJ9
  Jun 15 12:48:04.991: INFO: Retrieved 17/17 results with rv 20073 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MjAwNzMsInN0YXJ0IjoidGVtcGxhdGUtMDM5MFx1MDAwMCJ9
  Jun 15 12:48:05.040: INFO: Retrieved 9/17 results with rv 20073 and continue 
  STEP: retrieving those results all at once @ 06/15/24 12:48:05.04
  E0615 12:48:05.108430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:05.112: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-4714" for this suite. @ 06/15/24 12:48:05.144
• [21.461 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 06/15/24 12:48:05.197
  Jun 15 12:48:05.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:48:05.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:05.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:05.215
  STEP: Setting up server cert @ 06/15/24 12:48:05.236
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:48:05.397
  STEP: Deploying the webhook pod @ 06/15/24 12:48:05.405
  STEP: Wait for the deployment to be ready @ 06/15/24 12:48:05.418
  Jun 15 12:48:05.425: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 12:48:06.109484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:07.109577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 12:48:07.438
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:48:07.448
  E0615 12:48:08.110539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:08.449: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Jun 15 12:48:08.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 06/15/24 12:48:08.968
  STEP: Creating a custom resource that should be denied by the webhook @ 06/15/24 12:48:08.981
  E0615 12:48:09.110601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:10.110729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 06/15/24 12:48:10.998
  STEP: Updating the custom resource with disallowed data should be denied @ 06/15/24 12:48:11.004
  STEP: Deleting the custom resource should be denied @ 06/15/24 12:48:11.013
  STEP: Remove the offending key and value from the custom resource data @ 06/15/24 12:48:11.019
  STEP: Deleting the updated custom resource should be successful @ 06/15/24 12:48:11.028
  E0615 12:48:11.111214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:11.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7203" for this suite. @ 06/15/24 12:48:11.613
  STEP: Destroying namespace "webhook-markers-1330" for this suite. @ 06/15/24 12:48:11.622
• [6.433 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 06/15/24 12:48:11.63
  Jun 15 12:48:11.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:48:11.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:11.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:11.648
  STEP: Setting up server cert @ 06/15/24 12:48:11.671
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:48:11.823
  STEP: Deploying the webhook pod @ 06/15/24 12:48:11.83
  STEP: Wait for the deployment to be ready @ 06/15/24 12:48:11.84
  Jun 15 12:48:11.855: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 12:48:12.111803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:13.111894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 12:48:13.869
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:48:13.88
  E0615 12:48:14.112417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:14.881: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 06/15/24 12:48:14.889
  STEP: create a pod that should be denied by the webhook @ 06/15/24 12:48:14.901
  STEP: create a pod that causes the webhook to hang @ 06/15/24 12:48:14.907
  E0615 12:48:15.113130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:16.113581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:17.113964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:18.114167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:19.114470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:20.114782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:21.115043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:22.115183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:23.115272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:24.116343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 06/15/24 12:48:24.916
  STEP: create a configmap that should be admitted by the webhook @ 06/15/24 12:48:25.024
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 06/15/24 12:48:25.031
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 06/15/24 12:48:25.039
  STEP: create a namespace that bypass the webhook @ 06/15/24 12:48:25.045
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 06/15/24 12:48:25.058
  Jun 15 12:48:25.114: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0615 12:48:25.117060      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-6056" for this suite. @ 06/15/24 12:48:25.12
  STEP: Destroying namespace "webhook-markers-3924" for this suite. @ 06/15/24 12:48:25.128
  STEP: Destroying namespace "exempted-namespace-6063" for this suite. @ 06/15/24 12:48:25.133
• [13.510 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 06/15/24 12:48:25.14
  Jun 15 12:48:25.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename containers @ 06/15/24 12:48:25.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:25.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:25.158
  STEP: Creating a pod to test override command @ 06/15/24 12:48:25.161
  E0615 12:48:26.117624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:27.118201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:48:27.178
  Jun 15 12:48:27.183: INFO: Trying to get logs from node ip-172-31-7-7 pod client-containers-0521553a-de02-4a58-942d-f5901333eab4 container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:48:27.193
  Jun 15 12:48:27.210: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9451" for this suite. @ 06/15/24 12:48:27.213
• [2.081 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 06/15/24 12:48:27.221
  Jun 15 12:48:27.221: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:48:27.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:27.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:27.239
  STEP: Creating a pod to test downward api env vars @ 06/15/24 12:48:27.245
  E0615 12:48:28.118289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:29.118379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:48:29.268
  Jun 15 12:48:29.271: INFO: Trying to get logs from node ip-172-31-7-7 pod downward-api-8d14552f-920e-4446-91a6-c6a151a3f6c5 container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 12:48:29.279
  Jun 15 12:48:29.294: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5110" for this suite. @ 06/15/24 12:48:29.298
• [2.084 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 06/15/24 12:48:29.305
  Jun 15 12:48:29.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl-logs @ 06/15/24 12:48:29.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:29.318
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:29.321
  STEP: creating an pod @ 06/15/24 12:48:29.324
  Jun 15 12:48:29.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-logs-4769 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Jun 15 12:48:29.375: INFO: stderr: ""
  Jun 15 12:48:29.375: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 06/15/24 12:48:29.376
  Jun 15 12:48:29.376: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0615 12:48:30.118502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:31.118627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:31.384: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 06/15/24 12:48:31.384
  Jun 15 12:48:31.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-logs-4769 logs logs-generator logs-generator'
  Jun 15 12:48:31.434: INFO: stderr: ""
  Jun 15 12:48:31.434: INFO: stdout: "I0615 12:48:29.921317       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/7tfj 463\nI0615 12:48:30.121605       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/9qjs 276\nI0615 12:48:30.321911       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/lh4 312\nI0615 12:48:30.522281       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/6xh 561\nI0615 12:48:30.721517       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/6vmb 503\nI0615 12:48:30.921755       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/lk4t 485\nI0615 12:48:31.122053       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/w2x 464\nI0615 12:48:31.321320       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/pwzw 471\n"
  STEP: limiting log lines @ 06/15/24 12:48:31.434
  Jun 15 12:48:31.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-logs-4769 logs logs-generator logs-generator --tail=1'
  Jun 15 12:48:31.486: INFO: stderr: ""
  Jun 15 12:48:31.487: INFO: stdout: "I0615 12:48:31.321320       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/pwzw 471\n"
  Jun 15 12:48:31.487: INFO: got output "I0615 12:48:31.321320       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/pwzw 471\n"
  STEP: limiting log bytes @ 06/15/24 12:48:31.487
  Jun 15 12:48:31.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-logs-4769 logs logs-generator logs-generator --limit-bytes=1'
  Jun 15 12:48:31.540: INFO: stderr: ""
  Jun 15 12:48:31.540: INFO: stdout: "I"
  Jun 15 12:48:31.540: INFO: got output "I"
  STEP: exposing timestamps @ 06/15/24 12:48:31.54
  Jun 15 12:48:31.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-logs-4769 logs logs-generator logs-generator --tail=1 --timestamps'
  Jun 15 12:48:31.589: INFO: stderr: ""
  Jun 15 12:48:31.589: INFO: stdout: "2024-06-15T12:48:31.521714968Z I0615 12:48:31.521620       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/r7s 578\n"
  Jun 15 12:48:31.589: INFO: got output "2024-06-15T12:48:31.521714968Z I0615 12:48:31.521620       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/r7s 578\n"
  STEP: restricting to a time range @ 06/15/24 12:48:31.589
  E0615 12:48:32.119380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:33.119481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:34.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-logs-4769 logs logs-generator logs-generator --since=1s'
  E0615 12:48:34.120378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:34.140: INFO: stderr: ""
  Jun 15 12:48:34.140: INFO: stdout: "I0615 12:48:33.322135       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/kbhm 510\nI0615 12:48:33.521509       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/pxcp 292\nI0615 12:48:33.721805       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/jw8 220\nI0615 12:48:33.922095       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/2cbp 358\nI0615 12:48:34.121331       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/l4q 258\n"
  Jun 15 12:48:34.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-logs-4769 logs logs-generator logs-generator --since=24h'
  Jun 15 12:48:34.191: INFO: stderr: ""
  Jun 15 12:48:34.191: INFO: stdout: "I0615 12:48:29.921317       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/7tfj 463\nI0615 12:48:30.121605       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/9qjs 276\nI0615 12:48:30.321911       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/lh4 312\nI0615 12:48:30.522281       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/6xh 561\nI0615 12:48:30.721517       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/6vmb 503\nI0615 12:48:30.921755       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/lk4t 485\nI0615 12:48:31.122053       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/w2x 464\nI0615 12:48:31.321320       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/pwzw 471\nI0615 12:48:31.521620       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/r7s 578\nI0615 12:48:31.721914       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/d9k 593\nI0615 12:48:31.922256       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/n5xc 556\nI0615 12:48:32.121448       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/whzj 287\nI0615 12:48:32.321757       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/mfj 493\nI0615 12:48:32.522062       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/jbct 437\nI0615 12:48:32.722345       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/77gb 319\nI0615 12:48:32.921534       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/tnxb 208\nI0615 12:48:33.121822       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/768k 246\nI0615 12:48:33.322135       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/kbhm 510\nI0615 12:48:33.521509       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/pxcp 292\nI0615 12:48:33.721805       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/jw8 220\nI0615 12:48:33.922095       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/2cbp 358\nI0615 12:48:34.121331       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/l4q 258\n"
  Jun 15 12:48:34.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-logs-4769 delete pod logs-generator'
  Jun 15 12:48:35.019: INFO: stderr: ""
  Jun 15 12:48:35.019: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Jun 15 12:48:35.019: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-4769" for this suite. @ 06/15/24 12:48:35.024
• [5.725 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 06/15/24 12:48:35.031
  Jun 15 12:48:35.031: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:48:35.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:35.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:35.05
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:48:35.053
  E0615 12:48:35.121022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:36.121240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:37.121296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:38.121387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:48:39.077
  Jun 15 12:48:39.080: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-e201fdb6-3462-4e76-bc65-9bf4c961e905 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:48:39.086
  Jun 15 12:48:39.102: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5195" for this suite. @ 06/15/24 12:48:39.107
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 06/15/24 12:48:39.115
  Jun 15 12:48:39.115: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:48:39.115
  E0615 12:48:39.122082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:39.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:39.132
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:48:39.135
  E0615 12:48:40.122363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:41.122431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:42.122536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:43.122601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:48:43.161
  Jun 15 12:48:43.165: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-31cebc2d-4282-4db2-a7f5-96d3dd8113d8 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:48:43.172
  Jun 15 12:48:43.190: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7357" for this suite. @ 06/15/24 12:48:43.195
• [4.086 seconds]
------------------------------
SSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 06/15/24 12:48:43.201
  Jun 15 12:48:43.201: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename events @ 06/15/24 12:48:43.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:43.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:43.219
  STEP: Create set of events @ 06/15/24 12:48:43.222
  STEP: get a list of Events with a label in the current namespace @ 06/15/24 12:48:43.235
  STEP: delete a list of events @ 06/15/24 12:48:43.238
  Jun 15 12:48:43.238: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 06/15/24 12:48:43.262
  Jun 15 12:48:43.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4566" for this suite. @ 06/15/24 12:48:43.269
• [0.074 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 06/15/24 12:48:43.278
  Jun 15 12:48:43.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 12:48:43.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:43.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:43.297
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 06/15/24 12:48:43.3
  E0615 12:48:44.122869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:45.123160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:46.123800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:47.123842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:48:47.325
  Jun 15 12:48:47.328: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-0296936f-c3ca-4061-af05-d262165b5d5f container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:48:47.337
  Jun 15 12:48:47.356: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7884" for this suite. @ 06/15/24 12:48:47.36
• [4.090 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 06/15/24 12:48:47.368
  Jun 15 12:48:47.368: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename gc @ 06/15/24 12:48:47.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:48:47.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:48:47.386
  STEP: create the rc1 @ 06/15/24 12:48:47.392
  STEP: create the rc2 @ 06/15/24 12:48:47.396
  E0615 12:48:48.124402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:49.124491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:50.125656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:51.126599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:52.126691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:53.129384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 06/15/24 12:48:53.407
  STEP: delete the rc simpletest-rc-to-be-deleted @ 06/15/24 12:48:53.98
  STEP: wait for the rc to be deleted @ 06/15/24 12:48:53.987
  E0615 12:48:54.129678      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:55.129840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:56.131548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:57.132105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:48:58.132315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:48:58.998: INFO: 69 pods remaining
  Jun 15 12:48:58.998: INFO: 69 pods has nil DeletionTimestamp
  Jun 15 12:48:58.998: INFO: 
  E0615 12:48:59.133135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:00.133352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:01.133457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:02.134184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:03.134380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 06/15/24 12:49:03.999
  W0615 12:49:04.005077      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Jun 15 12:49:04.005: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Jun 15 12:49:04.005: INFO: Deleting pod "simpletest-rc-to-be-deleted-2jzjt" in namespace "gc-6023"
  Jun 15 12:49:04.018: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lt7t" in namespace "gc-6023"
  Jun 15 12:49:04.036: INFO: Deleting pod "simpletest-rc-to-be-deleted-2vwkj" in namespace "gc-6023"
  Jun 15 12:49:04.054: INFO: Deleting pod "simpletest-rc-to-be-deleted-4h4vj" in namespace "gc-6023"
  Jun 15 12:49:04.068: INFO: Deleting pod "simpletest-rc-to-be-deleted-4hrqm" in namespace "gc-6023"
  Jun 15 12:49:04.077: INFO: Deleting pod "simpletest-rc-to-be-deleted-4ls68" in namespace "gc-6023"
  Jun 15 12:49:04.089: INFO: Deleting pod "simpletest-rc-to-be-deleted-4qff9" in namespace "gc-6023"
  Jun 15 12:49:04.102: INFO: Deleting pod "simpletest-rc-to-be-deleted-4qrsn" in namespace "gc-6023"
  Jun 15 12:49:04.118: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rgbf" in namespace "gc-6023"
  Jun 15 12:49:04.132: INFO: Deleting pod "simpletest-rc-to-be-deleted-55jmc" in namespace "gc-6023"
  E0615 12:49:04.134438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:49:04.145: INFO: Deleting pod "simpletest-rc-to-be-deleted-62ln4" in namespace "gc-6023"
  Jun 15 12:49:04.162: INFO: Deleting pod "simpletest-rc-to-be-deleted-62sjq" in namespace "gc-6023"
  Jun 15 12:49:04.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-64fz9" in namespace "gc-6023"
  Jun 15 12:49:04.193: INFO: Deleting pod "simpletest-rc-to-be-deleted-67lkm" in namespace "gc-6023"
  Jun 15 12:49:04.205: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bhpz" in namespace "gc-6023"
  Jun 15 12:49:04.217: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bqdd" in namespace "gc-6023"
  Jun 15 12:49:04.234: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rzfg" in namespace "gc-6023"
  Jun 15 12:49:04.245: INFO: Deleting pod "simpletest-rc-to-be-deleted-6t54z" in namespace "gc-6023"
  Jun 15 12:49:04.260: INFO: Deleting pod "simpletest-rc-to-be-deleted-774kf" in namespace "gc-6023"
  Jun 15 12:49:04.272: INFO: Deleting pod "simpletest-rc-to-be-deleted-7kgks" in namespace "gc-6023"
  Jun 15 12:49:04.284: INFO: Deleting pod "simpletest-rc-to-be-deleted-7p7n7" in namespace "gc-6023"
  Jun 15 12:49:04.296: INFO: Deleting pod "simpletest-rc-to-be-deleted-7s8hd" in namespace "gc-6023"
  Jun 15 12:49:04.309: INFO: Deleting pod "simpletest-rc-to-be-deleted-7z5b4" in namespace "gc-6023"
  Jun 15 12:49:04.326: INFO: Deleting pod "simpletest-rc-to-be-deleted-8bsmx" in namespace "gc-6023"
  Jun 15 12:49:04.342: INFO: Deleting pod "simpletest-rc-to-be-deleted-8f5n9" in namespace "gc-6023"
  Jun 15 12:49:04.361: INFO: Deleting pod "simpletest-rc-to-be-deleted-8htf9" in namespace "gc-6023"
  Jun 15 12:49:04.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-8n5wp" in namespace "gc-6023"
  Jun 15 12:49:04.399: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ql28" in namespace "gc-6023"
  Jun 15 12:49:04.413: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rk6s" in namespace "gc-6023"
  Jun 15 12:49:04.426: INFO: Deleting pod "simpletest-rc-to-be-deleted-9z5jd" in namespace "gc-6023"
  Jun 15 12:49:04.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5jtr" in namespace "gc-6023"
  Jun 15 12:49:04.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-f947c" in namespace "gc-6023"
  Jun 15 12:49:04.477: INFO: Deleting pod "simpletest-rc-to-be-deleted-fh5xx" in namespace "gc-6023"
  Jun 15 12:49:04.493: INFO: Deleting pod "simpletest-rc-to-be-deleted-flrrc" in namespace "gc-6023"
  Jun 15 12:49:04.507: INFO: Deleting pod "simpletest-rc-to-be-deleted-fm987" in namespace "gc-6023"
  Jun 15 12:49:04.519: INFO: Deleting pod "simpletest-rc-to-be-deleted-fz5l7" in namespace "gc-6023"
  Jun 15 12:49:04.541: INFO: Deleting pod "simpletest-rc-to-be-deleted-g5gkd" in namespace "gc-6023"
  Jun 15 12:49:04.554: INFO: Deleting pod "simpletest-rc-to-be-deleted-g9b5b" in namespace "gc-6023"
  Jun 15 12:49:04.578: INFO: Deleting pod "simpletest-rc-to-be-deleted-gf72x" in namespace "gc-6023"
  Jun 15 12:49:04.601: INFO: Deleting pod "simpletest-rc-to-be-deleted-gh4dp" in namespace "gc-6023"
  Jun 15 12:49:04.613: INFO: Deleting pod "simpletest-rc-to-be-deleted-glms6" in namespace "gc-6023"
  Jun 15 12:49:04.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-gnsrv" in namespace "gc-6023"
  Jun 15 12:49:04.657: INFO: Deleting pod "simpletest-rc-to-be-deleted-gpsrk" in namespace "gc-6023"
  Jun 15 12:49:04.682: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjj8r" in namespace "gc-6023"
  Jun 15 12:49:04.694: INFO: Deleting pod "simpletest-rc-to-be-deleted-j8xl5" in namespace "gc-6023"
  Jun 15 12:49:04.707: INFO: Deleting pod "simpletest-rc-to-be-deleted-j9fmp" in namespace "gc-6023"
  Jun 15 12:49:04.721: INFO: Deleting pod "simpletest-rc-to-be-deleted-jsnsw" in namespace "gc-6023"
  Jun 15 12:49:04.735: INFO: Deleting pod "simpletest-rc-to-be-deleted-jwbqf" in namespace "gc-6023"
  Jun 15 12:49:04.747: INFO: Deleting pod "simpletest-rc-to-be-deleted-jwklz" in namespace "gc-6023"
  Jun 15 12:49:04.764: INFO: Deleting pod "simpletest-rc-to-be-deleted-kckt5" in namespace "gc-6023"
  Jun 15 12:49:04.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6023" for this suite. @ 06/15/24 12:49:04.793
• [17.433 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 06/15/24 12:49:04.801
  Jun 15 12:49:04.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:49:04.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:04.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:04.827
  STEP: Creating configMap with name configmap-test-volume-656dff79-1769-4712-b531-9342a98218c9 @ 06/15/24 12:49:04.83
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:49:04.835
  E0615 12:49:05.134744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:06.135706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:07.136290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:08.136380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:49:08.861
  Jun 15 12:49:08.866: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-configmaps-4e29fbc7-1fab-446c-95ec-a0fa5940c9b3 container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:49:08.871
  Jun 15 12:49:08.886: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8115" for this suite. @ 06/15/24 12:49:08.89
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 06/15/24 12:49:08.899
  Jun 15 12:49:08.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:49:08.899
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:08.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:08.914
  STEP: Creating the pod @ 06/15/24 12:49:08.917
  E0615 12:49:09.137229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:10.137516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:11.137825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:49:11.463: INFO: Successfully updated pod "annotationupdate944e6bcd-d09f-418c-91e7-007d846a6c42"
  E0615 12:49:12.137867      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:13.138700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:49:13.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4268" for this suite. @ 06/15/24 12:49:13.481
• [4.589 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 06/15/24 12:49:13.488
  Jun 15 12:49:13.488: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename dns @ 06/15/24 12:49:13.489
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:13.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:13.507
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 06/15/24 12:49:13.553
  Jun 15 12:49:13.562: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7557  5cb7250e-321b-4562-b2b2-6023eef915db 23619 0 2024-06-15 12:49:13 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-06-15 12:49:13 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-998hd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-998hd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0615 12:49:14.138795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:15.139003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 06/15/24 12:49:15.571
  Jun 15 12:49:15.571: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7557 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:49:15.571: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:49:15.571: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:49:15.571: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7557/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 06/15/24 12:49:15.631
  Jun 15 12:49:15.631: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7557 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 12:49:15.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 12:49:15.631: INFO: ExecWithOptions: Clientset creation
  Jun 15 12:49:15.632: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7557/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Jun 15 12:49:15.686: INFO: Deleting pod test-dns-nameservers...
  Jun 15 12:49:15.699: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7557" for this suite. @ 06/15/24 12:49:15.705
• [2.224 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1764
  STEP: Creating a kubernetes client @ 06/15/24 12:49:15.712
  Jun 15 12:49:15.712: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 12:49:15.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:15.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:15.732
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 06/15/24 12:49:15.734
  Jun 15 12:49:15.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-9062 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Jun 15 12:49:15.782: INFO: stderr: ""
  Jun 15 12:49:15.782: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 06/15/24 12:49:15.782
  Jun 15 12:49:15.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-9062 delete pods e2e-test-httpd-pod'
  E0615 12:49:16.139814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:17.139901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:49:17.710: INFO: stderr: ""
  Jun 15 12:49:17.710: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Jun 15 12:49:17.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9062" for this suite. @ 06/15/24 12:49:17.715
• [2.011 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 06/15/24 12:49:17.723
  Jun 15 12:49:17.723: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-runtime @ 06/15/24 12:49:17.724
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:17.736
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:17.74
  STEP: create the container @ 06/15/24 12:49:17.743
  W0615 12:49:17.750668      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 06/15/24 12:49:17.75
  E0615 12:49:18.140958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:19.141598      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:20.141686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 06/15/24 12:49:20.769
  STEP: the container should be terminated @ 06/15/24 12:49:20.772
  STEP: the termination message should be set @ 06/15/24 12:49:20.772
  Jun 15 12:49:20.772: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 06/15/24 12:49:20.772
  Jun 15 12:49:20.788: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1698" for this suite. @ 06/15/24 12:49:20.791
• [3.074 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:397
  STEP: Creating a kubernetes client @ 06/15/24 12:49:20.797
  Jun 15 12:49:20.797: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 12:49:20.798
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:20.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:20.815
  STEP: Counting existing ResourceQuota @ 06/15/24 12:49:20.818
  E0615 12:49:21.142051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:22.142157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:23.142329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:24.143156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:25.143267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 06/15/24 12:49:25.822
  STEP: Ensuring resource quota status is calculated @ 06/15/24 12:49:25.827
  E0615 12:49:26.143868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:27.144917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 06/15/24 12:49:27.832
  STEP: Ensuring resource quota status captures replication controller creation @ 06/15/24 12:49:27.847
  E0615 12:49:28.145828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:29.146011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 06/15/24 12:49:29.851
  STEP: Ensuring resource quota status released usage @ 06/15/24 12:49:29.86
  E0615 12:49:30.146622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:31.146736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:49:31.866: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-937" for this suite. @ 06/15/24 12:49:31.87
• [11.080 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 06/15/24 12:49:31.877
  Jun 15 12:49:31.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename runtimeclass @ 06/15/24 12:49:31.878
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:31.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:31.898
  STEP: getting /apis @ 06/15/24 12:49:31.902
  STEP: getting /apis/node.k8s.io @ 06/15/24 12:49:31.908
  STEP: getting /apis/node.k8s.io/v1 @ 06/15/24 12:49:31.909
  STEP: creating @ 06/15/24 12:49:31.91
  STEP: watching @ 06/15/24 12:49:31.927
  Jun 15 12:49:31.927: INFO: starting watch
  STEP: getting @ 06/15/24 12:49:31.933
  STEP: listing @ 06/15/24 12:49:31.936
  STEP: patching @ 06/15/24 12:49:31.939
  STEP: updating @ 06/15/24 12:49:31.945
  Jun 15 12:49:31.949: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 06/15/24 12:49:31.949
  STEP: deleting a collection @ 06/15/24 12:49:31.962
  Jun 15 12:49:31.977: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2020" for this suite. @ 06/15/24 12:49:31.98
• [0.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 06/15/24 12:49:31.989
  Jun 15 12:49:31.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename subpath @ 06/15/24 12:49:31.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:32.002
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:32.007
  STEP: Setting up data @ 06/15/24 12:49:32.01
  STEP: Creating pod pod-subpath-test-downwardapi-ttlx @ 06/15/24 12:49:32.02
  STEP: Creating a pod to test atomic-volume-subpath @ 06/15/24 12:49:32.02
  E0615 12:49:32.147456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:33.148364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:34.149278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:35.149358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:36.150305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:37.150396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:38.150793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:39.151106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:40.151177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:41.151289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:42.151608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:43.152533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:44.152955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:45.153055      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:46.153094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:47.153202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:48.154277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:49.154574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:50.155216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:51.155307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:52.155509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:53.155627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:49:54.086
  Jun 15 12:49:54.090: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-subpath-test-downwardapi-ttlx container test-container-subpath-downwardapi-ttlx: <nil>
  STEP: delete the pod @ 06/15/24 12:49:54.097
  STEP: Deleting pod pod-subpath-test-downwardapi-ttlx @ 06/15/24 12:49:54.112
  Jun 15 12:49:54.112: INFO: Deleting pod "pod-subpath-test-downwardapi-ttlx" in namespace "subpath-1617"
  Jun 15 12:49:54.118: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1617" for this suite. @ 06/15/24 12:49:54.121
• [22.139 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 06/15/24 12:49:54.128
  Jun 15 12:49:54.128: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:49:54.129
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:54.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:54.148
  STEP: Creating configMap with name projected-configmap-test-volume-36d74b0d-3202-41c2-8fe8-b28845983f27 @ 06/15/24 12:49:54.151
  E0615 12:49:54.156437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:49:54.157
  E0615 12:49:55.157503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:56.157820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:57.158792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:49:58.158888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:49:58.182
  Jun 15 12:49:58.185: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-configmaps-f98da184-0e2f-42a0-87a7-d5f52497ace9 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:49:58.193
  Jun 15 12:49:58.210: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3778" for this suite. @ 06/15/24 12:49:58.213
• [4.093 seconds]
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 06/15/24 12:49:58.222
  Jun 15 12:49:58.222: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:49:58.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:49:58.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:49:58.236
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:49:58.242
  E0615 12:49:59.159932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:00.160033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:01.160253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:02.160787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:50:02.27
  Jun 15 12:50:02.273: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-bc8cc4ef-7d93-4985-a096-5151890e9023 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:50:02.282
  Jun 15 12:50:02.300: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7136" for this suite. @ 06/15/24 12:50:02.303
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 06/15/24 12:50:02.311
  Jun 15 12:50:02.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replicaset @ 06/15/24 12:50:02.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:50:02.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:50:02.327
  STEP: Create a Replicaset @ 06/15/24 12:50:02.334
  STEP: Verify that the required pods have come up. @ 06/15/24 12:50:02.338
  Jun 15 12:50:02.341: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0615 12:50:03.160924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:04.161198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:05.161304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:06.161757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:07.161833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:07.345: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 06/15/24 12:50:07.345
  STEP: Getting /status @ 06/15/24 12:50:07.345
  Jun 15 12:50:07.349: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 06/15/24 12:50:07.349
  Jun 15 12:50:07.359: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 06/15/24 12:50:07.359
  Jun 15 12:50:07.361: INFO: Observed &ReplicaSet event: ADDED
  Jun 15 12:50:07.361: INFO: Observed &ReplicaSet event: MODIFIED
  Jun 15 12:50:07.361: INFO: Observed &ReplicaSet event: MODIFIED
  Jun 15 12:50:07.361: INFO: Observed &ReplicaSet event: MODIFIED
  Jun 15 12:50:07.361: INFO: Found replicaset test-rs in namespace replicaset-3396 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Jun 15 12:50:07.361: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 06/15/24 12:50:07.361
  Jun 15 12:50:07.361: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Jun 15 12:50:07.366: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 06/15/24 12:50:07.366
  Jun 15 12:50:07.368: INFO: Observed &ReplicaSet event: ADDED
  Jun 15 12:50:07.368: INFO: Observed &ReplicaSet event: MODIFIED
  Jun 15 12:50:07.368: INFO: Observed &ReplicaSet event: MODIFIED
  Jun 15 12:50:07.368: INFO: Observed &ReplicaSet event: MODIFIED
  Jun 15 12:50:07.368: INFO: Observed replicaset test-rs in namespace replicaset-3396 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Jun 15 12:50:07.368: INFO: Observed &ReplicaSet event: MODIFIED
  Jun 15 12:50:07.368: INFO: Found replicaset test-rs in namespace replicaset-3396 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Jun 15 12:50:07.368: INFO: Replicaset test-rs has a patched status
  Jun 15 12:50:07.369: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3396" for this suite. @ 06/15/24 12:50:07.372
• [5.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 06/15/24 12:50:07.381
  Jun 15 12:50:07.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:50:07.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:50:07.396
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:50:07.4
  STEP: Creating projection with secret that has name projected-secret-test-1c6b9930-591f-46aa-a233-6d975233ff18 @ 06/15/24 12:50:07.403
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:50:07.408
  E0615 12:50:08.162119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:09.162334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:10.162453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:11.162539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:50:11.438
  Jun 15 12:50:11.442: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-projected-secrets-afce92c6-cfc9-4917-a7c4-012686abeb2c container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:50:11.454
  Jun 15 12:50:11.468: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3044" for this suite. @ 06/15/24 12:50:11.472
• [4.099 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:641
  STEP: Creating a kubernetes client @ 06/15/24 12:50:11.48
  Jun 15 12:50:11.480: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename statefulset @ 06/15/24 12:50:11.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:50:11.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:50:11.497
  STEP: Creating service test in namespace statefulset-8807 @ 06/15/24 12:50:11.5
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 06/15/24 12:50:11.504
  STEP: Creating stateful set ss in namespace statefulset-8807 @ 06/15/24 12:50:11.509
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8807 @ 06/15/24 12:50:11.515
  Jun 15 12:50:11.519: INFO: Found 0 stateful pods, waiting for 1
  E0615 12:50:12.163267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:13.163301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:14.163345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:15.163437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:16.163886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:17.164919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:18.165280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:19.165535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:20.165789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:21.166703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:21.520: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 06/15/24 12:50:21.52
  Jun 15 12:50:21.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-8807 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 12:50:21.618: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 12:50:21.618: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 12:50:21.618: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Jun 15 12:50:21.622: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0615 12:50:22.167780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:23.168514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:24.168607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:25.168683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:26.168917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:27.169065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:28.169185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:29.169288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:30.169466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:31.169608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:31.624: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Jun 15 12:50:31.625: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Jun 15 12:50:31.641: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999851s
  E0615 12:50:32.169718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:32.645: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996612568s
  E0615 12:50:33.170234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:33.650: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992231076s
  E0615 12:50:34.170370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:34.655: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987117006s
  E0615 12:50:35.170505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:35.661: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981889144s
  E0615 12:50:36.171279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:36.666: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.976221416s
  E0615 12:50:37.172268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:37.670: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.971389261s
  E0615 12:50:38.172749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:38.675: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967722944s
  E0615 12:50:39.172831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:39.680: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.961725421s
  E0615 12:50:40.173536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:40.685: INFO: Verifying statefulset ss doesn't scale past 1 for another 956.9784ms
  E0615 12:50:41.173623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8807 @ 06/15/24 12:50:41.685
  Jun 15 12:50:41.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-8807 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Jun 15 12:50:41.784: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Jun 15 12:50:41.784: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 12:50:41.784: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Jun 15 12:50:41.788: INFO: Found 1 stateful pods, waiting for 3
  E0615 12:50:42.174595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:43.175425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:44.176351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:45.176438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:46.176752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:47.176854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:48.176951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:49.177217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:50.177370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:51.177529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:50:51.788: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 12:50:51.788: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 12:50:51.788: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 06/15/24 12:50:51.788
  STEP: Scale down will halt with unhealthy stateful pod @ 06/15/24 12:50:51.788
  Jun 15 12:50:51.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-8807 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 12:50:51.879: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 12:50:51.879: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 12:50:51.879: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Jun 15 12:50:51.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-8807 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 12:50:51.983: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 12:50:51.983: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 12:50:51.983: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Jun 15 12:50:51.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-8807 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 12:50:52.091: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 12:50:52.091: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 12:50:52.091: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Jun 15 12:50:52.091: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Jun 15 12:50:52.096: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0615 12:50:52.178512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:53.179120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:54.179358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:55.179528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:56.179809      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:57.180825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:58.180920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:50:59.182023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:00.182140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:01.182394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:02.099: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Jun 15 12:51:02.099: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Jun 15 12:51:02.099: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Jun 15 12:51:02.113: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999976s
  E0615 12:51:02.183248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:03.119: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996368891s
  E0615 12:51:03.183666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:04.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990190639s
  E0615 12:51:04.184699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:05.129: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985705866s
  E0615 12:51:05.185143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:06.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981155617s
  E0615 12:51:06.185509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:07.139: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976812864s
  E0615 12:51:07.186418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:08.143: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970994693s
  E0615 12:51:08.187155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:09.148: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966307423s
  E0615 12:51:09.187275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:10.153: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961623439s
  E0615 12:51:10.188141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:11.158: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.231805ms
  E0615 12:51:11.189113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8807 @ 06/15/24 12:51:12.159
  Jun 15 12:51:12.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-8807 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0615 12:51:12.189425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:12.264: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Jun 15 12:51:12.264: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 12:51:12.264: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Jun 15 12:51:12.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-8807 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Jun 15 12:51:12.365: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Jun 15 12:51:12.365: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 12:51:12.365: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Jun 15 12:51:12.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-8807 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Jun 15 12:51:12.460: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Jun 15 12:51:12.460: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 12:51:12.460: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Jun 15 12:51:12.460: INFO: Scaling statefulset ss to 0
  E0615 12:51:13.189590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:14.190138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:15.191041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:16.191848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:17.191872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:18.191937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:19.192470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:20.192564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:21.192661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:22.192727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 06/15/24 12:51:22.469
  Jun 15 12:51:22.469: INFO: Deleting all statefulset in ns statefulset-8807
  Jun 15 12:51:22.473: INFO: Scaling statefulset ss to 0
  Jun 15 12:51:22.479: INFO: Waiting for statefulset status.replicas updated to 0
  Jun 15 12:51:22.482: INFO: Deleting statefulset ss
  Jun 15 12:51:22.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8807" for this suite. @ 06/15/24 12:51:22.5
• [71.026 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 06/15/24 12:51:22.506
  Jun 15 12:51:22.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:51:22.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:22.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:22.526
  STEP: Creating configMap with name configmap-test-volume-map-fcc28c19-60cd-4d0f-beae-68ca7e07e847 @ 06/15/24 12:51:22.529
  STEP: Creating a pod to test consume configMaps @ 06/15/24 12:51:22.535
  E0615 12:51:23.192847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:24.193026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:25.193142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:26.193440      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:51:26.558
  Jun 15 12:51:26.561: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-configmaps-d4dcb1c4-0e53-468a-b74a-594a27f81331 container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 12:51:26.572
  Jun 15 12:51:26.592: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6350" for this suite. @ 06/15/24 12:51:26.596
• [4.097 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 06/15/24 12:51:26.603
  Jun 15 12:51:26.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 12:51:26.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:26.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:26.618
  Jun 15 12:51:26.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 12:51:27.194294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 06/15/24 12:51:27.85
  Jun 15 12:51:27.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6374 --namespace=crd-publish-openapi-6374 create -f -'
  E0615 12:51:28.194540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:29.194757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:29.921: INFO: stderr: ""
  Jun 15 12:51:29.921: INFO: stdout: "e2e-test-crd-publish-openapi-7189-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Jun 15 12:51:29.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6374 --namespace=crd-publish-openapi-6374 delete e2e-test-crd-publish-openapi-7189-crds test-cr'
  Jun 15 12:51:29.981: INFO: stderr: ""
  Jun 15 12:51:29.981: INFO: stdout: "e2e-test-crd-publish-openapi-7189-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Jun 15 12:51:29.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6374 --namespace=crd-publish-openapi-6374 apply -f -'
  Jun 15 12:51:30.034: INFO: stderr: ""
  Jun 15 12:51:30.034: INFO: stdout: "e2e-test-crd-publish-openapi-7189-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Jun 15 12:51:30.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6374 --namespace=crd-publish-openapi-6374 delete e2e-test-crd-publish-openapi-7189-crds test-cr'
  Jun 15 12:51:30.083: INFO: stderr: ""
  Jun 15 12:51:30.083: INFO: stdout: "e2e-test-crd-publish-openapi-7189-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 06/15/24 12:51:30.083
  Jun 15 12:51:30.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6374 explain e2e-test-crd-publish-openapi-7189-crds'
  Jun 15 12:51:30.126: INFO: stderr: ""
  Jun 15 12:51:30.126: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-7189-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0615 12:51:30.195430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:31.203512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:31.385: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6374" for this suite. @ 06/15/24 12:51:31.393
• [4.798 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:649
  STEP: Creating a kubernetes client @ 06/15/24 12:51:31.401
  Jun 15 12:51:31.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename svcaccounts @ 06/15/24 12:51:31.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:31.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:31.418
  STEP: creating a ServiceAccount @ 06/15/24 12:51:31.421
  STEP: watching for the ServiceAccount to be added @ 06/15/24 12:51:31.429
  STEP: patching the ServiceAccount @ 06/15/24 12:51:31.43
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 06/15/24 12:51:31.435
  STEP: deleting the ServiceAccount @ 06/15/24 12:51:31.439
  Jun 15 12:51:31.453: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6925" for this suite. @ 06/15/24 12:51:31.456
• [0.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 06/15/24 12:51:31.468
  Jun 15 12:51:31.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename events @ 06/15/24 12:51:31.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:31.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:31.483
  STEP: Create set of events @ 06/15/24 12:51:31.486
  Jun 15 12:51:31.490: INFO: created test-event-1
  Jun 15 12:51:31.494: INFO: created test-event-2
  Jun 15 12:51:31.498: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 06/15/24 12:51:31.498
  STEP: delete collection of events @ 06/15/24 12:51:31.502
  Jun 15 12:51:31.502: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 06/15/24 12:51:31.522
  Jun 15 12:51:31.522: INFO: requesting list of events to confirm quantity
  Jun 15 12:51:31.526: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4153" for this suite. @ 06/15/24 12:51:31.53
• [0.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 06/15/24 12:51:31.539
  Jun 15 12:51:31.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replicaset @ 06/15/24 12:51:31.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:31.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:31.555
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 06/15/24 12:51:31.558
  E0615 12:51:32.203873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:33.203897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 06/15/24 12:51:33.58
  STEP: Then the orphan pod is adopted @ 06/15/24 12:51:33.585
  E0615 12:51:34.203981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 06/15/24 12:51:34.592
  Jun 15 12:51:34.595: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 06/15/24 12:51:34.607
  E0615 12:51:35.204363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:35.617: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6742" for this suite. @ 06/15/24 12:51:35.621
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 06/15/24 12:51:35.629
  Jun 15 12:51:35.629: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:51:35.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:35.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:35.649
  STEP: Setting up server cert @ 06/15/24 12:51:35.671
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:51:35.913
  STEP: Deploying the webhook pod @ 06/15/24 12:51:35.923
  STEP: Wait for the deployment to be ready @ 06/15/24 12:51:35.935
  Jun 15 12:51:35.947: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 12:51:36.204668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:37.204773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 12:51:37.959
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:51:37.969
  E0615 12:51:38.205298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:38.969: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 06/15/24 12:51:38.977
  STEP: create a namespace for the webhook @ 06/15/24 12:51:38.991
  STEP: create a configmap should be unconditionally rejected by the webhook @ 06/15/24 12:51:39.005
  Jun 15 12:51:39.065: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4428" for this suite. @ 06/15/24 12:51:39.07
  STEP: Destroying namespace "webhook-markers-4388" for this suite. @ 06/15/24 12:51:39.078
  STEP: Destroying namespace "fail-closed-namespace-2367" for this suite. @ 06/15/24 12:51:39.085
• [3.463 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 06/15/24 12:51:39.092
  Jun 15 12:51:39.092: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:51:39.093
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:39.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:39.108
  STEP: Setting up server cert @ 06/15/24 12:51:39.132
  E0615 12:51:39.220102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:51:39.273
  STEP: Deploying the webhook pod @ 06/15/24 12:51:39.28
  STEP: Wait for the deployment to be ready @ 06/15/24 12:51:39.293
  Jun 15 12:51:39.306: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 12:51:40.220357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:41.220559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 12:51:41.319
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:51:41.335
  E0615 12:51:42.220592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:42.335: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 06/15/24 12:51:42.344
  STEP: Registering slow webhook via the AdmissionRegistration API @ 06/15/24 12:51:42.344
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 06/15/24 12:51:42.361
  E0615 12:51:43.221415      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 06/15/24 12:51:43.374
  STEP: Registering slow webhook via the AdmissionRegistration API @ 06/15/24 12:51:43.374
  E0615 12:51:44.221718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 06/15/24 12:51:44.404
  STEP: Registering slow webhook via the AdmissionRegistration API @ 06/15/24 12:51:44.404
  E0615 12:51:45.221811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:46.222726      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:47.222825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:48.223758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:49.224796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 06/15/24 12:51:49.438
  STEP: Registering slow webhook via the AdmissionRegistration API @ 06/15/24 12:51:49.438
  E0615 12:51:50.224923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:51.225128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:52.225212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:53.225341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:54.225623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:51:54.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7751" for this suite. @ 06/15/24 12:51:54.531
  STEP: Destroying namespace "webhook-markers-149" for this suite. @ 06/15/24 12:51:54.539
• [15.453 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 06/15/24 12:51:54.545
  Jun 15 12:51:54.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 12:51:54.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:54.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:54.564
  STEP: Creating projection with secret that has name projected-secret-test-cc750a27-46cc-47d8-8f13-f3e2bf075eb3 @ 06/15/24 12:51:54.567
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:51:54.572
  E0615 12:51:55.226530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:56.226841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:57.226960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:51:58.227894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:51:58.603
  Jun 15 12:51:58.607: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-secrets-038b35ed-9802-42c2-8633-3b11cd758fb8 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:51:58.613
  Jun 15 12:51:58.628: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5597" for this suite. @ 06/15/24 12:51:58.632
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 06/15/24 12:51:58.638
  Jun 15 12:51:58.638: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 12:51:58.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:51:58.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:51:58.655
  STEP: Create set of pods @ 06/15/24 12:51:58.659
  Jun 15 12:51:58.668: INFO: created test-pod-1
  Jun 15 12:51:58.675: INFO: created test-pod-2
  Jun 15 12:51:58.682: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 06/15/24 12:51:58.682
  E0615 12:51:59.227973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:00.228064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 06/15/24 12:52:00.735
  Jun 15 12:52:00.738: INFO: Pod quantity 3 is different from expected quantity 0
  E0615 12:52:01.228380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:01.740: INFO: Pod quantity 3 is different from expected quantity 0
  E0615 12:52:02.228466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:02.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2264" for this suite. @ 06/15/24 12:52:02.745
• [4.116 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 06/15/24 12:52:02.754
  Jun 15 12:52:02.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:52:02.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:02.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:02.772
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-4212 @ 06/15/24 12:52:02.774
  STEP: changing the ExternalName service to type=ClusterIP @ 06/15/24 12:52:02.78
  STEP: creating replication controller externalname-service in namespace services-4212 @ 06/15/24 12:52:02.792
  I0615 12:52:02.799786      19 runners.go:197] Created replication controller with name: externalname-service, namespace: services-4212, replica count: 2
  E0615 12:52:03.228977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:04.229781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:05.229970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 12:52:05.850732      19 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 12:52:05.850: INFO: Creating new exec pod
  E0615 12:52:06.230658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:07.230751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:08.231734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:08.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4212 exec execpod2fxvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Jun 15 12:52:08.957: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Jun 15 12:52:08.957: INFO: stdout: "externalname-service-nn6rg"
  Jun 15 12:52:08.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4212 exec execpod2fxvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.73 80'
  Jun 15 12:52:09.045: INFO: stderr: "+ nc -v -t -w 2 10.152.183.73 80\n+ echo hostName\nConnection to 10.152.183.73 80 port [tcp/http] succeeded!\n"
  Jun 15 12:52:09.045: INFO: stdout: ""
  E0615 12:52:09.231839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:09.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4212 exec execpod2fxvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.73 80'
  Jun 15 12:52:10.052: INFO: stderr: "+ nc -v -t -w 2 10.152.183.73 80\n+ echo hostName\nConnection to 10.152.183.73 80 port [tcp/http] succeeded!\n"
  Jun 15 12:52:10.052: INFO: stdout: ""
  E0615 12:52:10.232821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:10.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4212 exec execpod2fxvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.73 80'
  Jun 15 12:52:11.044: INFO: stderr: "+ nc -v -t -w 2 10.152.183.73 80\n+ echo hostName\nConnection to 10.152.183.73 80 port [tcp/http] succeeded!\n"
  Jun 15 12:52:11.044: INFO: stdout: ""
  E0615 12:52:11.233643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:11.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4212 exec execpod2fxvr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.73 80'
  Jun 15 12:52:12.049: INFO: stderr: "+ nc -v -t -w 2 10.152.183.73 80\n+ echo hostName\nConnection to 10.152.183.73 80 port [tcp/http] succeeded!\n"
  Jun 15 12:52:12.049: INFO: stdout: "externalname-service-cqk8x"
  Jun 15 12:52:12.049: INFO: Cleaning up the ExternalName to ClusterIP test service
  Jun 15 12:52:12.074: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4212" for this suite. @ 06/15/24 12:52:12.079
• [9.332 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 06/15/24 12:52:12.087
  Jun 15 12:52:12.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename var-expansion @ 06/15/24 12:52:12.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:12.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:12.156
  STEP: Creating a pod to test substitution in container's args @ 06/15/24 12:52:12.158
  E0615 12:52:12.233666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:13.233776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:14.233914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:15.234848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:52:16.182
  Jun 15 12:52:16.186: INFO: Trying to get logs from node ip-172-31-43-132 pod var-expansion-87b58c83-e964-430b-8774-3aca674afe38 container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 12:52:16.2
  Jun 15 12:52:16.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3360" for this suite. @ 06/15/24 12:52:16.221
• [4.141 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 06/15/24 12:52:16.228
  Jun 15 12:52:16.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:52:16.228
  E0615 12:52:16.235227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:16.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:16.246
  STEP: Creating the pod @ 06/15/24 12:52:16.249
  E0615 12:52:17.236142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:18.236260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:18.794: INFO: Successfully updated pod "labelsupdate69dbe104-1646-4f3f-be95-e2ee2166a1c5"
  E0615 12:52:19.237017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:20.237186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:21.237231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:22.237307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:22.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5516" for this suite. @ 06/15/24 12:52:22.822
• [6.600 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 06/15/24 12:52:22.828
  Jun 15 12:52:22.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 12:52:22.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:22.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:22.85
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 12:52:22.853
  E0615 12:52:23.238312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:24.238380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:25.239228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:26.239558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:52:26.878
  Jun 15 12:52:26.881: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-eeebb3a3-b47c-43d8-a9fb-e5d5c5b29121 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 12:52:26.886
  Jun 15 12:52:26.901: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9381" for this suite. @ 06/15/24 12:52:26.904
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 06/15/24 12:52:26.911
  Jun 15 12:52:26.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 12:52:26.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:26.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:26.927
  E0615 12:52:27.239695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:28.239775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:29.240386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:30.240456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:31.240541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:32.240583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:52:32.988
  Jun 15 12:52:32.991: INFO: Trying to get logs from node ip-172-31-7-7 pod client-envvars-31c75e00-22e3-4a9b-b850-411099792465 container env3cont: <nil>
  STEP: delete the pod @ 06/15/24 12:52:32.998
  Jun 15 12:52:33.015: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5241" for this suite. @ 06/15/24 12:52:33.02
• [6.118 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 06/15/24 12:52:33.029
  Jun 15 12:52:33.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 12:52:33.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:33.05
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:33.054
  STEP: Setting up server cert @ 06/15/24 12:52:33.078
  E0615 12:52:33.241289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 12:52:33.293
  STEP: Deploying the webhook pod @ 06/15/24 12:52:33.303
  STEP: Wait for the deployment to be ready @ 06/15/24 12:52:33.318
  Jun 15 12:52:33.331: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 12:52:34.242112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:35.242206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 12:52:35.343
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 12:52:35.353
  E0615 12:52:36.243091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:36.353: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 06/15/24 12:52:36.428
  STEP: Creating a configMap that should be mutated @ 06/15/24 12:52:36.437
  STEP: Deleting the collection of validation webhooks @ 06/15/24 12:52:36.456
  STEP: Creating a configMap that should not be mutated @ 06/15/24 12:52:36.506
  Jun 15 12:52:36.557: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8394" for this suite. @ 06/15/24 12:52:36.561
  STEP: Destroying namespace "webhook-markers-8060" for this suite. @ 06/15/24 12:52:36.568
• [3.547 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 06/15/24 12:52:36.576
  Jun 15 12:52:36.576: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 12:52:36.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:36.59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:36.595
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 06/15/24 12:52:36.598
  E0615 12:52:37.244094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:38.244171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:39.244269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:40.244444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:52:40.621
  Jun 15 12:52:40.624: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-09f1a77c-eec0-4bd1-a514-3ad66601ad96 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 12:52:40.633
  Jun 15 12:52:40.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1949" for this suite. @ 06/15/24 12:52:40.653
• [4.082 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 06/15/24 12:52:40.659
  Jun 15 12:52:40.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename disruption @ 06/15/24 12:52:40.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:40.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:40.676
  STEP: creating the pdb @ 06/15/24 12:52:40.679
  STEP: Waiting for the pdb to be processed @ 06/15/24 12:52:40.686
  STEP: updating the pdb @ 06/15/24 12:52:40.69
  STEP: Waiting for the pdb to be processed @ 06/15/24 12:52:40.699
  E0615 12:52:41.245058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:42.246018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 06/15/24 12:52:42.704
  STEP: Waiting for the pdb to be processed @ 06/15/24 12:52:42.715
  E0615 12:52:43.246409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:44.246523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 06/15/24 12:52:44.727
  Jun 15 12:52:44.730: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6111" for this suite. @ 06/15/24 12:52:44.733
• [4.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 06/15/24 12:52:44.741
  Jun 15 12:52:44.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:52:44.742
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:44.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:44.759
  STEP: Creating configMap with name configmap-test-upd-c0d17960-894c-401f-8c25-83e56c8c4b71 @ 06/15/24 12:52:44.766
  STEP: Creating the pod @ 06/15/24 12:52:44.771
  E0615 12:52:45.246728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:46.246826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 06/15/24 12:52:46.79
  STEP: Waiting for pod with binary data @ 06/15/24 12:52:46.798
  Jun 15 12:52:46.803: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2709" for this suite. @ 06/15/24 12:52:46.806
• [2.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2177
  STEP: Creating a kubernetes client @ 06/15/24 12:52:46.815
  Jun 15 12:52:46.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 12:52:46.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:46.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:46.834
  STEP: creating service in namespace services-7376 @ 06/15/24 12:52:46.842
  STEP: creating service affinity-clusterip in namespace services-7376 @ 06/15/24 12:52:46.842
  STEP: creating replication controller affinity-clusterip in namespace services-7376 @ 06/15/24 12:52:46.859
  I0615 12:52:46.866821      19 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-7376, replica count: 3
  E0615 12:52:47.247223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:48.247859      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:49.247924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 12:52:49.917718      19 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 12:52:49.925: INFO: Creating new exec pod
  E0615 12:52:50.248100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:51.248260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:52.248711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:52.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7376 exec execpod-affinity9vgl5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Jun 15 12:52:53.063: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Jun 15 12:52:53.063: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:52:53.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7376 exec execpod-affinity9vgl5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.88 80'
  Jun 15 12:52:53.188: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.88 80\nConnection to 10.152.183.88 80 port [tcp/http] succeeded!\n"
  Jun 15 12:52:53.188: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 12:52:53.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-7376 exec execpod-affinity9vgl5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.88:80/ ; done'
  E0615 12:52:53.250067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:53.402: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.88:80/\n"
  Jun 15 12:52:53.402: INFO: stdout: "\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9\naffinity-clusterip-x24m9"
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Received response from host: affinity-clusterip-x24m9
  Jun 15 12:52:53.402: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-7376, will wait for the garbage collector to delete the pods @ 06/15/24 12:52:53.418
  Jun 15 12:52:53.479: INFO: Deleting ReplicationController affinity-clusterip took: 6.285507ms
  Jun 15 12:52:53.579: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.365111ms
  E0615 12:52:54.250222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:55.250693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:56.251661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:56.398: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7376" for this suite. @ 06/15/24 12:52:56.401
• [9.592 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:147
  STEP: Creating a kubernetes client @ 06/15/24 12:52:56.407
  Jun 15 12:52:56.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubelet-test @ 06/15/24 12:52:56.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:56.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:56.428
  STEP: Waiting for pod completion @ 06/15/24 12:52:56.44
  E0615 12:52:57.251759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:52:58.252487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:52:58.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3541" for this suite. @ 06/15/24 12:52:58.461
• [2.060 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 06/15/24 12:52:58.468
  Jun 15 12:52:58.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 12:52:58.468
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:52:58.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:52:58.485
  STEP: Creating secret with name secret-test-map-186287f6-8343-4dc3-9bd0-0e600d4ca1e2 @ 06/15/24 12:52:58.487
  STEP: Creating a pod to test consume secrets @ 06/15/24 12:52:58.491
  E0615 12:52:59.253503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:00.253611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 12:53:00.511
  Jun 15 12:53:00.514: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-secrets-19ce4f89-c629-45b3-a8b4-cacb84e1a0cc container secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 12:53:00.52
  Jun 15 12:53:00.535: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6357" for this suite. @ 06/15/24 12:53:00.539
• [2.078 seconds]
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 06/15/24 12:53:00.546
  Jun 15 12:53:00.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename proxy @ 06/15/24 12:53:00.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:00.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:00.563
  STEP: starting an echo server on multiple ports @ 06/15/24 12:53:00.578
  STEP: creating replication controller proxy-service-g68n8 in namespace proxy-1585 @ 06/15/24 12:53:00.578
  I0615 12:53:00.589170      19 runners.go:197] Created replication controller with name: proxy-service-g68n8, namespace: proxy-1585, replica count: 1
  E0615 12:53:01.253728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 12:53:01.640171      19 runners.go:197] proxy-service-g68n8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0615 12:53:02.254044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 12:53:02.640662      19 runners.go:197] proxy-service-g68n8 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 12:53:02.645: INFO: setup took 2.078905387s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 06/15/24 12:53:02.645
  Jun 15 12:53:02.651: INFO: (0) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.781988ms)
  Jun 15 12:53:02.651: INFO: (0) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 5.531815ms)
  Jun 15 12:53:02.651: INFO: (0) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.793694ms)
  Jun 15 12:53:02.654: INFO: (0) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 8.4236ms)
  Jun 15 12:53:02.654: INFO: (0) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 8.638302ms)
  Jun 15 12:53:02.655: INFO: (0) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 9.234411ms)
  Jun 15 12:53:02.656: INFO: (0) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 10.391876ms)
  Jun 15 12:53:02.656: INFO: (0) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 10.854883ms)
  Jun 15 12:53:02.656: INFO: (0) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 11.023852ms)
  Jun 15 12:53:02.657: INFO: (0) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 11.280624ms)
  Jun 15 12:53:02.657: INFO: (0) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 11.099238ms)
  Jun 15 12:53:02.657: INFO: (0) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 11.301112ms)
  Jun 15 12:53:02.657: INFO: (0) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 11.193085ms)
  Jun 15 12:53:02.657: INFO: (0) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 11.171018ms)
  Jun 15 12:53:02.657: INFO: (0) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 11.499432ms)
  Jun 15 12:53:02.657: INFO: (0) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 11.561102ms)
  Jun 15 12:53:02.660: INFO: (1) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 2.873813ms)
  Jun 15 12:53:02.660: INFO: (1) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 3.067506ms)
  Jun 15 12:53:02.661: INFO: (1) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 3.946152ms)
  Jun 15 12:53:02.662: INFO: (1) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 4.024117ms)
  Jun 15 12:53:02.662: INFO: (1) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.424802ms)
  Jun 15 12:53:02.663: INFO: (1) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 5.964449ms)
  Jun 15 12:53:02.663: INFO: (1) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 6.055315ms)
  Jun 15 12:53:02.663: INFO: (1) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.925805ms)
  Jun 15 12:53:02.663: INFO: (1) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.159653ms)
  Jun 15 12:53:02.663: INFO: (1) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.96901ms)
  Jun 15 12:53:02.664: INFO: (1) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 6.387417ms)
  Jun 15 12:53:02.664: INFO: (1) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.764454ms)
  Jun 15 12:53:02.664: INFO: (1) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.243776ms)
  Jun 15 12:53:02.664: INFO: (1) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 7.091057ms)
  Jun 15 12:53:02.665: INFO: (1) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 7.335824ms)
  Jun 15 12:53:02.665: INFO: (1) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 7.489209ms)
  Jun 15 12:53:02.668: INFO: (2) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 2.807153ms)
  Jun 15 12:53:02.669: INFO: (2) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 3.834729ms)
  Jun 15 12:53:02.670: INFO: (2) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 4.486863ms)
  Jun 15 12:53:02.670: INFO: (2) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 4.384512ms)
  Jun 15 12:53:02.670: INFO: (2) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 4.951863ms)
  Jun 15 12:53:02.671: INFO: (2) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.140434ms)
  Jun 15 12:53:02.671: INFO: (2) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.958644ms)
  Jun 15 12:53:02.671: INFO: (2) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 6.010165ms)
  Jun 15 12:53:02.672: INFO: (2) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 6.118323ms)
  Jun 15 12:53:02.672: INFO: (2) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.15059ms)
  Jun 15 12:53:02.672: INFO: (2) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 6.61155ms)
  Jun 15 12:53:02.672: INFO: (2) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 7.15712ms)
  Jun 15 12:53:02.672: INFO: (2) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.073904ms)
  Jun 15 12:53:02.673: INFO: (2) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 7.588839ms)
  Jun 15 12:53:02.673: INFO: (2) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.633651ms)
  Jun 15 12:53:02.673: INFO: (2) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 7.868544ms)
  Jun 15 12:53:02.677: INFO: (3) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 3.947238ms)
  Jun 15 12:53:02.677: INFO: (3) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.109378ms)
  Jun 15 12:53:02.678: INFO: (3) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 4.981455ms)
  Jun 15 12:53:02.679: INFO: (3) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 5.13952ms)
  Jun 15 12:53:02.679: INFO: (3) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 5.542509ms)
  Jun 15 12:53:02.679: INFO: (3) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 5.546659ms)
  Jun 15 12:53:02.679: INFO: (3) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 5.942743ms)
  Jun 15 12:53:02.679: INFO: (3) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.77669ms)
  Jun 15 12:53:02.679: INFO: (3) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 5.900845ms)
  Jun 15 12:53:02.680: INFO: (3) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.054065ms)
  Jun 15 12:53:02.680: INFO: (3) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.564578ms)
  Jun 15 12:53:02.680: INFO: (3) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 6.686112ms)
  Jun 15 12:53:02.680: INFO: (3) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.796928ms)
  Jun 15 12:53:02.681: INFO: (3) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 7.22082ms)
  Jun 15 12:53:02.682: INFO: (3) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 8.233275ms)
  Jun 15 12:53:02.683: INFO: (3) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 9.111903ms)
  Jun 15 12:53:02.686: INFO: (4) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 3.332538ms)
  Jun 15 12:53:02.686: INFO: (4) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 3.617895ms)
  Jun 15 12:53:02.687: INFO: (4) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 4.381534ms)
  Jun 15 12:53:02.688: INFO: (4) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 4.84182ms)
  Jun 15 12:53:02.688: INFO: (4) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 4.992066ms)
  Jun 15 12:53:02.688: INFO: (4) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 5.359879ms)
  Jun 15 12:53:02.688: INFO: (4) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 5.715967ms)
  Jun 15 12:53:02.689: INFO: (4) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.092387ms)
  Jun 15 12:53:02.689: INFO: (4) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.204876ms)
  Jun 15 12:53:02.689: INFO: (4) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 6.486573ms)
  Jun 15 12:53:02.689: INFO: (4) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 6.554215ms)
  Jun 15 12:53:02.690: INFO: (4) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 6.803805ms)
  Jun 15 12:53:02.690: INFO: (4) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 7.002793ms)
  Jun 15 12:53:02.690: INFO: (4) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 6.978512ms)
  Jun 15 12:53:02.690: INFO: (4) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 7.184216ms)
  Jun 15 12:53:02.691: INFO: (4) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.691807ms)
  Jun 15 12:53:02.694: INFO: (5) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 2.881834ms)
  Jun 15 12:53:02.694: INFO: (5) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 3.143394ms)
  Jun 15 12:53:02.694: INFO: (5) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 3.670208ms)
  Jun 15 12:53:02.696: INFO: (5) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 4.589384ms)
  Jun 15 12:53:02.696: INFO: (5) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 4.722405ms)
  Jun 15 12:53:02.696: INFO: (5) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 4.59694ms)
  Jun 15 12:53:02.696: INFO: (5) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 5.427059ms)
  Jun 15 12:53:02.697: INFO: (5) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.608072ms)
  Jun 15 12:53:02.697: INFO: (5) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 6.58173ms)
  Jun 15 12:53:02.698: INFO: (5) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 6.657584ms)
  Jun 15 12:53:02.698: INFO: (5) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.81214ms)
  Jun 15 12:53:02.698: INFO: (5) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 6.893542ms)
  Jun 15 12:53:02.698: INFO: (5) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 7.169892ms)
  Jun 15 12:53:02.699: INFO: (5) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.963253ms)
  Jun 15 12:53:02.699: INFO: (5) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 7.958314ms)
  Jun 15 12:53:02.699: INFO: (5) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 8.084262ms)
  Jun 15 12:53:02.702: INFO: (6) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 2.746071ms)
  Jun 15 12:53:02.703: INFO: (6) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 3.735964ms)
  Jun 15 12:53:02.703: INFO: (6) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 3.825561ms)
  Jun 15 12:53:02.704: INFO: (6) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 4.040588ms)
  Jun 15 12:53:02.704: INFO: (6) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.857802ms)
  Jun 15 12:53:02.704: INFO: (6) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 4.924412ms)
  Jun 15 12:53:02.705: INFO: (6) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.564088ms)
  Jun 15 12:53:02.705: INFO: (6) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 5.653359ms)
  Jun 15 12:53:02.705: INFO: (6) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 5.994033ms)
  Jun 15 12:53:02.706: INFO: (6) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 6.08656ms)
  Jun 15 12:53:02.706: INFO: (6) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.302738ms)
  Jun 15 12:53:02.706: INFO: (6) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 6.315535ms)
  Jun 15 12:53:02.706: INFO: (6) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.855283ms)
  Jun 15 12:53:02.706: INFO: (6) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.99658ms)
  Jun 15 12:53:02.707: INFO: (6) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 7.475116ms)
  Jun 15 12:53:02.708: INFO: (6) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 8.55415ms)
  Jun 15 12:53:02.713: INFO: (7) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.490251ms)
  Jun 15 12:53:02.713: INFO: (7) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 4.515721ms)
  Jun 15 12:53:02.713: INFO: (7) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.937234ms)
  Jun 15 12:53:02.713: INFO: (7) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 4.924761ms)
  Jun 15 12:53:02.714: INFO: (7) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 5.388032ms)
  Jun 15 12:53:02.714: INFO: (7) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 5.623741ms)
  Jun 15 12:53:02.714: INFO: (7) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.763531ms)
  Jun 15 12:53:02.715: INFO: (7) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.712373ms)
  Jun 15 12:53:02.716: INFO: (7) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 7.451468ms)
  Jun 15 12:53:02.716: INFO: (7) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 7.464266ms)
  Jun 15 12:53:02.716: INFO: (7) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 7.911025ms)
  Jun 15 12:53:02.716: INFO: (7) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 7.664915ms)
  Jun 15 12:53:02.716: INFO: (7) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 8.095962ms)
  Jun 15 12:53:02.716: INFO: (7) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 8.056263ms)
  Jun 15 12:53:02.716: INFO: (7) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 8.054777ms)
  Jun 15 12:53:02.717: INFO: (7) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 8.505829ms)
  Jun 15 12:53:02.720: INFO: (8) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 2.995508ms)
  Jun 15 12:53:02.721: INFO: (8) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 3.579185ms)
  Jun 15 12:53:02.721: INFO: (8) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 3.847151ms)
  Jun 15 12:53:02.721: INFO: (8) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 4.390803ms)
  Jun 15 12:53:02.722: INFO: (8) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 4.733057ms)
  Jun 15 12:53:02.722: INFO: (8) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.650746ms)
  Jun 15 12:53:02.723: INFO: (8) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 5.717414ms)
  Jun 15 12:53:02.723: INFO: (8) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.790477ms)
  Jun 15 12:53:02.723: INFO: (8) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.019733ms)
  Jun 15 12:53:02.723: INFO: (8) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 6.286602ms)
  Jun 15 12:53:02.723: INFO: (8) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.517192ms)
  Jun 15 12:53:02.724: INFO: (8) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 6.709802ms)
  Jun 15 12:53:02.724: INFO: (8) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.55743ms)
  Jun 15 12:53:02.724: INFO: (8) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 6.98894ms)
  Jun 15 12:53:02.725: INFO: (8) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 8.414886ms)
  Jun 15 12:53:02.726: INFO: (8) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 8.62632ms)
  Jun 15 12:53:02.729: INFO: (9) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 3.710124ms)
  Jun 15 12:53:02.730: INFO: (9) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 3.852652ms)
  Jun 15 12:53:02.731: INFO: (9) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 4.907005ms)
  Jun 15 12:53:02.731: INFO: (9) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.098399ms)
  Jun 15 12:53:02.731: INFO: (9) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.01674ms)
  Jun 15 12:53:02.732: INFO: (9) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.007974ms)
  Jun 15 12:53:02.732: INFO: (9) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 5.995699ms)
  Jun 15 12:53:02.732: INFO: (9) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 6.244146ms)
  Jun 15 12:53:02.732: INFO: (9) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 6.449537ms)
  Jun 15 12:53:02.732: INFO: (9) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.389315ms)
  Jun 15 12:53:02.733: INFO: (9) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 6.885562ms)
  Jun 15 12:53:02.733: INFO: (9) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.934177ms)
  Jun 15 12:53:02.733: INFO: (9) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.115221ms)
  Jun 15 12:53:02.733: INFO: (9) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.663662ms)
  Jun 15 12:53:02.734: INFO: (9) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 7.650654ms)
  Jun 15 12:53:02.735: INFO: (9) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 9.038026ms)
  Jun 15 12:53:02.738: INFO: (10) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 2.86257ms)
  Jun 15 12:53:02.738: INFO: (10) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 3.074881ms)
  Jun 15 12:53:02.739: INFO: (10) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 3.979667ms)
  Jun 15 12:53:02.739: INFO: (10) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 4.32213ms)
  Jun 15 12:53:02.740: INFO: (10) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.537431ms)
  Jun 15 12:53:02.741: INFO: (10) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.940576ms)
  Jun 15 12:53:02.741: INFO: (10) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 6.353172ms)
  Jun 15 12:53:02.742: INFO: (10) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 6.21422ms)
  Jun 15 12:53:02.742: INFO: (10) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 6.295117ms)
  Jun 15 12:53:02.742: INFO: (10) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 6.541314ms)
  Jun 15 12:53:02.742: INFO: (10) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 6.417825ms)
  Jun 15 12:53:02.742: INFO: (10) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.512132ms)
  Jun 15 12:53:02.742: INFO: (10) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 6.839545ms)
  Jun 15 12:53:02.742: INFO: (10) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.048851ms)
  Jun 15 12:53:02.743: INFO: (10) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 7.450929ms)
  Jun 15 12:53:02.743: INFO: (10) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 7.6491ms)
  Jun 15 12:53:02.746: INFO: (11) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 3.005362ms)
  Jun 15 12:53:02.747: INFO: (11) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.130684ms)
  Jun 15 12:53:02.747: INFO: (11) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 4.193866ms)
  Jun 15 12:53:02.749: INFO: (11) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 5.414374ms)
  Jun 15 12:53:02.749: INFO: (11) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 5.376412ms)
  Jun 15 12:53:02.749: INFO: (11) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.509075ms)
  Jun 15 12:53:02.749: INFO: (11) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.493814ms)
  Jun 15 12:53:02.749: INFO: (11) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.85001ms)
  Jun 15 12:53:02.749: INFO: (11) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.031801ms)
  Jun 15 12:53:02.749: INFO: (11) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 5.885816ms)
  Jun 15 12:53:02.750: INFO: (11) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.789405ms)
  Jun 15 12:53:02.750: INFO: (11) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 6.66808ms)
  Jun 15 12:53:02.750: INFO: (11) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.70268ms)
  Jun 15 12:53:02.750: INFO: (11) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.045929ms)
  Jun 15 12:53:02.751: INFO: (11) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 8.061884ms)
  Jun 15 12:53:02.751: INFO: (11) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 8.039891ms)
  Jun 15 12:53:02.755: INFO: (12) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 3.20261ms)
  Jun 15 12:53:02.755: INFO: (12) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 3.582365ms)
  Jun 15 12:53:02.755: INFO: (12) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 3.702945ms)
  Jun 15 12:53:02.756: INFO: (12) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.150192ms)
  Jun 15 12:53:02.756: INFO: (12) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 4.701059ms)
  Jun 15 12:53:02.757: INFO: (12) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 5.432115ms)
  Jun 15 12:53:02.757: INFO: (12) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 5.275262ms)
  Jun 15 12:53:02.757: INFO: (12) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 5.769404ms)
  Jun 15 12:53:02.758: INFO: (12) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 6.621471ms)
  Jun 15 12:53:02.758: INFO: (12) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 6.715355ms)
  Jun 15 12:53:02.758: INFO: (12) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 6.659411ms)
  Jun 15 12:53:02.758: INFO: (12) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.782847ms)
  Jun 15 12:53:02.758: INFO: (12) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 6.801166ms)
  Jun 15 12:53:02.758: INFO: (12) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.893077ms)
  Jun 15 12:53:02.759: INFO: (12) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.33102ms)
  Jun 15 12:53:02.760: INFO: (12) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 8.098806ms)
  Jun 15 12:53:02.763: INFO: (13) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 3.10239ms)
  Jun 15 12:53:02.764: INFO: (13) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 4.369948ms)
  Jun 15 12:53:02.764: INFO: (13) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 4.690696ms)
  Jun 15 12:53:02.764: INFO: (13) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.41029ms)
  Jun 15 12:53:02.765: INFO: (13) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 5.286647ms)
  Jun 15 12:53:02.766: INFO: (13) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 5.803221ms)
  Jun 15 12:53:02.766: INFO: (13) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 5.754932ms)
  Jun 15 12:53:02.766: INFO: (13) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.923868ms)
  Jun 15 12:53:02.766: INFO: (13) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 6.046141ms)
  Jun 15 12:53:02.766: INFO: (13) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 6.473915ms)
  Jun 15 12:53:02.767: INFO: (13) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.99529ms)
  Jun 15 12:53:02.767: INFO: (13) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.043414ms)
  Jun 15 12:53:02.767: INFO: (13) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 6.956355ms)
  Jun 15 12:53:02.767: INFO: (13) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.227424ms)
  Jun 15 12:53:02.768: INFO: (13) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 8.130295ms)
  Jun 15 12:53:02.768: INFO: (13) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 8.458124ms)
  Jun 15 12:53:02.772: INFO: (14) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 2.955179ms)
  Jun 15 12:53:02.772: INFO: (14) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 3.334036ms)
  Jun 15 12:53:02.773: INFO: (14) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 4.246549ms)
  Jun 15 12:53:02.773: INFO: (14) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 4.422408ms)
  Jun 15 12:53:02.773: INFO: (14) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.779916ms)
  Jun 15 12:53:02.774: INFO: (14) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.207366ms)
  Jun 15 12:53:02.774: INFO: (14) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 4.963585ms)
  Jun 15 12:53:02.774: INFO: (14) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.627812ms)
  Jun 15 12:53:02.775: INFO: (14) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 5.812677ms)
  Jun 15 12:53:02.775: INFO: (14) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.20385ms)
  Jun 15 12:53:02.775: INFO: (14) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 6.459908ms)
  Jun 15 12:53:02.775: INFO: (14) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 6.793077ms)
  Jun 15 12:53:02.775: INFO: (14) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 6.949967ms)
  Jun 15 12:53:02.776: INFO: (14) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 7.648091ms)
  Jun 15 12:53:02.776: INFO: (14) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.676347ms)
  Jun 15 12:53:02.777: INFO: (14) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 8.238054ms)
  Jun 15 12:53:02.780: INFO: (15) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 3.285124ms)
  Jun 15 12:53:02.780: INFO: (15) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 3.203458ms)
  Jun 15 12:53:02.781: INFO: (15) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 3.928033ms)
  Jun 15 12:53:02.782: INFO: (15) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.122725ms)
  Jun 15 12:53:02.783: INFO: (15) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.144219ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.13784ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 6.47523ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 6.311531ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.261357ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 6.288753ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 6.564023ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 6.558133ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 6.594355ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 6.749129ms)
  Jun 15 12:53:02.784: INFO: (15) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 7.132029ms)
  Jun 15 12:53:02.785: INFO: (15) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 8.094211ms)
  Jun 15 12:53:02.789: INFO: (16) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 3.127514ms)
  Jun 15 12:53:02.789: INFO: (16) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 3.571713ms)
  Jun 15 12:53:02.790: INFO: (16) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 4.884686ms)
  Jun 15 12:53:02.790: INFO: (16) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 4.756646ms)
  Jun 15 12:53:02.791: INFO: (16) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 4.94119ms)
  Jun 15 12:53:02.791: INFO: (16) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.051385ms)
  Jun 15 12:53:02.791: INFO: (16) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 5.626762ms)
  Jun 15 12:53:02.791: INFO: (16) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 5.860338ms)
  Jun 15 12:53:02.792: INFO: (16) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 6.119278ms)
  Jun 15 12:53:02.792: INFO: (16) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 6.540502ms)
  Jun 15 12:53:02.792: INFO: (16) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 6.610792ms)
  Jun 15 12:53:02.792: INFO: (16) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.684024ms)
  Jun 15 12:53:02.793: INFO: (16) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.18719ms)
  Jun 15 12:53:02.793: INFO: (16) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.868116ms)
  Jun 15 12:53:02.794: INFO: (16) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 8.10291ms)
  Jun 15 12:53:02.794: INFO: (16) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 8.232941ms)
  Jun 15 12:53:02.797: INFO: (17) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 2.883579ms)
  Jun 15 12:53:02.798: INFO: (17) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 4.54696ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.674863ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.617975ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 5.806574ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 5.955908ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 5.948806ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 6.062071ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 6.085513ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.099056ms)
  Jun 15 12:53:02.800: INFO: (17) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 6.110645ms)
  Jun 15 12:53:02.801: INFO: (17) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 6.865834ms)
  Jun 15 12:53:02.801: INFO: (17) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 7.009471ms)
  Jun 15 12:53:02.801: INFO: (17) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.085995ms)
  Jun 15 12:53:02.801: INFO: (17) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 7.092031ms)
  Jun 15 12:53:02.801: INFO: (17) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 7.391755ms)
  Jun 15 12:53:02.806: INFO: (18) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 3.978707ms)
  Jun 15 12:53:02.806: INFO: (18) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 3.995907ms)
  Jun 15 12:53:02.807: INFO: (18) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 4.730724ms)
  Jun 15 12:53:02.807: INFO: (18) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 4.728523ms)
  Jun 15 12:53:02.807: INFO: (18) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.532968ms)
  Jun 15 12:53:02.807: INFO: (18) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 5.514643ms)
  Jun 15 12:53:02.807: INFO: (18) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 5.872039ms)
  Jun 15 12:53:02.807: INFO: (18) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 5.574219ms)
  Jun 15 12:53:02.808: INFO: (18) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 6.475956ms)
  Jun 15 12:53:02.808: INFO: (18) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 6.698162ms)
  Jun 15 12:53:02.809: INFO: (18) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 6.840707ms)
  Jun 15 12:53:02.809: INFO: (18) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 6.984389ms)
  Jun 15 12:53:02.809: INFO: (18) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.34193ms)
  Jun 15 12:53:02.809: INFO: (18) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 7.321607ms)
  Jun 15 12:53:02.809: INFO: (18) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 7.565805ms)
  Jun 15 12:53:02.810: INFO: (18) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 8.221005ms)
  Jun 15 12:53:02.813: INFO: (19) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:443/proxy/tlsrewritem... (200; 3.230949ms)
  Jun 15 12:53:02.814: INFO: (19) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:1080/proxy/rewriteme">... (200; 4.061763ms)
  Jun 15 12:53:02.815: INFO: (19) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:160/proxy/: foo (200; 4.466758ms)
  Jun 15 12:53:02.815: INFO: (19) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:460/proxy/: tls baz (200; 4.429504ms)
  Jun 15 12:53:02.815: INFO: (19) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname1/proxy/: foo (200; 4.980082ms)
  Jun 15 12:53:02.816: INFO: (19) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:162/proxy/: bar (200; 5.768844ms)
  Jun 15 12:53:02.817: INFO: (19) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:160/proxy/: foo (200; 6.159878ms)
  Jun 15 12:53:02.817: INFO: (19) /api/v1/namespaces/proxy-1585/pods/https:proxy-service-g68n8-r594s:462/proxy/: tls qux (200; 6.602417ms)
  Jun 15 12:53:02.817: INFO: (19) /api/v1/namespaces/proxy-1585/services/proxy-service-g68n8:portname2/proxy/: bar (200; 6.508831ms)
  Jun 15 12:53:02.817: INFO: (19) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s/proxy/rewriteme">test</a> (200; 7.133062ms)
  Jun 15 12:53:02.818: INFO: (19) /api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/: <a href="/api/v1/namespaces/proxy-1585/pods/proxy-service-g68n8-r594s:1080/proxy/rewriteme">test<... (200; 7.259095ms)
  Jun 15 12:53:02.818: INFO: (19) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname1/proxy/: tls baz (200; 7.331089ms)
  Jun 15 12:53:02.818: INFO: (19) /api/v1/namespaces/proxy-1585/pods/http:proxy-service-g68n8-r594s:162/proxy/: bar (200; 7.176428ms)
  Jun 15 12:53:02.818: INFO: (19) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname2/proxy/: bar (200; 7.685418ms)
  Jun 15 12:53:02.818: INFO: (19) /api/v1/namespaces/proxy-1585/services/https:proxy-service-g68n8:tlsportname2/proxy/: tls qux (200; 7.721959ms)
  Jun 15 12:53:02.818: INFO: (19) /api/v1/namespaces/proxy-1585/services/http:proxy-service-g68n8:portname1/proxy/: foo (200; 7.957522ms)
  STEP: deleting ReplicationController proxy-service-g68n8 in namespace proxy-1585, will wait for the garbage collector to delete the pods @ 06/15/24 12:53:02.818
  Jun 15 12:53:02.880: INFO: Deleting ReplicationController proxy-service-g68n8 took: 6.795122ms
  Jun 15 12:53:02.980: INFO: Terminating ReplicationController proxy-service-g68n8 pods took: 100.608509ms
  E0615 12:53:03.254279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:04.254629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:05.181: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-1585" for this suite. @ 06/15/24 12:53:05.185
• [4.645 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 06/15/24 12:53:05.191
  Jun 15 12:53:05.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename daemonsets @ 06/15/24 12:53:05.192
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:05.208
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:05.21
  Jun 15 12:53:05.235: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 06/15/24 12:53:05.24
  Jun 15 12:53:05.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:53:05.244: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 06/15/24 12:53:05.244
  E0615 12:53:05.254812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:05.267: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:53:05.267: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  E0615 12:53:06.255026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:06.267: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:53:06.267: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  E0615 12:53:07.255786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:07.268: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Jun 15 12:53:07.268: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 06/15/24 12:53:07.273
  Jun 15 12:53:07.296: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Jun 15 12:53:07.296: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0615 12:53:08.255899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:08.289: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:53:08.289: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 06/15/24 12:53:08.289
  Jun 15 12:53:08.300: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:53:08.300: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  E0615 12:53:09.255997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:09.300: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:53:09.300: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  E0615 12:53:10.256773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:10.300: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Jun 15 12:53:10.300: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 06/15/24 12:53:10.306
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8180, will wait for the garbage collector to delete the pods @ 06/15/24 12:53:10.306
  Jun 15 12:53:10.366: INFO: Deleting DaemonSet.extensions daemon-set took: 6.500903ms
  Jun 15 12:53:10.467: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.969235ms
  E0615 12:53:11.257100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:11.373: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 12:53:11.373: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Jun 15 12:53:11.376: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25963"},"items":null}

  Jun 15 12:53:11.379: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25963"},"items":null}

  Jun 15 12:53:11.403: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8180" for this suite. @ 06/15/24 12:53:11.408
• [6.228 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 06/15/24 12:53:11.42
  Jun 15 12:53:11.420: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sysctl @ 06/15/24 12:53:11.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:11.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:11.439
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 06/15/24 12:53:11.442
  STEP: Watching for error events or started pod @ 06/15/24 12:53:11.45
  E0615 12:53:12.258002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:13.258140      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 06/15/24 12:53:13.455
  STEP: Checking that the pod succeeded @ 06/15/24 12:53:13.463
  STEP: Getting logs from the pod @ 06/15/24 12:53:13.463
  STEP: Checking that the sysctl is actually updated @ 06/15/24 12:53:13.469
  Jun 15 12:53:13.470: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-4903" for this suite. @ 06/15/24 12:53:13.473
• [2.062 seconds]
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 06/15/24 12:53:13.481
  Jun 15 12:53:13.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename lease-test @ 06/15/24 12:53:13.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:13.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:13.496
  Jun 15 12:53:13.558: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-6883" for this suite. @ 06/15/24 12:53:13.561
• [0.087 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 06/15/24 12:53:13.569
  Jun 15 12:53:13.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename namespaces @ 06/15/24 12:53:13.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:13.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:13.587
  STEP: Creating namespace "e2e-ns-c6w6f" @ 06/15/24 12:53:13.59
  Jun 15 12:53:13.602: INFO: Namespace "e2e-ns-c6w6f-1614" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-c6w6f-1614" @ 06/15/24 12:53:13.602
  Jun 15 12:53:13.612: INFO: Namespace "e2e-ns-c6w6f-1614" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-c6w6f-1614" @ 06/15/24 12:53:13.612
  Jun 15 12:53:13.621: INFO: Namespace "e2e-ns-c6w6f-1614" has []v1.FinalizerName{"kubernetes"}
  Jun 15 12:53:13.621: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8669" for this suite. @ 06/15/24 12:53:13.626
  STEP: Destroying namespace "e2e-ns-c6w6f-1614" for this suite. @ 06/15/24 12:53:13.637
• [0.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 06/15/24 12:53:13.645
  Jun 15 12:53:13.645: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename dns @ 06/15/24 12:53:13.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:13.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:13.662
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 06/15/24 12:53:13.665
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 06/15/24 12:53:13.665
  STEP: creating a pod to probe DNS @ 06/15/24 12:53:13.665
  STEP: submitting the pod to kubernetes @ 06/15/24 12:53:13.665
  E0615 12:53:14.258934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:15.259116      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 06/15/24 12:53:15.685
  STEP: looking for the results for each expected name from probers @ 06/15/24 12:53:15.69
  Jun 15 12:53:15.705: INFO: DNS probes using dns-4298/dns-test-9f3e20aa-acad-425e-9152-4b9922ad68e7 succeeded

  STEP: deleting the pod @ 06/15/24 12:53:15.705
  Jun 15 12:53:15.718: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4298" for this suite. @ 06/15/24 12:53:15.722
• [2.083 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:163
  STEP: Creating a kubernetes client @ 06/15/24 12:53:15.728
  Jun 15 12:53:15.728: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename svcaccounts @ 06/15/24 12:53:15.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:15.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:15.745
  Jun 15 12:53:15.766: INFO: created pod pod-service-account-defaultsa
  Jun 15 12:53:15.766: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Jun 15 12:53:15.774: INFO: created pod pod-service-account-mountsa
  Jun 15 12:53:15.774: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Jun 15 12:53:15.784: INFO: created pod pod-service-account-nomountsa
  Jun 15 12:53:15.784: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Jun 15 12:53:15.793: INFO: created pod pod-service-account-defaultsa-mountspec
  Jun 15 12:53:15.793: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Jun 15 12:53:15.800: INFO: created pod pod-service-account-mountsa-mountspec
  Jun 15 12:53:15.800: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Jun 15 12:53:15.809: INFO: created pod pod-service-account-nomountsa-mountspec
  Jun 15 12:53:15.809: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Jun 15 12:53:15.815: INFO: created pod pod-service-account-defaultsa-nomountspec
  Jun 15 12:53:15.815: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Jun 15 12:53:15.825: INFO: created pod pod-service-account-mountsa-nomountspec
  Jun 15 12:53:15.825: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Jun 15 12:53:15.838: INFO: created pod pod-service-account-nomountsa-nomountspec
  Jun 15 12:53:15.838: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Jun 15 12:53:15.838: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7926" for this suite. @ 06/15/24 12:53:15.845
• [0.128 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 06/15/24 12:53:15.857
  Jun 15 12:53:15.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 12:53:15.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:15.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:15.877
  Jun 15 12:53:15.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: creating the pod @ 06/15/24 12:53:15.88
  STEP: submitting the pod to kubernetes @ 06/15/24 12:53:15.881
  E0615 12:53:16.259270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:17.259344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:17.958: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7818" for this suite. @ 06/15/24 12:53:17.961
• [2.113 seconds]
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:214
  STEP: Creating a kubernetes client @ 06/15/24 12:53:17.97
  Jun 15 12:53:17.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 06/15/24 12:53:17.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:17.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:17.99
  STEP: create the container to handle the HTTPGet hook request. @ 06/15/24 12:53:17.997
  E0615 12:53:18.259913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:19.259990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 06/15/24 12:53:20.02
  E0615 12:53:20.260668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:21.260745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 06/15/24 12:53:22.044
  E0615 12:53:22.261094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:23.261184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 06/15/24 12:53:24.06
  Jun 15 12:53:24.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1454" for this suite. @ 06/15/24 12:53:24.077
• [6.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 06/15/24 12:53:24.084
  Jun 15 12:53:24.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 12:53:24.085
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:53:24.104
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:53:24.107
  STEP: Creating pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705 @ 06/15/24 12:53:24.11
  E0615 12:53:24.261801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:25.261834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 06/15/24 12:53:26.128
  Jun 15 12:53:26.131: INFO: Initial restart count of pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 is 0
  Jun 15 12:53:26.135: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:26.262108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:27.263152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:28.141: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:28.263224      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:29.263292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:30.145: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:30.263986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:31.264115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:32.152: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:32.264773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:33.264874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:34.156: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:34.264925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:35.265931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:36.161: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:36.266820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:37.266973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:38.167: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:38.267961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:39.268195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:40.172: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:40.268938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:41.269166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:42.179: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:42.269540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:43.269866      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:44.184: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:44.270894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:45.271073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:46.190: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:46.271560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:47.271718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:48.194: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:48.272791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:49.273062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:50.199: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:50.274144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:51.274402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:52.205: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:52.275276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:53.275295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:54.209: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:54.275627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:55.276455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:56.215: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:56.277369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:57.277438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:53:58.219: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:53:58.278075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:53:59.278638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:00.224: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:00.279305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:01.279401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:02.229: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:02.279903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:03.280369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:04.234: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:04.280762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:05.281022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:06.239: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:06.281142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:07.281232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:08.244: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:08.281657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:09.281977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:10.249: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:10.282389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:11.282635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:12.254: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:12.283352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:13.284448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:14.258: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:14.284968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:15.285171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:16.265: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:16.285493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:17.285595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:18.270: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:18.285758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:19.286054      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:20.274: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:20.287023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:21.287117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:22.281: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:22.287232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:23.287294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:24.285: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:24.287652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:25.287800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:26.288040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:26.291: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:27.288195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:28.288486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:28.296: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:29.289097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:30.289312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:30.300: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:31.290196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:32.290701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:32.305: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:33.290929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:34.291195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:34.311: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:35.291310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:36.292339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:36.315: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:37.292432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:38.292529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:38.321: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:39.293449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:40.293636      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:40.325: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:41.293881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:42.293959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:42.331: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:43.294234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:44.294324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:44.335: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:45.294373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:46.294972      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:46.341: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:47.295071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:48.295318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:48.345: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:49.296361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:50.296572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:50.351: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:51.297443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:52.297535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:52.357: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:53.297679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:54.298494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:54.361: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:55.298806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:56.298890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:56.367: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:57.299579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:54:58.299899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:54:58.372: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:54:59.300192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:00.300404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:00.377: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:01.300617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:02.300734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:02.382: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:03.301106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:04.301214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:04.387: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:05.301427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:06.302255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:06.391: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:07.302978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:08.303300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:08.398: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:09.303389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:10.303492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:10.403: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:11.303589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:12.304002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:12.412: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:13.304615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:14.304838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:14.417: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:15.305071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:16.305573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:16.422: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:17.305675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:18.306650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:18.427: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:19.306747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:20.306925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:20.432: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:21.307432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:22.307536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:22.438: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:23.307633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:24.308454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:24.443: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:25.308544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:26.309512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:26.449: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:27.310280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:28.310462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:28.454: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:29.311209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:30.311324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:30.458: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:31.312352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:32.312599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:32.465: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:33.313035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:34.313133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:34.471: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:35.313439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:36.313916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:36.476: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:37.313994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:38.315029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:38.481: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:39.315264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:40.315293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:40.486: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:41.315489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:42.315537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:42.492: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:43.316143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:44.316251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:44.496: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:45.316668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:46.317023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:46.501: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:47.317792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:48.318594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:48.505: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:49.318715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:50.318811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:50.510: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:51.319026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:52.319076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:52.517: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:53.319263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:54.319333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:54.522: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:55.319436      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:56.319813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:56.526: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:57.319851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:55:58.320401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:55:58.532: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:55:59.320653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:00.320837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:00.537: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:01.321230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:02.321327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:02.541: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:03.321423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:04.321752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:04.547: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:05.321865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:06.322170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:06.552: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:07.322285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:08.322489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:08.558: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:09.323199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:10.323361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:10.563: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:11.323715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:12.324569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:12.569: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:13.325341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:14.325439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:14.574: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:15.325537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:16.325970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:16.579: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:17.326076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:18.326534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:18.584: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:19.327268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:20.327374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:20.588: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:21.328349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:22.328976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:22.596: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:23.329814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:24.330022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:24.601: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:25.330098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:26.330998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:26.606: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:27.331300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:28.332359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:28.611: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:29.332462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:30.332701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:30.616: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:31.333727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:32.334010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:32.621: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:33.334134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:34.334406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:34.627: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:35.334488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:36.334714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:36.633: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:37.334880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:38.335631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:38.638: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:39.335666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:40.335774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:40.643: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:41.336372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:42.337442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:42.647: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:43.337917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:44.338537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:44.652: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:45.338619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:46.338880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:46.657: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:47.339288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:48.339409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:48.663: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:49.339506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:50.340372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:50.668: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:51.340449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:52.340619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:52.672: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:53.340737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:54.340932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:54.679: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:55.341983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:56.342232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:56.684: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:57.342353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:56:58.342463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:56:58.689: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:56:59.342877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:00.343087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:00.694: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:01.343304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:02.343392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:02.699: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:03.343806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:04.344357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:04.703: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:05.344398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:06.344888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:06.709: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:07.345504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:08.346324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:08.714: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:09.346905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:10.347023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:10.720: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:11.347801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:12.347893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:12.724: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:13.347988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:14.348175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:14.730: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:15.348413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:16.348980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:16.735: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:17.349082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:18.349263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:18.739: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:19.349670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:20.350402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:20.745: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:21.350916      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:22.351121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:22.750: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:23.351484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:24.351702      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:24.756: INFO: Get pod test-webserver-7acfc9ac-18d4-4900-8360-c16d23ada3c1 in namespace container-probe-1705
  E0615 12:57:25.352052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:26.353009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 06/15/24 12:57:26.756
  Jun 15 12:57:26.771: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-1705" for this suite. @ 06/15/24 12:57:26.774
• [242.697 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 06/15/24 12:57:26.782
  Jun 15 12:57:26.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-runtime @ 06/15/24 12:57:26.782
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:57:26.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:57:26.801
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 06/15/24 12:57:26.813
  E0615 12:57:27.353873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:28.354798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:29.354970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:30.355276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:31.355739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:32.355841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:33.355944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:34.356030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:35.356340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:36.356964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:37.357928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:38.358788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:39.359692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:40.359783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 06/15/24 12:57:40.893
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 06/15/24 12:57:40.897
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 06/15/24 12:57:40.905
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 06/15/24 12:57:40.905
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 06/15/24 12:57:40.932
  E0615 12:57:41.359870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:42.360348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 06/15/24 12:57:42.947
  E0615 12:57:43.360473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 06/15/24 12:57:43.955
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 06/15/24 12:57:43.961
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 06/15/24 12:57:43.961
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 06/15/24 12:57:43.981
  E0615 12:57:44.360558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 06/15/24 12:57:44.993
  E0615 12:57:45.361400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:46.362292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 06/15/24 12:57:47.007
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 06/15/24 12:57:47.015
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 06/15/24 12:57:47.015
  Jun 15 12:57:47.038: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4573" for this suite. @ 06/15/24 12:57:47.043
• [20.269 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:357
  STEP: Creating a kubernetes client @ 06/15/24 12:57:47.051
  Jun 15 12:57:47.051: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 12:57:47.051
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:57:47.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:57:47.07
  STEP: creating a replication controller @ 06/15/24 12:57:47.073
  Jun 15 12:57:47.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 create -f -'
  Jun 15 12:57:47.152: INFO: stderr: ""
  Jun 15 12:57:47.152: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 06/15/24 12:57:47.152
  Jun 15 12:57:47.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Jun 15 12:57:47.202: INFO: stderr: ""
  Jun 15 12:57:47.202: INFO: stdout: "update-demo-nautilus-l2lsv update-demo-nautilus-rjvm6 "
  Jun 15 12:57:47.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-l2lsv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:57:47.245: INFO: stderr: ""
  Jun 15 12:57:47.245: INFO: stdout: ""
  Jun 15 12:57:47.245: INFO: update-demo-nautilus-l2lsv is created but not running
  E0615 12:57:47.363106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:48.363279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:49.364319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:50.364626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:51.364699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:52.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Jun 15 12:57:52.290: INFO: stderr: ""
  Jun 15 12:57:52.290: INFO: stdout: "update-demo-nautilus-l2lsv update-demo-nautilus-rjvm6 "
  Jun 15 12:57:52.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-l2lsv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:57:52.334: INFO: stderr: ""
  Jun 15 12:57:52.334: INFO: stdout: "true"
  Jun 15 12:57:52.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-l2lsv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0615 12:57:52.366987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:52.379: INFO: stderr: ""
  Jun 15 12:57:52.379: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Jun 15 12:57:52.379: INFO: validating pod update-demo-nautilus-l2lsv
  Jun 15 12:57:52.385: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Jun 15 12:57:52.385: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Jun 15 12:57:52.385: INFO: update-demo-nautilus-l2lsv is verified up and running
  Jun 15 12:57:52.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-rjvm6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:57:52.432: INFO: stderr: ""
  Jun 15 12:57:52.432: INFO: stdout: "true"
  Jun 15 12:57:52.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-rjvm6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Jun 15 12:57:52.476: INFO: stderr: ""
  Jun 15 12:57:52.476: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Jun 15 12:57:52.477: INFO: validating pod update-demo-nautilus-rjvm6
  Jun 15 12:57:52.482: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Jun 15 12:57:52.482: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Jun 15 12:57:52.482: INFO: update-demo-nautilus-rjvm6 is verified up and running
  STEP: scaling down the replication controller @ 06/15/24 12:57:52.482
  Jun 15 12:57:52.483: INFO: scanned /root for discovery docs: <nil>
  Jun 15 12:57:52.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0615 12:57:53.367548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:53.546: INFO: stderr: ""
  Jun 15 12:57:53.546: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 06/15/24 12:57:53.546
  Jun 15 12:57:53.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Jun 15 12:57:53.593: INFO: stderr: ""
  Jun 15 12:57:53.593: INFO: stdout: "update-demo-nautilus-l2lsv update-demo-nautilus-rjvm6 "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 06/15/24 12:57:53.593
  E0615 12:57:54.367636      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:55.367715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:56.367837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:57.367949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:57:58.368021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:58.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Jun 15 12:57:58.638: INFO: stderr: ""
  Jun 15 12:57:58.638: INFO: stdout: "update-demo-nautilus-rjvm6 "
  Jun 15 12:57:58.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-rjvm6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:57:58.682: INFO: stderr: ""
  Jun 15 12:57:58.682: INFO: stdout: "true"
  Jun 15 12:57:58.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-rjvm6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Jun 15 12:57:58.725: INFO: stderr: ""
  Jun 15 12:57:58.725: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Jun 15 12:57:58.725: INFO: validating pod update-demo-nautilus-rjvm6
  Jun 15 12:57:58.729: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Jun 15 12:57:58.729: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Jun 15 12:57:58.729: INFO: update-demo-nautilus-rjvm6 is verified up and running
  STEP: scaling up the replication controller @ 06/15/24 12:57:58.729
  Jun 15 12:57:58.730: INFO: scanned /root for discovery docs: <nil>
  Jun 15 12:57:58.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0615 12:57:59.368381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:57:59.793: INFO: stderr: ""
  Jun 15 12:57:59.793: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 06/15/24 12:57:59.793
  Jun 15 12:57:59.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Jun 15 12:57:59.838: INFO: stderr: ""
  Jun 15 12:57:59.838: INFO: stdout: "update-demo-nautilus-kkc7z update-demo-nautilus-rjvm6 "
  Jun 15 12:57:59.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-kkc7z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:57:59.883: INFO: stderr: ""
  Jun 15 12:57:59.883: INFO: stdout: "true"
  Jun 15 12:57:59.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-kkc7z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Jun 15 12:57:59.926: INFO: stderr: ""
  Jun 15 12:57:59.926: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Jun 15 12:57:59.926: INFO: validating pod update-demo-nautilus-kkc7z
  Jun 15 12:57:59.931: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Jun 15 12:57:59.931: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Jun 15 12:57:59.931: INFO: update-demo-nautilus-kkc7z is verified up and running
  Jun 15 12:57:59.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-rjvm6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Jun 15 12:57:59.975: INFO: stderr: ""
  Jun 15 12:57:59.975: INFO: stdout: "true"
  Jun 15 12:57:59.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods update-demo-nautilus-rjvm6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Jun 15 12:58:00.019: INFO: stderr: ""
  Jun 15 12:58:00.019: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Jun 15 12:58:00.019: INFO: validating pod update-demo-nautilus-rjvm6
  Jun 15 12:58:00.023: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Jun 15 12:58:00.023: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Jun 15 12:58:00.023: INFO: update-demo-nautilus-rjvm6 is verified up and running
  STEP: using delete to clean up resources @ 06/15/24 12:58:00.023
  Jun 15 12:58:00.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 delete --grace-period=0 --force -f -'
  Jun 15 12:58:00.072: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 12:58:00.072: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Jun 15 12:58:00.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get rc,svc -l name=update-demo --no-headers'
  Jun 15 12:58:00.135: INFO: stderr: "No resources found in kubectl-4320 namespace.\n"
  Jun 15 12:58:00.135: INFO: stdout: ""
  Jun 15 12:58:00.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4320 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Jun 15 12:58:00.213: INFO: stderr: ""
  Jun 15 12:58:00.213: INFO: stdout: ""
  Jun 15 12:58:00.213: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4320" for this suite. @ 06/15/24 12:58:00.218
• [13.177 seconds]
------------------------------
S
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 06/15/24 12:58:00.228
  Jun 15 12:58:00.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename controllerrevisions @ 06/15/24 12:58:00.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:58:00.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:58:00.249
  STEP: Creating DaemonSet "e2e-95s9j-daemon-set" @ 06/15/24 12:58:00.271
  STEP: Check that daemon pods launch on every node of the cluster. @ 06/15/24 12:58:00.276
  Jun 15 12:58:00.281: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:58:00.281: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:58:00.284: INFO: Number of nodes with available pods controlled by daemonset e2e-95s9j-daemon-set: 0
  Jun 15 12:58:00.284: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 12:58:00.369213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:01.282: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:58:01.282: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:58:01.286: INFO: Number of nodes with available pods controlled by daemonset e2e-95s9j-daemon-set: 0
  Jun 15 12:58:01.286: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 12:58:01.369257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:02.281: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:58:02.281: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 12:58:02.285: INFO: Number of nodes with available pods controlled by daemonset e2e-95s9j-daemon-set: 3
  Jun 15 12:58:02.285: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-95s9j-daemon-set
  STEP: Confirm DaemonSet "e2e-95s9j-daemon-set" successfully created with "daemonset-name=e2e-95s9j-daemon-set" label @ 06/15/24 12:58:02.289
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-95s9j-daemon-set" @ 06/15/24 12:58:02.294
  Jun 15 12:58:02.297: INFO: Located ControllerRevision: "e2e-95s9j-daemon-set-75fff8c75"
  STEP: Patching ControllerRevision "e2e-95s9j-daemon-set-75fff8c75" @ 06/15/24 12:58:02.301
  Jun 15 12:58:02.308: INFO: e2e-95s9j-daemon-set-75fff8c75 has been patched
  STEP: Create a new ControllerRevision @ 06/15/24 12:58:02.308
  Jun 15 12:58:02.313: INFO: Created ControllerRevision: e2e-95s9j-daemon-set-74c747bdc9
  STEP: Confirm that there are two ControllerRevisions @ 06/15/24 12:58:02.313
  Jun 15 12:58:02.313: INFO: Requesting list of ControllerRevisions to confirm quantity
  Jun 15 12:58:02.317: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-95s9j-daemon-set-75fff8c75" @ 06/15/24 12:58:02.317
  STEP: Confirm that there is only one ControllerRevision @ 06/15/24 12:58:02.323
  Jun 15 12:58:02.323: INFO: Requesting list of ControllerRevisions to confirm quantity
  Jun 15 12:58:02.327: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-95s9j-daemon-set-74c747bdc9" @ 06/15/24 12:58:02.33
  Jun 15 12:58:02.338: INFO: e2e-95s9j-daemon-set-74c747bdc9 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 06/15/24 12:58:02.338
  W0615 12:58:02.345188      19 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 06/15/24 12:58:02.345
  Jun 15 12:58:02.345: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0615 12:58:02.369985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:03.345: INFO: Requesting list of ControllerRevisions to confirm quantity
  Jun 15 12:58:03.350: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-95s9j-daemon-set-74c747bdc9=updated" @ 06/15/24 12:58:03.35
  STEP: Confirm that there is only one ControllerRevision @ 06/15/24 12:58:03.358
  Jun 15 12:58:03.358: INFO: Requesting list of ControllerRevisions to confirm quantity
  Jun 15 12:58:03.361: INFO: Found 1 ControllerRevisions
  Jun 15 12:58:03.364: INFO: ControllerRevision "e2e-95s9j-daemon-set-6cd8785db" has revision 3
  STEP: Deleting DaemonSet "e2e-95s9j-daemon-set" @ 06/15/24 12:58:03.366
  STEP: deleting DaemonSet.extensions e2e-95s9j-daemon-set in namespace controllerrevisions-8178, will wait for the garbage collector to delete the pods @ 06/15/24 12:58:03.366
  E0615 12:58:03.370399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:03.427: INFO: Deleting DaemonSet.extensions e2e-95s9j-daemon-set took: 5.952772ms
  Jun 15 12:58:03.528: INFO: Terminating DaemonSet.extensions e2e-95s9j-daemon-set pods took: 101.220198ms
  E0615 12:58:04.370613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:04.833: INFO: Number of nodes with available pods controlled by daemonset e2e-95s9j-daemon-set: 0
  Jun 15 12:58:04.833: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-95s9j-daemon-set
  Jun 15 12:58:04.837: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"27235"},"items":null}

  Jun 15 12:58:04.840: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"27235"},"items":null}

  Jun 15 12:58:04.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-8178" for this suite. @ 06/15/24 12:58:04.857
• [4.637 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 06/15/24 12:58:04.865
  Jun 15 12:58:04.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename watch @ 06/15/24 12:58:04.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:58:04.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:58:04.888
  STEP: creating a new configmap @ 06/15/24 12:58:04.895
  STEP: modifying the configmap once @ 06/15/24 12:58:04.904
  STEP: modifying the configmap a second time @ 06/15/24 12:58:04.915
  STEP: deleting the configmap @ 06/15/24 12:58:04.928
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 06/15/24 12:58:04.936
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 06/15/24 12:58:04.937
  Jun 15 12:58:04.937: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5389  149c8667-8c15-447e-a57e-adb9eaeab2e3 27244 0 2024-06-15 12:58:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-06-15 12:58:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:58:04.937: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5389  149c8667-8c15-447e-a57e-adb9eaeab2e3 27245 0 2024-06-15 12:58:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-06-15 12:58:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 12:58:04.938: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5389" for this suite. @ 06/15/24 12:58:04.942
• [0.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 06/15/24 12:58:04.951
  Jun 15 12:58:04.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename init-container @ 06/15/24 12:58:04.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:58:04.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:58:04.974
  STEP: creating the pod @ 06/15/24 12:58:04.978
  Jun 15 12:58:04.978: INFO: PodSpec: initContainers in spec.initContainers
  E0615 12:58:05.370747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:06.370835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:07.371304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:08.372339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:08.777: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3253" for this suite. @ 06/15/24 12:58:08.782
• [3.838 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 06/15/24 12:58:08.789
  Jun 15 12:58:08.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replication-controller @ 06/15/24 12:58:08.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:58:08.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:58:08.806
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 06/15/24 12:58:08.809
  E0615 12:58:09.373334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:10.373647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 06/15/24 12:58:10.836
  STEP: Then the orphan pod is adopted @ 06/15/24 12:58:10.843
  E0615 12:58:11.373693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:11.852: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5283" for this suite. @ 06/15/24 12:58:11.856
• [3.075 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 06/15/24 12:58:11.864
  Jun 15 12:58:11.864: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename deployment @ 06/15/24 12:58:11.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:58:11.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:58:11.88
  Jun 15 12:58:11.890: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E0615 12:58:12.374233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:13.374325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:14.374942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:15.375122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:16.375807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:16.895: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 06/15/24 12:58:16.895
  Jun 15 12:58:16.895: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 06/15/24 12:58:16.905
  E0615 12:58:17.375924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:18.376216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:18.928: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5821",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cb24b1a0-ecaf-42ee-a2f9-695bcef6eef9",
      ResourceVersion: (string) (len=5) "27472",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854053096,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053096,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053096,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053096,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053096,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-cleanup-deployment-7bc75bbdf6\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Jun 15 12:58:18.933: INFO: New ReplicaSet "test-cleanup-deployment-7bc75bbdf6" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-7bc75bbdf6",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5821",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "61ef7ade-a854-4644-9eba-06000b5d6140",
      ResourceVersion: (string) (len=5) "27459",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854053096,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "cb24b1a0-ecaf-42ee-a2f9-695bcef6eef9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053096,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 62 32 34 62 31  61 30 2d 65 63 61 66 2d  |\"cb24b1a0-ecaf-|
              00000120  34 32 65 65 2d 61 32 66  39 2d 36 39 35 62 63 65  |42ee-a2f9-695bce|
              00000130  66 36 65 65 66 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f6eef9\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 12:58:18.938: INFO: Pod "test-cleanup-deployment-7bc75bbdf6-hqdxm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-7bc75bbdf6-hqdxm",
      GenerateName: (string) (len=35) "test-cleanup-deployment-7bc75bbdf6-",
      Namespace: (string) (len=15) "deployment-5821",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7ec7afaf-b1e7-4c59-badc-63464f401c31",
      ResourceVersion: (string) (len=5) "27458",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854053096,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7bc75bbdf6"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-7bc75bbdf6",
          UID: (types.UID) (len=36) "61ef7ade-a854-4644-9eba-06000b5d6140",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053096,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 36 31  65 66 37 61 64 65 2d 61  |d\":\"61ef7ade-a|
              00000090  38 35 34 2d 34 36 34 34  2d 39 65 62 61 2d 30 36  |854-4644-9eba-06|
              000000a0  30 30 30 62 35 64 36 31  34 30 5c 22 7d 22 3a 7b  |000b5d6140\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  34 2e 31 36 30 5c 22 7d  |2.168.164.160\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s4h75",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s4h75",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053096,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053097,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854053096,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) (len=15) "192.168.164.160",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.164.160"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854053096,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854053097,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253",
          ContainerID: (string) (len=77) "containerd://0be648bdcaf6a114e7740c92325adb35e4b10158f5f8432f8e0e94f0ec5c85dc",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 12:58:18.939: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5821" for this suite. @ 06/15/24 12:58:18.942
• [7.085 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:751
  STEP: Creating a kubernetes client @ 06/15/24 12:58:18.95
  Jun 15 12:58:18.950: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename statefulset @ 06/15/24 12:58:18.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:58:18.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:58:18.965
  STEP: Creating service test in namespace statefulset-5188 @ 06/15/24 12:58:18.968
  STEP: Creating stateful set ss in namespace statefulset-5188 @ 06/15/24 12:58:18.974
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5188 @ 06/15/24 12:58:18.981
  Jun 15 12:58:18.988: INFO: Found 0 stateful pods, waiting for 1
  E0615 12:58:19.377161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:20.378177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:21.378278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:22.378526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:23.378602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:24.378693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:25.378827      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:26.378889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:27.378962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:28.379062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:28.986: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 06/15/24 12:58:28.986
  Jun 15 12:58:28.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-5188 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 12:58:29.092: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 12:58:29.092: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 12:58:29.092: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Jun 15 12:58:29.095: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0615 12:58:29.380056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:30.380152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:31.380298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:32.380371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:33.381477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:34.381599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:35.381675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:36.381799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:37.381935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:38.382017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:39.097: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Jun 15 12:58:39.097: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Jun 15 12:58:39.113: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
  Jun 15 12:58:39.113: INFO: ss-0  ip-172-31-43-132  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:19 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:18 +0000 UTC  }]
  Jun 15 12:58:39.113: INFO: 
  Jun 15 12:58:39.113: INFO: StatefulSet ss has not reached scale 3, at 1
  E0615 12:58:39.382799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:40.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996934s
  E0615 12:58:40.382895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:41.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991273073s
  E0615 12:58:41.383643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:42.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985999599s
  E0615 12:58:42.384014      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:43.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981599062s
  E0615 12:58:43.384840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:44.141: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974817883s
  E0615 12:58:44.385864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:45.147: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968586693s
  E0615 12:58:45.386703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:46.152: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.962801978s
  E0615 12:58:46.387020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:47.157: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95660132s
  E0615 12:58:47.387107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:48.163: INFO: Verifying statefulset ss doesn't scale past 3 for another 952.081753ms
  E0615 12:58:48.388142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5188 @ 06/15/24 12:58:49.164
  Jun 15 12:58:49.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-5188 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Jun 15 12:58:49.262: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Jun 15 12:58:49.263: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 12:58:49.263: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Jun 15 12:58:49.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-5188 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Jun 15 12:58:49.372: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Jun 15 12:58:49.372: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 12:58:49.372: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Jun 15 12:58:49.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-5188 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0615 12:58:49.388857      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:49.468: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Jun 15 12:58:49.468: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 12:58:49.468: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Jun 15 12:58:49.474: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 12:58:49.474: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 12:58:49.474: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 06/15/24 12:58:49.474
  Jun 15 12:58:49.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-5188 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 12:58:49.577: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 12:58:49.577: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 12:58:49.577: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Jun 15 12:58:49.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-5188 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 12:58:49.674: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 12:58:49.674: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 12:58:49.674: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Jun 15 12:58:49.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-5188 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 12:58:49.779: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 12:58:49.779: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 12:58:49.779: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Jun 15 12:58:49.779: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Jun 15 12:58:49.783: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0615 12:58:50.389363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:51.389456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:52.389581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:53.389770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:54.389983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:55.390152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:56.391115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:57.391258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:58.391357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:58:59.392327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:58:59.790: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Jun 15 12:58:59.790: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Jun 15 12:58:59.790: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Jun 15 12:58:59.803: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
  Jun 15 12:58:59.803: INFO: ss-0  ip-172-31-43-132  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:19 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:18 +0000 UTC  }]
  Jun 15 12:58:59.803: INFO: ss-1  ip-172-31-7-7     Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:40 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:39 +0000 UTC  }]
  Jun 15 12:58:59.803: INFO: ss-2  ip-172-31-17-110  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:39 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:39 +0000 UTC  }]
  Jun 15 12:58:59.803: INFO: 
  Jun 15 12:58:59.803: INFO: StatefulSet ss has not reached scale 0, at 3
  E0615 12:59:00.393045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:00.808: INFO: POD   NODE              PHASE      GRACE  CONDITIONS
  Jun 15 12:59:00.808: INFO: ss-0  ip-172-31-43-132  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:59:00 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:19 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:18 +0000 UTC  }]
  Jun 15 12:59:00.808: INFO: ss-2  ip-172-31-17-110  Succeeded  30s    [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:59:00 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:39 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:50 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 12:58:39 +0000 UTC  }]
  Jun 15 12:59:00.808: INFO: 
  Jun 15 12:59:00.808: INFO: StatefulSet ss has not reached scale 0, at 2
  E0615 12:59:01.393153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:01.813: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.98976603s
  E0615 12:59:02.393388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:02.819: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.985290303s
  E0615 12:59:03.394358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:03.824: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.97946897s
  E0615 12:59:04.394864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:04.829: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.974877781s
  E0615 12:59:05.395304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:05.834: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.96932592s
  E0615 12:59:06.396123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:06.838: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.964328311s
  E0615 12:59:07.396332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:07.844: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.960382841s
  E0615 12:59:08.396887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 12:59:08.848: INFO: Verifying statefulset ss doesn't scale past 0 for another 954.783417ms
  E0615 12:59:09.397568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5188 @ 06/15/24 12:59:09.848
  Jun 15 12:59:09.853: INFO: Scaling statefulset ss to 0
  Jun 15 12:59:09.860: INFO: Waiting for statefulset status.replicas updated to 0
  Jun 15 12:59:09.864: INFO: Deleting all statefulset in ns statefulset-5188
  Jun 15 12:59:09.867: INFO: Scaling statefulset ss to 0
  Jun 15 12:59:09.872: INFO: Waiting for statefulset status.replicas updated to 0
  Jun 15 12:59:09.876: INFO: Deleting statefulset ss
  Jun 15 12:59:09.889: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5188" for this suite. @ 06/15/24 12:59:09.893
• [50.949 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:170
  STEP: Creating a kubernetes client @ 06/15/24 12:59:09.9
  Jun 15 12:59:09.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 12:59:09.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:59:09.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:59:09.917
  STEP: creating a ConfigMap @ 06/15/24 12:59:09.92
  STEP: fetching the ConfigMap @ 06/15/24 12:59:09.926
  STEP: patching the ConfigMap @ 06/15/24 12:59:09.929
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 06/15/24 12:59:09.935
  STEP: deleting the ConfigMap by collection with a label selector @ 06/15/24 12:59:09.938
  STEP: listing all ConfigMaps in test namespace @ 06/15/24 12:59:09.946
  Jun 15 12:59:09.949: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5401" for this suite. @ 06/15/24 12:59:09.953
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1838
  STEP: Creating a kubernetes client @ 06/15/24 12:59:09.958
  Jun 15 12:59:09.958: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 12:59:09.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:59:09.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:59:09.976
  STEP: starting the proxy server @ 06/15/24 12:59:09.979
  Jun 15 12:59:09.979: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4552 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 06/15/24 12:59:10.009
  Jun 15 12:59:10.015: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4552" for this suite. @ 06/15/24 12:59:10.02
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 06/15/24 12:59:10.027
  Jun 15 12:59:10.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename cronjob @ 06/15/24 12:59:10.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 12:59:10.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 12:59:10.045
  STEP: Creating a ReplaceConcurrent cronjob @ 06/15/24 12:59:10.048
  STEP: Ensuring a job is scheduled @ 06/15/24 12:59:10.053
  E0615 12:59:10.398212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:11.398294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:12.398833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:13.399662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:14.400030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:15.399819      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:16.400425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:17.400600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:18.401523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:19.401684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:20.401864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:21.402118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:22.402226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:23.402407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:24.403042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:25.403264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:26.404031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:27.404148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:28.404265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:29.404343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:30.404948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:31.405137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:32.405811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:33.405917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:34.406003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:35.406217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:36.407322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:37.407409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:38.408383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:39.408482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:40.408572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:41.408739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:42.408838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:43.409811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:44.410543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:45.410731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:46.410798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:47.411036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:48.411523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:49.411632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:50.412473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:51.412529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:52.412647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:53.412751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:54.413790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:55.413978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:56.414261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:57.414519      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:58.414621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 12:59:59.414744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:00.414954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:01.415269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 06/15/24 13:00:02.058
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 06/15/24 13:00:02.061
  STEP: Ensuring the job is replaced with a new one @ 06/15/24 13:00:02.064
  E0615 13:00:02.416360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:03.417294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:04.418152      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:05.418242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:06.418855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:07.418965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:08.419868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:09.419949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:10.420049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:11.421064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:12.422061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:13.422149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:14.422322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:15.422575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:16.422617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:17.422731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:18.423431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:19.423535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:20.424079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:21.424292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:22.424439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:23.424534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:24.424624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:25.424836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:26.424990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:27.425185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:28.425249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:29.425437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:30.426358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:31.426464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:32.426768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:33.427456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:34.428424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:35.428650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:36.429575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:37.429847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:38.429893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:39.430022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:40.430813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:41.430846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:42.431794      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:43.432371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:44.432468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:45.432693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:46.433681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:47.433800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:48.433989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:49.434087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:50.435083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:51.435282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:52.436373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:53.437350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:54.437447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:55.437539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:56.437611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:57.437810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:58.438357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:00:59.438816      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:00.439575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:01.439665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 06/15/24 13:01:02.071
  Jun 15 13:01:02.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6573" for this suite. @ 06/15/24 13:01:02.082
• [112.063 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 06/15/24 13:01:02.091
  Jun 15 13:01:02.091: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename csi-storageclass @ 06/15/24 13:01:02.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:01:02.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:01:02.114
  STEP: Creating a StorageClass @ 06/15/24 13:01:02.117
  STEP: Get StorageClass "e2e-qgkft" @ 06/15/24 13:01:02.123
  STEP: Patching the StorageClass "e2e-qgkft" @ 06/15/24 13:01:02.126
  STEP: Delete StorageClass "e2e-qgkft" @ 06/15/24 13:01:02.131
  STEP: Confirm deletion of StorageClass "e2e-qgkft" @ 06/15/24 13:01:02.139
  STEP: Create a replacement StorageClass @ 06/15/24 13:01:02.142
  STEP: Updating StorageClass "e2e-v2-vv2bn" @ 06/15/24 13:01:02.147
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-vv2bn=updated" @ 06/15/24 13:01:02.154
  STEP: Deleting StorageClass "e2e-v2-vv2bn" via DeleteCollection @ 06/15/24 13:01:02.158
  STEP: Confirm deletion of StorageClass "e2e-v2-vv2bn" @ 06/15/24 13:01:02.165
  Jun 15 13:01:02.169: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csi-storageclass-4595" for this suite. @ 06/15/24 13:01:02.172
• [0.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
  STEP: Creating a kubernetes client @ 06/15/24 13:01:02.179
  Jun 15 13:01:02.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:01:02.18
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:01:02.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:01:02.196
  STEP: create deployment with httpd image @ 06/15/24 13:01:02.199
  Jun 15 13:01:02.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-7009 create -f -'
  Jun 15 13:01:02.262: INFO: stderr: ""
  Jun 15 13:01:02.262: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 06/15/24 13:01:02.262
  Jun 15 13:01:02.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-7009 diff -f -'
  E0615 13:01:02.439750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:03.440352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:04.440544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:05.440721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:06.440844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:01:06.555: INFO: rc: 1
  Jun 15 13:01:06.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-7009 delete -f -'
  Jun 15 13:01:06.603: INFO: stderr: ""
  Jun 15 13:01:06.603: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Jun 15 13:01:06.603: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7009" for this suite. @ 06/15/24 13:01:06.607
• [4.436 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 06/15/24 13:01:06.615
  Jun 15 13:01:06.615: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 13:01:06.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:01:06.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:01:06.638
  STEP: Creating secret with name secret-test-map-7cb14dc3-ab3d-4ded-8f87-4118ed861c59 @ 06/15/24 13:01:06.641
  STEP: Creating a pod to test consume secrets @ 06/15/24 13:01:06.646
  E0615 13:01:07.441806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:08.441910      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:09.442009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:10.442094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:01:10.671
  Jun 15 13:01:10.675: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-secrets-7e5e5e73-4eec-45a0-a039-3a666c5d10e4 container secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 13:01:10.694
  Jun 15 13:01:10.709: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1485" for this suite. @ 06/15/24 13:01:10.713
• [4.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:669
  STEP: Creating a kubernetes client @ 06/15/24 13:01:10.722
  Jun 15 13:01:10.722: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pv @ 06/15/24 13:01:10.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:01:10.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:01:10.738
  STEP: Creating initial PV and PVC @ 06/15/24 13:01:10.741
  Jun 15 13:01:10.741: INFO: Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-3799" @ 06/15/24 13:01:10.753
  STEP: Listing PVCs in namespace "pv-3799" @ 06/15/24 13:01:10.76
  STEP: Reading "pvc-2r8qw" Status @ 06/15/24 13:01:10.763
  STEP: Reading "pv-3799-5wxtx" Status @ 06/15/24 13:01:10.768
  STEP: Patching "pvc-2r8qw" Status @ 06/15/24 13:01:10.774
  STEP: Patching "pv-3799-5wxtx" Status @ 06/15/24 13:01:10.779
  STEP: Updating "pvc-2r8qw" Status @ 06/15/24 13:01:10.784
  STEP: Updating "pv-3799-5wxtx" Status @ 06/15/24 13:01:10.794
  Jun 15 13:01:10.803: INFO: AfterEach: deleting 1 PVCs and 1 PVs...
  Jun 15 13:01:10.803: INFO: Deleting PersistentVolumeClaim "pvc-2r8qw"
  Jun 15 13:01:10.812: INFO: Deleting PersistentVolume "pv-3799-5wxtx"
  Jun 15 13:01:10.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-3799" for this suite. @ 06/15/24 13:01:10.822
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1798
  STEP: Creating a kubernetes client @ 06/15/24 13:01:10.829
  Jun 15 13:01:10.829: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:01:10.83
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:01:10.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:01:10.848
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 06/15/24 13:01:10.85
  Jun 15 13:01:10.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2468 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Jun 15 13:01:10.902: INFO: stderr: ""
  Jun 15 13:01:10.902: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 06/15/24 13:01:10.902
  E0615 13:01:11.442539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:12.443005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:13.443125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:14.443461      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:15.443452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 06/15/24 13:01:15.953
  Jun 15 13:01:15.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2468 get pod e2e-test-httpd-pod -o json'
  Jun 15 13:01:15.997: INFO: stderr: ""
  Jun 15 13:01:15.997: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-06-15T13:01:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2468\",\n        \"resourceVersion\": \"28290\",\n        \"uid\": \"7f4e278a-00eb-46cf-987b-966f294ea335\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-tqjz4\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-43-132\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-tqjz4\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-06-15T13:01:12Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-06-15T13:01:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-06-15T13:01:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-06-15T13:01:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-06-15T13:01:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9eb2e894e80592a7338dbb84d86950c2417b6be0fb0a0d5def0991048975787c\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-06-15T13:01:11Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.43.132\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"172.31.43.132\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.40.251\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.40.251\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-06-15T13:01:10Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 06/15/24 13:01:15.997
  Jun 15 13:01:15.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2468 replace -f -'
  Jun 15 13:01:16.081: INFO: stderr: ""
  Jun 15 13:01:16.081: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 06/15/24 13:01:16.081
  Jun 15 13:01:16.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-2468 delete pods e2e-test-httpd-pod'
  E0615 13:01:16.444324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:17.444427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:01:18.123: INFO: stderr: ""
  Jun 15 13:01:18.123: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Jun 15 13:01:18.123: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2468" for this suite. @ 06/15/24 13:01:18.128
• [7.306 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 06/15/24 13:01:18.135
  Jun 15 13:01:18.135: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:01:18.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:01:18.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:01:18.153
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-e972dd1f-918d-4f31-94d6-1c036d77dcaf @ 06/15/24 13:01:18.159
  STEP: Creating the pod @ 06/15/24 13:01:18.164
  E0615 13:01:18.445390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:19.445486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-e972dd1f-918d-4f31-94d6-1c036d77dcaf @ 06/15/24 13:01:20.194
  STEP: waiting to observe update in volume @ 06/15/24 13:01:20.199
  E0615 13:01:20.445524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:21.445653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:22.446212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:23.446396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:24.446901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:25.447018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:26.447505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:27.448341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:28.448997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:29.449258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:30.449713      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:31.449792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:32.450110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:33.450289      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:34.450404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:35.450503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:36.451283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:37.451341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:38.452125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:39.452206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:40.452668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:41.452766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:42.453729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:43.453856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:44.454528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:45.454650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:46.455042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:47.455321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:48.455782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:49.455865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:50.456652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:51.456682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:52.457418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:53.457526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:54.457894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:55.458020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:56.458979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:57.459086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:58.459494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:01:59.459567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:00.459667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:01.459739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:02.460493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:03.460707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:04.461091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:05.461185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:06.461725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:07.461828      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:08.462191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:09.462394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:10.462743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:11.462895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:12.463456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:13.464482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:14.464982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:15.465103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:16.466113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:17.466226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:18.466469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:19.466604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:20.466792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:21.466929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:22.467017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:23.467110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:24.467295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:25.467548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:26.468316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:27.468723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:28.468805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:29.468903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:30.469018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:31.469147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:32.469200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:33.469293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:34.469379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:35.469560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:36.470619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:37.470735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:38.470846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:39.470942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:40.471037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:41.471913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:42.472000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:43.473045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:44.473162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:45.473199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:46.474181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:02:46.590: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7438" for this suite. @ 06/15/24 13:02:46.593
• [88.465 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 06/15/24 13:02:46.601
  Jun 15 13:02:46.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 13:02:46.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:02:46.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:02:46.62
  Jun 15 13:02:46.626: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1011" for this suite. @ 06/15/24 13:02:46.63
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3338
  STEP: Creating a kubernetes client @ 06/15/24 13:02:46.641
  Jun 15 13:02:46.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 13:02:46.641
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:02:46.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:02:46.657
  STEP: creating a Service @ 06/15/24 13:02:46.663
  STEP: watching for the Service to be added @ 06/15/24 13:02:46.674
  Jun 15 13:02:46.676: INFO: Found Service test-service-ftvmv in namespace services-7420 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 32519}]
  Jun 15 13:02:46.677: INFO: Service test-service-ftvmv created
  STEP: Getting /status @ 06/15/24 13:02:46.677
  Jun 15 13:02:46.683: INFO: Service test-service-ftvmv has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 06/15/24 13:02:46.683
  STEP: watching for the Service to be patched @ 06/15/24 13:02:46.689
  Jun 15 13:02:46.691: INFO: observed Service test-service-ftvmv in namespace services-7420 with annotations: map[] & LoadBalancer: {[]}
  Jun 15 13:02:46.691: INFO: Found Service test-service-ftvmv in namespace services-7420 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  <nil> []}]}
  Jun 15 13:02:46.691: INFO: Service test-service-ftvmv has service status patched
  STEP: updating the ServiceStatus @ 06/15/24 13:02:46.691
  Jun 15 13:02:46.701: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 06/15/24 13:02:46.702
  Jun 15 13:02:46.703: INFO: Observed Service test-service-ftvmv in namespace services-7420 with annotations: map[] & Conditions: {[]}
  Jun 15 13:02:46.703: INFO: Observed event: &Service{ObjectMeta:{test-service-ftvmv  services-7420  d7a38c43-a363-4661-8027-6486b2b56e7c 28574 0 2024-06-15 13:02:46 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-06-15 13:02:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:allocateLoadBalancerNodePorts":{},"f:externalTrafficPolicy":{},"f:internalTrafficPolicy":{},"f:loadBalancerClass":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-06-15 13:02:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:32519,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.200,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.200],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:*example.com/internal-vip,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,IPMode:nil,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Jun 15 13:02:46.704: INFO: Found Service test-service-ftvmv in namespace services-7420 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Jun 15 13:02:46.704: INFO: Service test-service-ftvmv has service status updated
  STEP: patching the service @ 06/15/24 13:02:46.704
  STEP: watching for the Service to be patched @ 06/15/24 13:02:46.713
  Jun 15 13:02:46.714: INFO: observed Service test-service-ftvmv in namespace services-7420 with labels: map[test-service-static:true]
  Jun 15 13:02:46.714: INFO: observed Service test-service-ftvmv in namespace services-7420 with labels: map[test-service-static:true]
  Jun 15 13:02:46.714: INFO: observed Service test-service-ftvmv in namespace services-7420 with labels: map[test-service-static:true]
  Jun 15 13:02:46.714: INFO: Found Service test-service-ftvmv in namespace services-7420 with labels: map[test-service:patched test-service-static:true]
  Jun 15 13:02:46.714: INFO: Service test-service-ftvmv patched
  STEP: deleting the service @ 06/15/24 13:02:46.714
  STEP: watching for the Service to be deleted @ 06/15/24 13:02:46.735
  Jun 15 13:02:46.737: INFO: Observed event: ADDED
  Jun 15 13:02:46.737: INFO: Observed event: MODIFIED
  Jun 15 13:02:46.737: INFO: Observed event: MODIFIED
  Jun 15 13:02:46.737: INFO: Observed event: MODIFIED
  Jun 15 13:02:46.737: INFO: Found Service test-service-ftvmv in namespace services-7420 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Jun 15 13:02:46.737: INFO: Service test-service-ftvmv deleted
  Jun 15 13:02:46.737: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7420" for this suite. @ 06/15/24 13:02:46.74
• [0.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1731
  STEP: Creating a kubernetes client @ 06/15/24 13:02:46.747
  Jun 15 13:02:46.747: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:02:46.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:02:46.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:02:46.766
  Jun 15 13:02:46.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-6838 version'
  Jun 15 13:02:46.810: INFO: stderr: ""
  Jun 15 13:02:46.810: INFO: stdout: "Client Version: v1.29.6\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.29.6\n"
  Jun 15 13:02:46.810: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6838" for this suite. @ 06/15/24 13:02:46.814
• [0.074 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:321
  STEP: Creating a kubernetes client @ 06/15/24 13:02:46.821
  Jun 15 13:02:46.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename statefulset @ 06/15/24 13:02:46.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:02:46.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:02:46.839
  STEP: Creating service test in namespace statefulset-7239 @ 06/15/24 13:02:46.842
  STEP: Creating a new StatefulSet @ 06/15/24 13:02:46.848
  Jun 15 13:02:46.861: INFO: Found 0 stateful pods, waiting for 3
  E0615 13:02:47.474846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:48.475805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:49.475891      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:50.475964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:51.476081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:52.476171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:53.476599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:54.476786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:55.476964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:56.477047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:02:56.860: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 13:02:56.860: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 13:02:56.860: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 13:02:56.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-7239 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 13:02:56.963: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 13:02:56.963: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 13:02:56.963: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0615 13:02:57.477704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:58.477813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:02:59.478805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:00.478854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:01.478962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:02.479052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:03.479155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:04.479272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:05.479396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:06.479470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 06/15/24 13:03:06.972
  Jun 15 13:03:06.993: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 06/15/24 13:03:06.993
  E0615 13:03:07.479969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:08.480068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:09.480335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:10.480409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:11.480510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:12.480626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:13.480708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:14.481070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:15.480943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:16.481016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 06/15/24 13:03:17.003
  Jun 15 13:03:17.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-7239 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Jun 15 13:03:17.097: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Jun 15 13:03:17.097: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 13:03:17.097: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0615 13:03:17.481398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:18.481518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:19.481691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:20.482717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:21.482821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:22.483156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:23.483273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:24.483365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:25.483458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:26.483557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 06/15/24 13:03:27.111
  Jun 15 13:03:27.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-7239 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Jun 15 13:03:27.200: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Jun 15 13:03:27.200: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Jun 15 13:03:27.200: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0615 13:03:27.484251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:28.484459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:29.484650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:30.484860      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:31.484951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:32.485201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:33.485393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:34.485517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:35.485631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:36.485937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:03:37.230: INFO: Updating stateful set ss2
  E0615 13:03:37.486650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:38.486795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:39.487102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:40.487293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:41.487387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:42.487482      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:43.487563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:44.487669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:45.488604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:46.488976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 06/15/24 13:03:47.24
  Jun 15 13:03:47.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=statefulset-7239 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Jun 15 13:03:47.345: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Jun 15 13:03:47.345: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Jun 15 13:03:47.345: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0615 13:03:47.490081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:48.490785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:49.490852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:50.491050      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:51.491286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:52.491379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:53.491479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:54.491552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:55.491660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:56.492337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:03:57.360: INFO: Deleting all statefulset in ns statefulset-7239
  Jun 15 13:03:57.364: INFO: Scaling statefulset ss2 to 0
  E0615 13:03:57.492698      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:58.492780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:03:59.492873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:00.493003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:01.493085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:02.493355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:03.493455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:04.493653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:05.493757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:06.494101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:04:07.378: INFO: Waiting for statefulset status.replicas updated to 0
  Jun 15 13:04:07.382: INFO: Deleting statefulset ss2
  Jun 15 13:04:07.396: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7239" for this suite. @ 06/15/24 13:04:07.401
• [80.588 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 06/15/24 13:04:07.409
  Jun 15 13:04:07.409: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 13:04:07.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:04:07.421
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:04:07.424
  Jun 15 13:04:07.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:04:07.494302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:08.494934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 06/15/24 13:04:08.687
  Jun 15 13:04:08.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6123 --namespace=crd-publish-openapi-6123 create -f -'
  E0615 13:04:09.495861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:10.496380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:04:10.752: INFO: stderr: ""
  Jun 15 13:04:10.752: INFO: stdout: "e2e-test-crd-publish-openapi-9947-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Jun 15 13:04:10.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6123 --namespace=crd-publish-openapi-6123 delete e2e-test-crd-publish-openapi-9947-crds test-cr'
  Jun 15 13:04:10.802: INFO: stderr: ""
  Jun 15 13:04:10.802: INFO: stdout: "e2e-test-crd-publish-openapi-9947-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Jun 15 13:04:10.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6123 --namespace=crd-publish-openapi-6123 apply -f -'
  Jun 15 13:04:10.868: INFO: stderr: ""
  Jun 15 13:04:10.868: INFO: stdout: "e2e-test-crd-publish-openapi-9947-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Jun 15 13:04:10.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6123 --namespace=crd-publish-openapi-6123 delete e2e-test-crd-publish-openapi-9947-crds test-cr'
  Jun 15 13:04:10.921: INFO: stderr: ""
  Jun 15 13:04:10.921: INFO: stdout: "e2e-test-crd-publish-openapi-9947-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 06/15/24 13:04:10.921
  Jun 15 13:04:10.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-6123 explain e2e-test-crd-publish-openapi-9947-crds'
  Jun 15 13:04:10.963: INFO: stderr: ""
  Jun 15 13:04:10.964: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-9947-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0615 13:04:11.496836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:04:12.191: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6123" for this suite. @ 06/15/24 13:04:12.198
• [4.796 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 06/15/24 13:04:12.205
  Jun 15 13:04:12.205: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 13:04:12.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:04:12.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:04:12.226
  E0615 13:04:12.497381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:13.497467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:14.498156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:15.498988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:16.499117      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:17.499721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:18.500645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:19.501398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:20.501441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:21.501749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:22.502596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:23.503286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:24.503887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:25.504248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:26.505097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:27.505555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:28.506021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:29.506661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:30.507499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:31.508352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:32.509109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:33.510196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:34.511020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:35.511382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:36.512357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:37.512929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:38.513508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:39.513938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:40.514357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:41.514841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:42.515344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:43.516107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:44.517090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:45.517431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:46.517971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:47.518671      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:48.518749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:49.519067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:50.519177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:51.520015      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:52.520428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:53.521473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:54.521944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:55.522332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:56.522666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:57.523433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:58.524128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:04:59.524980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:00.525385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:01.526112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:02.526554      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:03.526760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:04.527475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:05.528331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:06.528736      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:07.529716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:08.530479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:09.531166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:10.531952      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:11.532122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:05:12.242: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5353" for this suite. @ 06/15/24 13:05:12.246
• [60.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 06/15/24 13:05:12.254
  Jun 15 13:05:12.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 13:05:12.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:05:12.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:05:12.273
  STEP: Setting up server cert @ 06/15/24 13:05:12.303
  E0615 13:05:12.532483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 13:05:12.721
  STEP: Deploying the webhook pod @ 06/15/24 13:05:12.73
  STEP: Wait for the deployment to be ready @ 06/15/24 13:05:12.742
  Jun 15 13:05:12.748: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0615 13:05:13.533030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:14.533198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 13:05:14.761
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 13:05:14.77
  E0615 13:05:15.533290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:05:15.771: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 06/15/24 13:05:15.779
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 06/15/24 13:05:15.798
  STEP: Creating a configMap that should not be mutated @ 06/15/24 13:05:15.804
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 06/15/24 13:05:15.815
  STEP: Creating a configMap that should be mutated @ 06/15/24 13:05:15.822
  Jun 15 13:05:15.883: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8324" for this suite. @ 06/15/24 13:05:15.886
  STEP: Destroying namespace "webhook-markers-4611" for this suite. @ 06/15/24 13:05:15.897
• [3.648 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 06/15/24 13:05:15.903
  Jun 15 13:05:15.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename chunking @ 06/15/24 13:05:15.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:05:15.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:05:15.921
  STEP: creating a large number of resources @ 06/15/24 13:05:15.925
  E0615 13:05:16.534169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:17.534946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:18.535404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:19.536468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:20.536567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:21.537614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:22.538516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:23.538914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:24.539906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:25.539968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:26.540106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:27.540731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:28.540822      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:29.541708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:30.542409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:31.543363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:32.543974      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:33.544306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 06/15/24 13:05:33.611
  Jun 15 13:05:33.659: INFO: Retrieved 40/40 results with rv 29968 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page until the token expires @ 06/15/24 13:05:33.659
  E0615 13:05:34.544420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:35.544662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:36.544779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:37.544869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:38.544945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:39.545105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:40.545319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:41.545425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:42.545510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:43.545690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:44.545841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:45.545950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:46.546137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:47.546229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:48.546445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:49.546717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:50.546790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:51.546896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:52.546950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:53.547077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:05:53.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:05:54.547319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:55.547500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:56.547852      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:57.547941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:58.548608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:05:59.548717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:00.548895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:01.549026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:02.549142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:03.549341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:04.549602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:05.549818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:06.549918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:07.550417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:08.550597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:09.550701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:10.550941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:11.551656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:12.551999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:13.551861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:06:13.666: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:06:14.551929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:15.552333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:16.552580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:17.552842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:18.553756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:19.553978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:20.554279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:21.555040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:22.555176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:23.555273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:24.555360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:25.556348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:26.556604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:27.556699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:28.556875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:29.557509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:30.557583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:31.557685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:32.557851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:33.557937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:06:33.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:06:34.558004      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:35.558094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:36.559170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:37.559266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:38.560328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:39.560830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:40.561297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:41.561826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:42.561948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:43.562111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:44.562294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:45.562407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:46.562757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:47.562907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:48.563187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:49.563316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:50.563418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:51.563509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:52.563608      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:53.564352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:06:53.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:06:54.564450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:55.564614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:56.565606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:57.565695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:58.565791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:06:59.565873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:00.566090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:01.566278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:02.566577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:03.566756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:04.566847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:05.567060      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:06.567203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:07.567310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:08.567466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:09.567546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:10.567647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:11.568335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:12.568428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:13.568720      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:07:13.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:07:14.569904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:15.570058      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:16.570149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:17.570253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:18.570496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:19.570663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:20.570740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:21.570905      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:22.571208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:23.571274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:24.571368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:25.571468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:26.572374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:27.572465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:28.572652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:29.573167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:30.573298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:31.573472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:32.573637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:33.573787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:07:33.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:07:34.574035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:35.574143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:36.574543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:37.574648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:38.575263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:39.575331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:40.576331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:41.576435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:42.576667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:43.577317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:44.577411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:45.577851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:46.578112      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:47.579077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:48.579269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:49.579369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:50.579469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:51.580326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:52.580455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:53.581377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:07:53.666: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:07:54.581925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:55.582120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:56.582352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:57.582528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:58.582750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:07:59.583521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:00.583631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:01.584335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:02.584650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:03.584757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:04.584868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:05.584954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:06.585201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:07.585301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:08.585390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:09.585588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:10.585784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:11.585994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:12.589922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:13.590006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:08:13.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:08:14.590850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:15.591083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:16.591261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:17.592332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:18.592787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:19.592896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:20.592976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:21.593070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:22.594800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:23.594950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:24.595078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:25.595257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:26.596326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:27.596621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:28.596707      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:29.596902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:30.596997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:31.598090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:32.598309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:33.598385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:08:33.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:08:34.598528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:35.598621      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:36.598730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:37.598815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:38.598984      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:39.599187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:40.599287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:41.599378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:42.600777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:43.601088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:44.601502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:45.601714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:46.601798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:47.601883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:48.601994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:49.602199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:50.602278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:51.602465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:52.603930      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:53.604013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:08:53.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:08:54.604135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:55.604249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:56.604637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:57.604947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:58.605132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:08:59.605935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:00.606504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:01.606597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:02.606906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:03.606941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:04.607644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:05.608499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:06.608579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:07.608672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:08.608772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:09.609427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:10.609559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:11.609735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:12.609833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:13.609926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:09:13.664: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:09:14.610019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:15.610119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:16.611082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:17.611304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:18.612387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:19.612566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:20.613196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:21.613403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:22.614038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:23.614284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:24.614509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:25.614609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:26.614695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:27.615007      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:28.615858      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:29.616572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:30.616677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:31.616950      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:32.617079      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:33.617161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:09:33.666: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:09:34.617329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:35.618111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:36.618906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:37.619254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:38.620338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:39.620441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:40.620533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:41.620648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:42.621318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:43.621365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:44.621546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:45.621728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:46.621830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:47.621960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:48.623203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:49.623270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:50.623343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:51.623406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:52.626505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:53.626542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:09:53.664: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:09:54.627333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:55.628323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:56.629443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:57.629630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:58.629811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:09:59.630006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:00.630172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:01.630697      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:02.631185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:03.631264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:04.631367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:05.632366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:06.632840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:07.633293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:08.633394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:09.633572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:10.633767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:11.633864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:12.636218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:13.636333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:10:13.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:10:14.636394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:15.636488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:16.636838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:17.636933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:18.636993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:19.637092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:20.637284      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:21.637429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:22.638364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:23.638451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:24.638609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:25.638787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:26.639199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:27.639267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:28.639335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:29.640336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:30.640588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:31.640760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:32.640848      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:33.641032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:10:33.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:10:34.641712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:35.641824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:36.642082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:37.642555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:38.642801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:39.642892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:40.643071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:41.643297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:42.643483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:43.643560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:44.644328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:45.644501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:46.644780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:47.644865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:48.645046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:49.645169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:50.646034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:51.646135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:52.646297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:53.646445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:10:53.664: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:10:54.647183      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:55.647279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:56.647437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:57.647514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:58.647603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:10:59.647718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:00.647818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:01.647933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:02.648644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:03.648721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:04.648871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:05.648965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:06.649730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:07.650147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:08.650241      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:09.650316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:10.650568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:11.650809      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:12.651303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:13.651401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:11:13.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:11:14.651526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:15.652357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:16.653256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:17.654110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:18.655217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:19.655345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:20.655392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:21.656432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:22.656853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:23.657043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:24.657239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:25.657826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:26.658135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:27.658392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:28.658971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:29.659068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:30.659270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:31.660323      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:32.660642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:33.660672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:11:33.664: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:11:34.660792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:35.660968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:36.661116      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:37.661249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:38.661550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:39.661744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:40.662001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:41.662515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:42.662588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:43.662898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:44.663109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:45.663260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:46.663307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:47.663372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:48.664354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:49.664539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:50.664698      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:51.665433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:52.665502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:53.666196      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:11:53.666: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:11:54.666447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:55.667274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:56.667873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:57.667969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:58.668069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:11:59.669114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:00.669218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:01.669320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:02.669400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:03.669501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:04.669864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:05.669970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:06.670052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:07.670361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:08.670531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:09.670629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:10.670821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:11.671003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:12.671257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:12:13.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:12:13.671380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:14.671487      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:15.672466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:16.673426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:17.673548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:18.673716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:19.673982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:20.674182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:21.674340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:22.674438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:23.674714      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:24.674896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:25.675083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:26.675193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:27.675265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:28.675349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:29.676338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:30.676431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:31.676614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:32.677012      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:12:33.664: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:12:33.677956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:34.678668      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:35.678778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:36.678862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:37.678964      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:38.679120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:39.679257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:40.680322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:41.681392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:42.681759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:43.682710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:44.682845      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:45.683041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:46.683262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:47.683359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:48.684342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:49.684503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:50.684683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:51.684880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:52.685153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:12:53.666: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:12:53.685390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:54.685492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:55.685705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:56.686038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:57.686341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:58.686524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:12:59.686846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:00.686941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:01.687277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:02.687359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:03.687452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:04.687546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:05.687638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:06.687785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:07.688625      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:08.688712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:09.688983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:10.689204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:11.689396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:12.689484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:13:13.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:13:13.689691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:14.689791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:15.689894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:16.690239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:17.690557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:18.690753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:19.690929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:20.691158      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:21.691276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:22.691455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:23.692403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:24.692592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:25.692704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:26.693646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:27.693933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:28.695303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:29.696355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:30.696455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:31.696644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:32.696740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:13:33.666: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:13:33.697370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:34.697539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:35.697670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:36.698574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:37.698672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:38.698959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:39.699064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:40.699253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:41.700329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:42.700418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:43.700508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:44.700683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:45.700847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:46.700938      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:47.701041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:48.701225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:49.701320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:50.701501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:51.701677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:52.701945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:13:53.665: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:13:53.702785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:54.703618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:55.703719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:56.704047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:57.704414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:58.704514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:13:59.704703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:00.704893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:01.705109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:02.705448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:03.705547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:04.705596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:05.705769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:06.705946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:07.706274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:08.706610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:09.706802      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:10.706907      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:11.706992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:12.707269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:14:13.664: INFO: Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6Mjk5NjgsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9 has not expired yet
  E0615 13:14:13.708189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:14.708470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:15.708820      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:16.708917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:17.709242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:18.709505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:19.709680      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:20.709899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:21.710087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:22.710202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:23.710294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:24.710421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:25.710626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:26.710657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:27.710772      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:28.711481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:29.712336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:30.712435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:31.712612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:32.713009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:14:33.665: INFO: got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  Jun 15 13:14:33.665: INFO: Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 06/15/24 13:14:33.665
  STEP: retrieving all remaining pages @ 06/15/24 13:14:33.67
  Jun 15 13:14:33.674: INFO: Retrieved 40/40 results with rv 30999 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzA5OTksInN0YXJ0IjoidGVtcGxhdGUtMDExOVx1MDAwMCJ9
  Jun 15 13:14:33.678: INFO: Retrieved 40/40 results with rv 30999 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzA5OTksInN0YXJ0IjoidGVtcGxhdGUtMDE1OVx1MDAwMCJ9
  Jun 15 13:14:33.682: INFO: Retrieved 40/40 results with rv 30999 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzA5OTksInN0YXJ0IjoidGVtcGxhdGUtMDE5OVx1MDAwMCJ9
  Jun 15 13:14:33.685: INFO: Retrieved 40/40 results with rv 30999 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzA5OTksInN0YXJ0IjoidGVtcGxhdGUtMDIzOVx1MDAwMCJ9
  Jun 15 13:14:33.689: INFO: Retrieved 40/40 results with rv 30999 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzA5OTksInN0YXJ0IjoidGVtcGxhdGUtMDI3OVx1MDAwMCJ9
  Jun 15 13:14:33.693: INFO: Retrieved 40/40 results with rv 30999 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzA5OTksInN0YXJ0IjoidGVtcGxhdGUtMDMxOVx1MDAwMCJ9
  Jun 15 13:14:33.696: INFO: Retrieved 40/40 results with rv 30999 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MzA5OTksInN0YXJ0IjoidGVtcGxhdGUtMDM1OVx1MDAwMCJ9
  Jun 15 13:14:33.700: INFO: Retrieved 40/40 results with rv 30999 and continue 
  Jun 15 13:14:33.700: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-2777" for this suite. @ 06/15/24 13:14:33.705
  E0615 13:14:33.713035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
• [557.810 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 06/15/24 13:14:33.713
  Jun 15 13:14:33.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 13:14:33.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:14:33.73
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:14:33.732
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:14:33.735
  E0615 13:14:34.713167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:35.713372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:36.714301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:37.714401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:14:37.762
  Jun 15 13:14:37.765: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-d989b1d7-cc7e-47a5-a91c-9a43e320e812 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:14:37.782
  Jun 15 13:14:37.799: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4434" for this suite. @ 06/15/24 13:14:37.803
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:349
  STEP: Creating a kubernetes client @ 06/15/24 13:14:37.81
  Jun 15 13:14:37.810: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename security-context-test @ 06/15/24 13:14:37.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:14:37.824
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:14:37.827
  E0615 13:14:38.714515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:39.714719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:40.715295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:41.715406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:14:41.854: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7150" for this suite. @ 06/15/24 13:14:41.859
• [4.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 06/15/24 13:14:41.867
  Jun 15 13:14:41.867: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename watch @ 06/15/24 13:14:41.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:14:41.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:14:41.887
  STEP: creating a watch on configmaps with a certain label @ 06/15/24 13:14:41.889
  STEP: creating a new configmap @ 06/15/24 13:14:41.891
  STEP: modifying the configmap once @ 06/15/24 13:14:41.896
  STEP: changing the label value of the configmap @ 06/15/24 13:14:41.904
  STEP: Expecting to observe a delete notification for the watched object @ 06/15/24 13:14:41.912
  Jun 15 13:14:41.912: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6164  c9541b43-9bc8-4e22-bfd1-d41aed0a54d9 31474 0 2024-06-15 13:14:41 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-06-15 13:14:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 13:14:41.913: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6164  c9541b43-9bc8-4e22-bfd1-d41aed0a54d9 31475 0 2024-06-15 13:14:41 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-06-15 13:14:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 13:14:41.913: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6164  c9541b43-9bc8-4e22-bfd1-d41aed0a54d9 31476 0 2024-06-15 13:14:41 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-06-15 13:14:41 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 06/15/24 13:14:41.913
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 06/15/24 13:14:41.92
  E0615 13:14:42.715900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:43.715994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:44.716102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:45.716181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:46.716293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:47.716404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:48.717320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:49.717495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:50.718348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:51.718603      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 06/15/24 13:14:51.921
  STEP: modifying the configmap a third time @ 06/15/24 13:14:51.932
  STEP: deleting the configmap @ 06/15/24 13:14:51.94
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 06/15/24 13:14:51.945
  Jun 15 13:14:51.945: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6164  c9541b43-9bc8-4e22-bfd1-d41aed0a54d9 31519 0 2024-06-15 13:14:41 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-06-15 13:14:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 13:14:51.945: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6164  c9541b43-9bc8-4e22-bfd1-d41aed0a54d9 31520 0 2024-06-15 13:14:41 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-06-15 13:14:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 13:14:51.946: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6164  c9541b43-9bc8-4e22-bfd1-d41aed0a54d9 31521 0 2024-06-15 13:14:41 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-06-15 13:14:51 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 13:14:51.946: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6164" for this suite. @ 06/15/24 13:14:51.949
• [10.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 06/15/24 13:14:51.955
  Jun 15 13:14:51.955: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename init-container @ 06/15/24 13:14:51.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:14:51.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:14:51.972
  STEP: creating the pod @ 06/15/24 13:14:51.975
  Jun 15 13:14:51.975: INFO: PodSpec: initContainers in spec.initContainers
  E0615 13:14:52.718712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:53.718973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:54.720045      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:14:55.131: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2495" for this suite. @ 06/15/24 13:14:55.135
• [3.186 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 06/15/24 13:14:55.142
  Jun 15 13:14:55.142: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:14:55.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:14:55.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:14:55.16
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:14:55.163
  E0615 13:14:55.720348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:56.720424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:57.720530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:14:58.720616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:14:59.184
  Jun 15 13:14:59.189: INFO: Trying to get logs from node ip-172-31-43-132 pod downwardapi-volume-d1a35cb9-61c8-4a96-a271-88b42fe901b6 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:14:59.208
  Jun 15 13:14:59.222: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1719" for this suite. @ 06/15/24 13:14:59.226
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:488
  STEP: Creating a kubernetes client @ 06/15/24 13:14:59.235
  Jun 15 13:14:59.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename security-context-test @ 06/15/24 13:14:59.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:14:59.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:14:59.256
  E0615 13:14:59.721553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:00.721874      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:01.722016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:02.722127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:03.285: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-240" for this suite. @ 06/15/24 13:15:03.289
• [4.062 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 06/15/24 13:15:03.297
  Jun 15 13:15:03.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 13:15:03.298
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:15:03.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:15:03.316
  STEP: Setting up server cert @ 06/15/24 13:15:03.342
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 13:15:03.577
  STEP: Deploying the webhook pod @ 06/15/24 13:15:03.586
  STEP: Wait for the deployment to be ready @ 06/15/24 13:15:03.601
  Jun 15 13:15:03.609: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 13:15:03.722422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:04.722561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 13:15:05.62
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 13:15:05.631
  E0615 13:15:05.722980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:06.631: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 06/15/24 13:15:06.64
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 06/15/24 13:15:06.654
  STEP: Creating a dummy validating-webhook-configuration object @ 06/15/24 13:15:06.666
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 06/15/24 13:15:06.674
  STEP: Creating a dummy mutating-webhook-configuration object @ 06/15/24 13:15:06.681
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 06/15/24 13:15:06.69
  E0615 13:15:06.723786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:06.751: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7890" for this suite. @ 06/15/24 13:15:06.754
  STEP: Destroying namespace "webhook-markers-2589" for this suite. @ 06/15/24 13:15:06.761
• [3.470 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 06/15/24 13:15:06.768
  Jun 15 13:15:06.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename namespaces @ 06/15/24 13:15:06.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:15:06.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:15:06.786
  STEP: Updating Namespace "namespaces-8971" @ 06/15/24 13:15:06.789
  Jun 15 13:15:06.796: INFO: Namespace "namespaces-8971" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"95188bf7-85a8-44db-92ad-a0aaa244f60b", "kubernetes.io/metadata.name":"namespaces-8971", "namespaces-8971":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Jun 15 13:15:06.797: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8971" for this suite. @ 06/15/24 13:15:06.802
• [0.041 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 06/15/24 13:15:06.809
  Jun 15 13:15:06.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 13:15:06.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:15:06.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:15:06.824
  STEP: Creating configMap with name configmap-test-volume-69f2de30-ebcd-42f7-ba21-356e1adfd4d1 @ 06/15/24 13:15:06.828
  STEP: Creating a pod to test consume configMaps @ 06/15/24 13:15:06.832
  E0615 13:15:07.723906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:08.724000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:09.724104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:10.724217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:15:10.855
  Jun 15 13:15:10.860: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-configmaps-34768377-49b2-4b98-b7e1-2f31e02cd0d9 container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 13:15:10.867
  Jun 15 13:15:10.882: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-401" for this suite. @ 06/15/24 13:15:10.886
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 06/15/24 13:15:10.894
  Jun 15 13:15:10.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename limitrange @ 06/15/24 13:15:10.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:15:10.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:15:10.912
  STEP: Creating LimitRange "e2e-limitrange-pkfz5" in namespace "limitrange-8725" @ 06/15/24 13:15:10.916
  STEP: Creating another limitRange in another namespace @ 06/15/24 13:15:10.921
  Jun 15 13:15:10.936: INFO: Namespace "e2e-limitrange-pkfz5-9534" created
  Jun 15 13:15:10.936: INFO: Creating LimitRange "e2e-limitrange-pkfz5" in namespace "e2e-limitrange-pkfz5-9534"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-pkfz5" @ 06/15/24 13:15:10.946
  Jun 15 13:15:10.949: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-pkfz5" in "limitrange-8725" namespace @ 06/15/24 13:15:10.949
  Jun 15 13:15:10.955: INFO: LimitRange "e2e-limitrange-pkfz5" has been patched
  STEP: Delete LimitRange "e2e-limitrange-pkfz5" by Collection with labelSelector: "e2e-limitrange-pkfz5=patched" @ 06/15/24 13:15:10.955
  STEP: Confirm that the limitRange "e2e-limitrange-pkfz5" has been deleted @ 06/15/24 13:15:10.965
  Jun 15 13:15:10.965: INFO: Requesting list of LimitRange to confirm quantity
  Jun 15 13:15:10.969: INFO: Found 0 LimitRange with label "e2e-limitrange-pkfz5=patched"
  Jun 15 13:15:10.969: INFO: LimitRange "e2e-limitrange-pkfz5" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-pkfz5" @ 06/15/24 13:15:10.969
  Jun 15 13:15:10.972: INFO: Found 1 limitRange
  Jun 15 13:15:10.972: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-8725" for this suite. @ 06/15/24 13:15:10.976
  STEP: Destroying namespace "e2e-limitrange-pkfz5-9534" for this suite. @ 06/15/24 13:15:10.983
• [0.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 06/15/24 13:15:10.991
  Jun 15 13:15:10.991: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename subpath @ 06/15/24 13:15:10.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:15:11.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:15:11.01
  STEP: Setting up data @ 06/15/24 13:15:11.013
  STEP: Creating pod pod-subpath-test-secret-mnzf @ 06/15/24 13:15:11.023
  STEP: Creating a pod to test atomic-volume-subpath @ 06/15/24 13:15:11.023
  E0615 13:15:11.724935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:12.725033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:13.725137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:14.725251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:15.725334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:16.725488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:17.726043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:18.726244      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:19.726478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:20.727461      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:21.728360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:22.728499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:23.729486      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:24.729622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:25.729699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:26.730062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:27.730237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:28.730427      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:29.730551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:30.730797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:31.730981      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:32.731307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:33.732362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:34.733414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:15:35.099
  Jun 15 13:15:35.104: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-subpath-test-secret-mnzf container test-container-subpath-secret-mnzf: <nil>
  STEP: delete the pod @ 06/15/24 13:15:35.111
  STEP: Deleting pod pod-subpath-test-secret-mnzf @ 06/15/24 13:15:35.125
  Jun 15 13:15:35.125: INFO: Deleting pod "pod-subpath-test-secret-mnzf" in namespace "subpath-1608"
  Jun 15 13:15:35.129: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1608" for this suite. @ 06/15/24 13:15:35.134
• [24.149 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 06/15/24 13:15:35.141
  Jun 15 13:15:35.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 13:15:35.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:15:35.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:15:35.159
  STEP: Creating pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924 @ 06/15/24 13:15:35.162
  E0615 13:15:35.733509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:36.733615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 06/15/24 13:15:37.18
  Jun 15 13:15:37.184: INFO: Initial restart count of pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 is 0
  Jun 15 13:15:37.188: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:37.733704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:38.733832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:39.194: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:39.733949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:40.734061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:41.198: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:41.734849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:42.735008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:43.202: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:43.735991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:44.736100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:45.208: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:45.737026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:46.737107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:47.213: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:47.737763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:48.738335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:49.217: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:49.738337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:50.738435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:51.223: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:51.739198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:52.739271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:53.228: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:53.739644      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:54.739756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:55.232: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:55.740349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:56.740425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:57.238: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:57.741399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:15:58.741579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:15:59.243: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:15:59.741973      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:00.743059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:01.247: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:01.743291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:02.744353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:03.253: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:03.744455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:04.744537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:05.258: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:05.745125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:06.745233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:07.264: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:07.746145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:08.746228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:09.268: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:09.746315      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:10.746552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:11.274: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:11.746688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:12.747101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:13.278: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:13.747733      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:14.748616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:15.285: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:15.748699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:16.748795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:17.290: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:17.749533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:18.749711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:19.295: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:19.749892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:20.750096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:21.300: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:21.750504      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:22.750818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:23.305: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:23.751260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:24.751332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:25.311: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:25.752235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:26.752526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:27.316: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:27.752632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:28.752811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:29.321: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:29.753125      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:30.753366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:31.327: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:31.754336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:32.754567      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:33.333: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:33.755536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:34.755692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:35.337: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:35.755784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:36.756566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:37.343: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:37.756674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:38.757429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:39.348: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:39.758169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:40.759023      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:41.352: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:41.759422      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:42.759522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:43.357: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:43.759983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:44.760365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:45.363: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:45.761005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:46.761598      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:47.368: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:47.762691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:48.762857      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:49.372: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:49.762927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:50.763426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:51.378: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:51.763766      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:52.764464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:53.383: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:53.764556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:54.764835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:55.388: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:55.765650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:56.766281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:57.394: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:57.766378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:16:58.766515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:16:59.398: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:16:59.766614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:00.766723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:01.401: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:01.767526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:02.768327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:03.407: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:03.768627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:04.768719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:05.411: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:05.769417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:06.769940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:07.416: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:07.770243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:08.770481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:09.423: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:09.770541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:10.770724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:11.426: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:11.771563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:12.771610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:13.431: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:13.771914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:14.772337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:15.436: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:15.773478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:16.774535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:17.441: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:17.775257      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:18.775296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:19.446: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:19.776355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:20.776458      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:21.451: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:21.776888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:22.777423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:23.456: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:23.777991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:24.778388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:25.462: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:25.778806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:26.779248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:27.467: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:27.779398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:28.779501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:29.471: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:29.779583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:30.779676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:31.486: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:31.780076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:32.780373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:33.491: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:33.780464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:34.780564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:35.497: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:35.781560      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:36.782543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:37.501: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:37.783226      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:38.783296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:39.505: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:39.784357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:40.784498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:41.511: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:41.785500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:42.785700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:43.515: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:43.786491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:44.786595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:45.520: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:45.787235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:46.787523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:47.525: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:47.788085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:48.788197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:49.531: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:49.788508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:50.788602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:51.536: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:51.789371      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:52.789481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:53.541: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:53.789547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:54.789660      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:55.547: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:55.790373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:56.790548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:57.551: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:57.790795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:17:58.791052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:17:59.555: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:17:59.791100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:00.791293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:01.562: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:01.791538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:02.791642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:03.567: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:03.792695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:04.792889      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:05.572: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:05.792976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:06.793062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:07.577: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:07.794048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:08.794170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:09.582: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:09.794291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:10.794439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:11.588: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:11.794466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:12.794693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:13.592: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:13.795449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:14.795543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:15.598: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:15.796331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:16.796674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:17.603: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:17.797000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:18.797235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:19.608: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:19.798293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:20.798370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:21.614: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:21.798591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:22.798687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:23.618: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:23.799648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:24.800343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:25.623: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:25.800574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:26.801550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:27.627: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:27.801729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:28.801812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:29.634: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:29.802454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:30.802572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:31.639: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:31.803597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:32.804452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:33.643: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:33.805021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:34.805453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:35.650: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:35.806529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:36.806997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:37.655: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:37.808001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:38.808983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:39.660: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:39.809063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:40.809273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:41.666: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:41.810090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:42.810269      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:43.671: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:43.810739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:44.810909      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:45.677: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:45.811246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:46.811675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:47.681: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:47.812731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:48.812997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:49.686: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:49.813167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:50.813280      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:51.691: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:51.813842      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:52.813934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:53.695: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:53.814994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:54.815232      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:55.701: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:55.815655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:56.816094      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:57.706: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:57.816277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:18:58.816403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:18:59.710: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:18:59.817339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:00.817435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:01.716: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:01.818484      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:02.818579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:03.721: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:03.819399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:04.820329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:05.727: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:05.820462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:06.820531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:07.732: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:07.821238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:08.821354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:09.736: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:09.821469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:10.821914      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:11.740: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:11.822573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:12.822667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:13.747: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:13.823250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:14.823290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:15.753: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:15.824358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:16.824620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:17.757: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:17.825692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:18.825791      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:19.763: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:19.826708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:20.827529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:21.768: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:21.827569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:22.828485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:23.773: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:23.829246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:24.830074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:25.777: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:25.830113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:26.830517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:27.782: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:27.831352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:28.832321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:29.788: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:29.833321      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:30.833418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:31.793: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:31.834332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:32.834516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:33.797: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:33.834841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:34.835013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:35.803: INFO: Get pod test-grpc-dd8b4222-45c2-4cb9-bb71-bb25152ba974 in namespace container-probe-3924
  E0615 13:19:35.835088      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:36.835495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 06/15/24 13:19:37.803
  Jun 15 13:19:37.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3924" for this suite. @ 06/15/24 13:19:37.827
• [242.694 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 06/15/24 13:19:37.835
  Jun 15 13:19:37.835: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:19:37.835758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename custom-resource-definition @ 06/15/24 13:19:37.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:19:37.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:19:37.852
  STEP: fetching the /apis discovery document @ 06/15/24 13:19:37.855
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 06/15/24 13:19:37.857
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 06/15/24 13:19:37.857
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 06/15/24 13:19:37.857
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 06/15/24 13:19:37.858
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 06/15/24 13:19:37.858
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 06/15/24 13:19:37.859
  Jun 15 13:19:37.859: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5007" for this suite. @ 06/15/24 13:19:37.862
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 06/15/24 13:19:37.869
  Jun 15 13:19:37.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename daemonsets @ 06/15/24 13:19:37.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:19:37.883
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:19:37.885
  Jun 15 13:19:37.910: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 06/15/24 13:19:37.915
  Jun 15 13:19:37.920: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:37.920: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:37.922: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:19:37.922: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 13:19:38.836347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:38.920: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:38.921: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:38.925: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Jun 15 13:19:38.925: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  E0615 13:19:39.836446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:39.920: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:39.921: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:39.924: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 13:19:39.924: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 06/15/24 13:19:39.937
  STEP: Check that daemon pods images are updated. @ 06/15/24 13:19:39.948
  Jun 15 13:19:39.952: INFO: Wrong image for pod: daemon-set-59wdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Jun 15 13:19:39.952: INFO: Wrong image for pod: daemon-set-5b7bf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Jun 15 13:19:39.952: INFO: Wrong image for pod: daemon-set-fkws5. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Jun 15 13:19:39.959: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:39.959: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0615 13:19:40.837454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:40.955: INFO: Wrong image for pod: daemon-set-59wdr. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Jun 15 13:19:40.955: INFO: Wrong image for pod: daemon-set-fkws5. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Jun 15 13:19:40.955: INFO: Pod daemon-set-wmr27 is not available
  Jun 15 13:19:40.960: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:40.960: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0615 13:19:41.837932      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:41.954: INFO: Wrong image for pod: daemon-set-fkws5. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Jun 15 13:19:41.954: INFO: Pod daemon-set-jprpk is not available
  Jun 15 13:19:41.958: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:41.958: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0615 13:19:42.838876      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:42.957: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:42.957: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0615 13:19:43.839278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:43.957: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:43.957: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 06/15/24 13:19:43.957
  Jun 15 13:19:43.962: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:43.962: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:19:43.965: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 13:19:43.965: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 06/15/24 13:19:43.982
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8626, will wait for the garbage collector to delete the pods @ 06/15/24 13:19:43.982
  Jun 15 13:19:44.043: INFO: Deleting DaemonSet.extensions daemon-set took: 7.435702ms
  Jun 15 13:19:44.143: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.149982ms
  E0615 13:19:44.839564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:45.840008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:45.848: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:19:45.848: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Jun 15 13:19:45.851: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32602"},"items":null}

  Jun 15 13:19:45.855: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32602"},"items":null}

  Jun 15 13:19:45.868: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8626" for this suite. @ 06/15/24 13:19:45.871
• [8.010 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 06/15/24 13:19:45.879
  Jun 15 13:19:45.879: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 13:19:45.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:19:45.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:19:45.896
  STEP: Creating pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075 @ 06/15/24 13:19:45.899
  E0615 13:19:46.840238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:47.840324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 06/15/24 13:19:47.92
  Jun 15 13:19:47.923: INFO: Initial restart count of pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 is 0
  Jun 15 13:19:47.926: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:19:48.840358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:49.841259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:49.931: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:19:50.841383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:51.841650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:51.936: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:19:52.842157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:53.842266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:53.940: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:19:54.842863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:55.843113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:55.946: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:19:56.844165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:57.844391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:57.951: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:19:58.844885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:19:59.845931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:19:59.955: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:00.846697      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:01.846764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:01.962: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:02.847835      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:03.847949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:03.967: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:04.848032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:05.848127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:05.973: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:06.848402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:07.848494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:07.978: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:08.848708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:09.848935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:09.983: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:10.848999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:11.849563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:11.988: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:12.850137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:13.849731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:13.993: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:14.849936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:15.850151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:15.999: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:16.850989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:17.851195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:18.003: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:18.851276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:19.852333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:20.007: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:20.853425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:21.853870      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:22.013: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:22.854096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:23.854200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:24.017: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:24.854717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:25.854818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:26.024: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:26.855221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:27.855296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:28.029: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:28.855396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:29.856355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:30.034: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:30.857385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:31.857618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:32.040: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:32.857695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:33.858493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:34.045: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:34.858617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:35.858694      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:36.050: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:36.859467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:37.859562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:38.056: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:38.860444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:39.860609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:40.061: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:40.861687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:41.862312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:42.068: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:42.863260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:43.863357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:44.073: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:44.864327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:45.864503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:46.079: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:46.864565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:47.864755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:48.084: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:48.865142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:49.865318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:50.090: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  E0615 13:20:50.865429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:51.865816      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:20:52.095: INFO: Get pod test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 in namespace container-probe-4075
  Jun 15 13:20:52.095: INFO: Restart count of pod container-probe-4075/test-grpc-95dced82-9e3f-43fa-a37e-17dd11e02969 is now 1 (1m4.171748874s elapsed)
  STEP: deleting the pod @ 06/15/24 13:20:52.095
  Jun 15 13:20:52.107: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4075" for this suite. @ 06/15/24 13:20:52.11
• [66.238 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 06/15/24 13:20:52.118
  Jun 15 13:20:52.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 13:20:52.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:20:52.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:20:52.136
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:20:52.138
  E0615 13:20:52.865982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:53.866184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:54.866286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:55.866382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:20:56.162
  Jun 15 13:20:56.165: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-c8779f59-20f6-4bb3-b0d0-ba0a45a7b742 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:20:56.183
  Jun 15 13:20:56.198: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5342" for this suite. @ 06/15/24 13:20:56.201
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 06/15/24 13:20:56.208
  Jun 15 13:20:56.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename var-expansion @ 06/15/24 13:20:56.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:20:56.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:20:56.225
  STEP: Creating a pod to test env composition @ 06/15/24 13:20:56.229
  E0615 13:20:56.866539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:57.866635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:58.867174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:20:59.867279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:21:00.253
  Jun 15 13:21:00.258: INFO: Trying to get logs from node ip-172-31-7-7 pod var-expansion-3b2e94da-4b73-4b2d-ba1d-5a357f928da5 container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 13:21:00.264
  Jun 15 13:21:00.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-204" for this suite. @ 06/15/24 13:21:00.284
• [4.081 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 06/15/24 13:21:00.29
  Jun 15 13:21:00.290: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename gc @ 06/15/24 13:21:00.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:00.305
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:00.308
  STEP: create the rc @ 06/15/24 13:21:00.311
  W0615 13:21:00.317185      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0615 13:21:00.867669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:01.868629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:02.868710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:03.868787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:04.868949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 06/15/24 13:21:05.321
  STEP: wait for all pods to be garbage collected @ 06/15/24 13:21:05.326
  E0615 13:21:05.869185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:06.869556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:07.869774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:08.869872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:09.870071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 06/15/24 13:21:10.334
  W0615 13:21:10.339014      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Jun 15 13:21:10.339: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Jun 15 13:21:10.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1119" for this suite. @ 06/15/24 13:21:10.342
• [10.060 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 06/15/24 13:21:10.35
  Jun 15 13:21:10.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename dns @ 06/15/24 13:21:10.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:10.363
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:10.366
  STEP: Creating a test headless service @ 06/15/24 13:21:10.371
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7542 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7542;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7542 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7542;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7542.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7542.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7542.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7542.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7542.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7542.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7542.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7542.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7542.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7542.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7542.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7542.svc;check="$$(dig +notcp +noall +answer +search 84.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.84_udp@PTR;check="$$(dig +tcp +noall +answer +search 84.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.84_tcp@PTR;sleep 1; done
   @ 06/15/24 13:21:10.388
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7542 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7542;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7542 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7542;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7542.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7542.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7542.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7542.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7542.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7542.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7542.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7542.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7542.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7542.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7542.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7542.svc;check="$$(dig +notcp +noall +answer +search 84.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.84_udp@PTR;check="$$(dig +tcp +noall +answer +search 84.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.84_tcp@PTR;sleep 1; done
   @ 06/15/24 13:21:10.389
  STEP: creating a pod to probe DNS @ 06/15/24 13:21:10.389
  STEP: submitting the pod to kubernetes @ 06/15/24 13:21:10.389
  E0615 13:21:10.871036      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:11.872048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 06/15/24 13:21:12.416
  STEP: looking for the results for each expected name from probers @ 06/15/24 13:21:12.419
  Jun 15 13:21:12.424: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.428: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.431: INFO: Unable to read wheezy_udp@dns-test-service.dns-7542 from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.436: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7542 from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.439: INFO: Unable to read wheezy_udp@dns-test-service.dns-7542.svc from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.442: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7542.svc from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.446: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7542.svc from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.450: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7542.svc from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.468: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.471: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.474: INFO: Unable to read jessie_udp@dns-test-service.dns-7542 from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.478: INFO: Unable to read jessie_tcp@dns-test-service.dns-7542 from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.481: INFO: Unable to read jessie_udp@dns-test-service.dns-7542.svc from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.483: INFO: Unable to read jessie_tcp@dns-test-service.dns-7542.svc from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.487: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7542.svc from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.491: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7542.svc from pod dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129: the server could not find the requested resource (get pods dns-test-6795a215-4975-4a3e-af56-70dc09472129)
  Jun 15 13:21:12.506: INFO: Lookups using dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7542 wheezy_tcp@dns-test-service.dns-7542 wheezy_udp@dns-test-service.dns-7542.svc wheezy_tcp@dns-test-service.dns-7542.svc wheezy_udp@_http._tcp.dns-test-service.dns-7542.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7542.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7542 jessie_tcp@dns-test-service.dns-7542 jessie_udp@dns-test-service.dns-7542.svc jessie_tcp@dns-test-service.dns-7542.svc jessie_udp@_http._tcp.dns-test-service.dns-7542.svc jessie_tcp@_http._tcp.dns-test-service.dns-7542.svc]

  Jun 15 13:21:12.512: INFO: Pod client logs for webserver: 
  Jun 15 13:21:12.519: INFO: Pod client logs for querier: 
  Jun 15 13:21:12.524: INFO: Pod client logs for jessie-querier: 
  E0615 13:21:12.872665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:13.872761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:14.872841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:15.872954      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:16.873396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:17.503: INFO: DNS probes using dns-7542/dns-test-6795a215-4975-4a3e-af56-70dc09472129 succeeded

  STEP: deleting the pod @ 06/15/24 13:21:17.503
  STEP: deleting the test service @ 06/15/24 13:21:17.519
  STEP: deleting the test headless service @ 06/15/24 13:21:17.546
  Jun 15 13:21:17.559: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-7542" for this suite. @ 06/15/24 13:21:17.562
• [7.218 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 06/15/24 13:21:17.567
  Jun 15 13:21:17.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename dns @ 06/15/24 13:21:17.568
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:17.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:17.584
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3624.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3624.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 06/15/24 13:21:17.587
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3624.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3624.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 06/15/24 13:21:17.587
  STEP: creating a pod to probe /etc/hosts @ 06/15/24 13:21:17.587
  STEP: submitting the pod to kubernetes @ 06/15/24 13:21:17.587
  E0615 13:21:17.874119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:18.874302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 06/15/24 13:21:19.608
  STEP: looking for the results for each expected name from probers @ 06/15/24 13:21:19.611
  Jun 15 13:21:19.629: INFO: DNS probes using dns-3624/dns-test-5dbf592d-a9b2-4427-9e49-ef46a189edf3 succeeded

  STEP: deleting the pod @ 06/15/24 13:21:19.629
  Jun 15 13:21:19.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-3624" for this suite. @ 06/15/24 13:21:19.649
• [2.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
  STEP: Creating a kubernetes client @ 06/15/24 13:21:19.656
  Jun 15 13:21:19.656: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:21:19.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:19.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:19.675
  Jun 15 13:21:19.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-1334 create -f -'
  Jun 15 13:21:19.756: INFO: stderr: ""
  Jun 15 13:21:19.756: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Jun 15 13:21:19.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-1334 create -f -'
  Jun 15 13:21:19.844: INFO: stderr: ""
  Jun 15 13:21:19.844: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 06/15/24 13:21:19.844
  E0615 13:21:19.875259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:20.849: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:21:20.849: INFO: Found 1 / 1
  Jun 15 13:21:20.849: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Jun 15 13:21:20.853: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:21:20.853: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Jun 15 13:21:20.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-1334 describe pod agnhost-primary-jxrxh'
  E0615 13:21:20.875473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:20.905: INFO: stderr: ""
  Jun 15 13:21:20.905: INFO: stdout: "Name:             agnhost-primary-jxrxh\nNamespace:        kubectl-1334\nPriority:         0\nService Account:  default\nNode:             ip-172-31-7-7/172.31.7.7\nStart Time:       Sat, 15 Jun 2024 13:21:19 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.164.165\nIPs:\n  IP:           192.168.164.165\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://ef3d2939b2b637fe09725a38800fb02114006e0a5a7bcce110bfc1199bb61ed4\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:cc249acbd34692826b2b335335615e060fdb3c0bca4954507aa3a1d1194de253\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 15 Jun 2024 13:21:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-zzzv6 (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-zzzv6:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-1334/agnhost-primary-jxrxh to ip-172-31-7-7\n  Normal  Pulled     0s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
  Jun 15 13:21:20.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-1334 describe rc agnhost-primary'
  Jun 15 13:21:20.957: INFO: stderr: ""
  Jun 15 13:21:20.957: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-1334\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-jxrxh\n"
  Jun 15 13:21:20.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-1334 describe service agnhost-primary'
  Jun 15 13:21:21.009: INFO: stderr: ""
  Jun 15 13:21:21.009: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-1334\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.214\nIPs:               10.152.183.214\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.164.165:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Jun 15 13:21:21.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-1334 describe node ip-172-31-17-110'
  Jun 15 13:21:21.077: INFO: stderr: ""
  Jun 15 13:21:21.077: INFO: stdout: "Name:               ip-172-31-17-110\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    juju.io/cloud=ec2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-17-110\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 15 Jun 2024 11:52:36 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-17-110\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 15 Jun 2024 13:21:18 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 15 Jun 2024 12:04:20 +0000   Sat, 15 Jun 2024 12:04:20 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 15 Jun 2024 13:19:11 +0000   Sat, 15 Jun 2024 11:52:36 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 15 Jun 2024 13:19:11 +0000   Sat, 15 Jun 2024 11:52:36 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 15 Jun 2024 13:19:11 +0000   Sat, 15 Jun 2024 11:52:36 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 15 Jun 2024 13:19:11 +0000   Sat, 15 Jun 2024 11:55:19 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.17.110\n  Hostname:    ip-172-31-17-110\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      16069568Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7958148Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    2\n  ephemeral-storage:      14809713845\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7855748Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                      ec2703fb4cd848253eb57833e5df63cf\n  System UUID:                     ec2703fb-4cd8-4825-3eb5-7833e5df63cf\n  Boot ID:                         c763e695-fa5b-4e48-b5f9-9e4dd830eb91\n  Kernel Version:                  6.5.0-1020-aws\n  OS Image:                        Ubuntu 22.04.4 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.6.8\n  Kubelet Version:                 v1.29.6\n  Kube-Proxy Version:              v1.29.6\nNon-terminated Pods:               (8 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-pfb28           0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\n  kube-system                      calico-node-hkrvf                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                      coredns-bddfd76d7-mp2lw                                    100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     93m\n  kube-system                      kube-state-metrics-6f48cdd76-fzrm6                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  kube-system                      metrics-server-v0.6.3-69d7fbfdf8-nhfgd                     5m (0%)       100m (5%)   50Mi (0%)        300Mi (3%)     93m\n  kubernetes-dashboard             dashboard-metrics-scraper-5dd7cb5fc-6zmr5                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  kubernetes-dashboard             kubernetes-dashboard-7b899cb9d9-444dc                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-nhpcv    0 (0%)        0 (0%)      0 (0%)           0 (0%)         75m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    355m (17%)  100m (5%)\n  memory                 120Mi (1%)  470Mi (6%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:                  <none>\n"
  Jun 15 13:21:21.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-1334 describe namespace kubectl-1334'
  Jun 15 13:21:21.128: INFO: stderr: ""
  Jun 15 13:21:21.128: INFO: stdout: "Name:         kubectl-1334\nLabels:       e2e-framework=kubectl\n              e2e-run=95188bf7-85a8-44db-92ad-a0aaa244f60b\n              kubernetes.io/metadata.name=kubectl-1334\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Jun 15 13:21:21.128: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1334" for this suite. @ 06/15/24 13:21:21.132
• [1.485 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 06/15/24 13:21:21.141
  Jun 15 13:21:21.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:21:21.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:21.157
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:21.16
  STEP: Creating configMap with name projected-configmap-test-volume-6e926245-75fb-4eb7-8fa1-163536fc60c8 @ 06/15/24 13:21:21.163
  STEP: Creating a pod to test consume configMaps @ 06/15/24 13:21:21.168
  E0615 13:21:21.876134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:22.876202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:21:23.186
  Jun 15 13:21:23.190: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-projected-configmaps-c33febf3-1c37-480d-9fbe-01674b8b27b8 container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 13:21:23.205
  Jun 15 13:21:23.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3440" for this suite. @ 06/15/24 13:21:23.227
• [2.093 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:94
  STEP: Creating a kubernetes client @ 06/15/24 13:21:23.234
  Jun 15 13:21:23.234: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 13:21:23.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:23.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:23.252
  STEP: Creating configMap configmap-6534/configmap-test-2c8044ee-1fee-43cb-b7f7-2130d5b714a2 @ 06/15/24 13:21:23.254
  STEP: Creating a pod to test consume configMaps @ 06/15/24 13:21:23.259
  E0615 13:21:23.876441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:24.876454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:21:25.276
  Jun 15 13:21:25.279: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-configmaps-dbc4e157-9463-4325-8541-4c79526e8234 container env-test: <nil>
  STEP: delete the pod @ 06/15/24 13:21:25.286
  Jun 15 13:21:25.301: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6534" for this suite. @ 06/15/24 13:21:25.304
• [2.078 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 06/15/24 13:21:25.312
  Jun 15 13:21:25.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename daemonsets @ 06/15/24 13:21:25.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:25.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:25.333
  STEP: Creating a simple DaemonSet "daemon-set" @ 06/15/24 13:21:25.355
  STEP: Check that daemon pods launch on every node of the cluster. @ 06/15/24 13:21:25.361
  Jun 15 13:21:25.364: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:25.364: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:25.368: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:21:25.368: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 13:21:25.876632      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:26.365: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:26.365: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:26.368: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Jun 15 13:21:26.368: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  E0615 13:21:26.877286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:27.365: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:27.365: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:27.369: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 13:21:27.369: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 06/15/24 13:21:27.371
  Jun 15 13:21:27.393: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:27.393: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:27.396: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Jun 15 13:21:27.396: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  E0615 13:21:27.877459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:28.390: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:28.390: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:28.394: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Jun 15 13:21:28.394: INFO: Node ip-172-31-43-132 is running 0 daemon pod, expected 1
  E0615 13:21:28.878446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:29.389: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:29.389: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:21:29.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 13:21:29.393: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 06/15/24 13:21:29.393
  STEP: Deleting DaemonSet "daemon-set" @ 06/15/24 13:21:29.399
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1518, will wait for the garbage collector to delete the pods @ 06/15/24 13:21:29.4
  Jun 15 13:21:29.461: INFO: Deleting DaemonSet.extensions daemon-set took: 6.457077ms
  Jun 15 13:21:29.561: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.784507ms
  E0615 13:21:29.878897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:30.879243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:31.879626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:32.068: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:21:32.068: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Jun 15 13:21:32.072: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33365"},"items":null}

  Jun 15 13:21:32.075: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33365"},"items":null}

  Jun 15 13:21:32.091: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1518" for this suite. @ 06/15/24 13:21:32.094
• [6.788 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 06/15/24 13:21:32.101
  Jun 15 13:21:32.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 13:21:32.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:32.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:32.126
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-6232 @ 06/15/24 13:21:32.131
  STEP: changing the ExternalName service to type=NodePort @ 06/15/24 13:21:32.142
  STEP: creating replication controller externalname-service in namespace services-6232 @ 06/15/24 13:21:32.161
  I0615 13:21:32.170674      19 runners.go:197] Created replication controller with name: externalname-service, namespace: services-6232, replica count: 2
  E0615 13:21:32.879731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:33.880459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:34.880656      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 13:21:35.222210      19 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 13:21:35.222: INFO: Creating new exec pod
  E0615 13:21:35.880744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:36.881355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:37.882165      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:38.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6232 exec execpodftl8v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Jun 15 13:21:38.343: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Jun 15 13:21:38.343: INFO: stdout: "externalname-service-4g5vk"
  Jun 15 13:21:38.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6232 exec execpodftl8v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.94 80'
  Jun 15 13:21:38.432: INFO: stderr: "+ nc -v -t -w 2 10.152.183.94 80\nConnection to 10.152.183.94 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Jun 15 13:21:38.432: INFO: stdout: ""
  E0615 13:21:38.883166      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:39.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6232 exec execpodftl8v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.94 80'
  Jun 15 13:21:39.434: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.94 80\nConnection to 10.152.183.94 80 port [tcp/http] succeeded!\n"
  Jun 15 13:21:39.434: INFO: stdout: "externalname-service-4g5vk"
  Jun 15 13:21:39.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6232 exec execpodftl8v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.7 32086'
  Jun 15 13:21:39.521: INFO: stderr: "+ nc -v -t -w 2 172.31.7.7 32086\n+ echo hostName\nConnection to 172.31.7.7 32086 port [tcp/*] succeeded!\n"
  Jun 15 13:21:39.521: INFO: stdout: "externalname-service-4g5vk"
  Jun 15 13:21:39.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-6232 exec execpodftl8v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.132 32086'
  Jun 15 13:21:39.613: INFO: stderr: "+ nc -v -t -w 2 172.31.43.132 32086\n+ echo hostName\nConnection to 172.31.43.132 32086 port [tcp/*] succeeded!\n"
  Jun 15 13:21:39.613: INFO: stdout: "externalname-service-4g5vk"
  Jun 15 13:21:39.613: INFO: Cleaning up the ExternalName to NodePort test service
  Jun 15 13:21:39.640: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6232" for this suite. @ 06/15/24 13:21:39.644
• [7.550 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:163
  STEP: Creating a kubernetes client @ 06/15/24 13:21:39.651
  Jun 15 13:21:39.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 13:21:39.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:39.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:39.67
  STEP: Discovering how many secrets are in namespace by default @ 06/15/24 13:21:39.673
  E0615 13:21:39.883268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:40.884267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:41.884627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:42.885107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:43.885592      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 06/15/24 13:21:44.677
  E0615 13:21:44.886640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:45.887161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:46.887426      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:47.888239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:48.888939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 06/15/24 13:21:49.681
  STEP: Ensuring resource quota status is calculated @ 06/15/24 13:21:49.686
  E0615 13:21:49.889320      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:50.889439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 06/15/24 13:21:51.691
  STEP: Ensuring resource quota status captures secret creation @ 06/15/24 13:21:51.701
  E0615 13:21:51.890083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:52.891188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 06/15/24 13:21:53.707
  STEP: Ensuring resource quota status released usage @ 06/15/24 13:21:53.713
  E0615 13:21:53.892040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:54.892218      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:21:55.718: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2486" for this suite. @ 06/15/24 13:21:55.722
• [16.080 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:948
  STEP: Creating a kubernetes client @ 06/15/24 13:21:55.731
  Jun 15 13:21:55.731: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 13:21:55.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:55.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:55.752
  STEP: Creating a ResourceQuota @ 06/15/24 13:21:55.755
  STEP: Getting a ResourceQuota @ 06/15/24 13:21:55.761
  STEP: Listing all ResourceQuotas with LabelSelector @ 06/15/24 13:21:55.765
  STEP: Patching the ResourceQuota @ 06/15/24 13:21:55.77
  STEP: Deleting a Collection of ResourceQuotas @ 06/15/24 13:21:55.777
  STEP: Verifying the deleted ResourceQuota @ 06/15/24 13:21:55.788
  Jun 15 13:21:55.792: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4371" for this suite. @ 06/15/24 13:21:55.796
• [0.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 06/15/24 13:21:55.805
  Jun 15 13:21:55.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename apf @ 06/15/24 13:21:55.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:55.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:55.818
  STEP: getting /apis @ 06/15/24 13:21:55.821
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 06/15/24 13:21:55.826
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 06/15/24 13:21:55.827
  STEP: creating @ 06/15/24 13:21:55.828
  STEP: getting @ 06/15/24 13:21:55.85
  STEP: listing @ 06/15/24 13:21:55.854
  STEP: watching @ 06/15/24 13:21:55.858
  Jun 15 13:21:55.858: INFO: starting watch
  STEP: patching @ 06/15/24 13:21:55.859
  STEP: updating @ 06/15/24 13:21:55.865
  Jun 15 13:21:55.874: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 06/15/24 13:21:55.874
  STEP: patching /status @ 06/15/24 13:21:55.877
  STEP: updating /status @ 06/15/24 13:21:55.881
  E0615 13:21:55.892288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting @ 06/15/24 13:21:55.914
  STEP: deleting a collection @ 06/15/24 13:21:55.927
  Jun 15 13:21:55.948: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-4107" for this suite. @ 06/15/24 13:21:55.951
• [0.154 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 06/15/24 13:21:55.959
  Jun 15 13:21:55.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename apf @ 06/15/24 13:21:55.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:55.978
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:55.981
  STEP: getting /apis @ 06/15/24 13:21:55.984
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 06/15/24 13:21:55.987
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 06/15/24 13:21:55.989
  STEP: creating @ 06/15/24 13:21:55.99
  STEP: getting @ 06/15/24 13:21:56.006
  STEP: listing @ 06/15/24 13:21:56.01
  STEP: watching @ 06/15/24 13:21:56.013
  Jun 15 13:21:56.013: INFO: starting watch
  STEP: patching @ 06/15/24 13:21:56.014
  STEP: updating @ 06/15/24 13:21:56.02
  Jun 15 13:21:56.029: INFO: waiting for watch events with expected annotations
  STEP: getting /status @ 06/15/24 13:21:56.029
  STEP: patching /status @ 06/15/24 13:21:56.032
  STEP: updating /status @ 06/15/24 13:21:56.037
  STEP: deleting @ 06/15/24 13:21:56.045
  STEP: deleting a collection @ 06/15/24 13:21:56.059
  Jun 15 13:21:56.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-5456" for this suite. @ 06/15/24 13:21:56.082
• [0.131 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 06/15/24 13:21:56.09
  Jun 15 13:21:56.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 13:21:56.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:56.103
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:56.106
  STEP: creating the pod @ 06/15/24 13:21:56.109
  STEP: submitting the pod to kubernetes @ 06/15/24 13:21:56.109
  E0615 13:21:56.892682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:21:57.892823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 06/15/24 13:21:58.132
  STEP: updating the pod @ 06/15/24 13:21:58.136
  Jun 15 13:21:58.650: INFO: Successfully updated pod "pod-update-2f13a2bd-a0ab-4aa7-a560-ba411135efd0"
  STEP: verifying the updated pod is in kubernetes @ 06/15/24 13:21:58.655
  Jun 15 13:21:58.658: INFO: Pod update OK
  Jun 15 13:21:58.658: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1523" for this suite. @ 06/15/24 13:21:58.662
• [2.578 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1373
  STEP: Creating a kubernetes client @ 06/15/24 13:21:58.669
  Jun 15 13:21:58.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:21:58.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:58.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:58.685
  STEP: validating cluster-info @ 06/15/24 13:21:58.688
  Jun 15 13:21:58.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3339 cluster-info'
  Jun 15 13:21:58.730: INFO: stderr: ""
  Jun 15 13:21:58.730: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Jun 15 13:21:58.730: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3339" for this suite. @ 06/15/24 13:21:58.734
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3154
  STEP: Creating a kubernetes client @ 06/15/24 13:21:58.741
  Jun 15 13:21:58.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 13:21:58.741
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:58.754
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:58.759
  STEP: creating an Endpoint @ 06/15/24 13:21:58.766
  STEP: waiting for available Endpoint @ 06/15/24 13:21:58.77
  STEP: listing all Endpoints @ 06/15/24 13:21:58.771
  STEP: updating the Endpoint @ 06/15/24 13:21:58.774
  STEP: fetching the Endpoint @ 06/15/24 13:21:58.789
  STEP: patching the Endpoint @ 06/15/24 13:21:58.794
  STEP: fetching the Endpoint @ 06/15/24 13:21:58.802
  STEP: deleting the Endpoint by Collection @ 06/15/24 13:21:58.805
  STEP: waiting for Endpoint deletion @ 06/15/24 13:21:58.814
  STEP: fetching the Endpoint @ 06/15/24 13:21:58.815
  Jun 15 13:21:58.819: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2506" for this suite. @ 06/15/24 13:21:58.823
• [0.090 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 06/15/24 13:21:58.831
  Jun 15 13:21:58.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 13:21:58.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:21:58.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:21:58.85
  STEP: creating the pod @ 06/15/24 13:21:58.854
  STEP: setting up watch @ 06/15/24 13:21:58.854
  E0615 13:21:58.892847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: submitting the pod to kubernetes @ 06/15/24 13:21:58.958
  STEP: verifying the pod is in kubernetes @ 06/15/24 13:21:58.969
  STEP: verifying pod creation was observed @ 06/15/24 13:21:58.974
  E0615 13:21:59.893468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:00.893572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 06/15/24 13:22:00.99
  STEP: verifying pod deletion was observed @ 06/15/24 13:22:00.996
  Jun 15 13:22:01.861: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-490" for this suite. @ 06/15/24 13:22:01.865
• [3.040 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 06/15/24 13:22:01.871
  Jun 15 13:22:01.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename limitrange @ 06/15/24 13:22:01.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:01.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:01.889
  STEP: Creating a LimitRange @ 06/15/24 13:22:01.893
  STEP: Setting up watch @ 06/15/24 13:22:01.893
  E0615 13:22:01.894175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Submitting a LimitRange @ 06/15/24 13:22:01.997
  STEP: Verifying LimitRange creation was observed @ 06/15/24 13:22:02.003
  STEP: Fetching the LimitRange to ensure it has proper values @ 06/15/24 13:22:02.003
  Jun 15 13:22:02.006: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Jun 15 13:22:02.006: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 06/15/24 13:22:02.006
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 06/15/24 13:22:02.014
  Jun 15 13:22:02.020: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Jun 15 13:22:02.020: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 06/15/24 13:22:02.02
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 06/15/24 13:22:02.029
  Jun 15 13:22:02.035: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Jun 15 13:22:02.035: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 06/15/24 13:22:02.035
  STEP: Failing to create a Pod with more than max resources @ 06/15/24 13:22:02.037
  STEP: Updating a LimitRange @ 06/15/24 13:22:02.038
  STEP: Verifying LimitRange updating is effective @ 06/15/24 13:22:02.043
  E0615 13:22:02.895413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:03.895451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 06/15/24 13:22:04.048
  STEP: Failing to create a Pod with more than max resources @ 06/15/24 13:22:04.055
  STEP: Deleting a LimitRange @ 06/15/24 13:22:04.057
  STEP: Verifying the LimitRange was deleted @ 06/15/24 13:22:04.065
  E0615 13:22:04.896512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:05.896599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:06.896960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:07.897071      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:08.897252      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:09.070: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 06/15/24 13:22:09.07
  Jun 15 13:22:09.080: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-8737" for this suite. @ 06/15/24 13:22:09.086
• [7.223 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 06/15/24 13:22:09.094
  Jun 15 13:22:09.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pod-network-test @ 06/15/24 13:22:09.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:09.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:09.111
  STEP: Performing setup for networking test in namespace pod-network-test-9615 @ 06/15/24 13:22:09.114
  STEP: creating a selector @ 06/15/24 13:22:09.114
  STEP: Creating the service pods in kubernetes @ 06/15/24 13:22:09.114
  Jun 15 13:22:09.114: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0615 13:22:09.897634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:10.897815      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:11.898650      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:12.898875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:13.898953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:14.899108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:15.899262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:16.899547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:17.900334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:18.900515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:19.900620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:20.900706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 06/15/24 13:22:21.203
  E0615 13:22:21.901624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:22.901821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:23.223: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Jun 15 13:22:23.223: INFO: Breadth first check of 192.168.0.82 on host 172.31.17.110...
  Jun 15 13:22:23.226: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.164.168:9080/dial?request=hostname&protocol=http&host=192.168.0.82&port=8083&tries=1'] Namespace:pod-network-test-9615 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:22:23.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:22:23.227: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:22:23.227: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-9615/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.164.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.0.82%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Jun 15 13:22:23.283: INFO: Waiting for responses: map[]
  Jun 15 13:22:23.283: INFO: reached 192.168.0.82 after 0/1 tries
  Jun 15 13:22:23.283: INFO: Breadth first check of 192.168.40.196 on host 172.31.43.132...
  Jun 15 13:22:23.286: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.164.168:9080/dial?request=hostname&protocol=http&host=192.168.40.196&port=8083&tries=1'] Namespace:pod-network-test-9615 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:22:23.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:22:23.286: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:22:23.286: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-9615/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.164.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.40.196%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Jun 15 13:22:23.338: INFO: Waiting for responses: map[]
  Jun 15 13:22:23.338: INFO: reached 192.168.40.196 after 0/1 tries
  Jun 15 13:22:23.338: INFO: Breadth first check of 192.168.164.172 on host 172.31.7.7...
  Jun 15 13:22:23.343: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.164.168:9080/dial?request=hostname&protocol=http&host=192.168.164.172&port=8083&tries=1'] Namespace:pod-network-test-9615 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:22:23.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:22:23.344: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:22:23.344: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-9615/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.164.168%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.164.172%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Jun 15 13:22:23.389: INFO: Waiting for responses: map[]
  Jun 15 13:22:23.389: INFO: reached 192.168.164.172 after 0/1 tries
  Jun 15 13:22:23.389: INFO: Going to retry 0 out of 3 pods....
  Jun 15 13:22:23.389: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9615" for this suite. @ 06/15/24 13:22:23.394
• [14.308 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 06/15/24 13:22:23.403
  Jun 15 13:22:23.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 13:22:23.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:23.416
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:23.419
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-8904 @ 06/15/24 13:22:23.422
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 06/15/24 13:22:23.441
  STEP: creating service externalsvc in namespace services-8904 @ 06/15/24 13:22:23.441
  STEP: creating replication controller externalsvc in namespace services-8904 @ 06/15/24 13:22:23.461
  I0615 13:22:23.467557      19 runners.go:197] Created replication controller with name: externalsvc, namespace: services-8904, replica count: 2
  E0615 13:22:23.902481      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:24.902522      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:25.902770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 13:22:26.519719      19 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 06/15/24 13:22:26.524
  Jun 15 13:22:26.543: INFO: Creating new exec pod
  E0615 13:22:26.903326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:27.903409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:28.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-8904 exec execpodh4vzz -- /bin/sh -x -c nslookup nodeport-service.services-8904.svc.cluster.local'
  Jun 15 13:22:28.701: INFO: stderr: "+ nslookup nodeport-service.services-8904.svc.cluster.local\n"
  Jun 15 13:22:28.701: INFO: stdout: "Server:\t\t10.152.183.120\nAddress:\t10.152.183.120#53\n\nnodeport-service.services-8904.svc.cluster.local\tcanonical name = externalsvc.services-8904.svc.cluster.local.\nName:\texternalsvc.services-8904.svc.cluster.local\nAddress: 10.152.183.197\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-8904, will wait for the garbage collector to delete the pods @ 06/15/24 13:22:28.701
  Jun 15 13:22:28.763: INFO: Deleting ReplicationController externalsvc took: 5.944668ms
  Jun 15 13:22:28.864: INFO: Terminating ReplicationController externalsvc pods took: 100.35955ms
  E0615 13:22:28.904383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:29.904454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:30.904919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:31.905200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:31.980: INFO: Cleaning up the NodePort to ExternalName test service
  Jun 15 13:22:31.993: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8904" for this suite. @ 06/15/24 13:22:31.997
• [8.603 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 06/15/24 13:22:32.006
  Jun 15 13:22:32.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:22:32.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:32.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:32.024
  STEP: Creating the pod @ 06/15/24 13:22:32.027
  E0615 13:22:32.905447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:33.905756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:34.575: INFO: Successfully updated pod "annotationupdate1e1679bc-4e46-41b8-aeb9-4927ccc81cb8"
  E0615 13:22:34.906290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:35.906404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:36.907046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:37.907168      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:38.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1152" for this suite. @ 06/15/24 13:22:38.602
• [6.603 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 06/15/24 13:22:38.609
  Jun 15 13:22:38.609: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 13:22:38.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:38.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:38.627
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 06/15/24 13:22:38.631
  E0615 13:22:38.907527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:39.908449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:40.908701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:41.909010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:22:42.656
  Jun 15 13:22:42.659: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-f4221655-d90f-4a89-871a-634b534b53e1 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 13:22:42.667
  Jun 15 13:22:42.681: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7312" for this suite. @ 06/15/24 13:22:42.684
• [4.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 06/15/24 13:22:42.692
  Jun 15 13:22:42.692: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename daemonsets @ 06/15/24 13:22:42.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:42.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:42.708
  STEP: Creating simple DaemonSet "daemon-set" @ 06/15/24 13:22:42.732
  STEP: Check that daemon pods launch on every node of the cluster. @ 06/15/24 13:22:42.737
  Jun 15 13:22:42.744: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:22:42.744: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:22:42.747: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:22:42.747: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 13:22:42.909971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:43.741: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:22:43.741: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:22:43.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:22:43.745: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 13:22:43.910462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:44.742: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:22:44.742: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:22:44.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 13:22:44.745: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 06/15/24 13:22:44.748
  Jun 15 13:22:44.751: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 06/15/24 13:22:44.751
  Jun 15 13:22:44.762: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 06/15/24 13:22:44.762
  Jun 15 13:22:44.764: INFO: Observed &DaemonSet event: ADDED
  Jun 15 13:22:44.764: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.764: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.764: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.764: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.764: INFO: Found daemon set daemon-set in namespace daemonsets-8426 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Jun 15 13:22:44.764: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 06/15/24 13:22:44.764
  STEP: watching for the daemon set status to be patched @ 06/15/24 13:22:44.771
  Jun 15 13:22:44.773: INFO: Observed &DaemonSet event: ADDED
  Jun 15 13:22:44.773: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.773: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.773: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.773: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.773: INFO: Observed daemon set daemon-set in namespace daemonsets-8426 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Jun 15 13:22:44.773: INFO: Observed &DaemonSet event: MODIFIED
  Jun 15 13:22:44.773: INFO: Found daemon set daemon-set in namespace daemonsets-8426 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Jun 15 13:22:44.774: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 06/15/24 13:22:44.78
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8426, will wait for the garbage collector to delete the pods @ 06/15/24 13:22:44.78
  Jun 15 13:22:44.842: INFO: Deleting DaemonSet.extensions daemon-set took: 8.408157ms
  E0615 13:22:44.911428      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:44.942: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.644839ms
  E0615 13:22:45.912429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:46.247: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:22:46.247: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Jun 15 13:22:46.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34248"},"items":null}

  Jun 15 13:22:46.254: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34248"},"items":null}

  Jun 15 13:22:46.267: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8426" for this suite. @ 06/15/24 13:22:46.27
• [3.585 seconds]
------------------------------
SSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 06/15/24 13:22:46.277
  Jun 15 13:22:46.277: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename cronjob @ 06/15/24 13:22:46.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:46.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:46.296
  STEP: Creating a cronjob @ 06/15/24 13:22:46.299
  STEP: creating @ 06/15/24 13:22:46.299
  STEP: getting @ 06/15/24 13:22:46.304
  STEP: listing @ 06/15/24 13:22:46.307
  STEP: watching @ 06/15/24 13:22:46.31
  Jun 15 13:22:46.310: INFO: starting watch
  STEP: cluster-wide listing @ 06/15/24 13:22:46.311
  STEP: cluster-wide watching @ 06/15/24 13:22:46.314
  Jun 15 13:22:46.314: INFO: starting watch
  STEP: patching @ 06/15/24 13:22:46.315
  STEP: updating @ 06/15/24 13:22:46.323
  Jun 15 13:22:46.330: INFO: waiting for watch events with expected annotations
  Jun 15 13:22:46.330: INFO: saw patched and updated annotations
  STEP: patching /status @ 06/15/24 13:22:46.33
  STEP: updating /status @ 06/15/24 13:22:46.337
  STEP: get /status @ 06/15/24 13:22:46.343
  STEP: deleting @ 06/15/24 13:22:46.347
  STEP: deleting a collection @ 06/15/24 13:22:46.36
  Jun 15 13:22:46.370: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5945" for this suite. @ 06/15/24 13:22:46.374
• [0.103 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 06/15/24 13:22:46.38
  Jun 15 13:22:46.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 13:22:46.381
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:46.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:46.397
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 06/15/24 13:22:46.4
  E0615 13:22:46.912532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:47.912619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:48.912719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:49.913399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:22:50.425
  Jun 15 13:22:50.429: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-8cf8fd36-fb95-4e9e-9162-a2b11e390da8 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 13:22:50.435
  Jun 15 13:22:50.449: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2501" for this suite. @ 06/15/24 13:22:50.453
• [4.080 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 06/15/24 13:22:50.461
  Jun 15 13:22:50.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:22:50.461
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:50.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:50.481
  STEP: Creating projection with secret that has name projected-secret-test-56a08a93-a193-4b00-9264-99f29cbdcac8 @ 06/15/24 13:22:50.485
  STEP: Creating a pod to test consume secrets @ 06/15/24 13:22:50.489
  E0615 13:22:50.913434      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:51.913612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:52.913647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:53.914628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:22:54.515
  Jun 15 13:22:54.519: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-secrets-6ad0b5f0-e7f3-4b04-8c5b-ee4d33cb9edc container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 13:22:54.524
  Jun 15 13:22:54.540: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6267" for this suite. @ 06/15/24 13:22:54.544
• [4.089 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1015
  STEP: Creating a kubernetes client @ 06/15/24 13:22:54.55
  Jun 15 13:22:54.550: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 13:22:54.55
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:22:54.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:22:54.567
  STEP: Creating resourceQuota "e2e-rq-status-598sk" @ 06/15/24 13:22:54.573
  Jun 15 13:22:54.580: INFO: Resource quota "e2e-rq-status-598sk" reports spec: hard cpu limit of 500m
  Jun 15 13:22:54.580: INFO: Resource quota "e2e-rq-status-598sk" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-598sk" /status @ 06/15/24 13:22:54.58
  STEP: Confirm /status for "e2e-rq-status-598sk" resourceQuota via watch @ 06/15/24 13:22:54.589
  Jun 15 13:22:54.591: INFO: observed resourceQuota "e2e-rq-status-598sk" in namespace "resourcequota-633" with hard status: v1.ResourceList(nil)
  Jun 15 13:22:54.591: INFO: Found resourceQuota "e2e-rq-status-598sk" in namespace "resourcequota-633" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Jun 15 13:22:54.591: INFO: ResourceQuota "e2e-rq-status-598sk" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 06/15/24 13:22:54.594
  Jun 15 13:22:54.598: INFO: Resource quota "e2e-rq-status-598sk" reports spec: hard cpu limit of 1
  Jun 15 13:22:54.598: INFO: Resource quota "e2e-rq-status-598sk" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-598sk" /status @ 06/15/24 13:22:54.598
  STEP: Confirm /status for "e2e-rq-status-598sk" resourceQuota via watch @ 06/15/24 13:22:54.606
  Jun 15 13:22:54.608: INFO: observed resourceQuota "e2e-rq-status-598sk" in namespace "resourcequota-633" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Jun 15 13:22:54.608: INFO: Found resourceQuota "e2e-rq-status-598sk" in namespace "resourcequota-633" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Jun 15 13:22:54.608: INFO: ResourceQuota "e2e-rq-status-598sk" /status was patched
  STEP: Get "e2e-rq-status-598sk" /status @ 06/15/24 13:22:54.608
  Jun 15 13:22:54.614: INFO: Resourcequota "e2e-rq-status-598sk" reports status: hard cpu of 1
  Jun 15 13:22:54.614: INFO: Resourcequota "e2e-rq-status-598sk" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-598sk" /status before checking Spec is unchanged @ 06/15/24 13:22:54.617
  Jun 15 13:22:54.622: INFO: Resourcequota "e2e-rq-status-598sk" reports status: hard cpu of 2
  Jun 15 13:22:54.622: INFO: Resourcequota "e2e-rq-status-598sk" reports status: hard memory of 2Gi
  Jun 15 13:22:54.624: INFO: Found resourceQuota "e2e-rq-status-598sk" in namespace "resourcequota-633" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Jun 15 13:22:54.628: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a78ba0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a78bd0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a78c00), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:22:54.915642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:55.915742      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:56.916658      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:57.916735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:22:58.916860      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:22:59.627: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a78e40), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a78e70), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a78ea0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:22:59.917867      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:00.917969      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:01.918667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:02.918936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:03.919047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:04.630: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a79200), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a79260), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a79290), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:04.919942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:05.920030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:06.920353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:07.920471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:08.920661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:09.628: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045aeb10), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045aeb40), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045aeb88), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:09.920893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:10.920991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:11.921703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:12.921779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:13.922000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:14.628: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a79818), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a79878), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004a798c0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:14.923043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:15.923294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:16.923384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:17.923576      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:18.923661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:19.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af098), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af0f8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af158), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:19.924137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:20.924229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:21.924630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:22.924735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:23.924863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:24.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af428), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af458), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af4b8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:24.925755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:25.925855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:26.926749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:27.926839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:28.926934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:29.628: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af6f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af728), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045af770), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:29.927034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:30.927127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:31.927811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:32.928352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:33.928542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:34.630: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0006280a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628198), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:34.928804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:35.928986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:36.929476      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:37.929582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:38.929784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:39.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045afc38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045afc80), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0045afd58), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:39.930731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:40.930834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:41.931799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:42.932353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:43.932465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:44.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72150), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d721b0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d721e0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:44.933301      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:45.934205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:46.934784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:47.934849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:48.934944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:49.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d728b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72918), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72960), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:49.935118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:50.935313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:51.936365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:52.936473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:53.936654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:54.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628a20), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628a50), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628a80), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:54.937431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:55.937527      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:56.937670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:57.937806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:23:58.937883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:23:59.628: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628ea0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628ee8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628f48), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:23:59.938206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:00.938471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:01.938807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:02.939167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:03.939346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:24:04.630: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d73128), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d73158), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d73218), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:24:04.939690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:05.939787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:06.939854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:07.939977      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:08.940064      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:24:09.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000629458), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0006294b8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000629530), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:24:09.940536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:10.940630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:11.940685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:12.941057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:13.941020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:24:14.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72180), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d721c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72210), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:24:14.940966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:15.941164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:16.941662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:17.941767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:18.942093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:24:19.629: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72720), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72780), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72870), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:24:19.942146      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:20.942345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:21.943318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:22.943417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:23.944343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:24:24.628: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0006285b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628618), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628678), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:24:24.945400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:25.945687      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:26.946131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:27.946331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:28.946541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:24:29.630: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72f00), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72f30), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d72f90), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:24:29.947398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:30.947552      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:31.947863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:32.947958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:33.948329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:24:34.633: INFO: ResourceQuota "e2e-rq-status-598sk" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-598sk", GenerateName:"", Namespace:"resourcequota-633", SelfLink:"", UID:"9e70c8f5-f66c-4089-abe0-2060d03a2753", ResourceVersion:"34379", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-598sk"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628b58), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628b88), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 22, 54, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000628bb8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0615 13:24:34.948957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:35.949217      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:36.949830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:37.950118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:38.950318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:24:39.630: INFO: ResourceQuota "e2e-rq-status-598sk" Spec was unchanged and /status reset
  Jun 15 13:24:39.630: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-633" for this suite. @ 06/15/24 13:24:39.634
• [105.094 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 06/15/24 13:24:39.643
  Jun 15 13:24:39.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename ingressclass @ 06/15/24 13:24:39.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:24:39.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:24:39.659
  STEP: getting /apis @ 06/15/24 13:24:39.662
  STEP: getting /apis/networking.k8s.io @ 06/15/24 13:24:39.665
  STEP: getting /apis/networking.k8s.iov1 @ 06/15/24 13:24:39.666
  STEP: creating @ 06/15/24 13:24:39.667
  STEP: getting @ 06/15/24 13:24:39.681
  STEP: listing @ 06/15/24 13:24:39.684
  STEP: watching @ 06/15/24 13:24:39.689
  Jun 15 13:24:39.689: INFO: starting watch
  STEP: patching @ 06/15/24 13:24:39.69
  STEP: updating @ 06/15/24 13:24:39.696
  Jun 15 13:24:39.701: INFO: waiting for watch events with expected annotations
  Jun 15 13:24:39.701: INFO: saw patched and updated annotations
  STEP: deleting @ 06/15/24 13:24:39.701
  STEP: deleting a collection @ 06/15/24 13:24:39.713
  Jun 15 13:24:39.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-8789" for this suite. @ 06/15/24 13:24:39.732
• [0.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 06/15/24 13:24:39.738
  Jun 15 13:24:39.738: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename gc @ 06/15/24 13:24:39.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:24:39.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:24:39.755
  STEP: create the rc @ 06/15/24 13:24:39.761
  W0615 13:24:39.767446      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0615 13:24:39.950769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:40.951057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:41.951430      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:42.975006      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 06/15/24 13:24:43.772
  STEP: wait for the rc to be deleted @ 06/15/24 13:24:43.788
  E0615 13:24:43.975891      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:44.994223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:45.995341      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:46.995847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:47.995934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 06/15/24 13:24:48.793
  E0615 13:24:48.996122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:49.996331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:50.996424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:51.997199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:52.997353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:53.997605      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:54.997677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:55.997755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:56.998193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:57.998285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:58.998370      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:24:59.998555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:00.998811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:01.998873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:02.998917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:03.999029      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:04.999261      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:06.000325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:07.000767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:08.000866      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:09.001123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:10.001392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:11.001599      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:12.001913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:13.002781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:14.003248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:15.003405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:16.003503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:17.003606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:18.004332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 06/15/24 13:25:18.802
  W0615 13:25:18.807541      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Jun 15 13:25:18.807: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Jun 15 13:25:18.807: INFO: Deleting pod "simpletest.rc-2bkj4" in namespace "gc-8668"
  Jun 15 13:25:18.821: INFO: Deleting pod "simpletest.rc-2bwt7" in namespace "gc-8668"
  Jun 15 13:25:18.841: INFO: Deleting pod "simpletest.rc-2drf6" in namespace "gc-8668"
  Jun 15 13:25:18.853: INFO: Deleting pod "simpletest.rc-2f5l4" in namespace "gc-8668"
  Jun 15 13:25:18.866: INFO: Deleting pod "simpletest.rc-2jwnp" in namespace "gc-8668"
  Jun 15 13:25:18.877: INFO: Deleting pod "simpletest.rc-2r899" in namespace "gc-8668"
  Jun 15 13:25:18.891: INFO: Deleting pod "simpletest.rc-2vcrr" in namespace "gc-8668"
  Jun 15 13:25:18.902: INFO: Deleting pod "simpletest.rc-4nq7z" in namespace "gc-8668"
  Jun 15 13:25:18.913: INFO: Deleting pod "simpletest.rc-4xzfw" in namespace "gc-8668"
  Jun 15 13:25:18.926: INFO: Deleting pod "simpletest.rc-62mqf" in namespace "gc-8668"
  Jun 15 13:25:18.938: INFO: Deleting pod "simpletest.rc-65vlw" in namespace "gc-8668"
  Jun 15 13:25:18.950: INFO: Deleting pod "simpletest.rc-6w8nz" in namespace "gc-8668"
  Jun 15 13:25:18.964: INFO: Deleting pod "simpletest.rc-6z54z" in namespace "gc-8668"
  Jun 15 13:25:18.978: INFO: Deleting pod "simpletest.rc-6zcdp" in namespace "gc-8668"
  Jun 15 13:25:18.993: INFO: Deleting pod "simpletest.rc-7g8c6" in namespace "gc-8668"
  E0615 13:25:19.004836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:19.011: INFO: Deleting pod "simpletest.rc-7krfs" in namespace "gc-8668"
  Jun 15 13:25:19.029: INFO: Deleting pod "simpletest.rc-7kvl5" in namespace "gc-8668"
  Jun 15 13:25:19.041: INFO: Deleting pod "simpletest.rc-88q4g" in namespace "gc-8668"
  Jun 15 13:25:19.059: INFO: Deleting pod "simpletest.rc-8dq6c" in namespace "gc-8668"
  Jun 15 13:25:19.079: INFO: Deleting pod "simpletest.rc-8qqlt" in namespace "gc-8668"
  Jun 15 13:25:19.094: INFO: Deleting pod "simpletest.rc-92khg" in namespace "gc-8668"
  Jun 15 13:25:19.109: INFO: Deleting pod "simpletest.rc-96dfd" in namespace "gc-8668"
  Jun 15 13:25:19.123: INFO: Deleting pod "simpletest.rc-9b98p" in namespace "gc-8668"
  Jun 15 13:25:19.137: INFO: Deleting pod "simpletest.rc-9p4vm" in namespace "gc-8668"
  Jun 15 13:25:19.150: INFO: Deleting pod "simpletest.rc-b2gpv" in namespace "gc-8668"
  Jun 15 13:25:19.164: INFO: Deleting pod "simpletest.rc-b6sf4" in namespace "gc-8668"
  Jun 15 13:25:19.199: INFO: Deleting pod "simpletest.rc-bdlp6" in namespace "gc-8668"
  Jun 15 13:25:19.210: INFO: Deleting pod "simpletest.rc-bhnl5" in namespace "gc-8668"
  Jun 15 13:25:19.226: INFO: Deleting pod "simpletest.rc-bjs4n" in namespace "gc-8668"
  Jun 15 13:25:19.239: INFO: Deleting pod "simpletest.rc-brkr4" in namespace "gc-8668"
  Jun 15 13:25:19.258: INFO: Deleting pod "simpletest.rc-bw26w" in namespace "gc-8668"
  Jun 15 13:25:19.271: INFO: Deleting pod "simpletest.rc-c42kp" in namespace "gc-8668"
  Jun 15 13:25:19.289: INFO: Deleting pod "simpletest.rc-c5crh" in namespace "gc-8668"
  Jun 15 13:25:19.310: INFO: Deleting pod "simpletest.rc-c6gs6" in namespace "gc-8668"
  Jun 15 13:25:19.346: INFO: Deleting pod "simpletest.rc-c9jl2" in namespace "gc-8668"
  Jun 15 13:25:19.362: INFO: Deleting pod "simpletest.rc-ccs82" in namespace "gc-8668"
  Jun 15 13:25:19.376: INFO: Deleting pod "simpletest.rc-cmw2v" in namespace "gc-8668"
  Jun 15 13:25:19.397: INFO: Deleting pod "simpletest.rc-cvsmx" in namespace "gc-8668"
  Jun 15 13:25:19.412: INFO: Deleting pod "simpletest.rc-d6hgm" in namespace "gc-8668"
  Jun 15 13:25:19.425: INFO: Deleting pod "simpletest.rc-dzkzw" in namespace "gc-8668"
  Jun 15 13:25:19.449: INFO: Deleting pod "simpletest.rc-f4l8s" in namespace "gc-8668"
  Jun 15 13:25:19.461: INFO: Deleting pod "simpletest.rc-f4njz" in namespace "gc-8668"
  Jun 15 13:25:19.480: INFO: Deleting pod "simpletest.rc-ff4k9" in namespace "gc-8668"
  Jun 15 13:25:19.498: INFO: Deleting pod "simpletest.rc-fm2fz" in namespace "gc-8668"
  Jun 15 13:25:19.511: INFO: Deleting pod "simpletest.rc-fttd2" in namespace "gc-8668"
  Jun 15 13:25:19.523: INFO: Deleting pod "simpletest.rc-g5vwj" in namespace "gc-8668"
  Jun 15 13:25:19.572: INFO: Deleting pod "simpletest.rc-g9h47" in namespace "gc-8668"
  Jun 15 13:25:19.596: INFO: Deleting pod "simpletest.rc-gnd82" in namespace "gc-8668"
  Jun 15 13:25:19.607: INFO: Deleting pod "simpletest.rc-gsg8z" in namespace "gc-8668"
  Jun 15 13:25:19.627: INFO: Deleting pod "simpletest.rc-hcm2n" in namespace "gc-8668"
  Jun 15 13:25:19.643: INFO: Deleting pod "simpletest.rc-jh97p" in namespace "gc-8668"
  Jun 15 13:25:19.658: INFO: Deleting pod "simpletest.rc-jkkm5" in namespace "gc-8668"
  Jun 15 13:25:19.673: INFO: Deleting pod "simpletest.rc-kcdck" in namespace "gc-8668"
  Jun 15 13:25:19.685: INFO: Deleting pod "simpletest.rc-kl5l2" in namespace "gc-8668"
  Jun 15 13:25:19.702: INFO: Deleting pod "simpletest.rc-ldr7k" in namespace "gc-8668"
  Jun 15 13:25:19.718: INFO: Deleting pod "simpletest.rc-ljwjk" in namespace "gc-8668"
  Jun 15 13:25:19.734: INFO: Deleting pod "simpletest.rc-lnb8z" in namespace "gc-8668"
  Jun 15 13:25:19.746: INFO: Deleting pod "simpletest.rc-lxv4s" in namespace "gc-8668"
  Jun 15 13:25:19.761: INFO: Deleting pod "simpletest.rc-mmv9f" in namespace "gc-8668"
  Jun 15 13:25:19.773: INFO: Deleting pod "simpletest.rc-mz6dk" in namespace "gc-8668"
  Jun 15 13:25:19.817: INFO: Deleting pod "simpletest.rc-mzgwh" in namespace "gc-8668"
  Jun 15 13:25:19.830: INFO: Deleting pod "simpletest.rc-n2swf" in namespace "gc-8668"
  Jun 15 13:25:19.842: INFO: Deleting pod "simpletest.rc-nc9xc" in namespace "gc-8668"
  Jun 15 13:25:19.858: INFO: Deleting pod "simpletest.rc-ndljt" in namespace "gc-8668"
  Jun 15 13:25:19.873: INFO: Deleting pod "simpletest.rc-p7dfb" in namespace "gc-8668"
  Jun 15 13:25:19.884: INFO: Deleting pod "simpletest.rc-pmqqx" in namespace "gc-8668"
  Jun 15 13:25:19.898: INFO: Deleting pod "simpletest.rc-qb592" in namespace "gc-8668"
  Jun 15 13:25:19.908: INFO: Deleting pod "simpletest.rc-qd7sh" in namespace "gc-8668"
  Jun 15 13:25:19.919: INFO: Deleting pod "simpletest.rc-qqjhx" in namespace "gc-8668"
  Jun 15 13:25:19.932: INFO: Deleting pod "simpletest.rc-qrdwm" in namespace "gc-8668"
  Jun 15 13:25:19.944: INFO: Deleting pod "simpletest.rc-qvrz2" in namespace "gc-8668"
  Jun 15 13:25:19.958: INFO: Deleting pod "simpletest.rc-qxrc8" in namespace "gc-8668"
  E0615 13:25:20.005681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:20.005: INFO: Deleting pod "simpletest.rc-r8rw6" in namespace "gc-8668"
  Jun 15 13:25:20.057: INFO: Deleting pod "simpletest.rc-r9cvd" in namespace "gc-8668"
  Jun 15 13:25:20.114: INFO: Deleting pod "simpletest.rc-rgsn5" in namespace "gc-8668"
  Jun 15 13:25:20.157: INFO: Deleting pod "simpletest.rc-rlcbf" in namespace "gc-8668"
  Jun 15 13:25:20.209: INFO: Deleting pod "simpletest.rc-rvcbb" in namespace "gc-8668"
  Jun 15 13:25:20.258: INFO: Deleting pod "simpletest.rc-rvst2" in namespace "gc-8668"
  Jun 15 13:25:20.306: INFO: Deleting pod "simpletest.rc-s5nxc" in namespace "gc-8668"
  Jun 15 13:25:20.356: INFO: Deleting pod "simpletest.rc-s9hjt" in namespace "gc-8668"
  Jun 15 13:25:20.426: INFO: Deleting pod "simpletest.rc-sjhsk" in namespace "gc-8668"
  Jun 15 13:25:20.460: INFO: Deleting pod "simpletest.rc-sz757" in namespace "gc-8668"
  Jun 15 13:25:20.506: INFO: Deleting pod "simpletest.rc-tsp55" in namespace "gc-8668"
  Jun 15 13:25:20.559: INFO: Deleting pod "simpletest.rc-v5cbv" in namespace "gc-8668"
  Jun 15 13:25:20.607: INFO: Deleting pod "simpletest.rc-vhz5j" in namespace "gc-8668"
  Jun 15 13:25:20.656: INFO: Deleting pod "simpletest.rc-vqgt6" in namespace "gc-8668"
  Jun 15 13:25:20.707: INFO: Deleting pod "simpletest.rc-vxwmn" in namespace "gc-8668"
  Jun 15 13:25:20.754: INFO: Deleting pod "simpletest.rc-w48wm" in namespace "gc-8668"
  Jun 15 13:25:20.807: INFO: Deleting pod "simpletest.rc-w4v94" in namespace "gc-8668"
  Jun 15 13:25:20.860: INFO: Deleting pod "simpletest.rc-w5lx5" in namespace "gc-8668"
  Jun 15 13:25:20.910: INFO: Deleting pod "simpletest.rc-wmhxr" in namespace "gc-8668"
  Jun 15 13:25:20.959: INFO: Deleting pod "simpletest.rc-wmwcw" in namespace "gc-8668"
  E0615 13:25:21.006564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:21.008: INFO: Deleting pod "simpletest.rc-wnpm2" in namespace "gc-8668"
  Jun 15 13:25:21.068: INFO: Deleting pod "simpletest.rc-xc8q6" in namespace "gc-8668"
  Jun 15 13:25:21.111: INFO: Deleting pod "simpletest.rc-xn86x" in namespace "gc-8668"
  Jun 15 13:25:21.160: INFO: Deleting pod "simpletest.rc-xtjpc" in namespace "gc-8668"
  Jun 15 13:25:21.211: INFO: Deleting pod "simpletest.rc-xttf6" in namespace "gc-8668"
  Jun 15 13:25:21.255: INFO: Deleting pod "simpletest.rc-xwl75" in namespace "gc-8668"
  Jun 15 13:25:21.310: INFO: Deleting pod "simpletest.rc-z98pk" in namespace "gc-8668"
  Jun 15 13:25:21.375: INFO: Deleting pod "simpletest.rc-zqvdc" in namespace "gc-8668"
  Jun 15 13:25:21.407: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8668" for this suite. @ 06/15/24 13:25:21.46
• [41.763 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 06/15/24 13:25:21.501
  Jun 15 13:25:21.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:25:21.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:21.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:21.551
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:25:21.578
  E0615 13:25:22.007564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:23.007643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:24.008307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:25.008384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:25:25.601
  Jun 15 13:25:25.605: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-e3e6c3d7-4504-444d-822f-061818bf1544 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:25:25.614
  Jun 15 13:25:25.631: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6335" for this suite. @ 06/15/24 13:25:25.635
• [4.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 06/15/24 13:25:25.643
  Jun 15 13:25:25.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename field-validation @ 06/15/24 13:25:25.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:25.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:25.66
  Jun 15 13:25:25.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:25:26.008611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:27.008706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:28.008739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:28.743: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1704" for this suite. @ 06/15/24 13:25:28.746
• [3.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 06/15/24 13:25:28.753
  Jun 15 13:25:28.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 13:25:28.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:28.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:28.767
  STEP: Setting up server cert @ 06/15/24 13:25:28.794
  E0615 13:25:29.009197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 13:25:29.218
  STEP: Deploying the webhook pod @ 06/15/24 13:25:29.23
  STEP: Wait for the deployment to be ready @ 06/15/24 13:25:29.251
  Jun 15 13:25:29.264: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 13:25:30.009743      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:31.009944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 13:25:31.276
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 13:25:31.284
  E0615 13:25:32.010249      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:32.284: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 06/15/24 13:25:32.291
  STEP: create a pod @ 06/15/24 13:25:32.304
  E0615 13:25:33.010347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:34.010445      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 06/15/24 13:25:34.321
  Jun 15 13:25:34.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=webhook-2105 attach --namespace=webhook-2105 to-be-attached-pod -i -c=container1'
  Jun 15 13:25:34.374: INFO: rc: 1
  Jun 15 13:25:34.429: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2105" for this suite. @ 06/15/24 13:25:34.433
  STEP: Destroying namespace "webhook-markers-325" for this suite. @ 06/15/24 13:25:34.443
• [5.698 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 06/15/24 13:25:34.451
  Jun 15 13:25:34.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename gc @ 06/15/24 13:25:34.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:34.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:34.468
  STEP: create the rc @ 06/15/24 13:25:34.474
  W0615 13:25:34.478664      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0615 13:25:35.010915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:36.023394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:37.026975      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:38.027336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 06/15/24 13:25:38.487
  STEP: wait for the rc to be deleted @ 06/15/24 13:25:38.495
  E0615 13:25:39.027540      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:39.547: INFO: 80 pods remaining
  Jun 15 13:25:39.547: INFO: 80 pods has nil DeletionTimestamp
  Jun 15 13:25:39.547: INFO: 
  E0615 13:25:40.041148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:40.513: INFO: 71 pods remaining
  Jun 15 13:25:40.513: INFO: 70 pods has nil DeletionTimestamp
  Jun 15 13:25:40.513: INFO: 
  E0615 13:25:41.043387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:41.526: INFO: 60 pods remaining
  Jun 15 13:25:41.526: INFO: 60 pods has nil DeletionTimestamp
  Jun 15 13:25:41.526: INFO: 
  E0615 13:25:42.043979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:42.509: INFO: 40 pods remaining
  Jun 15 13:25:42.509: INFO: 40 pods has nil DeletionTimestamp
  Jun 15 13:25:42.509: INFO: 
  E0615 13:25:43.045204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:43.519: INFO: 31 pods remaining
  Jun 15 13:25:43.519: INFO: 30 pods has nil DeletionTimestamp
  Jun 15 13:25:43.520: INFO: 
  E0615 13:25:44.045264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:44.518: INFO: 20 pods remaining
  Jun 15 13:25:44.518: INFO: 20 pods has nil DeletionTimestamp
  Jun 15 13:25:44.518: INFO: 
  E0615 13:25:45.046040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 06/15/24 13:25:45.512
  W0615 13:25:45.518702      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Jun 15 13:25:45.518: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Jun 15 13:25:45.518: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-406" for this suite. @ 06/15/24 13:25:45.522
• [11.079 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 06/15/24 13:25:45.53
  Jun 15 13:25:45.530: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename field-validation @ 06/15/24 13:25:45.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:45.546
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:45.552
  STEP: apply creating a deployment @ 06/15/24 13:25:45.558
  Jun 15 13:25:45.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4854" for this suite. @ 06/15/24 13:25:45.587
• [0.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 06/15/24 13:25:45.597
  Jun 15 13:25:45.597: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 13:25:45.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:45.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:45.619
  STEP: Creating secret with name secret-test-ae558f40-1180-41f3-9511-e53fdccdc526 @ 06/15/24 13:25:45.625
  STEP: Creating a pod to test consume secrets @ 06/15/24 13:25:45.635
  E0615 13:25:46.046129      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:47.046956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:48.047677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:49.047850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:25:49.658
  Jun 15 13:25:49.662: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-secrets-d232c5a8-fcf2-41e6-9577-27ae25a29e8b container secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 13:25:49.668
  Jun 15 13:25:49.685: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6002" for this suite. @ 06/15/24 13:25:49.689
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 06/15/24 13:25:49.698
  Jun 15 13:25:49.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename disruption @ 06/15/24 13:25:49.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:49.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:49.713
  STEP: Creating a kubernetes client @ 06/15/24 13:25:49.717
  Jun 15 13:25:49.717: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename disruption-2 @ 06/15/24 13:25:49.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:49.732
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:49.735
  STEP: Waiting for the pdb to be processed @ 06/15/24 13:25:49.744
  STEP: Waiting for the pdb to be processed @ 06/15/24 13:25:49.757
  STEP: Waiting for the pdb to be processed @ 06/15/24 13:25:49.767
  STEP: listing a collection of PDBs across all namespaces @ 06/15/24 13:25:49.773
  STEP: listing a collection of PDBs in namespace disruption-1791 @ 06/15/24 13:25:49.776
  STEP: deleting a collection of PDBs @ 06/15/24 13:25:49.779
  STEP: Waiting for the PDB collection to be deleted @ 06/15/24 13:25:49.791
  Jun 15 13:25:49.794: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-9282" for this suite. @ 06/15/24 13:25:49.797
  Jun 15 13:25:49.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1791" for this suite. @ 06/15/24 13:25:49.807
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 06/15/24 13:25:49.814
  Jun 15 13:25:49.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename watch @ 06/15/24 13:25:49.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:49.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:49.831
  STEP: creating a watch on configmaps @ 06/15/24 13:25:49.834
  STEP: creating a new configmap @ 06/15/24 13:25:49.836
  STEP: modifying the configmap once @ 06/15/24 13:25:49.842
  STEP: closing the watch once it receives two notifications @ 06/15/24 13:25:49.85
  Jun 15 13:25:49.850: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8777  991ca21a-6a1d-42b1-800f-8c6c8ad55be4 39138 0 2024-06-15 13:25:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-06-15 13:25:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 13:25:49.850: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8777  991ca21a-6a1d-42b1-800f-8c6c8ad55be4 39139 0 2024-06-15 13:25:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-06-15 13:25:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 06/15/24 13:25:49.85
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 06/15/24 13:25:49.857
  STEP: deleting the configmap @ 06/15/24 13:25:49.858
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 06/15/24 13:25:49.864
  Jun 15 13:25:49.864: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8777  991ca21a-6a1d-42b1-800f-8c6c8ad55be4 39140 0 2024-06-15 13:25:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-06-15 13:25:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 13:25:49.864: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8777  991ca21a-6a1d-42b1-800f-8c6c8ad55be4 39141 0 2024-06-15 13:25:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-06-15 13:25:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Jun 15 13:25:49.864: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8777" for this suite. @ 06/15/24 13:25:49.868
• [0.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 06/15/24 13:25:49.878
  Jun 15 13:25:49.878: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 13:25:49.879
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:49.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:49.895
  STEP: creating a Pod with a static label @ 06/15/24 13:25:49.905
  STEP: watching for Pod to be ready @ 06/15/24 13:25:49.913
  Jun 15 13:25:49.916: INFO: observed Pod pod-test in namespace pods-3198 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Jun 15 13:25:49.919: INFO: observed Pod pod-test in namespace pods-3198 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:49 +0000 UTC  }]
  Jun 15 13:25:49.939: INFO: observed Pod pod-test in namespace pods-3198 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:49 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:49 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:49 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:49 +0000 UTC  }]
  E0615 13:25:50.048470      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:51.048767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:51.267: INFO: Found Pod pod-test in namespace pods-3198 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:51 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-06-15 13:25:49 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 06/15/24 13:25:51.271
  STEP: getting the Pod and ensuring that it's patched @ 06/15/24 13:25:51.281
  STEP: replacing the Pod's status Ready condition to False @ 06/15/24 13:25:51.284
  STEP: check the Pod again to ensure its Ready conditions are False @ 06/15/24 13:25:51.296
  STEP: deleting the Pod via a Collection with a LabelSelector @ 06/15/24 13:25:51.296
  STEP: watching for the Pod to be deleted @ 06/15/24 13:25:51.306
  Jun 15 13:25:51.308: INFO: observed event type MODIFIED
  E0615 13:25:52.049756      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:53.050265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:53.275: INFO: observed event type MODIFIED
  Jun 15 13:25:53.413: INFO: observed event type MODIFIED
  E0615 13:25:54.050943      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:54.276: INFO: observed event type MODIFIED
  Jun 15 13:25:54.288: INFO: observed event type MODIFIED
  Jun 15 13:25:54.295: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3198" for this suite. @ 06/15/24 13:25:54.298
• [4.426 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1863
  STEP: Creating a kubernetes client @ 06/15/24 13:25:54.304
  Jun 15 13:25:54.304: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:25:54.305
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:54.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:54.322
  STEP: Starting the proxy @ 06/15/24 13:25:54.325
  Jun 15 13:25:54.325: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4254 proxy --unix-socket=/tmp/kubectl-proxy-unix1653907907/test'
  STEP: retrieving proxy /api/ output @ 06/15/24 13:25:54.356
  Jun 15 13:25:54.357: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4254" for this suite. @ 06/15/24 13:25:54.361
• [0.063 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:109
  STEP: Creating a kubernetes client @ 06/15/24 13:25:54.367
  Jun 15 13:25:54.367: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubelet-test @ 06/15/24 13:25:54.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:54.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:54.383
  E0615 13:25:55.051310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:56.051438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:57.052433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:25:58.052520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:25:58.406: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2755" for this suite. @ 06/15/24 13:25:58.41
• [4.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 06/15/24 13:25:58.431
  Jun 15 13:25:58.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename cronjob @ 06/15/24 13:25:58.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:25:58.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:25:58.46
  STEP: Creating a cronjob @ 06/15/24 13:25:58.465
  STEP: Ensuring more than one job is running at a time @ 06/15/24 13:25:58.471
  E0615 13:25:59.053495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:00.054546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:01.054637      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:02.054764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:03.054776      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:04.054939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:05.055024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:06.055161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:07.055646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:08.056376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:09.057369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:10.057555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:11.057634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:12.057808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:13.058477      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:14.058684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:15.058769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:16.058976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:17.059696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:18.059807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:19.059900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:20.059993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:21.060369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:22.060831      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:23.060971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:24.061851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:25.062683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:26.062996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:27.063097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:28.063296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:29.064223      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:30.064420      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:31.064541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:32.064786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:33.065642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:34.065990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:35.066262      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:36.066585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:37.067361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:38.067553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:39.067646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:40.068304      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:41.069247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:42.070150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:43.070242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:44.070359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:45.071282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:46.071377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:47.071478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:48.071571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:49.071674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:50.071813      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:51.072141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:52.072229      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:53.072836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:54.072929      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:55.073237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:56.073340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:57.073896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:58.074615      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:26:59.074769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:00.075363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 06/15/24 13:27:00.476
  STEP: Removing cronjob @ 06/15/24 13:27:00.478
  Jun 15 13:27:00.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3281" for this suite. @ 06/15/24 13:27:00.488
• [62.068 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 06/15/24 13:27:00.497
  Jun 15 13:27:00.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-runtime @ 06/15/24 13:27:00.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:27:00.52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:27:00.524
  STEP: create the container @ 06/15/24 13:27:00.527
  W0615 13:27:00.535848      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 06/15/24 13:27:00.536
  E0615 13:27:01.075453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:02.076302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:03.076408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 06/15/24 13:27:03.551
  STEP: the container should be terminated @ 06/15/24 13:27:03.556
  STEP: the termination message should be set @ 06/15/24 13:27:03.556
  Jun 15 13:27:03.556: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 06/15/24 13:27:03.556
  Jun 15 13:27:03.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6686" for this suite. @ 06/15/24 13:27:03.577
• [3.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 06/15/24 13:27:03.586
  Jun 15 13:27:03.586: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 13:27:03.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:27:03.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:27:03.602
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 06/15/24 13:27:03.605
  Jun 15 13:27:03.605: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:27:04.076505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:27:04.923: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:27:05.077086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:06.078017      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:07.078344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:08.079075      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:09.079220      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:27:09.968: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4779" for this suite. @ 06/15/24 13:27:09.976
• [6.397 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 06/15/24 13:27:09.984
  Jun 15 13:27:09.984: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-watch @ 06/15/24 13:27:09.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:27:09.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:27:10.002
  Jun 15 13:27:10.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:27:10.079810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:11.080020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:12.080110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 06/15/24 13:27:12.544
  Jun 15 13:27:12.549: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-06-15T13:27:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-06-15T13:27:12Z]] name:name1 resourceVersion:40064 uid:767621d4-5014-4777-aa8b-7cb34332e8fb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0615 13:27:13.081123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:14.081342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:15.081412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:16.081508      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:17.082037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:18.082469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:19.082740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:20.083551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:21.083652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:22.084334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 06/15/24 13:27:22.55
  Jun 15 13:27:22.556: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-06-15T13:27:22Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-06-15T13:27:22Z]] name:name2 resourceVersion:40091 uid:489870af-e3db-4783-974a-e826b56fc032] num:map[num1:9223372036854775807 num2:1000000]]}
  E0615 13:27:23.084382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:24.084478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:25.084683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:26.084887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:27.085402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:28.085509      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:29.085696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:30.085892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:31.087941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:32.088924      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 06/15/24 13:27:32.557
  Jun 15 13:27:32.564: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-06-15T13:27:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-06-15T13:27:32Z]] name:name1 resourceVersion:40126 uid:767621d4-5014-4777-aa8b-7cb34332e8fb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0615 13:27:33.089474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:34.090302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:35.090763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:36.091163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:37.091447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:38.092337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:39.092939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:40.093355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:41.093571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:42.093944      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 06/15/24 13:27:42.565
  Jun 15 13:27:42.572: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-06-15T13:27:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-06-15T13:27:42Z]] name:name2 resourceVersion:40146 uid:489870af-e3db-4783-974a-e826b56fc032] num:map[num1:9223372036854775807 num2:1000000]]}
  E0615 13:27:43.094039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:44.094153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:45.095101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:46.095274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:47.095855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:48.095963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:49.096352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:50.096421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:51.096502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:52.096770      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 06/15/24 13:27:52.573
  Jun 15 13:27:52.583: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-06-15T13:27:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-06-15T13:27:32Z]] name:name1 resourceVersion:40170 uid:767621d4-5014-4777-aa8b-7cb34332e8fb] num:map[num1:9223372036854775807 num2:1000000]]}
  E0615 13:27:53.097452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:54.097550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:55.097667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:56.098563      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:57.098816      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:58.099010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:27:59.099256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:00.099372      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:01.100349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:02.100691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 06/15/24 13:28:02.59
  Jun 15 13:28:02.605: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-06-15T13:27:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-06-15T13:27:42Z]] name:name2 resourceVersion:40190 uid:489870af-e3db-4783-974a-e826b56fc032] num:map[num1:9223372036854775807 num2:1000000]]}
  E0615 13:28:03.100834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:04.100947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:05.101040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:06.101285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:07.101769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:08.101877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:09.102097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:10.102225      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:11.102384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:12.102752      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:13.102999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:28:13.122: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-930" for this suite. @ 06/15/24 13:28:13.126
• [63.150 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 06/15/24 13:28:13.133
  Jun 15 13:28:13.133: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replicaset @ 06/15/24 13:28:13.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:28:13.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:28:13.156
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 06/15/24 13:28:13.159
  Jun 15 13:28:13.168: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0615 13:28:14.103276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:15.103407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:16.103493      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:17.103997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:18.104091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:28:18.173: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 06/15/24 13:28:18.173
  STEP: getting scale subresource @ 06/15/24 13:28:18.173
  STEP: updating a scale subresource @ 06/15/24 13:28:18.177
  STEP: verifying the replicaset Spec.Replicas was modified @ 06/15/24 13:28:18.183
  STEP: Patch a scale subresource @ 06/15/24 13:28:18.191
  Jun 15 13:28:18.215: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5827" for this suite. @ 06/15/24 13:28:18.219
• [5.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:655
  STEP: Creating a kubernetes client @ 06/15/24 13:28:18.239
  Jun 15 13:28:18.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename job @ 06/15/24 13:28:18.239
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:28:18.255
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:28:18.26
  STEP: Creating a job @ 06/15/24 13:28:18.263
  STEP: Ensuring active pods == parallelism @ 06/15/24 13:28:18.27
  E0615 13:28:19.104248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:20.104306      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 06/15/24 13:28:20.275
  Jun 15 13:28:20.794: INFO: Successfully updated pod "adopt-release-ld8qm"
  STEP: Checking that the Job readopts the Pod @ 06/15/24 13:28:20.794
  E0615 13:28:21.104785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:22.104959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 06/15/24 13:28:22.804
  E0615 13:28:23.105672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:28:23.315: INFO: Successfully updated pod "adopt-release-ld8qm"
  STEP: Checking that the Job releases the Pod @ 06/15/24 13:28:23.316
  E0615 13:28:24.105827      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:25.105941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:28:25.327: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8839" for this suite. @ 06/15/24 13:28:25.332
• [7.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 06/15/24 13:28:25.339
  Jun 15 13:28:25.339: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename subpath @ 06/15/24 13:28:25.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:28:25.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:28:25.359
  STEP: Setting up data @ 06/15/24 13:28:25.362
  STEP: Creating pod pod-subpath-test-configmap-jksr @ 06/15/24 13:28:25.372
  STEP: Creating a pod to test atomic-volume-subpath @ 06/15/24 13:28:25.372
  E0615 13:28:26.106123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:27.106735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:28.106800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:29.106982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:30.107595      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:31.107763      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:32.107808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:33.108454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:34.108541      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:35.108635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:36.108715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:37.108808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:38.108983      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:39.109067      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:40.109334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:41.109654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:42.110419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:43.110646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:44.111518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:45.112350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:46.113253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:47.113748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:48.113872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:49.114103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:28:49.45
  Jun 15 13:28:49.455: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-subpath-test-configmap-jksr container test-container-subpath-configmap-jksr: <nil>
  STEP: delete the pod @ 06/15/24 13:28:49.47
  STEP: Deleting pod pod-subpath-test-configmap-jksr @ 06/15/24 13:28:49.485
  Jun 15 13:28:49.485: INFO: Deleting pod "pod-subpath-test-configmap-jksr" in namespace "subpath-5203"
  Jun 15 13:28:49.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5203" for this suite. @ 06/15/24 13:28:49.494
• [24.162 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 06/15/24 13:28:49.501
  Jun 15 13:28:49.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 13:28:49.502
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:28:49.519
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:28:49.521
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:28:49.524
  E0615 13:28:50.114210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:51.114297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:52.114646      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:53.114939      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:28:53.551
  Jun 15 13:28:53.554: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-a1eb979f-7e98-46b8-9d76-5896dae427c7 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:28:53.561
  Jun 15 13:28:53.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5708" for this suite. @ 06/15/24 13:28:53.583
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:155
  STEP: Creating a kubernetes client @ 06/15/24 13:28:53.59
  Jun 15 13:28:53.590: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 13:28:53.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:28:53.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:28:53.607
  STEP: creating a secret @ 06/15/24 13:28:53.61
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 06/15/24 13:28:53.615
  STEP: patching the secret @ 06/15/24 13:28:53.619
  STEP: deleting the secret using a LabelSelector @ 06/15/24 13:28:53.628
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 06/15/24 13:28:53.64
  Jun 15 13:28:53.643: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4394" for this suite. @ 06/15/24 13:28:53.647
• [0.063 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 06/15/24 13:28:53.653
  Jun 15 13:28:53.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 13:28:53.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:28:53.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:28:53.671
  STEP: Creating configMap with name configmap-test-volume-864263b7-a024-4b81-b593-8a84bfbe8a75 @ 06/15/24 13:28:53.674
  STEP: Creating a pod to test consume configMaps @ 06/15/24 13:28:53.678
  E0615 13:28:54.115239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:55.115410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:56.115503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:57.115622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:28:57.701
  Jun 15 13:28:57.704: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-configmaps-12fa8569-4329-441b-a014-5048df01ddec container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 13:28:57.712
  Jun 15 13:28:57.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5200" for this suite. @ 06/15/24 13:28:57.732
• [4.085 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 06/15/24 13:28:57.739
  Jun 15 13:28:57.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 13:28:57.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:28:57.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:28:57.756
  STEP: creating the pod @ 06/15/24 13:28:57.759
  STEP: submitting the pod to kubernetes @ 06/15/24 13:28:57.759
  W0615 13:28:57.769152      19 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0615 13:28:58.116471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:28:59.116574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 06/15/24 13:28:59.783
  STEP: updating the pod @ 06/15/24 13:28:59.786
  E0615 13:29:00.117124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:29:00.301: INFO: Successfully updated pod "pod-update-activedeadlineseconds-932b251d-6ae9-4322-a439-b4dffae4aa86"
  E0615 13:29:01.117208      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:02.117282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:03.117429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:04.117524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:29:04.314: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5727" for this suite. @ 06/15/24 13:29:04.319
• [6.587 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 06/15/24 13:29:04.326
  Jun 15 13:29:04.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 13:29:04.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:04.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:04.345
  STEP: Creating secret with name secret-test-8f0d8fca-58a2-44fa-a2e0-e6b970494330 @ 06/15/24 13:29:04.369
  STEP: Creating a pod to test consume secrets @ 06/15/24 13:29:04.376
  E0615 13:29:05.117596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:06.117862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:07.118355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:08.118423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:29:08.4
  Jun 15 13:29:08.404: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-secrets-9fd4e0cd-8b51-48fc-b1a8-e670114e1319 container secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 13:29:08.409
  Jun 15 13:29:08.425: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-671" for this suite. @ 06/15/24 13:29:08.43
  STEP: Destroying namespace "secret-namespace-6199" for this suite. @ 06/15/24 13:29:08.438
• [4.118 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 06/15/24 13:29:08.445
  Jun 15 13:29:08.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 13:29:08.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:08.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:08.461
  STEP: Creating Pod @ 06/15/24 13:29:08.463
  E0615 13:29:09.119207      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:10.119282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 06/15/24 13:29:10.485
  Jun 15 13:29:10.485: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-9359 PodName:pod-sharedvolume-4e321f7f-2de8-4218-9d46-37c876516464 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:29:10.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:29:10.486: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:29:10.486: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-9359/pods/pod-sharedvolume-4e321f7f-2de8-4218-9d46-37c876516464/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Jun 15 13:29:10.547: INFO: Exec stderr: ""
  Jun 15 13:29:10.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9359" for this suite. @ 06/15/24 13:29:10.554
• [2.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 06/15/24 13:29:10.565
  Jun 15 13:29:10.565: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename runtimeclass @ 06/15/24 13:29:10.566
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:10.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:10.587
  Jun 15 13:29:10.647: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8999" for this suite. @ 06/15/24 13:29:10.652
• [0.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 06/15/24 13:29:10.66
  Jun 15 13:29:10.660: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 13:29:10.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:10.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:10.682
  Jun 15 13:29:10.731: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3733" for this suite. @ 06/15/24 13:29:10.734
• [0.082 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 06/15/24 13:29:10.742
  Jun 15 13:29:10.742: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename csistoragecapacity @ 06/15/24 13:29:10.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:10.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:10.761
  STEP: getting /apis @ 06/15/24 13:29:10.765
  STEP: getting /apis/storage.k8s.io @ 06/15/24 13:29:10.769
  STEP: getting /apis/storage.k8s.io/v1 @ 06/15/24 13:29:10.77
  STEP: creating @ 06/15/24 13:29:10.772
  STEP: watching @ 06/15/24 13:29:10.791
  Jun 15 13:29:10.791: INFO: starting watch
  STEP: getting @ 06/15/24 13:29:10.8
  STEP: listing in namespace @ 06/15/24 13:29:10.804
  STEP: listing across namespaces @ 06/15/24 13:29:10.807
  STEP: patching @ 06/15/24 13:29:10.811
  STEP: updating @ 06/15/24 13:29:10.816
  Jun 15 13:29:10.821: INFO: waiting for watch events with expected annotations in namespace
  Jun 15 13:29:10.821: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 06/15/24 13:29:10.821
  STEP: deleting a collection @ 06/15/24 13:29:10.837
  Jun 15 13:29:10.854: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-9520" for this suite. @ 06/15/24 13:29:10.86
• [0.126 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1538
  STEP: Creating a kubernetes client @ 06/15/24 13:29:10.868
  Jun 15 13:29:10.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:29:10.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:10.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:10.89
  STEP: creating Agnhost RC @ 06/15/24 13:29:10.904
  Jun 15 13:29:10.904: INFO: namespace kubectl-3653
  Jun 15 13:29:10.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3653 create -f -'
  Jun 15 13:29:10.989: INFO: stderr: ""
  Jun 15 13:29:10.989: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 06/15/24 13:29:10.989
  E0615 13:29:11.120339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:29:11.994: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:29:11.994: INFO: Found 0 / 1
  E0615 13:29:12.121145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:29:12.994: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:29:12.994: INFO: Found 1 / 1
  Jun 15 13:29:12.994: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Jun 15 13:29:12.999: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:29:12.999: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Jun 15 13:29:12.999: INFO: wait on agnhost-primary startup in kubectl-3653 
  Jun 15 13:29:12.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3653 logs agnhost-primary-b4d78 agnhost-primary'
  Jun 15 13:29:13.058: INFO: stderr: ""
  Jun 15 13:29:13.058: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 06/15/24 13:29:13.058
  Jun 15 13:29:13.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3653 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  E0615 13:29:13.121287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:29:13.121: INFO: stderr: ""
  Jun 15 13:29:13.121: INFO: stdout: "service/rm2 exposed\n"
  Jun 15 13:29:13.126: INFO: Service rm2 in namespace kubectl-3653 found.
  E0615 13:29:14.121735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:15.121804      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 06/15/24 13:29:15.134
  Jun 15 13:29:15.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3653 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Jun 15 13:29:15.190: INFO: stderr: ""
  Jun 15 13:29:15.190: INFO: stdout: "service/rm3 exposed\n"
  Jun 15 13:29:15.198: INFO: Service rm3 in namespace kubectl-3653 found.
  E0615 13:29:16.122795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:17.123051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:29:17.207: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3653" for this suite. @ 06/15/24 13:29:17.212
• [6.352 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 06/15/24 13:29:17.22
  Jun 15 13:29:17.220: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 13:29:17.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:17.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:17.243
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 06/15/24 13:29:17.246
  E0615 13:29:18.123296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:19.123380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:20.123471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:21.123572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:29:21.272
  Jun 15 13:29:21.276: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-c03a5982-7262-4e36-8568-df27a58b06ae container test-container: <nil>
  STEP: delete the pod @ 06/15/24 13:29:21.293
  Jun 15 13:29:21.310: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7445" for this suite. @ 06/15/24 13:29:21.313
• [4.099 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:889
  STEP: Creating a kubernetes client @ 06/15/24 13:29:21.319
  Jun 15 13:29:21.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 13:29:21.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:21.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:21.34
  STEP: Creating a ResourceQuota @ 06/15/24 13:29:21.343
  STEP: Getting a ResourceQuota @ 06/15/24 13:29:21.347
  STEP: Updating a ResourceQuota @ 06/15/24 13:29:21.352
  STEP: Verifying a ResourceQuota was modified @ 06/15/24 13:29:21.361
  STEP: Deleting a ResourceQuota @ 06/15/24 13:29:21.364
  STEP: Verifying the deleted ResourceQuota @ 06/15/24 13:29:21.371
  Jun 15 13:29:21.374: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6978" for this suite. @ 06/15/24 13:29:21.38
• [0.068 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 06/15/24 13:29:21.388
  Jun 15 13:29:21.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename init-container @ 06/15/24 13:29:21.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:29:21.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:29:21.455
  STEP: creating the pod @ 06/15/24 13:29:21.459
  Jun 15 13:29:21.459: INFO: PodSpec: initContainers in spec.initContainers
  E0615 13:29:22.124463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:23.124989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:24.125901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:25.126035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:26.126784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:27.126897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:28.127024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:29.127300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:30.127418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:31.127514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:32.127606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:33.127679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:34.127780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:35.127864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:36.128130      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:37.128331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:38.128976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:39.129059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:40.129132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:41.129795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:42.130033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:43.130266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:44.130444      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:45.130529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:46.130879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:47.131896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:48.132433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:49.132619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:50.132764      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:51.132993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:52.133900      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:53.134019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:54.134107      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:55.134192      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:56.134886      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:57.134958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:58.135047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:29:59.135258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:00.135354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:01.136331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:30:01.725: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3a6bd044-7289-4af8-b67e-abe02709be39", GenerateName:"", Namespace:"init-container-4815", SelfLink:"", UID:"4286e85c-99d9-4311-a60b-290a8e02f2f8", ResourceVersion:"41045", Generation:0, CreationTimestamp:time.Date(2024, time.June, 15, 13, 29, 21, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"459276345"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 29, 21, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003b8dbc0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.June, 15, 13, 30, 1, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003b8dc08), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-c2mpv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0053a7e80), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-c2mpv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-c2mpv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-c2mpv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006cef3d0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-7-7", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0000f70a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006cef460)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006cef480)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006cef488), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc006cef48c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc001098fc0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.June, 15, 13, 29, 22, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.June, 15, 13, 29, 21, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.June, 15, 13, 29, 21, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.June, 15, 13, 29, 21, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.June, 15, 13, 29, 21, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.7.7", HostIPs:[]v1.HostIP{v1.HostIP{IP:"172.31.7.7"}}, PodIP:"192.168.164.180", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.164.180"}}, StartTime:time.Date(2024, time.June, 15, 13, 29, 21, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0000f71f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0000f7260)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://c58ec2c618ee4701b767302b6a1eb289d0156bade2b7b66ffab332cbb362f1e2", Started:(*bool)(0xc006cef52a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0053a7ee0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc006cef53f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0053a7ec0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc006cef50f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Jun 15 13:30:01.725: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-4815" for this suite. @ 06/15/24 13:30:01.73
• [40.351 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:277
  STEP: Creating a kubernetes client @ 06/15/24 13:30:01.739
  Jun 15 13:30:01.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename svcaccounts @ 06/15/24 13:30:01.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:30:01.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:30:01.758
  STEP: Creating a pod to test service account token:  @ 06/15/24 13:30:01.761
  E0615 13:30:02.136935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:03.137002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:04.137945      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:05.138030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:30:05.785
  Jun 15 13:30:05.788: INFO: Trying to get logs from node ip-172-31-43-132 pod test-pod-a7d2ebb9-f53e-4da5-b0c5-199d8ebda11d container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 13:30:05.801
  Jun 15 13:30:05.819: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2876" for this suite. @ 06/15/24 13:30:05.824
• [4.092 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 06/15/24 13:30:05.831
  Jun 15 13:30:05.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename var-expansion @ 06/15/24 13:30:05.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:30:05.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:30:05.849
  STEP: Creating a pod to test substitution in container's command @ 06/15/24 13:30:05.855
  E0615 13:30:06.138683      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:07.138798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:08.139397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:09.139505      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:30:09.881
  Jun 15 13:30:09.886: INFO: Trying to get logs from node ip-172-31-43-132 pod var-expansion-c642ce71-9e62-4440-b5f1-5a71761c43cd container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 13:30:09.892
  Jun 15 13:30:09.907: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2412" for this suite. @ 06/15/24 13:30:09.91
• [4.085 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 06/15/24 13:30:09.917
  Jun 15 13:30:09.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 06/15/24 13:30:09.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:30:09.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:30:09.936
  STEP: creating a target pod @ 06/15/24 13:30:09.94
  E0615 13:30:10.139590      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:11.139679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 06/15/24 13:30:11.963
  E0615 13:30:12.140692      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:13.140920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 06/15/24 13:30:13.982
  Jun 15 13:30:13.982: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-9692 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:30:13.982: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:30:13.983: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:30:13.983: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-9692/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Jun 15 13:30:14.027: INFO: Exec stderr: ""
  Jun 15 13:30:14.033: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-9692" for this suite. @ 06/15/24 13:30:14.038
• [4.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 06/15/24 13:30:14.044
  Jun 15 13:30:14.045: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-preemption @ 06/15/24 13:30:14.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:30:14.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:30:14.065
  Jun 15 13:30:14.082: INFO: Waiting up to 1m0s for all nodes to be ready
  E0615 13:30:14.141128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:15.141253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:16.141594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:17.141774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:18.142456      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:19.142774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:20.143042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:21.143155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:22.144056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:23.144345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:24.145291      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:25.145539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:26.145716      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:27.145887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:28.146172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:29.146273      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:30.147123      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:31.147282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:32.147899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:33.147986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:34.148963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:35.149144      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:36.149464      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:37.149788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:38.150582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:39.151049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:40.151449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:41.152331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:42.152920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:43.153044      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:44.154020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:45.154172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:46.154823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:47.155066      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:48.156181      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:49.156494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:50.157062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:51.157174      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:52.157627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:53.157780      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:54.158439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:55.158674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:56.159228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:57.159405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:58.159843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:30:59.159963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:00.160238      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:01.160313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:02.160450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:03.160526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:04.161004      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:05.161270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:06.161485      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:07.161569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:08.161664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:09.161836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:10.161936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:11.162529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:12.162927      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:13.163031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:31:14.087: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 06/15/24 13:31:14.092
  Jun 15 13:31:14.092: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-preemption-path @ 06/15/24 13:31:14.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:31:14.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:31:14.111
  STEP: Finding an available node @ 06/15/24 13:31:14.114
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 06/15/24 13:31:14.114
  E0615 13:31:14.163093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:15.163344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 06/15/24 13:31:16.136
  Jun 15 13:31:16.150: INFO: found a healthy node: ip-172-31-7-7
  E0615 13:31:16.164109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:17.165011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:18.165099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:19.166089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:20.166299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:21.166871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:22.166949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:31:22.210: INFO: pods created so far: [1 1 1]
  Jun 15 13:31:22.210: INFO: length of pods created so far: 3
  E0615 13:31:23.167723      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:24.168351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:31:24.221: INFO: pods created so far: [2 2 1]
  E0615 13:31:25.169405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:26.169411      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:27.169530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:28.169589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:29.169810      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:30.170187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:31.170279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:31:31.294: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-8995" for this suite. @ 06/15/24 13:31:31.299
  Jun 15 13:31:31.305: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4378" for this suite. @ 06/15/24 13:31:31.309
• [77.270 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:708
  STEP: Creating a kubernetes client @ 06/15/24 13:31:31.315
  Jun 15 13:31:31.315: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-pred @ 06/15/24 13:31:31.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:31:31.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:31:31.34
  Jun 15 13:31:31.343: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Jun 15 13:31:31.350: INFO: Waiting for terminating namespaces to be deleted...
  Jun 15 13:31:31.352: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-17-110 before test
  Jun 15 13:31:31.358: INFO: nginx-ingress-controller-kubernetes-worker-pfb28 from ingress-nginx-kubernetes-worker started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.358: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: calico-node-hkrvf from kube-system started at 2024-06-15 12:04:11 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.358: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: coredns-bddfd76d7-mp2lw from kube-system started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.358: INFO: 	Container coredns ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: kube-state-metrics-6f48cdd76-fzrm6 from kube-system started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.358: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: metrics-server-v0.6.3-69d7fbfdf8-nhfgd from kube-system started at 2024-06-15 11:55:24 +0000 UTC (2 container statuses recorded)
  Jun 15 13:31:31.358: INFO: 	Container metrics-server ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: dashboard-metrics-scraper-5dd7cb5fc-6zmr5 from kubernetes-dashboard started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.358: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: kubernetes-dashboard-7b899cb9d9-444dc from kubernetes-dashboard started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.358: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-nhpcv from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:31:31.358: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: 	Container systemd-logs ready: true, restart count 0
  Jun 15 13:31:31.358: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-43-132 before test
  Jun 15 13:31:31.363: INFO: nginx-ingress-controller-kubernetes-worker-z9k8m from ingress-nginx-kubernetes-worker started at 2024-06-15 12:01:27 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.363: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:31:31.363: INFO: calico-node-f899m from kube-system started at 2024-06-15 12:04:32 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.363: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:31:31.363: INFO: sonobuoy-e2e-job-6485ce82c274498d from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:31:31.363: INFO: 	Container e2e ready: true, restart count 0
  Jun 15 13:31:31.363: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:31:31.363: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-xzkdr from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:31:31.363: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:31:31.363: INFO: 	Container systemd-logs ready: true, restart count 0
  Jun 15 13:31:31.363: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-7-7 before test
  Jun 15 13:31:31.368: INFO: nginx-ingress-controller-kubernetes-worker-qm4rb from ingress-nginx-kubernetes-worker started at 2024-06-15 12:43:19 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.368: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:31:31.368: INFO: calico-node-6rvnh from kube-system started at 2024-06-15 12:03:27 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.368: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:31:31.368: INFO: pod4 from sched-preemption-path-8995 started at 2024-06-15 13:31:23 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.368: INFO: 	Container pod4 ready: true, restart count 0
  Jun 15 13:31:31.368: INFO: rs-pod3-x7mph from sched-preemption-path-8995 started at 2024-06-15 13:31:20 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.368: INFO: 	Container pod3 ready: true, restart count 0
  Jun 15 13:31:31.368: INFO: sonobuoy from sonobuoy started at 2024-06-15 12:05:44 +0000 UTC (1 container statuses recorded)
  Jun 15 13:31:31.368: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Jun 15 13:31:31.368: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-mkhb2 from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:31:31.368: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:31:31.368: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 06/15/24 13:31:31.368
  E0615 13:31:32.171051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:33.171303      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 06/15/24 13:31:33.39
  STEP: Trying to apply a random label on the found node. @ 06/15/24 13:31:33.409
  STEP: verifying the node has the label kubernetes.io/e2e-f6084d57-77bf-49e9-95ff-361330d349d7 95 @ 06/15/24 13:31:33.419
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 06/15/24 13:31:33.424
  E0615 13:31:34.172206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:35.172360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.43.132 on the node which pod4 resides and expect not scheduled @ 06/15/24 13:31:35.441
  E0615 13:31:36.172805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:37.172895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:38.173393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:39.173467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:40.173587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:41.173693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:42.173737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:43.174811      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:44.174926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:45.175016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:46.175795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:47.175879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:48.176001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:49.176087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:50.176200      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:51.176377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:52.176462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:53.176566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:54.176821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:55.176918      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:56.177821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:57.178727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:58.179040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:31:59.179268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:00.180163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:01.181003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:02.181179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:03.181287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:04.182272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:05.182369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:06.183417      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:07.183525      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:08.184385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:09.184750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:10.184853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:11.185078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:12.185962      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:13.186072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:14.186534      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:15.186610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:16.186836      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:17.187895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:18.187991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:19.188089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:20.188408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:21.188558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:22.189309      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:23.189463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:24.190518      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:25.190642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:26.191020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:27.191111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:28.191282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:29.191385      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:30.192205      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:31.192292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:32.193156      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:33.193310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:34.193438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:35.193549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:36.194452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:37.194730      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:38.195089      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:39.195286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:40.195439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:41.195537      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:42.196368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:43.196512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:44.196602      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:45.196695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:46.196729      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:47.196814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:48.197480      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:49.197580      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:50.197689      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:51.198535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:52.198574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:53.198659      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:54.199654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:55.199754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:56.200653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:57.200744      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:58.200847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:32:59.201245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:00.201355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:01.201463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:02.201640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:03.201728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:04.202299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:05.202584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:06.203495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:07.203584      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:08.204060      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:09.205147      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:10.205645      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:11.205790      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:12.206254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:13.206360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:14.206474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:15.206661      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:16.207462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:17.207571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:18.207669      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:19.207761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:20.207807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:21.208833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:22.208956      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:23.209145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:24.209382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:25.209573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:26.209674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:27.209909      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:28.209988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:29.210179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:30.210228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:31.211245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:32.211325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:33.212358      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:34.212447      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:35.212619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:36.213571      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:37.213869      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:38.214019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:39.214114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:40.214858      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:41.214947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:42.215612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:43.215657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:44.215922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:45.216386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:46.217362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:47.218406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:48.218539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:49.218734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:50.219550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:51.220322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:52.221022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:53.221124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:54.221691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:55.222648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:56.222919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:57.223991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:58.224092      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:33:59.224292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:00.225352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:01.225609      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:02.225742      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:03.225850      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:04.225991      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:05.226254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:06.226803      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:07.227555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:08.228496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:09.228589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:10.228849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:11.228937      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:12.229018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:13.230039      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:14.230677      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:15.230784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:16.231829      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:17.231923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:18.232325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:19.232416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:20.233333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:21.233442      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:22.233528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:23.233715      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:24.233838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:25.234042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:26.234151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:27.234459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:28.235053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:29.235300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:30.236101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:31.236436      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:32.237379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:33.238373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:34.238966      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:35.239260      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:36.239808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:37.239865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:38.239951      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:39.240387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:40.241091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:41.241245      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:42.242247      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:43.242339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:44.243101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:45.243342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:46.244283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:47.244897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:48.244990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:49.245194      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:50.245365      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:51.246329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:52.246702      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:53.246941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:54.247653      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:55.248332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:56.248779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:57.248925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:58.249016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:34:59.249274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:00.250472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:01.250564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:02.250799      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:03.251400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:04.252157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:05.252419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:06.252863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:07.252948      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:08.253853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:09.253965      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:10.254062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:11.254153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:12.254672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:13.254949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:14.255460      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:15.255558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:16.256258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:17.256368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:18.256925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:19.257164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:20.257406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:21.257473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:22.257762      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:23.258497      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:24.259154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:25.259270      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:26.259778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:27.260364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:28.260686      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:29.260851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:30.261690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:31.261837      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:32.262854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:33.262955      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:34.263873      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:35.264326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:36.264387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:37.264423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:38.264880      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:39.264978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:40.265068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:41.265182      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:42.265281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:43.265478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:44.265652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:45.265838      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:46.266539      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:47.266638      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:48.267335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:49.268331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:50.268994      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:51.269109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:52.269193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:53.269377      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:54.270439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:55.270640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:56.271594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:57.271657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:58.272579      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:35:59.272795      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:00.272895      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:01.272990      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:02.273754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:03.273830      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:04.273941      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:05.274077      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:06.274881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:07.275022      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:08.275920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:09.276441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:10.277347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:11.277490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:12.278550      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:13.278643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:14.279172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:15.279290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:16.279968      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:17.279979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:18.281053      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:19.281154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:20.282002      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:21.282120      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:22.282376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:23.282585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:24.282771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:25.283068      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:26.283369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:27.283500      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:28.284533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:29.284616      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:30.285393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:31.285492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:32.285947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:33.286097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:34.286360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:35.286569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-f6084d57-77bf-49e9-95ff-361330d349d7 off the node ip-172-31-43-132 @ 06/15/24 13:36:35.451
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-f6084d57-77bf-49e9-95ff-361330d349d7 @ 06/15/24 13:36:35.468
  Jun 15 13:36:35.472: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-907" for this suite. @ 06/15/24 13:36:35.478
• [304.170 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 06/15/24 13:36:35.486
  Jun 15 13:36:35.486: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 06/15/24 13:36:35.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:36:35.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:36:35.506
  STEP: creating a target pod @ 06/15/24 13:36:35.509
  E0615 13:36:36.287282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:37.287381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 06/15/24 13:36:37.534
  E0615 13:36:38.287734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:39.288588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 06/15/24 13:36:39.552
  Jun 15 13:36:39.552: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-5819 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:36:39.552: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:36:39.552: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:36:39.552: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-5819/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Jun 15 13:36:39.610: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 06/15/24 13:36:39.63
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 06/15/24 13:36:39.634
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 06/15/24 13:36:39.646
  Jun 15 13:36:39.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-5819" for this suite. @ 06/15/24 13:36:39.655
• [4.178 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 06/15/24 13:36:39.664
  Jun 15 13:36:39.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename pods @ 06/15/24 13:36:39.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:36:39.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:36:39.682
  STEP: creating the pod @ 06/15/24 13:36:39.685
  STEP: submitting the pod to kubernetes @ 06/15/24 13:36:39.685
  STEP: verifying QOS class is set on the pod @ 06/15/24 13:36:39.7
  Jun 15 13:36:39.705: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8412" for this suite. @ 06/15/24 13:36:39.709
• [0.053 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:887
  STEP: Creating a kubernetes client @ 06/15/24 13:36:39.717
  Jun 15 13:36:39.717: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:36:39.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:36:39.73
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:36:39.734
  STEP: validating api versions @ 06/15/24 13:36:39.736
  Jun 15 13:36:39.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-6394 api-versions'
  Jun 15 13:36:39.777: INFO: stderr: ""
  Jun 15 13:36:39.777: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Jun 15 13:36:39.777: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6394" for this suite. @ 06/15/24 13:36:39.781
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 06/15/24 13:36:39.788
  Jun 15 13:36:39.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:36:39.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:36:39.805
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:36:39.808
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:36:39.812
  E0615 13:36:40.289499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:41.289784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:42.290775      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:43.290853      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:36:43.838
  Jun 15 13:36:43.841: INFO: Trying to get logs from node ip-172-31-43-132 pod downwardapi-volume-7011f603-7d0f-4a46-b58e-d3a572c27f3b container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:36:43.86
  Jun 15 13:36:43.876: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3502" for this suite. @ 06/15/24 13:36:43.88
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1031
  STEP: Creating a kubernetes client @ 06/15/24 13:36:43.888
  Jun 15 13:36:43.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename statefulset @ 06/15/24 13:36:43.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:36:43.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:36:43.906
  STEP: Creating service test in namespace statefulset-3818 @ 06/15/24 13:36:43.909
  STEP: Creating statefulset ss in namespace statefulset-3818 @ 06/15/24 13:36:43.919
  Jun 15 13:36:43.935: INFO: Found 0 stateful pods, waiting for 1
  E0615 13:36:44.291366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:45.292190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:46.292432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:47.292547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:48.292708      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:49.292808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:50.292919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:51.293161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:52.293258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:53.294153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:36:53.936: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 06/15/24 13:36:53.943
  STEP: Getting /status @ 06/15/24 13:36:53.952
  Jun 15 13:36:53.956: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 06/15/24 13:36:53.956
  Jun 15 13:36:53.966: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 06/15/24 13:36:53.966
  Jun 15 13:36:53.967: INFO: Observed &StatefulSet event: ADDED
  Jun 15 13:36:53.967: INFO: Found Statefulset ss in namespace statefulset-3818 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Jun 15 13:36:53.967: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 06/15/24 13:36:53.967
  Jun 15 13:36:53.967: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Jun 15 13:36:53.975: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 06/15/24 13:36:53.975
  Jun 15 13:36:53.977: INFO: Observed &StatefulSet event: ADDED
  Jun 15 13:36:53.977: INFO: Deleting all statefulset in ns statefulset-3818
  Jun 15 13:36:53.980: INFO: Scaling statefulset ss to 0
  E0615 13:36:54.294209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:55.294317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:56.295056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:57.295265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:58.295379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:36:59.295473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:00.296347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:01.297160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:02.297675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:03.297406      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:37:03.996: INFO: Waiting for statefulset status.replicas updated to 0
  Jun 15 13:37:03.999: INFO: Deleting statefulset ss
  Jun 15 13:37:04.014: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3818" for this suite. @ 06/15/24 13:37:04.018
• [20.136 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 06/15/24 13:37:04.025
  Jun 15 13:37:04.025: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename cronjob @ 06/15/24 13:37:04.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:37:04.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:37:04.045
  STEP: Creating a ForbidConcurrent cronjob @ 06/15/24 13:37:04.048
  STEP: Ensuring a job is scheduled @ 06/15/24 13:37:04.053
  E0615 13:37:04.297935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:05.298042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:06.298627      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:07.299702      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:08.299863      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:09.300346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:10.301025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:11.301098      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:12.301718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:13.301817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:14.302374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:15.302457      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:16.303391      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:17.303501      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:18.304336      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:19.304429      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:20.304528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:21.304734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:22.305561      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:23.305665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:24.306436      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:25.306671      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:26.307243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:27.307549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:28.308359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:29.308588      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:30.309101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:31.309401      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:32.310305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:33.310410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:34.311449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:35.311533      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:36.312374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:37.312492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:38.313228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:39.313343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:40.314318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:41.314416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:42.315233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:43.315293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:44.315923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:45.316367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:46.316915      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:47.316997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:48.318081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:49.319033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:50.319236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:51.319298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:52.320313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:53.320432      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:54.320898      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:55.320987      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:56.321119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:57.321516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:58.322000      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:37:59.322103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:00.322569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:01.322807      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 06/15/24 13:38:02.057
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 06/15/24 13:38:02.062
  STEP: Ensuring no more jobs are scheduled @ 06/15/24 13:38:02.067
  E0615 13:38:02.323601      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:03.324423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:04.324887      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:05.324998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:06.325665      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:07.325778      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:08.326490      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:09.326696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:10.327157      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:11.327281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:12.327399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:13.327488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:14.327885      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:15.328712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:16.329169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:17.329307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:18.329421      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:19.329700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:20.329806      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:21.330031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:22.330131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:23.330227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:24.330342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:25.330399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:26.330551      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:27.330682      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:28.331340      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:29.331436      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:30.331834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:31.331919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:32.332906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:33.333106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:34.334016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:35.334096      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:36.334488      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:37.335393      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:38.336185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:39.336299      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:40.336353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:41.336452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:42.337175      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:43.337285      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:44.338179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:45.338275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:46.338349      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:47.338433      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:48.338993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:49.339104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:50.339606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:51.340356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:52.341040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:53.341127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:54.341161      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:55.341242      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:56.341861      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:57.341996      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:58.342971      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:38:59.343090      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:00.343893      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:01.343989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:02.344189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:03.344302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:04.345081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:05.345300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:06.346031      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:07.347095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:08.347258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:09.347359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:10.348346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:11.348623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:12.349135      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:13.349233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:14.350048      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:15.350154      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:16.350896      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:17.351754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:18.352213      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:19.352305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:20.352970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:21.353059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:22.353178      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:23.353367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:24.354040      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:25.354131      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:26.355172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:27.355395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:28.356105      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:29.356354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:30.357095      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:31.357199      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:32.357300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:33.357745      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:34.357783      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:35.358294      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:36.359049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:37.359272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:38.360332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:39.360516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:40.360629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:41.361568      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:42.362185      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:43.362295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:44.362691      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:45.363209      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:46.363310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:47.363405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:48.363883      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:49.363976      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:50.364100      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:51.364212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:52.364978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:53.365489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:54.365545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:55.365643      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:56.366115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:57.366408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:58.367180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:39:59.367381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:00.367472      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:01.367575      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:02.367771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:03.368521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:04.368618      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:05.368788      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:06.369446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:07.369582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:08.370253      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:09.370412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:10.371335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:11.372342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:12.372936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:13.373113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:14.373641      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:15.373818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:16.374384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:17.374639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:18.375517      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:19.375628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:20.376114      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:21.376227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:22.376343      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:23.376520      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:24.377198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:25.378001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:26.378832      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:27.379062      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:28.379892      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:29.380348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:30.380906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:31.381009      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:32.381942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:33.382193      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:34.382695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:35.382926      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:36.383414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:37.384334      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:38.384407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:39.384589      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:40.385195      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:41.385360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:42.386111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:43.386234      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:44.387155      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:45.387268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:46.388070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:47.388302      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:48.388398      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:49.388491      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:50.389287      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:51.389381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:52.389424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:53.389586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:54.390510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:55.391374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:56.391878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:57.391979      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:58.393041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:40:59.393134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:00.393630      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:01.393822      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:02.394046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:03.394210      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:04.395243      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:05.395367      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:06.396011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:07.396087      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:08.396690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:09.396935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:10.397101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:11.398019      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:12.398746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:13.398841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:14.399375      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:15.400374      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:16.401288      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:17.401396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:18.401871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:19.402032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:20.402171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:21.402479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:22.403203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:23.403327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:24.403652      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:25.404400      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:26.404685      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:27.404785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:28.405059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:29.405256      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:30.405841      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:31.406091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:32.406779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:33.407675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:34.407759      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:35.407911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:36.408749      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:37.409047      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:38.409137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:39.409311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:40.409717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:41.409998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:42.410267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:43.410352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:44.410478      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:45.410684      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:46.411657      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:47.411761      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:48.412337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:49.412459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:50.412610      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:51.413312      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:52.413564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:53.413840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:54.414834      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:55.415010      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:56.416049      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:57.416352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:58.417191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:41:59.417239      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:00.417672      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:01.417760      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:02.418103      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:03.418619      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:04.419696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:05.420425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:06.420524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:07.420846      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:08.421899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:09.422176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:10.422202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:11.422453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:12.422675      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:13.422781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:14.422812      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:15.422904      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:16.423317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:17.423463      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:18.423531      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:19.424354      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:20.424460      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:21.424549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:22.424704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:23.424923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:24.425913      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:25.426046      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:26.426150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:27.426549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:28.426640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:29.426779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:30.426878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:31.427757      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:32.428324      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:33.428492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:34.429188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:35.429308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:36.429765      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:37.430070      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:38.430622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:39.430872      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:40.430958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:41.431171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:42.431278      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:43.432353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:44.432706      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:45.432796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:46.433717      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:47.434085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:48.434177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:49.434263      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:50.434454      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:51.434647      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:52.435471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:53.435556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:54.435925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:55.436347      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:56.437065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:57.437925      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:58.438056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:42:59.438086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:00.438443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:01.438773      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 06/15/24 13:43:02.076
  Jun 15 13:43:02.082: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5232" for this suite. @ 06/15/24 13:43:02.087
• [358.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 06/15/24 13:43:02.096
  Jun 15 13:43:02.096: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename server-version @ 06/15/24 13:43:02.096
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:43:02.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:43:02.116
  STEP: Request ServerVersion @ 06/15/24 13:43:02.12
  STEP: Confirm major version @ 06/15/24 13:43:02.121
  Jun 15 13:43:02.121: INFO: Major version: 1
  STEP: Confirm minor version @ 06/15/24 13:43:02.121
  Jun 15 13:43:02.121: INFO: cleanMinorVersion: 29
  Jun 15 13:43:02.121: INFO: Minor version: 29
  Jun 15 13:43:02.121: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-5164" for this suite. @ 06/15/24 13:43:02.125
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 06/15/24 13:43:02.132
  Jun 15 13:43:02.132: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 13:43:02.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:43:02.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:43:02.151
  Jun 15 13:43:02.154: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:43:02.439034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:03.439235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 06/15/24 13:43:03.446
  Jun 15 13:43:03.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 create -f -'
  E0615 13:43:04.439295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:05.439353      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:43:05.522: INFO: stderr: ""
  Jun 15 13:43:05.522: INFO: stdout: "e2e-test-crd-publish-openapi-5604-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Jun 15 13:43:05.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 delete e2e-test-crd-publish-openapi-5604-crds test-foo'
  Jun 15 13:43:05.572: INFO: stderr: ""
  Jun 15 13:43:05.572: INFO: stdout: "e2e-test-crd-publish-openapi-5604-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Jun 15 13:43:05.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 apply -f -'
  Jun 15 13:43:05.624: INFO: stderr: ""
  Jun 15 13:43:05.624: INFO: stdout: "e2e-test-crd-publish-openapi-5604-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Jun 15 13:43:05.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 delete e2e-test-crd-publish-openapi-5604-crds test-foo'
  Jun 15 13:43:05.673: INFO: stderr: ""
  Jun 15 13:43:05.673: INFO: stdout: "e2e-test-crd-publish-openapi-5604-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 06/15/24 13:43:05.673
  Jun 15 13:43:05.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 create -f -'
  Jun 15 13:43:05.717: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 06/15/24 13:43:05.717
  Jun 15 13:43:05.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 create -f -'
  Jun 15 13:43:05.773: INFO: rc: 1
  Jun 15 13:43:05.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 apply -f -'
  Jun 15 13:43:05.824: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 06/15/24 13:43:05.824
  Jun 15 13:43:05.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 create -f -'
  Jun 15 13:43:05.868: INFO: rc: 1
  Jun 15 13:43:05.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 --namespace=crd-publish-openapi-3577 apply -f -'
  Jun 15 13:43:05.933: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 06/15/24 13:43:05.933
  Jun 15 13:43:05.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 explain e2e-test-crd-publish-openapi-5604-crds'
  Jun 15 13:43:05.974: INFO: stderr: ""
  Jun 15 13:43:05.974: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5604-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 06/15/24 13:43:05.974
  Jun 15 13:43:05.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 explain e2e-test-crd-publish-openapi-5604-crds.metadata'
  Jun 15 13:43:06.016: INFO: stderr: ""
  Jun 15 13:43:06.016: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5604-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Jun 15 13:43:06.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 explain e2e-test-crd-publish-openapi-5604-crds.spec'
  Jun 15 13:43:06.060: INFO: stderr: ""
  Jun 15 13:43:06.060: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5604-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Jun 15 13:43:06.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 explain e2e-test-crd-publish-openapi-5604-crds.spec.bars'
  Jun 15 13:43:06.102: INFO: stderr: ""
  Jun 15 13:43:06.102: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5604-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 06/15/24 13:43:06.102
  Jun 15 13:43:06.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=crd-publish-openapi-3577 explain e2e-test-crd-publish-openapi-5604-crds.spec.bars2'
  Jun 15 13:43:06.142: INFO: rc: 1
  E0615 13:43:06.440191      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:43:07.406: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3577" for this suite. @ 06/15/24 13:43:07.413
• [5.290 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 06/15/24 13:43:07.422
  Jun 15 13:43:07.422: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename watch @ 06/15/24 13:43:07.422
  E0615 13:43:07.440389      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:43:07.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:43:07.443
  STEP: getting a starting resourceVersion @ 06/15/24 13:43:07.448
  STEP: starting a background goroutine to produce watch events @ 06/15/24 13:43:07.451
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 06/15/24 13:43:07.451
  E0615 13:43:08.441267      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:09.441784      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:43:10.230: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-5591" for this suite. @ 06/15/24 13:43:10.278
• [2.910 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 06/15/24 13:43:10.332
  Jun 15 13:43:10.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename custom-resource-definition @ 06/15/24 13:43:10.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:43:10.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:43:10.354
  Jun 15 13:43:10.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:43:10.442197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:43:10.899: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9624" for this suite. @ 06/15/24 13:43:10.903
• [0.579 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 06/15/24 13:43:10.911
  Jun 15 13:43:10.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-preemption @ 06/15/24 13:43:10.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:43:10.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:43:10.931
  Jun 15 13:43:10.945: INFO: Waiting up to 1m0s for all nodes to be ready
  E0615 13:43:11.442305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:12.442935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:13.443839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:14.444373      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:15.444569      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:16.445024      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:17.445102      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:18.445777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:19.446392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:20.447203      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:21.447339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:22.447465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:23.447982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:24.448871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:25.449640      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:26.450110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:27.450221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:28.450498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:29.450634      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:30.450818      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:31.451035      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:32.451277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:33.452143      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:34.452414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:35.452526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:36.452639      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:37.452912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:38.453073      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:39.454076      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:40.454902      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:41.455620      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:42.455705      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:43.455801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:44.456339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:45.456431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:46.456920      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:47.457758      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:48.457840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:49.458506      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:50.458693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:51.458792      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:52.458890      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:53.459255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:54.460329      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:55.460570      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:56.461381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:57.461809      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:58.461970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:43:59.462498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:00.462547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:01.462728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:02.463021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:03.463767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:04.463851      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:05.463958      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:06.464065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:07.464548      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:08.464734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:09.465514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:10.465607      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:44:10.951: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 06/15/24 13:44:10.955
  Jun 15 13:44:10.974: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Jun 15 13:44:10.981: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Jun 15 13:44:10.998: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Jun 15 13:44:11.004: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Jun 15 13:44:11.025: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Jun 15 13:44:11.038: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 06/15/24 13:44:11.039
  E0615 13:44:11.466197      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:12.466281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 06/15/24 13:44:13.064
  E0615 13:44:13.467118      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:14.467277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:15.467378      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:16.468286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:44:17.163: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6816" for this suite. @ 06/15/24 13:44:17.167
• [66.261 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 06/15/24 13:44:17.173
  Jun 15 13:44:17.173: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:44:17.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:44:17.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:44:17.195
  STEP: Creating configMap with name cm-test-opt-del-8df4a147-2857-44a6-8f36-f85a3a874707 @ 06/15/24 13:44:17.2
  STEP: Creating configMap with name cm-test-opt-upd-a272c4c0-86af-4369-822b-eb6d4b1bd14c @ 06/15/24 13:44:17.205
  STEP: Creating the pod @ 06/15/24 13:44:17.208
  E0615 13:44:17.468693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:18.468769      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-8df4a147-2857-44a6-8f36-f85a3a874707 @ 06/15/24 13:44:19.258
  STEP: Updating configmap cm-test-opt-upd-a272c4c0-86af-4369-822b-eb6d4b1bd14c @ 06/15/24 13:44:19.266
  STEP: Creating configMap with name cm-test-opt-create-e16eebb9-60f2-4d18-9373-88d92e032dec @ 06/15/24 13:44:19.27
  STEP: waiting to observe update in volume @ 06/15/24 13:44:19.277
  E0615 13:44:19.469362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:20.469558      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:21.469942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:22.470032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:23.470345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:24.470473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:25.471190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:26.471277      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:27.471779      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:28.472348      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:29.472441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:30.472654      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:31.473332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:32.473443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:33.474376      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:34.474545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:35.475339      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:36.476189      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:37.477074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:38.477160      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:39.477394      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:40.478034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:41.478934      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:42.479942      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:43.480258      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:44.480362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:45.480821      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:46.481171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:47.482250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:48.482549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:49.482930      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:50.483586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:51.484275      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:52.484350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:53.484670      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:54.484777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:55.484911      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:56.485187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:57.485735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:58.485862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:44:59.486796      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:00.486899      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:01.487292      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:02.488361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:03.489325      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:04.489410      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:05.489631      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:06.489741      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:07.490359      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:08.490532      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:09.491214      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:10.492250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:11.492495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:12.493543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:13.493718      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:14.493847      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:15.493949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:16.494878      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:17.494989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:18.495266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:19.495405      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:20.496351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:21.496448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:22.497352      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:23.497483      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:24.497664      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:25.497740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:26.498106      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:27.498202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:28.499097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:29.499283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:30.499307      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:31.499555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:32.499781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:33.499931      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:34.500020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:35.500474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:36.500566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:37.500865      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:38.500953      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:39.501081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:40.501240      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:41.501387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:42.501663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:43.501921      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:44.502797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:45.503033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:45:45.657: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9282" for this suite. @ 06/15/24 13:45:45.66
• [88.494 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 06/15/24 13:45:45.667
  Jun 15 13:45:45.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:45:45.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:45:45.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:45:45.686
  STEP: Creating configMap with name projected-configmap-test-volume-map-cc5f3e90-d270-4363-9eb2-0a560c35c68a @ 06/15/24 13:45:45.689
  STEP: Creating a pod to test consume configMaps @ 06/15/24 13:45:45.693
  E0615 13:45:46.503295      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:47.503465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:48.503495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:49.503596      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:45:49.717
  Jun 15 13:45:49.721: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-projected-configmaps-27e011ee-5edf-43be-9e6e-eb67b2b07777 container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 13:45:49.737
  Jun 15 13:45:49.752: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-110" for this suite. @ 06/15/24 13:45:49.756
• [4.096 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 06/15/24 13:45:49.764
  Jun 15 13:45:49.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 13:45:49.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:45:49.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:45:49.786
  STEP: Setting up server cert @ 06/15/24 13:45:49.81
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 13:45:50.104
  STEP: Deploying the webhook pod @ 06/15/24 13:45:50.127
  STEP: Wait for the deployment to be ready @ 06/15/24 13:45:50.139
  Jun 15 13:45:50.146: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0615 13:45:50.504387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:51.504546      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 13:45:52.158
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 13:45:52.17
  E0615 13:45:52.504600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:45:53.170: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 06/15/24 13:45:53.18
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 06/15/24 13:45:53.181
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 06/15/24 13:45:53.181
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 06/15/24 13:45:53.181
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 06/15/24 13:45:53.183
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 06/15/24 13:45:53.183
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 06/15/24 13:45:53.184
  Jun 15 13:45:53.216: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9843" for this suite. @ 06/15/24 13:45:53.219
  STEP: Destroying namespace "webhook-markers-2059" for this suite. @ 06/15/24 13:45:53.229
• [3.471 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 06/15/24 13:45:53.236
  Jun 15 13:45:53.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-preemption @ 06/15/24 13:45:53.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:45:53.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:45:53.256
  Jun 15 13:45:53.272: INFO: Waiting up to 1m0s for all nodes to be ready
  E0615 13:45:53.505381      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:54.506128      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:55.506617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:56.506703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:57.507212      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:58.507314      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:45:59.508069      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:00.509013      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:01.509566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:02.509667      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:03.509777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:04.509993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:05.510115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:06.510179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:07.510355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:08.510521      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:09.511448      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:10.511547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:11.512293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:12.512383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:13.512471      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:14.512798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:15.512894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:16.512963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:17.513823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:18.514027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:19.514126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:20.514230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:21.514771      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:22.514868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:23.514978      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:24.515097      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:25.516016      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:26.516119      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:27.517081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:28.517177      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:29.517264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:30.517663      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:31.518648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:32.518748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:33.518839      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:34.519101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:35.519259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:36.520167      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:37.520230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:38.520418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:39.520586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:40.521544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:41.522082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:42.522172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:43.522734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:44.522862      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:45.523021      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:46.524169      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:47.524362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:48.525142      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:49.525739      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:50.525940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:51.526057      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:52.526186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:46:53.278: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 06/15/24 13:46:53.281
  Jun 15 13:46:53.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-preemption-path @ 06/15/24 13:46:53.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:46:53.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:46:53.301
  Jun 15 13:46:53.317: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Jun 15 13:46:53.321: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Jun 15 13:46:53.390: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-7337" for this suite. @ 06/15/24 13:46:53.394
  Jun 15 13:46:53.402: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6202" for this suite. @ 06/15/24 13:46:53.406
• [60.176 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 06/15/24 13:46:53.412
  Jun 15 13:46:53.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 13:46:53.413
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:46:53.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:46:53.431
  STEP: Setting up server cert @ 06/15/24 13:46:53.458
  E0615 13:46:53.526369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 13:46:53.766
  STEP: Deploying the webhook pod @ 06/15/24 13:46:53.773
  STEP: Wait for the deployment to be ready @ 06/15/24 13:46:53.783
  Jun 15 13:46:53.792: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 13:46:54.526536      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:55.526635      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 13:46:55.802
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 13:46:55.812
  E0615 13:46:56.527702      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:46:56.813: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Jun 15 13:46:56.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3311-crds.webhook.example.com via the AdmissionRegistration API @ 06/15/24 13:46:57.332
  STEP: Creating a custom resource while v1 is storage version @ 06/15/24 13:46:57.346
  E0615 13:46:57.527805      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:46:58.527877      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 06/15/24 13:46:59.376
  STEP: Patching the custom resource while v2 is storage version @ 06/15/24 13:46:59.388
  E0615 13:46:59.528110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:46:59.971: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5137" for this suite. @ 06/15/24 13:46:59.976
  STEP: Destroying namespace "webhook-markers-3902" for this suite. @ 06/15/24 13:46:59.984
• [6.579 seconds]
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 06/15/24 13:46:59.991
  Jun 15 13:46:59.991: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename runtimeclass @ 06/15/24 13:46:59.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:00.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:00.012
  STEP: Deleting RuntimeClass runtimeclass-9729-delete-me @ 06/15/24 13:47:00.02
  STEP: Waiting for the RuntimeClass to disappear @ 06/15/24 13:47:00.025
  Jun 15 13:47:00.035: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9729" for this suite. @ 06/15/24 13:47:00.038
• [0.052 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 06/15/24 13:47:00.043
  Jun 15 13:47:00.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename podtemplate @ 06/15/24 13:47:00.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:00.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:00.062
  Jun 15 13:47:00.091: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3303" for this suite. @ 06/15/24 13:47:00.096
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 06/15/24 13:47:00.103
  Jun 15 13:47:00.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 13:47:00.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:00.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:00.121
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 06/15/24 13:47:00.123
  E0615 13:47:00.529186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:01.529399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:02.529492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:03.529581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:47:04.144
  Jun 15 13:47:04.148: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-a3b374d6-1664-4558-8b0a-8d100f96a15e container test-container: <nil>
  STEP: delete the pod @ 06/15/24 13:47:04.154
  Jun 15 13:47:04.172: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2070" for this suite. @ 06/15/24 13:47:04.175
• [4.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1632
  STEP: Creating a kubernetes client @ 06/15/24 13:47:04.183
  Jun 15 13:47:04.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:47:04.183
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:04.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:04.203
  STEP: creating the pod @ 06/15/24 13:47:04.206
  Jun 15 13:47:04.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3426 create -f -'
  Jun 15 13:47:04.290: INFO: stderr: ""
  Jun 15 13:47:04.290: INFO: stdout: "pod/pause created\n"
  E0615 13:47:04.530134      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:05.530319      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 06/15/24 13:47:06.299
  Jun 15 13:47:06.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3426 label pods pause testing-label=testing-label-value'
  Jun 15 13:47:06.351: INFO: stderr: ""
  Jun 15 13:47:06.351: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 06/15/24 13:47:06.351
  Jun 15 13:47:06.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3426 get pod pause -L testing-label'
  Jun 15 13:47:06.396: INFO: stderr: ""
  Jun 15 13:47:06.396: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 06/15/24 13:47:06.396
  Jun 15 13:47:06.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3426 label pods pause testing-label-'
  Jun 15 13:47:06.448: INFO: stderr: ""
  Jun 15 13:47:06.448: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 06/15/24 13:47:06.448
  Jun 15 13:47:06.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3426 get pod pause -L testing-label'
  Jun 15 13:47:06.492: INFO: stderr: ""
  Jun 15 13:47:06.493: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 06/15/24 13:47:06.493
  Jun 15 13:47:06.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3426 delete --grace-period=0 --force -f -'
  E0615 13:47:06.531005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:06.548: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Jun 15 13:47:06.548: INFO: stdout: "pod \"pause\" force deleted\n"
  Jun 15 13:47:06.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3426 get rc,svc -l name=pause --no-headers'
  Jun 15 13:47:06.599: INFO: stderr: "No resources found in kubectl-3426 namespace.\n"
  Jun 15 13:47:06.599: INFO: stdout: ""
  Jun 15 13:47:06.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-3426 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Jun 15 13:47:06.643: INFO: stderr: ""
  Jun 15 13:47:06.643: INFO: stdout: ""
  Jun 15 13:47:06.643: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3426" for this suite. @ 06/15/24 13:47:06.649
• [2.472 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 06/15/24 13:47:06.655
  Jun 15 13:47:06.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename dns @ 06/15/24 13:47:06.655
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:06.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:06.677
  STEP: Creating a test headless service @ 06/15/24 13:47:06.68
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9815.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9815.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9815.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9815.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9815.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9815.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9815.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9815.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9815.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9815.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 234.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.234_udp@PTR;check="$$(dig +tcp +noall +answer +search 234.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.234_tcp@PTR;sleep 1; done
   @ 06/15/24 13:47:06.696
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9815.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9815.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9815.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9815.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9815.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9815.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9815.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9815.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9815.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9815.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 234.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.234_udp@PTR;check="$$(dig +tcp +noall +answer +search 234.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.234_tcp@PTR;sleep 1; done
   @ 06/15/24 13:47:06.696
  STEP: creating a pod to probe DNS @ 06/15/24 13:47:06.696
  STEP: submitting the pod to kubernetes @ 06/15/24 13:47:06.696
  E0615 13:47:07.531316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:08.531441      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 06/15/24 13:47:08.722
  STEP: looking for the results for each expected name from probers @ 06/15/24 13:47:08.726
  Jun 15 13:47:08.730: INFO: Unable to read wheezy_udp@dns-test-service.dns-9815.svc.cluster.local from pod dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f: the server could not find the requested resource (get pods dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f)
  Jun 15 13:47:08.735: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9815.svc.cluster.local from pod dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f: the server could not find the requested resource (get pods dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f)
  Jun 15 13:47:08.739: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local from pod dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f: the server could not find the requested resource (get pods dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f)
  Jun 15 13:47:08.741: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local from pod dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f: the server could not find the requested resource (get pods dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f)
  Jun 15 13:47:08.762: INFO: Unable to read jessie_udp@dns-test-service.dns-9815.svc.cluster.local from pod dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f: the server could not find the requested resource (get pods dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f)
  Jun 15 13:47:08.765: INFO: Unable to read jessie_tcp@dns-test-service.dns-9815.svc.cluster.local from pod dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f: the server could not find the requested resource (get pods dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f)
  Jun 15 13:47:08.769: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local from pod dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f: the server could not find the requested resource (get pods dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f)
  Jun 15 13:47:08.773: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local from pod dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f: the server could not find the requested resource (get pods dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f)
  Jun 15 13:47:08.787: INFO: Lookups using dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f failed for: [wheezy_udp@dns-test-service.dns-9815.svc.cluster.local wheezy_tcp@dns-test-service.dns-9815.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local jessie_udp@dns-test-service.dns-9815.svc.cluster.local jessie_tcp@dns-test-service.dns-9815.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9815.svc.cluster.local]

  Jun 15 13:47:08.794: INFO: Pod client logs for webserver: 
  Jun 15 13:47:08.798: INFO: Pod client logs for querier: 
  Jun 15 13:47:08.804: INFO: Pod client logs for jessie-querier: 
  E0615 13:47:09.532366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:10.532469      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:11.532703      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:12.532808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:13.532906      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:13.793: INFO: DNS probes using dns-9815/dns-test-11d6988d-27c0-4f7b-982e-77ce748ee42f succeeded

  STEP: deleting the pod @ 06/15/24 13:47:13.793
  STEP: deleting the test service @ 06/15/24 13:47:13.81
  STEP: deleting the test headless service @ 06/15/24 13:47:13.835
  Jun 15 13:47:13.844: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9815" for this suite. @ 06/15/24 13:47:13.848
• [7.199 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 06/15/24 13:47:13.854
  Jun 15 13:47:13.854: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename gc @ 06/15/24 13:47:13.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:13.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:13.871
  STEP: create the deployment @ 06/15/24 13:47:13.874
  W0615 13:47:13.878916      19 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 06/15/24 13:47:13.878
  STEP: delete the deployment @ 06/15/24 13:47:14.386
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 06/15/24 13:47:14.395
  E0615 13:47:14.533173      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 06/15/24 13:47:14.915
  W0615 13:47:14.920003      19 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Jun 15 13:47:14.920: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Jun 15 13:47:14.920: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-217" for this suite. @ 06/15/24 13:47:14.923
• [1.076 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 06/15/24 13:47:14.93
  Jun 15 13:47:14.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename deployment @ 06/15/24 13:47:14.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:14.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:14.952
  Jun 15 13:47:14.955: INFO: Creating simple deployment test-new-deployment
  Jun 15 13:47:14.966: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0615 13:47:15.533266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:16.534254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 06/15/24 13:47:16.981
  STEP: updating a scale subresource @ 06/15/24 13:47:16.985
  STEP: verifying the deployment Spec.Replicas was modified @ 06/15/24 13:47:16.99
  STEP: Patch a scale subresource @ 06/15/24 13:47:16.993
  Jun 15 13:47:17.019: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3236",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4e957096-5d27-4b02-ad31-5c6c7d1839b4",
      ResourceVersion: (string) (len=5) "44584",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854056034,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056034,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056034,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Jun 15 13:47:17.029: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3236",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "aa6f20a7-8aca-40a8-b5c3-4c433afd461b",
      ResourceVersion: (string) (len=5) "44594",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854056034,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "4",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "5",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "4e957096-5d27-4b02-ad31-5c6c7d1839b4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056037,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 65 39 35 37 30  39 36 2d 35 64 32 37 2d  |\"4e957096-5d27-|
              00000120  34 62 30 32 2d 61 64 33  31 2d 35 63 36 63 37 64  |4b02-ad31-5c6c7d|
              00000130  31 38 33 39 62 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |1839b4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056037,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(4),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Jun 15 13:47:17.034: INFO: Pod "test-new-deployment-557759b7c7-dthkd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-dthkd",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-3236",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ba2b7109-3776-437b-8619-63c0b9b3a1b3",
      ResourceVersion: (string) (len=5) "44578",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854056034,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "aa6f20a7-8aca-40a8-b5c3-4c433afd461b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056034,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 61  36 66 32 30 61 37 2d 38  |d\":\"aa6f20a7-8|
              00000090  61 63 61 2d 34 30 61 38  2d 62 35 63 33 2d 34 63  |aca-40a8-b5c3-4c|
              000000a0  34 33 33 61 66 64 34 36  31 62 5c 22 7d 22 3a 7b  |433afd461b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=664) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 39  |,"k:{\"ip\":\"19|
              00000260  32 2e 31 36 38 2e 31 36  34 2e 31 36 35 5c 22 7d  |2.168.164.165\"}|
              00000270  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              00000280  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000290  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-q4tcd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-q4tcd",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "ip-172-31-7-7",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056034,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056034,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=10) "172.31.7.7",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=10) "172.31.7.7"
        }
      },
      PodIP: (string) (len=15) "192.168.164.165",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.164.165"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854056034,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63854056035,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://25d5702e680d9e8064658faaf843fcb961200208a181b4e7dc0e85b9046dbfc6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 13:47:17.035: INFO: Pod "test-new-deployment-557759b7c7-tvzx4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-tvzx4",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-3236",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7f43bfe2-7d1f-4da7-a0a4-aa7e55f31fc3",
      ResourceVersion: (string) (len=5) "44595",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854056036,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "aa6f20a7-8aca-40a8-b5c3-4c433afd461b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056036,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 61  36 66 32 30 61 37 2d 38  |d\":\"aa6f20a7-8|
              00000090  61 63 61 2d 34 30 61 38  2d 62 35 63 33 2d 34 63  |aca-40a8-b5c3-4c|
              000000a0  34 33 33 61 66 64 34 36  31 62 5c 22 7d 22 3a 7b  |433afd461b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056037,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gfgtc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gfgtc",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-43-132",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056037,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056037,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056037,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056037,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63854056037,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.43.132",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "172.31.43.132"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63854056037,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Jun 15 13:47:17.036: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3236" for this suite. @ 06/15/24 13:47:17.04
• [2.126 seconds]
------------------------------
SSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 06/15/24 13:47:17.056
  Jun 15 13:47:17.057: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 06/15/24 13:47:17.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:17.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:17.081
  STEP: Setting up the test @ 06/15/24 13:47:17.088
  STEP: Creating hostNetwork=false pod @ 06/15/24 13:47:17.088
  E0615 13:47:17.534392      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:18.534614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 06/15/24 13:47:19.112
  E0615 13:47:19.535629      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:20.535710      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 06/15/24 13:47:21.132
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 06/15/24 13:47:21.132
  Jun 15 13:47:21.132: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.132: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.132: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.132: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Jun 15 13:47:21.178: INFO: Exec stderr: ""
  Jun 15 13:47:21.178: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.178: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.179: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.179: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Jun 15 13:47:21.222: INFO: Exec stderr: ""
  Jun 15 13:47:21.222: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.222: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.222: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.222: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Jun 15 13:47:21.266: INFO: Exec stderr: ""
  Jun 15 13:47:21.266: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.266: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.266: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.266: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Jun 15 13:47:21.319: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 06/15/24 13:47:21.319
  Jun 15 13:47:21.319: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.320: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.320: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.320: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Jun 15 13:47:21.362: INFO: Exec stderr: ""
  Jun 15 13:47:21.362: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.362: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.363: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.363: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Jun 15 13:47:21.410: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 06/15/24 13:47:21.41
  Jun 15 13:47:21.410: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.411: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.411: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Jun 15 13:47:21.468: INFO: Exec stderr: ""
  Jun 15 13:47:21.468: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.468: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.468: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Jun 15 13:47:21.515: INFO: Exec stderr: ""
  Jun 15 13:47:21.515: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.516: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.516: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  E0615 13:47:21.535732      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:21.571: INFO: Exec stderr: ""
  Jun 15 13:47:21.571: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9326 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Jun 15 13:47:21.571: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  Jun 15 13:47:21.572: INFO: ExecWithOptions: Clientset creation
  Jun 15 13:47:21.572: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9326/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Jun 15 13:47:21.611: INFO: Exec stderr: ""
  Jun 15 13:47:21.611: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-9326" for this suite. @ 06/15/24 13:47:21.615
• [4.566 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 06/15/24 13:47:21.622
  Jun 15 13:47:21.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 13:47:21.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:21.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:21.642
  STEP: Creating a pod to test downward api env vars @ 06/15/24 13:47:21.645
  E0615 13:47:22.535854      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:23.536063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:24.536132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:25.536230      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:47:25.67
  Jun 15 13:47:25.674: INFO: Trying to get logs from node ip-172-31-43-132 pod downward-api-1bb3a820-b01a-400f-bc1d-b1f459f1184b container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 13:47:25.686
  Jun 15 13:47:25.705: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3409" for this suite. @ 06/15/24 13:47:25.709
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 06/15/24 13:47:25.714
  Jun 15 13:47:25.714: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:47:25.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:25.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:25.736
  STEP: Creating projection with secret that has name projected-secret-test-map-8075f6e4-534c-48e5-b5d1-129e216c422c @ 06/15/24 13:47:25.739
  STEP: Creating a pod to test consume secrets @ 06/15/24 13:47:25.743
  E0615 13:47:26.536413      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:27.536499      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:28.537080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:29.537296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:47:29.764
  Jun 15 13:47:29.769: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-secrets-207238c2-232e-460d-bf9d-61cfbcf33f3c container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 06/15/24 13:47:29.775
  Jun 15 13:47:29.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-437" for this suite. @ 06/15/24 13:47:29.793
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:808
  STEP: Creating a kubernetes client @ 06/15/24 13:47:29.799
  Jun 15 13:47:29.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 13:47:29.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:29.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:29.82
  STEP: Creating a ResourceQuota with best effort scope @ 06/15/24 13:47:29.822
  STEP: Ensuring ResourceQuota status is calculated @ 06/15/24 13:47:29.826
  E0615 13:47:30.537399      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:31.537528      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 06/15/24 13:47:31.832
  STEP: Ensuring ResourceQuota status is calculated @ 06/15/24 13:47:31.837
  E0615 13:47:32.538099      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:33.538231      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 06/15/24 13:47:33.841
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 06/15/24 13:47:33.854
  E0615 13:47:34.538283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:35.538467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 06/15/24 13:47:35.86
  E0615 13:47:36.539164      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:37.539338      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 06/15/24 13:47:37.864
  STEP: Ensuring resource quota status released the pod usage @ 06/15/24 13:47:37.881
  E0615 13:47:38.539437      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:39.540379      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 06/15/24 13:47:39.887
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 06/15/24 13:47:39.897
  E0615 13:47:40.540479      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:41.540562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 06/15/24 13:47:41.902
  E0615 13:47:42.540917      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:43.540999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 06/15/24 13:47:43.907
  STEP: Ensuring resource quota status released the pod usage @ 06/15/24 13:47:43.924
  E0615 13:47:44.541855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:45.542074      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:45.928: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5457" for this suite. @ 06/15/24 13:47:45.932
• [16.141 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 06/15/24 13:47:45.941
  Jun 15 13:47:45.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename container-probe @ 06/15/24 13:47:45.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:47:45.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:47:45.96
  STEP: Creating pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065 @ 06/15/24 13:47:45.963
  E0615 13:47:46.542985      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:47.543086      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 06/15/24 13:47:47.983
  Jun 15 13:47:47.987: INFO: Initial restart count of pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 is 0
  Jun 15 13:47:47.990: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:47:48.544129      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:49.544246      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:49.996: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:47:50.545151      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:51.546033      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:52.001: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:47:52.546221      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:53.546455      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:54.006: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:47:54.546530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:55.547496      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:56.012: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:47:56.548011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:57.548082      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:47:58.016: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:47:58.548700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:47:59.548879      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:00.020: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:00.548970      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:01.549133      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:02.024: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:02.550171      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:03.550404      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:04.030: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:04.551248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:05.551327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:06.035: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:06.552162      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:07.552342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:08.041: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:08.553402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:09.553530      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:10.046: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:10.553623      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:11.553823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:12.052: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:12.554748      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:13.554844      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:14.056: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:14.555524      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:15.555622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:16.063: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:16.556330      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:17.556451      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:18.068: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:18.557414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:19.558423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:20.073: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:20.559215      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:21.559342      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:22.077: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:22.560346      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:23.560611      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:24.083: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:24.560712      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:25.560903      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:26.090: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:26.561126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:27.561368      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:28.094: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:28.562115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:29.562751      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:30.100: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:30.563423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:31.564357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:32.105: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:32.565115      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:33.565190      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:34.111: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:34.565446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:35.565597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:36.116: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:36.566132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:37.566503      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:38.121: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:38.566581      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:39.566679      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:40.127: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:40.566737      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:41.566856      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:42.131: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:42.567928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:43.568093      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:44.137: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:44.568693      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:45.568787      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:46.141: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:46.569184      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:47.569559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:48.146: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:48.569591      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:49.570150      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:50.150: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:50.570250      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:51.570344      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:52.157: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:52.571042      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:53.571163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:54.162: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:54.571881      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:55.572382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:56.168: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:56.572921      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:57.573032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:48:58.173: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:48:58.574018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:48:59.574110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:00.179: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:00.574960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:01.575056      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:02.183: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:02.575281      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:03.575274      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:04.189: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:04.575701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:05.576351      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:06.194: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:06.576614      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:07.576936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:08.198: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:08.577059      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:09.577781      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:10.204: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:10.577935      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:11.578946      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:12.209: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:12.579688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:13.580333      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:14.213: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:14.581384      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:15.581594      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:16.220: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:16.581651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:17.582026      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:18.223: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:18.582126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:19.582357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:20.229: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:20.582949      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:21.583515      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:22.234: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:22.583622      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:23.583700      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:24.240: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:24.584386      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:25.584577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:26.246: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:26.584626      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:27.584750      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:28.252: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:28.584921      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:29.585032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:30.256: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:30.586011      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:31.586108      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:32.260: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:32.586628      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:33.586704      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:34.265: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:34.587674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:35.588574      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:36.269: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:36.588731      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:37.588798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:38.274: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:38.589740      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:39.589894      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:40.280: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:40.590104      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:41.590327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:42.286: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:42.596724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:43.597279      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:44.290: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:44.597512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:45.597597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:46.295: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:46.598345      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:47.598424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:48.300: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:48.599204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:49.599316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:50.305: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:50.599963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:51.600350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:52.310: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:52.600549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:53.600624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:54.314: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:54.601322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:55.601450      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:56.319: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:56.602041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:57.602145      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:49:58.325: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:49:58.602988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:49:59.603248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:00.329: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:00.603676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:01.604350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:02.336: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:02.605402      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:03.605510      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:04.341: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:04.606542      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:05.606746      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:06.346: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:06.606843      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:07.606936      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:08.351: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:08.607360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:09.607452      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:10.355: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:10.608132      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:11.608236      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:12.361: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:12.608549      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:13.609032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:14.366: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:14.609833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:15.610025      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:16.371: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:16.610462      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:17.610564      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:18.375: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:18.611276      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:19.611366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:20.381: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:20.612357      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:21.612446      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:22.387: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:22.613027      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:23.613124      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:24.392: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:24.613597      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:25.613777      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:26.397: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:26.613857      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:27.614254      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:28.403: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:28.615172      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:29.615300      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:30.408: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:30.616122      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:31.616282      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:32.413: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:32.619310      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:33.619416      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:34.417: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:34.620293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:35.620502      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:36.422: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:36.621037      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:37.621308      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:38.427: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:38.622264      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:39.622409      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:40.432: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:40.623431      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:41.623535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:42.437: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:42.626556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:43.626674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:44.442: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:44.627283      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:45.627380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:46.449: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:46.628366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:47.628681      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:48.453: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:48.629382      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:49.629554      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:50.457: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:50.630259      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:51.630489      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:52.463: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:52.630562      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:53.630928      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:54.468: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:54.631826      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:55.632412      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:56.473: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:56.632727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:57.632808      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:50:58.479: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:50:58.632908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:50:59.632992      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:00.484: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:00.633065      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:01.633573      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:02.491: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:02.633754      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:03.633864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:04.498: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:04.634544      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:05.634753      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:06.504: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:06.634800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:07.635187      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:08.510: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:08.635286      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:09.635313      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:10.515: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:10.635419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:11.636332      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:12.518: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:12.637101      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:13.637439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:14.525: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:14.637495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:15.638020      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:16.531: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:16.638298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:17.638388      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:18.536: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:18.639206      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:19.639290      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:20.541: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:20.639711      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:21.639933      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:22.547: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:22.641719      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:23.642078      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:24.552: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:24.642179      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:25.642361      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:26.557: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:26.643216      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:27.643298      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:28.563: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:28.643387      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:29.644364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:30.569: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:30.645322      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:31.645473      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:32.572: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:32.646395      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:33.646466      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:34.578: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:34.647032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:35.647407      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:36.584: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:36.647701      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:37.647798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:38.588: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:38.648721      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:39.648897      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:40.593: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:40.649768      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:41.649947      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:42.604: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:42.650999      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:43.651109      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:44.610: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:44.651864      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:45.652337      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:46.616: INFO: Get pod liveness-f6eb88c7-c4ee-4bee-98ea-2ca5cc390692 in namespace container-probe-7065
  E0615 13:51:46.653396      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:47.653495      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 06/15/24 13:51:48.616
  Jun 15 13:51:48.629: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7065" for this suite. @ 06/15/24 13:51:48.636
• [242.701 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 06/15/24 13:51:48.642
  Jun 15 13:51:48.642: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename dns @ 06/15/24 13:51:48.643
  E0615 13:51:48.653633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:51:48.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:51:48.665
  STEP: Creating a test headless service @ 06/15/24 13:51:48.668
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9373.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9373.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9373.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9373.svc.cluster.local;sleep 1; done
   @ 06/15/24 13:51:48.674
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9373.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9373.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9373.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9373.svc.cluster.local;sleep 1; done
   @ 06/15/24 13:51:48.674
  STEP: creating a pod to probe DNS @ 06/15/24 13:51:48.674
  STEP: submitting the pod to kubernetes @ 06/15/24 13:51:48.674
  E0615 13:51:49.654582      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:50.654793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 06/15/24 13:51:50.698
  STEP: looking for the results for each expected name from probers @ 06/15/24 13:51:50.702
  Jun 15 13:51:50.707: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local from pod dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0: the server could not find the requested resource (get pods dns-test-56357f8f-766e-4663-960e-5d109ed30ef0)
  Jun 15 13:51:50.710: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local from pod dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0: the server could not find the requested resource (get pods dns-test-56357f8f-766e-4663-960e-5d109ed30ef0)
  Jun 15 13:51:50.714: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9373.svc.cluster.local from pod dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0: the server could not find the requested resource (get pods dns-test-56357f8f-766e-4663-960e-5d109ed30ef0)
  Jun 15 13:51:50.718: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9373.svc.cluster.local from pod dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0: the server could not find the requested resource (get pods dns-test-56357f8f-766e-4663-960e-5d109ed30ef0)
  Jun 15 13:51:50.721: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local from pod dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0: the server could not find the requested resource (get pods dns-test-56357f8f-766e-4663-960e-5d109ed30ef0)
  Jun 15 13:51:50.726: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local from pod dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0: the server could not find the requested resource (get pods dns-test-56357f8f-766e-4663-960e-5d109ed30ef0)
  Jun 15 13:51:50.730: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9373.svc.cluster.local from pod dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0: the server could not find the requested resource (get pods dns-test-56357f8f-766e-4663-960e-5d109ed30ef0)
  Jun 15 13:51:50.733: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9373.svc.cluster.local from pod dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0: the server could not find the requested resource (get pods dns-test-56357f8f-766e-4663-960e-5d109ed30ef0)
  Jun 15 13:51:50.733: INFO: Lookups using dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9373.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9373.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9373.svc.cluster.local jessie_udp@dns-test-service-2.dns-9373.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9373.svc.cluster.local]

  Jun 15 13:51:50.748: INFO: Pod client logs for webserver: 
  Jun 15 13:51:50.753: INFO: Pod client logs for querier: 
  Jun 15 13:51:50.760: INFO: Pod client logs for jessie-querier: 
  E0615 13:51:51.654912      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:52.656063      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:53.656435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:54.656553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:55.656655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:55.736: INFO: DNS probes using dns-9373/dns-test-56357f8f-766e-4663-960e-5d109ed30ef0 succeeded

  STEP: deleting the pod @ 06/15/24 13:51:55.737
  STEP: deleting the test headless service @ 06/15/24 13:51:55.748
  Jun 15 13:51:55.762: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9373" for this suite. @ 06/15/24 13:51:55.767
• [7.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 06/15/24 13:51:55.775
  Jun 15 13:51:55.775: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename discovery @ 06/15/24 13:51:55.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:51:55.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:51:55.792
  STEP: Setting up server cert @ 06/15/24 13:51:55.796
  Jun 15 13:51:55.982: INFO: Checking APIGroup: apiregistration.k8s.io
  Jun 15 13:51:55.984: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Jun 15 13:51:55.984: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Jun 15 13:51:55.984: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Jun 15 13:51:55.984: INFO: Checking APIGroup: apps
  Jun 15 13:51:55.985: INFO: PreferredVersion.GroupVersion: apps/v1
  Jun 15 13:51:55.985: INFO: Versions found [{apps/v1 v1}]
  Jun 15 13:51:55.985: INFO: apps/v1 matches apps/v1
  Jun 15 13:51:55.985: INFO: Checking APIGroup: events.k8s.io
  Jun 15 13:51:55.986: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Jun 15 13:51:55.986: INFO: Versions found [{events.k8s.io/v1 v1}]
  Jun 15 13:51:55.986: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Jun 15 13:51:55.986: INFO: Checking APIGroup: authentication.k8s.io
  Jun 15 13:51:55.987: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Jun 15 13:51:55.988: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Jun 15 13:51:55.988: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Jun 15 13:51:55.988: INFO: Checking APIGroup: authorization.k8s.io
  Jun 15 13:51:55.989: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Jun 15 13:51:55.989: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Jun 15 13:51:55.989: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Jun 15 13:51:55.989: INFO: Checking APIGroup: autoscaling
  Jun 15 13:51:55.990: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Jun 15 13:51:55.990: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Jun 15 13:51:55.990: INFO: autoscaling/v2 matches autoscaling/v2
  Jun 15 13:51:55.990: INFO: Checking APIGroup: batch
  Jun 15 13:51:55.991: INFO: PreferredVersion.GroupVersion: batch/v1
  Jun 15 13:51:55.991: INFO: Versions found [{batch/v1 v1}]
  Jun 15 13:51:55.991: INFO: batch/v1 matches batch/v1
  Jun 15 13:51:55.991: INFO: Checking APIGroup: certificates.k8s.io
  Jun 15 13:51:55.992: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Jun 15 13:51:55.992: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Jun 15 13:51:55.992: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Jun 15 13:51:55.992: INFO: Checking APIGroup: networking.k8s.io
  Jun 15 13:51:55.993: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Jun 15 13:51:55.993: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Jun 15 13:51:55.993: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Jun 15 13:51:55.993: INFO: Checking APIGroup: policy
  Jun 15 13:51:55.995: INFO: PreferredVersion.GroupVersion: policy/v1
  Jun 15 13:51:55.995: INFO: Versions found [{policy/v1 v1}]
  Jun 15 13:51:55.995: INFO: policy/v1 matches policy/v1
  Jun 15 13:51:55.995: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Jun 15 13:51:55.996: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Jun 15 13:51:55.996: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Jun 15 13:51:55.996: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Jun 15 13:51:55.996: INFO: Checking APIGroup: storage.k8s.io
  Jun 15 13:51:55.997: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Jun 15 13:51:55.997: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Jun 15 13:51:55.997: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Jun 15 13:51:55.997: INFO: Checking APIGroup: admissionregistration.k8s.io
  Jun 15 13:51:55.998: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Jun 15 13:51:55.998: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Jun 15 13:51:55.998: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Jun 15 13:51:55.998: INFO: Checking APIGroup: apiextensions.k8s.io
  Jun 15 13:51:55.999: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Jun 15 13:51:55.999: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Jun 15 13:51:55.999: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Jun 15 13:51:55.999: INFO: Checking APIGroup: scheduling.k8s.io
  Jun 15 13:51:56.001: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Jun 15 13:51:56.001: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Jun 15 13:51:56.001: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Jun 15 13:51:56.001: INFO: Checking APIGroup: coordination.k8s.io
  Jun 15 13:51:56.002: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Jun 15 13:51:56.002: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Jun 15 13:51:56.002: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Jun 15 13:51:56.002: INFO: Checking APIGroup: node.k8s.io
  Jun 15 13:51:56.003: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Jun 15 13:51:56.003: INFO: Versions found [{node.k8s.io/v1 v1}]
  Jun 15 13:51:56.003: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Jun 15 13:51:56.003: INFO: Checking APIGroup: discovery.k8s.io
  Jun 15 13:51:56.004: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Jun 15 13:51:56.004: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Jun 15 13:51:56.004: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Jun 15 13:51:56.004: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Jun 15 13:51:56.005: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  Jun 15 13:51:56.005: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1 v1} {flowcontrol.apiserver.k8s.io/v1beta3 v1beta3}]
  Jun 15 13:51:56.005: INFO: flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  Jun 15 13:51:56.005: INFO: Checking APIGroup: metrics.k8s.io
  Jun 15 13:51:56.006: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  Jun 15 13:51:56.006: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  Jun 15 13:51:56.006: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  Jun 15 13:51:56.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-3349" for this suite. @ 06/15/24 13:51:56.01
• [0.240 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:447
  STEP: Creating a kubernetes client @ 06/15/24 13:51:56.015
  Jun 15 13:51:56.015: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-pred @ 06/15/24 13:51:56.016
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:51:56.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:51:56.034
  Jun 15 13:51:56.037: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Jun 15 13:51:56.044: INFO: Waiting for terminating namespaces to be deleted...
  Jun 15 13:51:56.048: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-17-110 before test
  Jun 15 13:51:56.054: INFO: nginx-ingress-controller-kubernetes-worker-pfb28 from ingress-nginx-kubernetes-worker started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.054: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: calico-node-hkrvf from kube-system started at 2024-06-15 12:04:11 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.054: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: coredns-bddfd76d7-mp2lw from kube-system started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.054: INFO: 	Container coredns ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: kube-state-metrics-6f48cdd76-fzrm6 from kube-system started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.054: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: metrics-server-v0.6.3-69d7fbfdf8-nhfgd from kube-system started at 2024-06-15 11:55:24 +0000 UTC (2 container statuses recorded)
  Jun 15 13:51:56.054: INFO: 	Container metrics-server ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: dashboard-metrics-scraper-5dd7cb5fc-6zmr5 from kubernetes-dashboard started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.054: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: kubernetes-dashboard-7b899cb9d9-444dc from kubernetes-dashboard started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.054: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-nhpcv from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:51:56.054: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: 	Container systemd-logs ready: true, restart count 0
  Jun 15 13:51:56.054: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-43-132 before test
  Jun 15 13:51:56.059: INFO: nginx-ingress-controller-kubernetes-worker-z9k8m from ingress-nginx-kubernetes-worker started at 2024-06-15 12:01:27 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.059: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:51:56.059: INFO: calico-node-f899m from kube-system started at 2024-06-15 12:04:32 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.059: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:51:56.059: INFO: sonobuoy-e2e-job-6485ce82c274498d from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:51:56.059: INFO: 	Container e2e ready: true, restart count 0
  Jun 15 13:51:56.059: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:51:56.059: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-xzkdr from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:51:56.059: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:51:56.059: INFO: 	Container systemd-logs ready: true, restart count 0
  Jun 15 13:51:56.059: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-7-7 before test
  Jun 15 13:51:56.063: INFO: nginx-ingress-controller-kubernetes-worker-qm4rb from ingress-nginx-kubernetes-worker started at 2024-06-15 12:43:19 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.063: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:51:56.063: INFO: calico-node-6rvnh from kube-system started at 2024-06-15 12:03:27 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.063: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:51:56.063: INFO: sonobuoy from sonobuoy started at 2024-06-15 12:05:44 +0000 UTC (1 container statuses recorded)
  Jun 15 13:51:56.063: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Jun 15 13:51:56.063: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-mkhb2 from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:51:56.063: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:51:56.063: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 06/15/24 13:51:56.063
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17d931d3391b3fe5], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] @ 06/15/24 13:51:56.092
  E0615 13:51:56.657032      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:51:57.089: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6596" for this suite. @ 06/15/24 13:51:57.092
• [1.084 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 06/15/24 13:51:57.099
  Jun 15 13:51:57.099: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 13:51:57.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:51:57.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:51:57.12
  STEP: Creating a pod to test emptydir volume type on node default medium @ 06/15/24 13:51:57.122
  E0615 13:51:57.657198      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:58.657305      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:51:59.657390      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:00.657465      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:52:01.144
  Jun 15 13:52:01.148: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-084ff74f-e06d-4c4a-82d0-027afa58a0a2 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 13:52:01.156
  Jun 15 13:52:01.173: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5042" for this suite. @ 06/15/24 13:52:01.177
• [4.084 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1698
  STEP: Creating a kubernetes client @ 06/15/24 13:52:01.183
  Jun 15 13:52:01.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubectl @ 06/15/24 13:52:01.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:01.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:01.2
  STEP: creating Agnhost RC @ 06/15/24 13:52:01.203
  Jun 15 13:52:01.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4955 create -f -'
  Jun 15 13:52:01.281: INFO: stderr: ""
  Jun 15 13:52:01.281: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 06/15/24 13:52:01.281
  E0615 13:52:01.657543      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:52:02.285: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:52:02.285: INFO: Found 0 / 1
  E0615 13:52:02.658083      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:52:03.286: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:52:03.286: INFO: Found 1 / 1
  Jun 15 13:52:03.286: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 06/15/24 13:52:03.286
  Jun 15 13:52:03.290: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:52:03.290: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Jun 15 13:52:03.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=kubectl-4955 patch pod agnhost-primary-tsnqk -p {"metadata":{"annotations":{"x":"y"}}}'
  Jun 15 13:52:03.342: INFO: stderr: ""
  Jun 15 13:52:03.342: INFO: stdout: "pod/agnhost-primary-tsnqk patched\n"
  STEP: checking annotations @ 06/15/24 13:52:03.342
  Jun 15 13:52:03.345: INFO: Selector matched 1 pods for map[app:agnhost]
  Jun 15 13:52:03.345: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Jun 15 13:52:03.345: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4955" for this suite. @ 06/15/24 13:52:03.35
• [2.175 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:47
  STEP: Creating a kubernetes client @ 06/15/24 13:52:03.358
  Jun 15 13:52:03.358: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename secrets @ 06/15/24 13:52:03.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:03.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:03.376
  STEP: Creating secret with name secret-test-c3f7f13a-7806-4796-945e-8c482e12e79c @ 06/15/24 13:52:03.379
  STEP: Creating a pod to test consume secrets @ 06/15/24 13:52:03.383
  E0615 13:52:03.659127      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:04.659237      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:05.660176      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:06.660425      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:52:07.409
  Jun 15 13:52:07.413: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-secrets-7cdeb3c9-74f1-427b-ac17-8ead8895e1df container secret-env-test: <nil>
  STEP: delete the pod @ 06/15/24 13:52:07.419
  Jun 15 13:52:07.435: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8810" for this suite. @ 06/15/24 13:52:07.438
• [4.086 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:962
  STEP: Creating a kubernetes client @ 06/15/24 13:52:07.444
  Jun 15 13:52:07.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename statefulset @ 06/15/24 13:52:07.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:07.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:07.467
  STEP: Creating service test in namespace statefulset-6483 @ 06/15/24 13:52:07.472
  Jun 15 13:52:07.490: INFO: Found 0 stateful pods, waiting for 1
  E0615 13:52:07.660516      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:08.660624      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:09.660868      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:10.661233      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:11.661545      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:12.661825      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:13.662041      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:14.662350      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:15.662438      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:16.662600      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:52:17.491: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 06/15/24 13:52:17.497
  W0615 13:52:17.509572      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Jun 15 13:52:17.519: INFO: Found 1 stateful pods, waiting for 2
  E0615 13:52:17.663418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:18.663507      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:19.663578      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:20.663688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:21.663988      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:22.664051      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:23.665052      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:24.665137      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:25.665317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:26.665690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:52:27.519: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Jun 15 13:52:27.519: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 06/15/24 13:52:27.526
  STEP: Delete all of the StatefulSets @ 06/15/24 13:52:27.531
  STEP: Verify that StatefulSets have been deleted @ 06/15/24 13:52:27.539
  Jun 15 13:52:27.542: INFO: Deleting all statefulset in ns statefulset-6483
  Jun 15 13:52:27.557: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6483" for this suite. @ 06/15/24 13:52:27.566
• [20.128 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 06/15/24 13:52:27.573
  Jun 15 13:52:27.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename namespaces @ 06/15/24 13:52:27.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:27.59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:27.593
  STEP: Creating a test namespace @ 06/15/24 13:52:27.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:27.612
  STEP: Creating a service in the namespace @ 06/15/24 13:52:27.615
  STEP: Deleting the namespace @ 06/15/24 13:52:27.627
  STEP: Waiting for the namespace to be removed. @ 06/15/24 13:52:27.633
  E0615 13:52:27.666111      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:28.666774      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:29.667296      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:30.667435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:31.668186      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:32.668556      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 06/15/24 13:52:33.637
  STEP: Verifying there is no service in the namespace @ 06/15/24 13:52:33.654
  Jun 15 13:52:33.657: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-285" for this suite. @ 06/15/24 13:52:33.66
  E0615 13:52:33.668676      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "nsdeletetest-2500" for this suite. @ 06/15/24 13:52:33.673
  Jun 15 13:52:33.676: INFO: Namespace nsdeletetest-2500 was already deleted
  STEP: Destroying namespace "nsdeletetest-8088" for this suite. @ 06/15/24 13:52:33.676
• [6.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 06/15/24 13:52:33.682
  Jun 15 13:52:33.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename custom-resource-definition @ 06/15/24 13:52:33.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:33.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:33.702
  Jun 15 13:52:33.705: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:52:34.669512      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:35.669800      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:36.669995      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:52:36.786: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5287" for this suite. @ 06/15/24 13:52:36.789
• [3.114 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:810
  STEP: Creating a kubernetes client @ 06/15/24 13:52:36.796
  Jun 15 13:52:36.796: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename svcaccounts @ 06/15/24 13:52:36.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:36.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:36.814
  STEP: Creating ServiceAccount "e2e-sa-m2x6d"  @ 06/15/24 13:52:36.817
  Jun 15 13:52:36.822: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-m2x6d"  @ 06/15/24 13:52:36.822
  Jun 15 13:52:36.830: INFO: AutomountServiceAccountToken: true
  Jun 15 13:52:36.830: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6435" for this suite. @ 06/15/24 13:52:36.835
• [0.045 seconds]
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:219
  STEP: Creating a kubernetes client @ 06/15/24 13:52:36.84
  Jun 15 13:52:36.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 13:52:36.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:36.856
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:36.859
  STEP: Creating a pod to test downward api env vars @ 06/15/24 13:52:36.862
  E0615 13:52:37.670153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:38.670435      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:39.670604      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:40.670849      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:52:40.893
  Jun 15 13:52:40.895: INFO: Trying to get logs from node ip-172-31-7-7 pod downward-api-d6cf87cd-5097-41ad-8fcf-19cb8fc86fb7 container dapi-container: <nil>
  STEP: delete the pod @ 06/15/24 13:52:40.903
  Jun 15 13:52:40.918: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2709" for this suite. @ 06/15/24 13:52:40.921
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:855
  STEP: Creating a kubernetes client @ 06/15/24 13:52:40.927
  Jun 15 13:52:40.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename job @ 06/15/24 13:52:40.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:40.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:40.947
  STEP: Creating a suspended job @ 06/15/24 13:52:40.953
  STEP: Patching the Job @ 06/15/24 13:52:40.959
  STEP: Watching for Job to be patched @ 06/15/24 13:52:41.003
  Jun 15 13:52:41.008: INFO: Event ADDED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-job-label:e2e-hxhg2] and annotations: map[]
  Jun 15 13:52:41.008: INFO: Event MODIFIED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-job-label:e2e-hxhg2] and annotations: map[]
  Jun 15 13:52:41.008: INFO: Event MODIFIED found for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[]
  STEP: Updating the job @ 06/15/24 13:52:41.008
  STEP: Watching for Job to be updated @ 06/15/24 13:52:41.027
  Jun 15 13:52:41.028: INFO: Event MODIFIED found for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  Jun 15 13:52:41.028: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 06/15/24 13:52:41.028
  Jun 15 13:52:41.031: INFO: Job: e2e-hxhg2 as labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2]
  STEP: Waiting for job to complete @ 06/15/24 13:52:41.031
  E0615 13:52:41.671424      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:42.671557      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:43.672453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:44.672529      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:45.672633      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:46.672725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:47.673369      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:48.673453      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 06/15/24 13:52:49.036
  STEP: Watching for Job to be deleted @ 06/15/24 13:52:49.046
  Jun 15 13:52:49.048: INFO: Event MODIFIED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  Jun 15 13:52:49.048: INFO: Event MODIFIED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  Jun 15 13:52:49.048: INFO: Event MODIFIED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  Jun 15 13:52:49.048: INFO: Event MODIFIED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  Jun 15 13:52:49.048: INFO: Event MODIFIED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  Jun 15 13:52:49.048: INFO: Event MODIFIED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  Jun 15 13:52:49.048: INFO: Event MODIFIED observed for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  Jun 15 13:52:49.048: INFO: Event DELETED found for Job e2e-hxhg2 in namespace job-8582 with labels: map[e2e-hxhg2:patched e2e-job-label:e2e-hxhg2] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 06/15/24 13:52:49.048
  Jun 15 13:52:49.053: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8582" for this suite. @ 06/15/24 13:52:49.057
• [8.144 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 06/15/24 13:52:49.072
  Jun 15 13:52:49.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename discovery @ 06/15/24 13:52:49.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:49.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:49.103
  STEP: Setting up server cert @ 06/15/24 13:52:49.107
  STEP: Requesting APIResourceList from "/api/v1" @ 06/15/24 13:52:49.391
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 06/15/24 13:52:49.393
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 06/15/24 13:52:49.394
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 06/15/24 13:52:49.395
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 06/15/24 13:52:49.397
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 06/15/24 13:52:49.398
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 06/15/24 13:52:49.399
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 06/15/24 13:52:49.4
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 06/15/24 13:52:49.401
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 06/15/24 13:52:49.403
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 06/15/24 13:52:49.404
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 06/15/24 13:52:49.405
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 06/15/24 13:52:49.406
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 06/15/24 13:52:49.408
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 06/15/24 13:52:49.409
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 06/15/24 13:52:49.41
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 06/15/24 13:52:49.411
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 06/15/24 13:52:49.412
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 06/15/24 13:52:49.413
  Jun 15 13:52:49.415: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8140" for this suite. @ 06/15/24 13:52:49.418
• [0.353 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2236
  STEP: Creating a kubernetes client @ 06/15/24 13:52:49.426
  Jun 15 13:52:49.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 13:52:49.426
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:49.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:49.445
  STEP: creating service in namespace services-1006 @ 06/15/24 13:52:49.448
  STEP: creating service affinity-nodeport-transition in namespace services-1006 @ 06/15/24 13:52:49.448
  STEP: creating replication controller affinity-nodeport-transition in namespace services-1006 @ 06/15/24 13:52:49.464
  I0615 13:52:49.471718      19 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-1006, replica count: 3
  E0615 13:52:49.673871      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:50.673993      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:51.674959      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 13:52:52.522498      19 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 13:52:52.534: INFO: Creating new exec pod
  E0615 13:52:52.675666      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:53.676423      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:54.677331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:52:55.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1006 exec execpod-affinityrv8w9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Jun 15 13:52:55.651: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Jun 15 13:52:55.651: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 13:52:55.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1006 exec execpod-affinityrv8w9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.244 80'
  E0615 13:52:55.678255      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:52:55.745: INFO: stderr: "+ nc -v -t -w 2 10.152.183.244 80\n+ echo hostName\nConnection to 10.152.183.244 80 port [tcp/http] succeeded!\n"
  Jun 15 13:52:55.745: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 13:52:55.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1006 exec execpod-affinityrv8w9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.17.110 31006'
  Jun 15 13:52:55.846: INFO: stderr: "+ nc -v -t -w 2 172.31.17.110 31006\n+ echo hostName\nConnection to 172.31.17.110 31006 port [tcp/*] succeeded!\n"
  Jun 15 13:52:55.846: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 13:52:55.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1006 exec execpod-affinityrv8w9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.7.7 31006'
  Jun 15 13:52:55.937: INFO: stderr: "+ nc -v -t -w 2 172.31.7.7 31006\n+ echo hostName\nConnection to 172.31.7.7 31006 port [tcp/*] succeeded!\n"
  Jun 15 13:52:55.937: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 13:52:55.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1006 exec execpod-affinityrv8w9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.17.110:31006/ ; done'
  Jun 15 13:52:56.106: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n"
  Jun 15 13:52:56.106: INFO: stdout: "\naffinity-nodeport-transition-pslt6\naffinity-nodeport-transition-94625\naffinity-nodeport-transition-94625\naffinity-nodeport-transition-94625\naffinity-nodeport-transition-94625\naffinity-nodeport-transition-pslt6\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-pslt6\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-94625\naffinity-nodeport-transition-94625\naffinity-nodeport-transition-pslt6\naffinity-nodeport-transition-94625\naffinity-nodeport-transition-94625"
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-pslt6
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-94625
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-94625
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-94625
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-94625
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-pslt6
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-pslt6
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-94625
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-94625
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-pslt6
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-94625
  Jun 15 13:52:56.106: INFO: Received response from host: affinity-nodeport-transition-94625
  Jun 15 13:52:56.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-1006 exec execpod-affinityrv8w9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.17.110:31006/ ; done'
  Jun 15 13:52:56.298: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.17.110:31006/\n"
  Jun 15 13:52:56.298: INFO: stdout: "\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n\naffinity-nodeport-transition-8dd9n"
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Received response from host: affinity-nodeport-transition-8dd9n
  Jun 15 13:52:56.298: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-1006, will wait for the garbage collector to delete the pods @ 06/15/24 13:52:56.31
  Jun 15 13:52:56.372: INFO: Deleting ReplicationController affinity-nodeport-transition took: 8.149214ms
  Jun 15 13:52:56.474: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.137439ms
  E0615 13:52:56.678673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:57.679091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:52:58.679318      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:52:59.601: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1006" for this suite. @ 06/15/24 13:52:59.605
• [10.185 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 06/15/24 13:52:59.611
  Jun 15 13:52:59.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename var-expansion @ 06/15/24 13:52:59.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:52:59.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:52:59.629
  E0615 13:52:59.680163      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:00.680222      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:01.651: INFO: Deleting pod "var-expansion-1b876873-eb9a-4ec1-a536-b52ea34d1af2" in namespace "var-expansion-8469"
  Jun 15 13:53:01.659: INFO: Wait up to 5m0s for pod "var-expansion-1b876873-eb9a-4ec1-a536-b52ea34d1af2" to be fully deleted
  E0615 13:53:01.680888      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:02.680997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:03.667: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8469" for this suite. @ 06/15/24 13:53:03.672
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 06/15/24 13:53:03.68
  Jun 15 13:53:03.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:53:03.681034      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename daemonsets @ 06/15/24 13:53:03.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:03.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:03.701
  STEP: Creating simple DaemonSet "daemon-set" @ 06/15/24 13:53:03.721
  STEP: Check that daemon pods launch on every node of the cluster. @ 06/15/24 13:53:03.727
  Jun 15 13:53:03.730: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:53:03.730: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:53:03.733: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:53:03.733: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 13:53:04.682003      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:04.734: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:53:04.734: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:53:04.738: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Jun 15 13:53:04.738: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 13:53:05.682110      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:05.733: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:53:05.733: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:53:05.736: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 13:53:05.736: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 06/15/24 13:53:05.74
  STEP: DeleteCollection of the DaemonSets @ 06/15/24 13:53:05.743
  STEP: Verify that ReplicaSets have been deleted @ 06/15/24 13:53:05.751
  Jun 15 13:53:05.764: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"46408"},"items":null}

  Jun 15 13:53:05.766: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"46411"},"items":[{"metadata":{"name":"daemon-set-nxdqm","generateName":"daemon-set-","namespace":"daemonsets-7860","uid":"577b9f85-e22d-450b-aa46-a8db5f4dd744","resourceVersion":"46409","creationTimestamp":"2024-06-15T13:53:03Z","deletionTimestamp":"2024-06-15T13:53:35Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b9821644-5992-42ac-a59d-3d798ff3219b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-06-15T13:53:03Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b9821644-5992-42ac-a59d-3d798ff3219b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-06-15T13:53:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.164.167\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-trw7m","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-trw7m","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-7-7","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-7-7"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:03Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:03Z"}],"hostIP":"172.31.7.7","hostIPs":[{"ip":"172.31.7.7"}],"podIP":"192.168.164.167","podIPs":[{"ip":"192.168.164.167"}],"startTime":"2024-06-15T13:53:03Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-06-15T13:53:04Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://a2ec8328e15227ece4e82310b50a0933cf75cee3e60663a5a599e9a8fc9332e8","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wm25b","generateName":"daemon-set-","namespace":"daemonsets-7860","uid":"d0c17b76-d04a-4070-b3c1-aad62fedf360","resourceVersion":"46410","creationTimestamp":"2024-06-15T13:53:03Z","deletionTimestamp":"2024-06-15T13:53:35Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b9821644-5992-42ac-a59d-3d798ff3219b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-06-15T13:53:03Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b9821644-5992-42ac-a59d-3d798ff3219b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-06-15T13:53:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.0.101\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-4479g","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-4479g","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-17-110","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-17-110"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:03Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:03Z"}],"hostIP":"172.31.17.110","hostIPs":[{"ip":"172.31.17.110"}],"podIP":"192.168.0.101","podIPs":[{"ip":"192.168.0.101"}],"startTime":"2024-06-15T13:53:03Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-06-15T13:53:04Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://49369c6700fb740b5042efb2394384269a9ce34608fdf361a099cc2295018ee4","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wzpz4","generateName":"daemon-set-","namespace":"daemonsets-7860","uid":"c362ee63-83c6-4199-ac70-4a2d0909cc37","resourceVersion":"46372","creationTimestamp":"2024-06-15T13:53:03Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b9821644-5992-42ac-a59d-3d798ff3219b","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-06-15T13:53:03Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b9821644-5992-42ac-a59d-3d798ff3219b\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-06-15T13:53:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.40.226\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-llrff","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-llrff","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-43-132","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-43-132"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:03Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:04Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-06-15T13:53:03Z"}],"hostIP":"172.31.43.132","hostIPs":[{"ip":"172.31.43.132"}],"podIP":"192.168.40.226","podIPs":[{"ip":"192.168.40.226"}],"startTime":"2024-06-15T13:53:03Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-06-15T13:53:04Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://f6df5795db249a18314010e4515937bfafaf29bb722f78a232cfeddb401fb2ef","started":true}],"qosClass":"BestEffort"}}]}

  Jun 15 13:53:05.781: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7860" for this suite. @ 06/15/24 13:53:05.785
• [2.113 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:46
  STEP: Creating a kubernetes client @ 06/15/24 13:53:05.793
  Jun 15 13:53:05.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename configmap @ 06/15/24 13:53:05.794
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:05.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:05.815
  STEP: Creating configMap configmap-5862/configmap-test-821d6685-65e3-4466-a247-1b91d5548382 @ 06/15/24 13:53:05.818
  STEP: Creating a pod to test consume configMaps @ 06/15/24 13:53:05.822
  E0615 13:53:06.682960      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:07.683043      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:08.683180      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:09.683327      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:53:09.845
  Jun 15 13:53:09.849: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-configmaps-109a8db6-61d1-4b25-9936-71348fb3287e container env-test: <nil>
  STEP: delete the pod @ 06/15/24 13:53:09.855
  Jun 15 13:53:09.872: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5862" for this suite. @ 06/15/24 13:53:09.875
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:902
  STEP: Creating a kubernetes client @ 06/15/24 13:53:09.882
  Jun 15 13:53:09.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename statefulset @ 06/15/24 13:53:09.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:09.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:09.903
  STEP: Creating service test in namespace statefulset-8189 @ 06/15/24 13:53:09.906
  STEP: Creating statefulset ss in namespace statefulset-8189 @ 06/15/24 13:53:09.911
  Jun 15 13:53:09.920: INFO: Found 0 stateful pods, waiting for 1
  E0615 13:53:10.683565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:11.684316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:12.684408      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:13.684566      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:14.684785      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:15.685091      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:16.685188      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:17.685356      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:18.685523      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:19.685655      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:19.922: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 06/15/24 13:53:19.929
  STEP: updating a scale subresource @ 06/15/24 13:53:19.933
  STEP: verifying the statefulset Spec.Replicas was modified @ 06/15/24 13:53:19.939
  STEP: Patch a scale subresource @ 06/15/24 13:53:19.942
  STEP: verifying the statefulset Spec.Replicas was modified @ 06/15/24 13:53:19.948
  Jun 15 13:53:19.952: INFO: Deleting all statefulset in ns statefulset-8189
  Jun 15 13:53:19.957: INFO: Scaling statefulset ss to 0
  E0615 13:53:20.685725      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:21.685998      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:22.686201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:23.686297      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:24.686492      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:25.686586      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:26.687585      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:27.687695      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:28.687786      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:29.688397      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:29.973: INFO: Waiting for statefulset status.replicas updated to 0
  Jun 15 13:53:29.976: INFO: Deleting statefulset ss
  Jun 15 13:53:29.988: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8189" for this suite. @ 06/15/24 13:53:29.991
• [20.117 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 06/15/24 13:53:29.998
  Jun 15 13:53:29.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename crd-publish-openapi @ 06/15/24 13:53:29.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:30.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:30.018
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 06/15/24 13:53:30.021
  Jun 15 13:53:30.022: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:53:30.689030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:31.689113      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:32.690121      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:33.690331      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:34.691008      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 06/15/24 13:53:35.062
  Jun 15 13:53:35.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:53:35.691798      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:36.339: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  E0615 13:53:36.692419      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:37.692876      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:38.693606      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:39.694153      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:40.694227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:41.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5607" for this suite. @ 06/15/24 13:53:41.355
• [11.365 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 06/15/24 13:53:41.364
  Jun 15 13:53:41.364: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:53:41.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:41.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:41.387
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:53:41.39
  E0615 13:53:41.694823      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:42.694923      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:43.695824      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:44.695922      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:53:45.417
  Jun 15 13:53:45.420: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-03c5b120-b980-4e8c-90cb-8c3aaa5b095f container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:53:45.428
  Jun 15 13:53:45.443: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4599" for this suite. @ 06/15/24 13:53:45.447
• [4.090 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 06/15/24 13:53:45.454
  Jun 15 13:53:45.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename disruption @ 06/15/24 13:53:45.454
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:45.47
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:45.473
  STEP: Waiting for the pdb to be processed @ 06/15/24 13:53:45.48
  E0615 13:53:45.696383      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:46.696986      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 06/15/24 13:53:47.513
  Jun 15 13:53:47.517: INFO: running pods: 0 < 3
  E0615 13:53:47.697514      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:48.697617      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:49.522: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3471" for this suite. @ 06/15/24 13:53:49.525
• [4.079 seconds]
------------------------------
SS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 06/15/24 13:53:49.533
  Jun 15 13:53:49.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename conformance-tests @ 06/15/24 13:53:49.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:49.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:49.555
  STEP: Getting node addresses @ 06/15/24 13:53:49.558
  Jun 15 13:53:49.558: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Jun 15 13:53:49.564: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-5341" for this suite. @ 06/15/24 13:53:49.567
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:470
  STEP: Creating a kubernetes client @ 06/15/24 13:53:49.573
  Jun 15 13:53:49.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename sched-pred @ 06/15/24 13:53:49.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:49.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:49.592
  Jun 15 13:53:49.595: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Jun 15 13:53:49.601: INFO: Waiting for terminating namespaces to be deleted...
  Jun 15 13:53:49.605: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-17-110 before test
  Jun 15 13:53:49.608: INFO: nginx-ingress-controller-kubernetes-worker-pfb28 from ingress-nginx-kubernetes-worker started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.608: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:53:49.608: INFO: calico-node-hkrvf from kube-system started at 2024-06-15 12:04:11 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.608: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:53:49.608: INFO: coredns-bddfd76d7-mp2lw from kube-system started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.608: INFO: 	Container coredns ready: true, restart count 0
  Jun 15 13:53:49.608: INFO: kube-state-metrics-6f48cdd76-fzrm6 from kube-system started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.608: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Jun 15 13:53:49.608: INFO: metrics-server-v0.6.3-69d7fbfdf8-nhfgd from kube-system started at 2024-06-15 11:55:24 +0000 UTC (2 container statuses recorded)
  Jun 15 13:53:49.608: INFO: 	Container metrics-server ready: true, restart count 0
  Jun 15 13:53:49.609: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Jun 15 13:53:49.609: INFO: dashboard-metrics-scraper-5dd7cb5fc-6zmr5 from kubernetes-dashboard started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.609: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Jun 15 13:53:49.609: INFO: kubernetes-dashboard-7b899cb9d9-444dc from kubernetes-dashboard started at 2024-06-15 11:55:24 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.609: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Jun 15 13:53:49.609: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-nhpcv from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:53:49.609: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:53:49.609: INFO: 	Container systemd-logs ready: true, restart count 0
  Jun 15 13:53:49.609: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-43-132 before test
  Jun 15 13:53:49.615: INFO: pod-1 from disruption-3471 started at 2024-06-15 13:53:47 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.615: INFO: 	Container donothing ready: true, restart count 0
  Jun 15 13:53:49.615: INFO: nginx-ingress-controller-kubernetes-worker-z9k8m from ingress-nginx-kubernetes-worker started at 2024-06-15 12:01:27 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.615: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:53:49.615: INFO: calico-node-f899m from kube-system started at 2024-06-15 12:04:32 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.615: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:53:49.615: INFO: sonobuoy-e2e-job-6485ce82c274498d from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:53:49.615: INFO: 	Container e2e ready: true, restart count 0
  Jun 15 13:53:49.615: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:53:49.615: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-xzkdr from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:53:49.615: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:53:49.615: INFO: 	Container systemd-logs ready: true, restart count 0
  Jun 15 13:53:49.615: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-7-7 before test
  Jun 15 13:53:49.620: INFO: pod-0 from disruption-3471 started at 2024-06-15 13:53:47 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.620: INFO: 	Container donothing ready: true, restart count 0
  Jun 15 13:53:49.620: INFO: pod-2 from disruption-3471 started at 2024-06-15 13:53:47 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.620: INFO: 	Container donothing ready: true, restart count 0
  Jun 15 13:53:49.620: INFO: nginx-ingress-controller-kubernetes-worker-qm4rb from ingress-nginx-kubernetes-worker started at 2024-06-15 12:43:19 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.620: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Jun 15 13:53:49.620: INFO: calico-node-6rvnh from kube-system started at 2024-06-15 12:03:27 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.620: INFO: 	Container calico-node ready: true, restart count 0
  Jun 15 13:53:49.620: INFO: sonobuoy from sonobuoy started at 2024-06-15 12:05:44 +0000 UTC (1 container statuses recorded)
  Jun 15 13:53:49.620: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Jun 15 13:53:49.620: INFO: sonobuoy-systemd-logs-daemon-set-1de51ad2bff1430b-mkhb2 from sonobuoy started at 2024-06-15 12:05:46 +0000 UTC (2 container statuses recorded)
  Jun 15 13:53:49.620: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Jun 15 13:53:49.620: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 06/15/24 13:53:49.62
  E0615 13:53:49.697919      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:50.698414      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 06/15/24 13:53:51.641
  STEP: Trying to apply a random label on the found node. @ 06/15/24 13:53:51.656
  STEP: verifying the node has the label kubernetes.io/e2e-21389714-e54b-469e-ab1f-43d90b9784aa 42 @ 06/15/24 13:53:51.663
  STEP: Trying to relaunch the pod, now with labels. @ 06/15/24 13:53:51.666
  E0615 13:53:51.698728      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:52.699326      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-21389714-e54b-469e-ab1f-43d90b9784aa off the node ip-172-31-7-7 @ 06/15/24 13:53:53.685
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-21389714-e54b-469e-ab1f-43d90b9784aa @ 06/15/24 13:53:53.696
  E0615 13:53:53.699734      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:53:53.700: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8417" for this suite. @ 06/15/24 13:53:53.704
• [4.138 seconds]
------------------------------
S
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 06/15/24 13:53:53.711
  Jun 15 13:53:53.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename disruption @ 06/15/24 13:53:53.712
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:53.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:53.728
  STEP: Waiting for the pdb to be processed @ 06/15/24 13:53:53.735
  E0615 13:53:54.699855      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:55.699940      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 06/15/24 13:53:55.74
  STEP: Waiting for all pods to be running @ 06/15/24 13:53:55.75
  Jun 15 13:53:55.754: INFO: running pods: 0 < 1
  E0615 13:53:56.700251      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:57.700355      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 06/15/24 13:53:57.754
  STEP: Waiting for the pdb to be processed @ 06/15/24 13:53:57.768
  STEP: Patching PodDisruptionBudget status @ 06/15/24 13:53:57.775
  STEP: Waiting for the pdb to be processed @ 06/15/24 13:53:57.786
  Jun 15 13:53:57.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2507" for this suite. @ 06/15/24 13:53:57.791
• [4.088 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 06/15/24 13:53:57.799
  Jun 15 13:53:57.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir @ 06/15/24 13:53:57.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:57.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:57.818
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 06/15/24 13:53:57.821
  E0615 13:53:58.700449      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:53:59.700538      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:53:59.838
  Jun 15 13:53:59.840: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-c34faf46-e1bd-4bbe-95bd-610669eb7ff8 container test-container: <nil>
  STEP: delete the pod @ 06/15/24 13:53:59.856
  Jun 15 13:53:59.871: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5246" for this suite. @ 06/15/24 13:53:59.875
• [2.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 06/15/24 13:53:59.882
  Jun 15 13:53:59.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename subpath @ 06/15/24 13:53:59.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:53:59.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:53:59.907
  STEP: Setting up data @ 06/15/24 13:53:59.91
  STEP: Creating pod pod-subpath-test-configmap-bqcr @ 06/15/24 13:53:59.918
  STEP: Creating a pod to test atomic-volume-subpath @ 06/15/24 13:53:59.918
  E0615 13:54:00.700651      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:01.701559      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:02.702235      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:03.703201      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:04.703817      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:05.704360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:06.705248      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:07.705612      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:08.705662      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:09.705793      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:10.706613      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:11.707202      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:12.708138      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:13.708227      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:14.708317      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:15.708688      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:16.708789      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:17.709587      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:18.709699      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:19.709957      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:20.710038      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:21.710673      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:22.711268      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:23.712362      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:54:23.996
  Jun 15 13:54:23.999: INFO: Trying to get logs from node ip-172-31-43-132 pod pod-subpath-test-configmap-bqcr container test-container-subpath-configmap-bqcr: <nil>
  STEP: delete the pod @ 06/15/24 13:54:24.004
  STEP: Deleting pod pod-subpath-test-configmap-bqcr @ 06/15/24 13:54:24.022
  Jun 15 13:54:24.022: INFO: Deleting pod "pod-subpath-test-configmap-bqcr" in namespace "subpath-3159"
  Jun 15 13:54:24.025: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3159" for this suite. @ 06/15/24 13:54:24.029
• [24.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 06/15/24 13:54:24.035
  Jun 15 13:54:24.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename downward-api @ 06/15/24 13:54:24.036
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:54:24.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:54:24.055
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:54:24.058
  E0615 13:54:24.713126      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:25.713228      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:26.713311      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:27.713555      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:54:28.083
  Jun 15 13:54:28.088: INFO: Trying to get logs from node ip-172-31-7-7 pod downwardapi-volume-e6150391-2b03-46c4-a158-8a853cebc289 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:54:28.094
  Jun 15 13:54:28.107: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7964" for this suite. @ 06/15/24 13:54:28.111
• [4.083 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2199
  STEP: Creating a kubernetes client @ 06/15/24 13:54:28.118
  Jun 15 13:54:28.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename services @ 06/15/24 13:54:28.119
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:54:28.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:54:28.138
  STEP: creating service in namespace services-4951 @ 06/15/24 13:54:28.141
  STEP: creating service affinity-clusterip-transition in namespace services-4951 @ 06/15/24 13:54:28.141
  STEP: creating replication controller affinity-clusterip-transition in namespace services-4951 @ 06/15/24 13:54:28.15
  I0615 13:54:28.159213      19 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-4951, replica count: 3
  E0615 13:54:28.713747      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:29.714081      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:30.714204      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0615 13:54:31.210447      19 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Jun 15 13:54:31.218: INFO: Creating new exec pod
  E0615 13:54:31.714443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:32.714840      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:33.715526      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:34.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4951 exec execpod-affinity9zgcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Jun 15 13:54:34.327: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Jun 15 13:54:34.327: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 13:54:34.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4951 exec execpod-affinity9zgcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.59 80'
  Jun 15 13:54:34.417: INFO: stderr: "+ nc -v -t -w 2 10.152.183.59 80\n+ echo hostName\nConnection to 10.152.183.59 80 port [tcp/http] succeeded!\n"
  Jun 15 13:54:34.417: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Jun 15 13:54:34.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4951 exec execpod-affinity9zgcs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.59:80/ ; done'
  Jun 15 13:54:34.569: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n"
  Jun 15 13:54:34.569: INFO: stdout: "\naffinity-clusterip-transition-9qbxv\naffinity-clusterip-transition-lw5dw\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-lw5dw\naffinity-clusterip-transition-9qbxv\naffinity-clusterip-transition-9qbxv\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-9qbxv\naffinity-clusterip-transition-lw5dw\naffinity-clusterip-transition-lw5dw\naffinity-clusterip-transition-9qbxv\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-lw5dw\naffinity-clusterip-transition-9qbxv\naffinity-clusterip-transition-9qbxv"
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-9qbxv
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-lw5dw
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-lw5dw
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-9qbxv
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-9qbxv
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-9qbxv
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-lw5dw
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-lw5dw
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-9qbxv
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-lw5dw
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-9qbxv
  Jun 15 13:54:34.569: INFO: Received response from host: affinity-clusterip-transition-9qbxv
  Jun 15 13:54:34.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2624435875 --namespace=services-4951 exec execpod-affinity9zgcs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.59:80/ ; done'
  Jun 15 13:54:34.705: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.59:80/\n"
  Jun 15 13:54:34.706: INFO: stdout: "\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj\naffinity-clusterip-transition-5kgpj"
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Received response from host: affinity-clusterip-transition-5kgpj
  Jun 15 13:54:34.706: INFO: Cleaning up the exec pod
  E0615 13:54:34.716136      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-4951, will wait for the garbage collector to delete the pods @ 06/15/24 13:54:34.718
  Jun 15 13:54:34.781: INFO: Deleting ReplicationController affinity-clusterip-transition took: 6.989796ms
  Jun 15 13:54:34.881: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.448604ms
  E0615 13:54:35.716328      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:36.716982      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:37.699: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4951" for this suite. @ 06/15/24 13:54:37.702
• [9.589 seconds]
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 06/15/24 13:54:37.707
  Jun 15 13:54:37.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename svcaccounts @ 06/15/24 13:54:37.708
  E0615 13:54:37.718141      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:54:37.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:54:37.727
  E0615 13:54:38.718467      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:39.718755      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 06/15/24 13:54:39.752
  Jun 15 13:54:39.752: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4557 pod-service-account-b8ba5618-3a5a-4464-b6db-367c8e27e420 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 06/15/24 13:54:39.84
  Jun 15 13:54:39.840: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4557 pod-service-account-b8ba5618-3a5a-4464-b6db-367c8e27e420 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 06/15/24 13:54:39.928
  Jun 15 13:54:39.928: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4557 pod-service-account-b8ba5618-3a5a-4464-b6db-367c8e27e420 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Jun 15 13:54:40.025: INFO: Got root ca configmap in namespace "svcaccounts-4557"
  Jun 15 13:54:40.027: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4557" for this suite. @ 06/15/24 13:54:40.031
• [2.330 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 06/15/24 13:54:40.038
  Jun 15 13:54:40.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename daemonsets @ 06/15/24 13:54:40.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:54:40.056
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:54:40.059
  Jun 15 13:54:40.084: INFO: Create a RollingUpdate DaemonSet
  Jun 15 13:54:40.088: INFO: Check that daemon pods launch on every node of the cluster
  Jun 15 13:54:40.091: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:40.091: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:40.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:54:40.095: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 13:54:40.719735      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:41.093: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:41.094: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:41.096: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Jun 15 13:54:41.096: INFO: Node ip-172-31-17-110 is running 0 daemon pod, expected 1
  E0615 13:54:41.720316      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:42.093: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:42.093: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:42.096: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Jun 15 13:54:42.096: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Jun 15 13:54:42.096: INFO: Update the DaemonSet to trigger a rollout
  Jun 15 13:54:42.106: INFO: Updating DaemonSet daemon-set
  E0615 13:54:42.720494      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:43.118: INFO: Roll back the DaemonSet before rollout is complete
  Jun 15 13:54:43.126: INFO: Updating DaemonSet daemon-set
  Jun 15 13:54:43.126: INFO: Make sure DaemonSet rollback is complete
  Jun 15 13:54:43.129: INFO: Wrong image for pod: daemon-set-2dvl9. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Jun 15 13:54:43.129: INFO: Pod daemon-set-2dvl9 is not available
  Jun 15 13:54:43.132: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:43.133: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0615 13:54:43.720961      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:44.136: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:44.136: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0615 13:54:44.721727      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:45.132: INFO: Pod daemon-set-mzxmg is not available
  Jun 15 13:54:45.135: INFO: DaemonSet pods can't tolerate node ip-172-31-3-208 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Jun 15 13:54:45.135: INFO: DaemonSet pods can't tolerate node ip-172-31-94-186 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 06/15/24 13:54:45.144
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4632, will wait for the garbage collector to delete the pods @ 06/15/24 13:54:45.144
  Jun 15 13:54:45.203: INFO: Deleting DaemonSet.extensions daemon-set took: 5.700519ms
  Jun 15 13:54:45.304: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.806951ms
  E0615 13:54:45.722418      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:46.707: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Jun 15 13:54:46.707: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Jun 15 13:54:46.710: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"47482"},"items":null}

  Jun 15 13:54:46.715: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"47482"},"items":null}

  E0615 13:54:46.722997      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:46.727: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4632" for this suite. @ 06/15/24 13:54:46.731
• [6.701 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 06/15/24 13:54:46.739
  Jun 15 13:54:46.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename replication-controller @ 06/15/24 13:54:46.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:54:46.757
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:54:46.76
  Jun 15 13:54:46.763: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0615 13:54:47.723272      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 06/15/24 13:54:47.774
  STEP: Checking rc "condition-test" has the desired failure condition set @ 06/15/24 13:54:47.78
  E0615 13:54:48.724363      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 06/15/24 13:54:48.788
  Jun 15 13:54:48.796: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 06/15/24 13:54:48.797
  E0615 13:54:49.724459      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:49.806: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6429" for this suite. @ 06/15/24 13:54:49.809
• [3.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 06/15/24 13:54:49.817
  Jun 15 13:54:49.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename prestop @ 06/15/24 13:54:49.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:54:49.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:54:49.836
  STEP: Creating server pod server in namespace prestop-3455 @ 06/15/24 13:54:49.839
  STEP: Waiting for pods to come up. @ 06/15/24 13:54:49.848
  E0615 13:54:50.724553      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:51.724690      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-3455 @ 06/15/24 13:54:51.859
  E0615 13:54:52.724767      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:53.724901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 06/15/24 13:54:53.877
  E0615 13:54:54.725072      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:55.725170      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:56.725266      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:57.725366      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:54:58.726271      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:54:58.891: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 06/15/24 13:54:58.891
  Jun 15 13:54:58.907: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-3455" for this suite. @ 06/15/24 13:54:58.912
• [9.102 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 06/15/24 13:54:58.919
  Jun 15 13:54:58.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:54:58.919
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:54:58.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:54:58.938
  STEP: Creating configMap with name projected-configmap-test-volume-map-9d95b3ee-e320-4b1f-a3ba-180eb3fb20bf @ 06/15/24 13:54:58.941
  STEP: Creating a pod to test consume configMaps @ 06/15/24 13:54:58.948
  E0615 13:54:59.726475      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:00.726572      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:01.727565      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:02.727649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:55:02.97
  Jun 15 13:55:02.973: INFO: Trying to get logs from node ip-172-31-7-7 pod pod-projected-configmaps-df658316-1a66-4b0e-af4e-7ebe5962426f container agnhost-container: <nil>
  STEP: delete the pod @ 06/15/24 13:55:02.98
  Jun 15 13:55:02.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3952" for this suite. @ 06/15/24 13:55:03
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:51
  STEP: Creating a kubernetes client @ 06/15/24 13:55:03.007
  Jun 15 13:55:03.007: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename kubelet-test @ 06/15/24 13:55:03.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:55:03.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:55:03.025
  E0615 13:55:03.727724      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:04.727782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:55:05.056: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7166" for this suite. @ 06/15/24 13:55:05.059
• [2.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 06/15/24 13:55:05.071
  Jun 15 13:55:05.071: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename containers @ 06/15/24 13:55:05.072
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:55:05.088
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:55:05.091
  E0615 13:55:05.728335      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:06.728989      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:55:07.115: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4232" for this suite. @ 06/15/24 13:55:07.119
• [2.054 seconds]
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 06/15/24 13:55:07.125
  Jun 15 13:55:07.125: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename projected @ 06/15/24 13:55:07.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:55:07.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:55:07.144
  STEP: Creating a pod to test downward API volume plugin @ 06/15/24 13:55:07.146
  E0615 13:55:07.730080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:08.730360      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:09.730498      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:10.730648      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 06/15/24 13:55:11.169
  Jun 15 13:55:11.173: INFO: Trying to get logs from node ip-172-31-43-132 pod downwardapi-volume-e6525638-e988-4b1e-a070-141467320fd9 container client-container: <nil>
  STEP: delete the pod @ 06/15/24 13:55:11.179
  Jun 15 13:55:11.191: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2756" for this suite. @ 06/15/24 13:55:11.195
• [4.077 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:784
  STEP: Creating a kubernetes client @ 06/15/24 13:55:11.202
  Jun 15 13:55:11.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename job @ 06/15/24 13:55:11.203
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:55:11.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:55:11.221
  STEP: Creating a job @ 06/15/24 13:55:11.224
  STEP: Ensure pods equal to parallelism count is attached to the job @ 06/15/24 13:55:11.23
  E0615 13:55:11.730797      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:12.730866      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 06/15/24 13:55:13.234
  STEP: updating /status @ 06/15/24 13:55:13.241
  STEP: get /status @ 06/15/24 13:55:13.248
  Jun 15 13:55:13.252: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1176" for this suite. @ 06/15/24 13:55:13.258
• [2.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:234
  STEP: Creating a kubernetes client @ 06/15/24 13:55:13.265
  Jun 15 13:55:13.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename resourcequota @ 06/15/24 13:55:13.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:55:13.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:55:13.285
  STEP: Counting existing ResourceQuota @ 06/15/24 13:55:13.288
  E0615 13:55:13.731801      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:14.731908      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:15.731980      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:16.733005      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:17.734030      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 06/15/24 13:55:18.292
  STEP: Ensuring resource quota status is calculated @ 06/15/24 13:55:18.296
  E0615 13:55:18.734139      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:19.734380      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 06/15/24 13:55:20.301
  STEP: Ensuring ResourceQuota status captures the pod usage @ 06/15/24 13:55:20.315
  E0615 13:55:20.735001      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:21.735085      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 06/15/24 13:55:22.319
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 06/15/24 13:55:22.321
  STEP: Ensuring a pod cannot update its resource requirements @ 06/15/24 13:55:22.324
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 06/15/24 13:55:22.329
  E0615 13:55:22.735265      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:23.735364      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 06/15/24 13:55:24.334
  STEP: Ensuring resource quota status released the pod usage @ 06/15/24 13:55:24.346
  E0615 13:55:24.735963      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:25.736061      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:55:26.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4814" for this suite. @ 06/15/24 13:55:26.354
• [13.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 06/15/24 13:55:26.363
  Jun 15 13:55:26.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename emptydir-wrapper @ 06/15/24 13:55:26.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:55:26.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:55:26.382
  STEP: Creating 50 configmaps @ 06/15/24 13:55:26.384
  STEP: Creating RC which spawns configmap-volume pods @ 06/15/24 13:55:26.618
  Jun 15 13:55:26.733: INFO: Pod name wrapped-volume-race-4a2f3fd9-d5ce-4204-9543-ed0f5b392829: Found 3 pods out of 5
  E0615 13:55:26.736535      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:27.736696      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:28.736782      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:29.736875      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:30.737080      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:31.737443      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:55:31.741: INFO: Pod name wrapped-volume-race-4a2f3fd9-d5ce-4204-9543-ed0f5b392829: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 06/15/24 13:55:31.741
  STEP: Creating RC which spawns configmap-volume pods @ 06/15/24 13:55:31.77
  Jun 15 13:55:31.784: INFO: Pod name wrapped-volume-race-b6667c81-225b-4b21-9435-1d09e9612736: Found 0 pods out of 5
  E0615 13:55:32.737583      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:33.737649      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:34.737814      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:35.737901      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:36.738148      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:55:36.792: INFO: Pod name wrapped-volume-race-b6667c81-225b-4b21-9435-1d09e9612736: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 06/15/24 13:55:36.792
  STEP: Creating RC which spawns configmap-volume pods @ 06/15/24 13:55:36.812
  Jun 15 13:55:36.824: INFO: Pod name wrapped-volume-race-5bce2069-c044-440e-b833-65f52cda2394: Found 0 pods out of 5
  E0615 13:55:37.738577      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:38.738642      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:39.738833      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:40.739018      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:41.739293      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:55:41.833: INFO: Pod name wrapped-volume-race-5bce2069-c044-440e-b833-65f52cda2394: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 06/15/24 13:55:41.833
  STEP: deleting ReplicationController wrapped-volume-race-5bce2069-c044-440e-b833-65f52cda2394 in namespace emptydir-wrapper-9613, will wait for the garbage collector to delete the pods @ 06/15/24 13:55:41.85
  Jun 15 13:55:41.911: INFO: Deleting ReplicationController wrapped-volume-race-5bce2069-c044-440e-b833-65f52cda2394 took: 7.80568ms
  Jun 15 13:55:42.012: INFO: Terminating ReplicationController wrapped-volume-race-5bce2069-c044-440e-b833-65f52cda2394 pods took: 100.54214ms
  E0615 13:55:42.739439      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-b6667c81-225b-4b21-9435-1d09e9612736 in namespace emptydir-wrapper-9613, will wait for the garbage collector to delete the pods @ 06/15/24 13:55:43.512
  Jun 15 13:55:43.574: INFO: Deleting ReplicationController wrapped-volume-race-b6667c81-225b-4b21-9435-1d09e9612736 took: 7.813936ms
  Jun 15 13:55:43.674: INFO: Terminating ReplicationController wrapped-volume-race-b6667c81-225b-4b21-9435-1d09e9612736 pods took: 100.154603ms
  E0615 13:55:43.740474      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:44.741084      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-4a2f3fd9-d5ce-4204-9543-ed0f5b392829 in namespace emptydir-wrapper-9613, will wait for the garbage collector to delete the pods @ 06/15/24 13:55:45.374
  Jun 15 13:55:45.439: INFO: Deleting ReplicationController wrapped-volume-race-4a2f3fd9-d5ce-4204-9543-ed0f5b392829 took: 9.836324ms
  Jun 15 13:55:45.539: INFO: Terminating ReplicationController wrapped-volume-race-4a2f3fd9-d5ce-4204-9543-ed0f5b392829 pods took: 100.740892ms
  E0615 13:55:45.741403      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 06/15/24 13:55:46.74
  E0615 13:55:46.741674      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:55:47.023: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-9613" for this suite. @ 06/15/24 13:55:47.027
• [20.670 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 06/15/24 13:55:47.033
  Jun 15 13:55:47.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2624435875
  STEP: Building a namespace api object, basename webhook @ 06/15/24 13:55:47.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 06/15/24 13:55:47.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 06/15/24 13:55:47.055
  STEP: Setting up server cert @ 06/15/24 13:55:47.08
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 06/15/24 13:55:47.296
  STEP: Deploying the webhook pod @ 06/15/24 13:55:47.304
  STEP: Wait for the deployment to be ready @ 06/15/24 13:55:47.317
  Jun 15 13:55:47.329: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0615 13:55:47.742149      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0615 13:55:48.742547      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 06/15/24 13:55:49.341
  STEP: Verifying the service has paired with the endpoint @ 06/15/24 13:55:49.35
  E0615 13:55:49.743468      19 retrywatcher.go:129] "Watch failed" err="context canceled"
  Jun 15 13:55:50.350: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 06/15/24 13:55:50.36
  STEP: create a configmap that should be updated by the webhook @ 06/15/24 13:55:50.374
  Jun 15 13:55:50.427: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3052" for this suite. @ 06/15/24 13:55:50.433
  STEP: Destroying namespace "webhook-markers-171" for this suite. @ 06/15/24 13:55:50.438
• [3.410 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:88
  Jun 15 13:55:50.445: INFO: Running AfterSuite actions on node 1
  Jun 15 13:55:50.445: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:161
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:621
[ReportAfterSuite] PASSED [0.030 seconds]
------------------------------

Ran 388 of 7408 Specs in 6593.385 seconds
SUCCESS! -- 388 Passed | 0 Failed | 0 Pending | 7020 Skipped
PASS

Ginkgo ran 1 suite in 1h49m54.385504074s
Test Suite Passed
